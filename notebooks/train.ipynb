{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "74c304b6-871e-4f8b-8e50-4cbf1ab46c70",
            "metadata": {},
            "source": [
                "\n",
                "## import"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "9589260c-50a2-4050-b385-4aa9acb9eaac",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import shutil\n",
                "\n",
                "import numpy as np\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "import torch.optim as optim\n",
                "import torchvision\n",
                "from datasets_prep.dataset import create_dataset\n",
                "from diffusion import sample_from_model, sample_posterior, \\\n",
                "    q_sample_pairs, get_time_schedule, \\\n",
                "    Posterior_Coefficients, Diffusion_Coefficients\n",
                "#from DWT_IDWT.DWT_IDWT_layer import DWT_2D, IDWT_2D\n",
                "#from pytorch_wavelets import DWTForward, DWTInverse\n",
                "from torch.multiprocessing import Process\n",
                "from utils import init_processes, copy_source, broadcast_params\n",
                "import yaml\n",
                "\n",
                "from ldm.util import instantiate_from_config\n",
                "from omegaconf import OmegaConf\n",
                "import wandb"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d98a87a4-3315-430c-8db0-69dcbb9b297b",
            "metadata": {},
            "source": [
                "## utils"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "0f6ef80e-c53e-4687-ab90-c0422a49da84",
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_model_from_config(config_path, ckpt):\n",
                "    print(f\"Loading model from {ckpt}\")\n",
                "    config = OmegaConf.load(config_path)\n",
                "    pl_sd = torch.load(ckpt, map_location=\"cpu\")\n",
                "    #global_step = pl_sd[\"global_step\"]\n",
                "    sd = pl_sd[\"state_dict\"]\n",
                "    model = instantiate_from_config(config.model)\n",
                "    m, u = model.load_state_dict(sd, strict=False)\n",
                "    model = model.first_stage_model\n",
                "    model.cuda()\n",
                "    model.eval()\n",
                "    del m\n",
                "    del u\n",
                "    del pl_sd\n",
                "    return model\n",
                "\n",
                "def grad_penalty_call(args, D_real, x_t):\n",
                "    grad_real = torch.autograd.grad(\n",
                "        outputs=D_real.sum(), inputs=x_t, create_graph=True\n",
                "    )[0]\n",
                "    grad_penalty = (\n",
                "        grad_real.view(grad_real.size(0), -1).norm(2, dim=1) ** 2\n",
                "    ).mean()\n",
                "\n",
                "    grad_penalty = args.r1_gamma / 2 * grad_penalty\n",
                "    grad_penalty.backward()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d891bc25-8b42-4d7e-ab93-be83c4585ff0",
            "metadata": {},
            "source": [
                "## config"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "2c25d872-bb86-4525-ba72-30951f955396",
            "metadata": {},
            "outputs": [],
            "source": [
                "from get_args import get_args\n",
                "args = [\n",
                "    \"--dataset\", \"afhq_cat\", \"--image_size\", \"256\",\n",
                "    \"--exp\", \"test\", \"--num_channels\", \"4\",\n",
                "    \"--num_channels_dae\", \"128\", \"--ch_mult\", \"1\", \"2\", \"2\", \"2\", \n",
                "    \"--num_timesteps\", \"2\", \"--num_res_blocks\", \"2\", \n",
                "    \"--batch_size\", \"32\", \"--num_epoch\", \"200\", \n",
                "    \"--ngf\", \"64\", \"--embedding_type\", \"positional\", \n",
                "    \"--use_ema\", \"--ema_decay\", \"0.999\",\n",
                "    \"--r1_gamma\", \"2.\", \"--nz\", \"100\",\n",
                "    \"--z_emb_dim\", \"256\", \"--lr_d\", \"1.0e-4\",\n",
                "    \"--lr_g\", \"2e-4\", \"--lazy_reg\", \"10\",\n",
                "    \"--save_content\", \"--datadir\", \"data/afhq\", \n",
                "    \"--master_port\", \"6084\", \"--num_process_per_node\", \"0\",\n",
                "    \"--current_resolution\", \"128\", \"--attn_resolution\", \"16\",\n",
                "    \"--num_disc_layers\", \"4\", \"--rec_loss\", \n",
                "    \"--save_content_every\", \"1\", \"--AutoEncoder_config\", \"./autoencoder/config/kl-f2.yaml\", \n",
                "    \"--AutoEncoder_ckpt\", \"./autoencoder/weight/kl-f2.ckpt\", \"--scale_factor\", \"6.0\", \n",
                "    \"--no_lr_decay\", \"--sigmoid_learning\"\n",
                "]\n",
                "\n",
                "args = get_args(args)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "6c8edb41-4a8d-4f0c-9335-46512f6ff5fe",
            "metadata": {},
            "outputs": [],
            "source": [
                "from get_args import get_args\n",
                "args = [\n",
                "    \"--dataset\", \"cifar10\", \"--image_size\", \"32\",\n",
                "    \"--exp\", \"test\", \"--num_channels\", \"4\",\n",
                "    \"--num_channels_dae\", \"128\", \"--ch_mult\", \"1\", \"2\", \"2\", \"2\", \n",
                "    \"--num_timesteps\", \"2\", \"--num_res_blocks\", \"2\", \n",
                "    \"--batch_size\", \"32\", \"--num_epoch\", \"200\", \n",
                "    \"--ngf\", \"64\", \"--embedding_type\", \"positional\", \n",
                "    \"--use_ema\", \"--ema_decay\", \"0.999\",\n",
                "    \"--r1_gamma\", \"2.\", \"--nz\", \"100\",\n",
                "    \"--z_emb_dim\", \"256\", \"--lr_d\", \"1.0e-4\",\n",
                "    \"--lr_g\", \"2e-4\", \"--lazy_reg\", \"10\",\n",
                "    \"--save_content\", \"--datadir\", \"data/cifar-10\", \n",
                "    \"--master_port\", \"6084\", \"--num_process_per_node\", \"0\",\n",
                "    \"--current_resolution\", \"16\", \"--attn_resolution\", \"16\",\n",
                "    \"--num_disc_layers\", \"4\", \"--rec_loss\", \n",
                "    \"--save_content_every\", \"1\", \"--AutoEncoder_config\", \"./autoencoder/config/kl-f2.yaml\", \n",
                "    \"--AutoEncoder_ckpt\", \"./autoencoder/weight/kl-f2.ckpt\", \"--scale_factor\", \"6.0\", \n",
                "    \"--no_lr_decay\", \"--sigmoid_learning\"\n",
                "]\n",
                "\n",
                "args = get_args(args)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b1a3b19e-5201-406c-8b46-e7bdc4887b7d",
            "metadata": {},
            "source": [
                "## wandb setting\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "66391d0e-24a1-4371-b5f8-06632cc40445",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "Finishing last run (ID:38ozll6x) before initializing another..."
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "VBox(children=(Label(value='0.014 MB of 0.022 MB uploaded\\r'), FloatProgress(value=0.6176345186322163, max=1.0…"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<style>\n",
                            "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
                            "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
                            "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
                            "    </style>\n",
                            "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>D_loss_per_iter</td><td>█▁▁▁</td></tr><tr><td>G_loss_per_100iter</td><td>▄▇█▁</td></tr><tr><td>time_per_100iter</td><td>▁███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>D_loss_per_iter</td><td>0.00564</td></tr><tr><td>G_loss_per_100iter</td><td>5.8771</td></tr><tr><td>time_per_100iter</td><td>7.98588</td></tr></table><br/></div></div>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            " View run <strong style=\"color:#cdcd00\">hearty-totem-18</strong> at: <a href='https://wandb.ai/kotomiya07/TEST/runs/38ozll6x' target=\"_blank\">https://wandb.ai/kotomiya07/TEST/runs/38ozll6x</a><br/> View project at: <a href='https://wandb.ai/kotomiya07/TEST' target=\"_blank\">https://wandb.ai/kotomiya07/TEST</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Find logs at: <code>./wandb/run-20240904_152817-38ozll6x/logs</code>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Successfully finished last run (ID:38ozll6x). Initializing new run:<br/>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "e246145c418c4764bad3e2f237d0414b",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112120752740238, max=1.0…"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Tracking run with wandb version 0.17.8"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Run data is saved locally in <code>/scratch/users/std/2021/21k0005/improved-ddgan/wandb/run-20240904_152904-irpdtnxj</code>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Syncing run <strong><a href='https://wandb.ai/kotomiya07/TEST/runs/irpdtnxj' target=\"_blank\">fancy-feather-19</a></strong> to <a href='https://wandb.ai/kotomiya07/TEST' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            " View project at <a href='https://wandb.ai/kotomiya07/TEST' target=\"_blank\">https://wandb.ai/kotomiya07/TEST</a>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            " View run at <a href='https://wandb.ai/kotomiya07/TEST/runs/irpdtnxj' target=\"_blank\">https://wandb.ai/kotomiya07/TEST/runs/irpdtnxj</a>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/kotomiya07/TEST/runs/irpdtnxj?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
                        ],
                        "text/plain": [
                            "<wandb.sdk.wandb_run.Run at 0x7f8ec4e3c910>"
                        ]
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "wandb.init(\n",
                "            project=\"TEST\",\n",
                "            config={\n",
                "                \"dataset\": args.dataset,\n",
                "                \"image_size\": args.image_size,\n",
                "                \"channels\": args.num_channels,\n",
                "                \"timesteps\": args.num_timesteps,\n",
                "                \"nz\": args.nz,\n",
                "                \"epochs\": args.num_epoch,\n",
                "                \"ngf\": args.ngf,\n",
                "                \"lr_g\": args.lr_g,\n",
                "                \"lr_d\": args.lr_d,\n",
                "                \"batch_size\": args.batch_size,\n",
                "                \"r1_gamma\": args.r1_gamma,\n",
                "                \"lazy_reg\": args.lazy_reg,\n",
                "                \"use_ema\": args.use_ema,\n",
                "                \"ema_decay\": args.ema_decay,\n",
                "                \"no_lr_decay\": args.no_lr_decay,\n",
                "                \"use_pytorch_wavelet\": args.use_pytorch_wavelet,\n",
                "                \"rec_loss\": args.rec_loss,\n",
                "                \"net_type\": args.net_type,\n",
                "                \"num_disc_layers\": args.num_disc_layers,\n",
                "                \"no_use_fbn\": args.no_use_fbn,\n",
                "                \"no_use_freq\": args.no_use_freq,\n",
                "                \"no_use_residual\": args.no_use_residual,\n",
                "                \"scale_factor\": args.scale_factor,\n",
                "                \"AutoEncoder_config\": args.AutoEncoder_config,\n",
                "                \"AutoEncoder_ckpt\": args.AutoEncoder_ckpt,\n",
                "                \"sigmoid_learning\": args.sigmoid_learning,\n",
                "            }\n",
                "        )"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "36a6c9d4-8d3f-4fef-aa53-8248caebf840",
            "metadata": {},
            "source": [
                "## train\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "5ce020e4-4a06-4f99-b867-125d37ee0539",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Files already downloaded and verified\n",
                        "GEN: <class 'score_sde.models.ncsnpp_generator_adagn.NCSNpp'>, DISC: [<class 'score_sde.models.discriminator.Discriminator_small'>, <class 'score_sde.models.discriminator.Discriminator_large'>]\n",
                        "making attention of type 'vanilla' with 256 in_channels\n",
                        "making attention of type 'vanilla' with 256 in_channels\n",
                        "making attention of type 'vanilla' with 256 in_channels\n",
                        "Working with z of shape (1, 4, 16, 16) = 1024 dimensions.\n",
                        "making attention of type 'vanilla' with 256 in_channels\n",
                        "making attention of type 'vanilla' with 256 in_channels\n",
                        "making attention of type 'vanilla' with 256 in_channels\n",
                        "making attention of type 'vanilla' with 256 in_channels\n",
                        "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
                        "=> loaded checkpoint (epoch 2)\n"
                    ]
                }
            ],
            "source": [
                "rank = gpu = 0\n",
                "from EMA import EMA\n",
                "from score_sde.models.discriminator import Discriminator_large, Discriminator_small\n",
                "from score_sde.models.ncsnpp_generator_adagn import NCSNpp, WaveletNCSNpp\n",
                "\n",
                "torch.manual_seed(args.seed + rank)\n",
                "torch.cuda.manual_seed(args.seed + rank)\n",
                "torch.cuda.manual_seed_all(args.seed + rank)\n",
                "device = torch.device('cuda:{}'.format(gpu))\n",
                "\n",
                "batch_size = args.batch_size\n",
                "\n",
                "nz = args.nz  # latent dimension\n",
                "\n",
                "dataset = create_dataset(args)\n",
                "#train_sampler = torch.utils.data.distributed.DistributedSampler(dataset,\n",
                "#                                                                num_replicas=args.world_size,\n",
                "#                                                                rank=rank)\n",
                "data_loader = torch.utils.data.DataLoader(dataset,\n",
                "                                            batch_size=batch_size,\n",
                "                                            shuffle=False,\n",
                "                                            num_workers=args.num_workers,\n",
                "                                            pin_memory=True,\n",
                "                                            drop_last=True)\n",
                "args.ori_image_size = args.image_size\n",
                "args.image_size = args.current_resolution\n",
                "G_NET_ZOO = {\"normal\": NCSNpp, \"wavelet\": WaveletNCSNpp}\n",
                "gen_net = G_NET_ZOO[args.net_type]\n",
                "disc_net = [Discriminator_small, Discriminator_large]\n",
                "print(\"GEN: {}, DISC: {}\".format(gen_net, disc_net))\n",
                "netG = gen_net(args).to(device)\n",
                "\n",
                "if args.dataset in ['cifar10', 'stl10', 'afhq_cat']:\n",
                "    netD = disc_net[0](nc=2 * args.num_channels, ngf=args.ngf,\n",
                "                        t_emb_dim=args.t_emb_dim,\n",
                "                        act=nn.LeakyReLU(0.2), num_layers=args.num_disc_layers).to(device)\n",
                "else:\n",
                "    netD = disc_net[1](nc=2 * args.num_channels, ngf=args.ngf,\n",
                "                        t_emb_dim=args.t_emb_dim,\n",
                "                        act=nn.LeakyReLU(0.2), num_layers=args.num_disc_layers).to(device)\n",
                "\n",
                "#broadcast_params(netG.parameters())\n",
                "#broadcast_params(netD.parameters())\n",
                "\n",
                "optimizerD = optim.Adam(filter(lambda p: p.requires_grad, netD.parameters(\n",
                ")), lr=args.lr_d, betas=(args.beta1, args.beta2))\n",
                "optimizerG = optim.Adam(filter(lambda p: p.requires_grad, netG.parameters(\n",
                ")), lr=args.lr_g, betas=(args.beta1, args.beta2))\n",
                "\n",
                "if args.use_ema:\n",
                "    optimizerG = EMA(optimizerG, ema_decay=args.ema_decay)\n",
                "\n",
                "schedulerG = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
                "    optimizerG, args.num_epoch, eta_min=1e-5)\n",
                "schedulerD = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
                "    optimizerD, args.num_epoch, eta_min=1e-5)\n",
                "\n",
                "# ddp\n",
                "#netG = nn.parallel.DistributedDataParallel(\n",
                "#    netG, device_ids=[gpu])\n",
                "#netD = nn.parallel.DistributedDataParallel(netD, device_ids=[gpu])\n",
                "\n",
                "\"\"\"############### DELETE TO AVOID ERROR ###############\"\"\"\n",
                "# Wavelet Pooling\n",
                "#if not args.use_pytorch_wavelet:\n",
                "#    dwt = DWT_2D(\"haar\")\n",
                "#    iwt = IDWT_2D(\"haar\")\n",
                "#else:\n",
                "#    dwt = DWTForward(J=1, mode='zero', wave='haar').cuda()\n",
                "#    iwt = DWTInverse(mode='zero', wave='haar').cuda()\n",
                "    \n",
                "\n",
                "#load encoder and decoder\n",
                "config_path = args.AutoEncoder_config \n",
                "ckpt_path = args.AutoEncoder_ckpt \n",
                "\n",
                "if args.dataset in ['cifar10', 'stl10', 'coco', 'afhq_cat']:\n",
                "    with open(config_path, 'r') as file:\n",
                "        config = yaml.safe_load(file)\n",
                "    \n",
                "    AutoEncoder = instantiate_from_config(config['model'])\n",
                "    \n",
                "\n",
                "    checkpoint = torch.load(ckpt_path, map_location=device)\n",
                "    AutoEncoder.load_state_dict(checkpoint['state_dict'])\n",
                "    AutoEncoder.eval()\n",
                "    AutoEncoder.to(device)\n",
                "\n",
                "else:\n",
                "    AutoEncoder = load_model_from_config(config_path, ckpt_path)\n",
                "\"\"\"############### END DELETING ###############\"\"\"\n",
                "\n",
                "num_levels = int(np.log2(args.ori_image_size // args.current_resolution))\n",
                "\n",
                "exp = args.exp\n",
                "parent_dir = \"./saved_info/{}\".format(args.dataset)\n",
                "\n",
                "exp_path = os.path.join(parent_dir, exp)\n",
                "if rank == 0:\n",
                "    if not os.path.exists(exp_path):\n",
                "        os.makedirs(exp_path)\n",
                "        copy_source(__file__, exp_path)\n",
                "        shutil.copytree('score_sde/models', os.path.join(exp_path, 'score_sde/models'))\n",
                "\n",
                "coeff = Diffusion_Coefficients(args, device)\n",
                "pos_coeff = Posterior_Coefficients(args, device)\n",
                "T = get_time_schedule(args, device)\n",
                "\n",
                "if args.resume or os.path.exists(os.path.join(exp_path, 'content.pth')):\n",
                "    checkpoint_file = os.path.join(exp_path, 'content.pth')\n",
                "    checkpoint = torch.load(checkpoint_file, map_location=device)\n",
                "    init_epoch = checkpoint['epoch']\n",
                "    epoch = init_epoch\n",
                "    # load G\n",
                "    netG.load_state_dict(checkpoint['netG_dict'])\n",
                "    #optimizerG.load_state_dict(checkpoint['optimizerG'])\n",
                "    schedulerG.load_state_dict(checkpoint['schedulerG'])\n",
                "    # load D\n",
                "    netD.load_state_dict(checkpoint['netD_dict'])\n",
                "    #optimizerD.load_state_dict(checkpoint['optimizerD'])\n",
                "    schedulerD.load_state_dict(checkpoint['schedulerD'])\n",
                "\n",
                "    global_step = checkpoint['global_step']\n",
                "    print(\"=> loaded checkpoint (epoch {})\"\n",
                "            .format(checkpoint['epoch']))\n",
                "else:\n",
                "    global_step, epoch, init_epoch = 0, 0, 0\n",
                "\n",
                "'''Sigmoid learning parameter'''\n",
                "gamma = 6\n",
                "beta = np.linspace(-gamma, gamma, args.num_epoch+1)\n",
                "alpha = 1 - 1 / (1+np.exp(-beta))\n",
                "\n",
                "if args.dataset in ['cifar10'] and args.class_conditional:\n",
                "    class_embedding = nn.Embedding(10, nz).to(device)\n",
                "\n",
                "nrow = 2\n",
                "if args.batch_size >= 5:\n",
                "    nrow = 3\n",
                "if args.batch_size >= 10:\n",
                "    nrow = 10"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "34310442-04bd-4cbf-a5d4-106360bcea74",
            "metadata": {},
            "source": [
                "## train loop"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "e473230c-006d-4f7d-9205-8a43e9eed543",
            "metadata": {
                "scrolled": true
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/scratch/users/std/2021/21k0005/improved-ddgan/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
                        "  warnings.warn(_create_warning_msg(\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 2, Iteration: 0\n",
                        "OUTTTT\n",
                        "epoch 2 iteration0, G Loss: 7.687418460845947, D Loss: 0.08819055557250977, alpha: 0.9972130037809577\n",
                        "Epoch: 2, Iteration: 10\n",
                        "Epoch: 2, Iteration: 20\n",
                        "Epoch: 2, Iteration: 30\n",
                        "Epoch: 2, Iteration: 40\n",
                        "Epoch: 2, Iteration: 50\n",
                        "OUTTTT\n",
                        "Epoch: 2, Iteration: 60\n",
                        "Epoch: 2, Iteration: 70\n",
                        "Epoch: 2, Iteration: 80\n",
                        "Epoch: 2, Iteration: 90\n",
                        "Epoch: 2, Iteration: 100\n",
                        "OUTTTT\n",
                        "epoch 2 iteration100, G Loss: 9.737632751464844, D Loss: 0.0017735939472913742, alpha: 0.9972130037809577\n",
                        "Epoch: 2, Iteration: 110\n",
                        "Epoch: 2, Iteration: 120\n",
                        "Epoch: 2, Iteration: 130\n",
                        "Epoch: 2, Iteration: 140\n",
                        "Epoch: 2, Iteration: 150\n",
                        "OUTTTT\n",
                        "Epoch: 2, Iteration: 160\n",
                        "Epoch: 2, Iteration: 170\n",
                        "Epoch: 2, Iteration: 180\n",
                        "Epoch: 2, Iteration: 190\n",
                        "Epoch: 2, Iteration: 200\n",
                        "OUTTTT\n",
                        "epoch 2 iteration200, G Loss: 10.644046783447266, D Loss: 0.0027751740999519825, alpha: 0.9972130037809577\n",
                        "Epoch: 2, Iteration: 210\n",
                        "Epoch: 2, Iteration: 220\n",
                        "Epoch: 2, Iteration: 230\n",
                        "Epoch: 2, Iteration: 240\n",
                        "Epoch: 2, Iteration: 250\n",
                        "OUTTTT\n",
                        "Epoch: 2, Iteration: 260\n",
                        "Epoch: 2, Iteration: 270\n",
                        "Epoch: 2, Iteration: 280\n",
                        "Epoch: 2, Iteration: 290\n",
                        "Epoch: 2, Iteration: 300\n",
                        "OUTTTT\n",
                        "epoch 2 iteration300, G Loss: 5.877096652984619, D Loss: 0.00564388744533062, alpha: 0.9972130037809577\n",
                        "Epoch: 2, Iteration: 310\n"
                    ]
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[7], line 130\u001b[0m\n\u001b[1;32m    126\u001b[0m     errG \u001b[38;5;241m=\u001b[39m errG \u001b[38;5;241m+\u001b[39m rec_loss\n\u001b[1;32m    129\u001b[0m errG\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m--> 130\u001b[0m \u001b[43moptimizerG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m global_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m iteration \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
                        "File \u001b[0;32m/scratch/users/std/2021/21k0005/improved-ddgan/.venv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:75\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     74\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m/scratch/users/std/2021/21k0005/improved-ddgan/EMA.py:50\u001b[0m, in \u001b[0;36mEMA.step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m         params[p\u001b[38;5;241m.\u001b[39mshape] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124midx\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m: []}\n\u001b[1;32m     48\u001b[0m         ema[p\u001b[38;5;241m.\u001b[39mshape] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 50\u001b[0m     \u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     ema[p\u001b[38;5;241m.\u001b[39mshape]\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mema\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m params:\n",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "for epoch in range(init_epoch, args.num_epoch + 1):\n",
                "    #train_sampler.set_epoch(epoch)\n",
                "    \n",
                "    start = torch.cuda.Event(enable_timing=True)\n",
                "    end = torch.cuda.Event(enable_timing=True)\n",
                "    start.record()\n",
                "\n",
                "    start_epoch = torch.cuda.Event(enable_timing=True)\n",
                "    end_epoch = torch.cuda.Event(enable_timing=True)\n",
                "    start_epoch.record()\n",
                "    for iteration, (x, y) in enumerate(data_loader):\n",
                "        for p in netD.parameters():\n",
                "            p.requires_grad = True\n",
                "        netD.zero_grad()\n",
                "\n",
                "        for p in netG.parameters():\n",
                "            p.requires_grad = False\n",
                "\n",
                "        # sample from p(x_0)\n",
                "        x0 = x.to(device, non_blocking=True)\n",
                "\n",
                "        \"\"\"################# Change here: Encoder #################\"\"\"\n",
                "        with torch.no_grad():\n",
                "            posterior = AutoEncoder.encode(x0)\n",
                "            real_data = posterior.sample().detach()\n",
                "        #print(\"MIN:{}, MAX:{}\".format(real_data.min(), real_data.max()))\n",
                "        real_data = real_data / args.scale_factor #300.0  # [-1, 1]\n",
                "        \n",
                "        \n",
                "        #assert -1 <= real_data.min() < 0\n",
                "        #assert 0 < real_data.max() <= 1\n",
                "        \"\"\"################# End change: Encoder #################\"\"\"\n",
                "        # sample t\n",
                "        t = torch.randint(0, args.num_timesteps,\n",
                "                          (real_data.size(0),), device=device)\n",
                "        \n",
                "        if args.dataset in ['cifar10'] and args.class_conditional:\n",
                "            y = y.to(device)\n",
                "            y_emb = class_embedding(y)\n",
                "\n",
                "        x_t, x_tp1 = q_sample_pairs(coeff, real_data, t)\n",
                "        x_t.requires_grad = True\n",
                "\n",
                "        \"\"\"################# Save Sample #################\"\"\"\n",
                "        if iteration % 10 == 0:\n",
                "            print(f\"Epoch: {epoch}, Iteration: {iteration}\")\n",
                "        if iteration % 50 == 0:\n",
                "            x_t_1 = torch.randn_like(posterior.sample())\n",
                "            if args.dataset in ['cifar10'] and args.class_conditional:\n",
                "                y = torch.arange(0, 10).repeat(x_t_1.size(0)//10 + 1)[:x_t_1.size(0)].to(device)\n",
                "                y_emb = class_embedding(y)\n",
                "                fake_sample = sample_from_model(\n",
                "                    pos_coeff, netG, args.num_timesteps, x_t_1, T, args, class_emb=y_emb)\n",
                "            else:\n",
                "                fake_sample = sample_from_model(\n",
                "                    pos_coeff, netG, args.num_timesteps, x_t_1, T, args)\n",
                "            fake_sample *= args.scale_factor #300\n",
                "            with torch.no_grad():\n",
                "                fake_sample = AutoEncoder.decode(fake_sample)\n",
                "\n",
                "            #rec_data = (torch.clamp(rec_data, -1, 1) + 1) / 2\n",
                "            fake_sample = (torch.clamp(fake_sample, -1, 1) + 1) / 2  # 0-1\n",
                "            torchvision.utils.save_image(fake_sample, os.path.join(\n",
                "                exp_path, 'sample_discrete_epoch_{}.png'.format(epoch)), nrow=nrow)\n",
                "\n",
                "\n",
                "        # train with real\n",
                "        D_real = netD(x_t, t, x_tp1.detach()).view(-1)\n",
                "        errD_real = F.softplus(-D_real).mean()\n",
                "\n",
                "        errD_real.backward(retain_graph=True)\n",
                "\n",
                "        if args.lazy_reg is None:\n",
                "            grad_penalty_call(args, D_real, x_t)\n",
                "        else:\n",
                "            if global_step % args.lazy_reg == 0:\n",
                "                grad_penalty_call(args, D_real, x_t)\n",
                "\n",
                "        # train with fake\n",
                "        latent_z = torch.randn(batch_size, nz, device=device)\n",
                "        if args.dataset in ['cifar10'] and args.class_conditional:\n",
                "            x_0_predict = netG(x_tp1.detach(), t, torch.cat([latent_z, y_emb], dim=1).detach())\n",
                "        else:\n",
                "            x_0_predict = netG(x_tp1.detach(), t, latent_z)\n",
                "        x_pos_sample = sample_posterior(pos_coeff, x_0_predict, x_tp1, t)\n",
                "\n",
                "        output = netD(x_pos_sample, t, x_tp1.detach()).view(-1)\n",
                "        errD_fake = F.softplus(output).mean()\n",
                "\n",
                "        errD_fake.backward()\n",
                "\n",
                "        errD = errD_real + errD_fake\n",
                "        # Update D\n",
                "        optimizerD.step()\n",
                "\n",
                "        # update G\n",
                "        for p in netD.parameters():\n",
                "            p.requires_grad = False\n",
                "\n",
                "        for p in netG.parameters():\n",
                "            p.requires_grad = True\n",
                "        netG.zero_grad()\n",
                "\n",
                "        t = torch.randint(0, args.num_timesteps,\n",
                "                          (real_data.size(0),), device=device)\n",
                "        x_t, x_tp1 = q_sample_pairs(coeff, real_data, t)\n",
                "\n",
                "        latent_z = torch.randn(batch_size, nz, device=device)\n",
                "        if args.dataset in ['cifar10'] and args.class_conditional:\n",
                "            x_0_predict = netG(x_tp1.detach(), t, torch.cat([latent_z, y_emb], dim=1).detach())\n",
                "        else:\n",
                "            x_0_predict = netG(x_tp1.detach(), t, latent_z)\n",
                "        x_pos_sample = sample_posterior(pos_coeff, x_0_predict, x_tp1, t)\n",
                "\n",
                "        output = netD(x_pos_sample, t, x_tp1.detach()).view(-1)\n",
                "        errG = F.softplus(-output).mean()\n",
                "\n",
                "        # reconstructior loss\n",
                "        if args.sigmoid_learning and args.rec_loss:\n",
                "            ######alpha\n",
                "            rec_loss = F.l1_loss(x_0_predict, real_data)\n",
                "            errG = errG + alpha[epoch]*rec_loss\n",
                "\n",
                "        elif args.rec_loss and not args.sigmoid_learning:\n",
                "            rec_loss = F.l1_loss(x_0_predict, real_data)\n",
                "            errG = errG + rec_loss\n",
                "        \n",
                "\n",
                "        errG.backward()\n",
                "        optimizerG.step()\n",
                "\n",
                "        global_step += 1\n",
                "        if iteration % 100 == 0:\n",
                "            if rank == 0:\n",
                "                end.record()\n",
                "                torch.cuda.synchronize()\n",
                "                elapsed_time = start.elapsed_time(end)\n",
                "                if args.sigmoid_learning:\n",
                "                    print('epoch {} iteration{}, G Loss: {}, D Loss: {}, alpha: {}'.format(\n",
                "                        epoch, iteration, errG.item(), errD.item(), alpha[epoch]))\n",
                "                elif args.rec_loss:\n",
                "                    print('epoch {} iteration{}, G Loss: {}, D Loss: {}, rec_loss: {}'.format(\n",
                "                        epoch, iteration, errG.item(), errD.item(), rec_loss.item()))\n",
                "                else:   \n",
                "                    print('epoch {} iteration{}, G Loss: {}, D Loss: {}'.format(\n",
                "                        epoch, iteration, errG.item(), errD.item()))\n",
                "                wandb.log({\"G_loss_per_100iter\": errG.item(), \"D_loss_per_iter\": errD.item(), \"time_per_100iter\": elapsed_time / 1000})\n",
                "                start = torch.cuda.Event(enable_timing=True)\n",
                "                end = torch.cuda.Event(enable_timing=True)\n",
                "                start.record()\n",
                "\n",
                "    if not args.no_lr_decay:\n",
                "\n",
                "        schedulerG.step()\n",
                "        schedulerD.step()\n",
                "\n",
                "    if rank == 0:\n",
                "        end_epoch.record()\n",
                "        torch.cuda.synchronize()\n",
                "        time_per_epoch = start_epoch.elapsed_time(end_epoch)\n",
                "        wandb.log({\"G_loss\": errG.item(), \"D_loss\": errD.item(), \"alpha\": alpha[epoch], \"time_per_epoch\": time_per_epoch / 1000})\n",
                "        ########################################\n",
                "        x_t_1 = torch.randn_like(posterior.sample())\n",
                "        if args.dataset in ['cifar10'] and args.class_conditional:\n",
                "            y = torch.arange(0, 10).repeat(x_t_1.size(0)//10 + 1)[:x_t_1.size(0)].to(device)\n",
                "            y_emb = class_embedding(y)\n",
                "            fake_sample = sample_from_model(\n",
                "                pos_coeff, netG, args.num_timesteps, x_t_1, T, args, class_emb=y_emb)\n",
                "        else:\n",
                "            fake_sample = sample_from_model(\n",
                "                pos_coeff, netG, args.num_timesteps, x_t_1, T, args)\n",
                "\n",
                "        \"\"\"############## CHANGE HERE: DECODER ##############\"\"\"\n",
                "        fake_sample *= args.scale_factor #300\n",
                "        real_data *= args.scale_factor #300\n",
                "        with torch.no_grad():\n",
                "            fake_sample = AutoEncoder.decode(fake_sample)\n",
                "            real_data = AutoEncoder.decode(real_data)\n",
                "        \n",
                "        fake_sample = (torch.clamp(fake_sample, -1, 1) + 1) / 2  # 0-1\n",
                "        real_data = (torch.clamp(real_data, -1, 1) + 1) / 2  # 0-1 \n",
                "        \n",
                "        \"\"\"############## END HERE: DECODER ##############\"\"\"\n",
                "\n",
                "        torchvision.utils.save_image(fake_sample, os.path.join(\n",
                "            exp_path, 'sample_discrete_epoch_{}.png'.format(epoch)), nrow=nrow)\n",
                "        torchvision.utils.save_image(\n",
                "            real_data, os.path.join(exp_path, 'real_data.png'),nrow=nrow)\n",
                "\n",
                "        if args.save_content:\n",
                "            if epoch % args.save_content_every == 0:\n",
                "                print('Saving content.')\n",
                "                content = {'epoch': epoch + 1, 'global_step': global_step, 'args': args,\n",
                "                           'netG_dict': netG.state_dict(), 'optimizerG': optimizerG.state_dict(),\n",
                "                           'schedulerG': schedulerG.state_dict(), 'netD_dict': netD.state_dict(),\n",
                "                           'optimizerD': optimizerD.state_dict(), 'schedulerD': schedulerD.state_dict()}\n",
                "                torch.save(content, os.path.join(exp_path, 'content.pth'))\n",
                "\n",
                "        if epoch % args.save_ckpt_every == 0:\n",
                "            if args.use_ema:\n",
                "                optimizerG.swap_parameters_with_ema(\n",
                "                    store_params_in_ema=True)\n",
                "\n",
                "            torch.save(netG.state_dict(), os.path.join(\n",
                "                exp_path, 'netG_{}.pth'.format(epoch)))\n",
                "            if args.use_ema:\n",
                "                optimizerG.swap_parameters_with_ema(\n",
                "                    store_params_in_ema=True)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e342c7e2-ae35-44ac-b07f-3f74c297984a",
            "metadata": {},
            "source": [
                "## show image"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "047ed4a8-a919-4dea-ac2a-e4ee3734afd3",
            "metadata": {},
            "outputs": [],
            "source": [
                "from PIL import Image"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "a31f6242-893d-4255-8cd6-f2127946b75f",
            "metadata": {},
            "outputs": [],
            "source": [
                "tmp = iter(data_loader)\n",
                "x, y = next(tmp)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "id": "00c27efc-dd2b-49e6-b27b-987e63e60eae",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(torch.Size([32, 3, 32, 32]),\n",
                            " tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6, 4, 3, 6, 6,\n",
                            "         2, 6, 3, 5, 4, 0, 0, 9]))"
                        ]
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "x.shape, y"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "id": "9bf6a6fa-e845-4250-8112-21536fb156c6",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 640x480 with 1 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "from torchvision import transforms\n",
                "img = transforms.ToPILImage(mode=\"RGB\")(x[0])\n",
                "plt.imshow(img)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "id": "0e3a20f7-9437-4290-bae8-b5cc8f2b9489",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 640x480 with 1 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "real_data = (torch.clamp(x[0], -1, 1) + 1) / 2\n",
                "img = transforms.ToPILImage(mode=\"RGB\")(real_data)\n",
                "plt.imshow(img)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8ba87163-541e-4449-8315-2164e3e3db70",
            "metadata": {},
            "outputs": [],
            "source": [
                "real_data = (torch.clamp(x[3], -1, 1) + 1) / 2  # 0-1 \n",
                "\n",
                "torchvision.utils.save_image(\n",
                "    real_data, os.path.join(\"./\", 'real_data.png'))\n",
                "imgPIL = Image.open(\"./real_data.png\")  # 画像読み込み\n",
                "\n",
                "print(y[3])\n",
                "imgPIL.show()  # 画像表示"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5bc75d17",
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": [
                "from ldm.util import instantiate_from_config\n",
                "config_path = \"./autoencoder/config/kl-f2.yaml\"\n",
                "ckpt_path = \"./autoencoder/weight/kl-f2.ckpt\"\n",
                "with open(config_path, 'r') as file:\n",
                "    config = yaml.safe_load(file)\n",
                "\n",
                "AutoEncoder2 = instantiate_from_config(config['model'])\n",
                "\n",
                "\n",
                "checkpoint = torch.load(ckpt_path, map_location=device)\n",
                "AutoEncoder2.load_state_dict(checkpoint['state_dict'])\n",
                "AutoEncoder2.eval()\n",
                "AutoEncoder2.to(device)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b3ead0d8",
            "metadata": {},
            "outputs": [],
            "source": [
                "torch.cuda.empty_cache()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "42f202ff",
            "metadata": {},
            "outputs": [],
            "source": [
                "x0 = x.to(device)\n",
                "print(x0.shape)\n",
                "with torch.no_grad():\n",
                "    posterior = AutoEncoder.encode(x0)\n",
                "    real_data = posterior.detach()\n",
                "print(real_data.shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "da18b692",
            "metadata": {},
            "outputs": [],
            "source": [
                "x0 = x.to(device)\n",
                "with torch.no_grad():\n",
                "    posterior = AutoEncoder2.encode(x0)\n",
                "    real_data = posterior.sample().detach()\n",
                "print(real_data.shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "bc121430-0a8d-4363-aa6e-4f131c30bf61",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "venv"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}