{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2ceca2ab",
            "metadata": {},
            "outputs": [],
            "source": [
                "from get_args import get_args\n",
                "args = [\n",
                "\"--dataset\",\"celeba_256_no_transform\",\n",
                "\"--image_size\",\"256\",\n",
                "\"--exp\",\"vq-f4-256-bCR\",\n",
                "\"--num_channels\",\"3\",\n",
                "\"--num_channels_dae\",\"128\",\n",
                "\"--num_timesteps\",\"2\",\n",
                "\"--num_res_blocks\",\"2\",\n",
                "\"--batch_size\",\"32\",\n",
                "\"--num_epoch\",\"1000\",\n",
                "\"--ngf\",\"64\",\n",
                "\"--nz\",\"100\",\n",
                "\"--z_emb_dim\",\"256\",\n",
                "\"--n_mlp\",\"4\",\n",
                "\"--embedding_type\",\"positional\",\n",
                "\"--use_ema\",\n",
                "\"--ema_decay\",\"0.999\",\n",
                "\"--r1_gamma\",\"2.\",\n",
                "\"--lr_d\",\"1.0e-4\",\n",
                "\"--lr_g\",\"2.0e-4\",\n",
                "\"--lazy_reg\",\"10\",\n",
                "\"--ch_mult\", \"1\", \"2\", \"2\", \"2\",\n",
                "\"--save_content\",\n",
                "\"--datadir\",\"data/celeba/celeba-lmdb/\",\n",
                "\"--master_port\",\"6087\",\n",
                "\"--num_process_per_node\",\"1\",\n",
                "\"--save_content_every\",\"1\",\n",
                "\"--current_resolution\", \"64\",\n",
                "\"--attn_resolutions\", \"16\",\n",
                "\"--num_disc_layers\", \"4\",\n",
                "\"--scale_factor\", \"6.0\",\n",
                "\"--no_lr_decay\", \n",
                "\"--AutoEncoder_config\", \"autoencoder/config/vq-f4.yaml\", \n",
                "\"--AutoEncoder_ckpt\", \"autoencoder/weight/vq-f4.ckpt\", \n",
                "\"--rec_loss\",\n",
                "\"--sigmoid_learning\",\n",
                "]\n",
                "\n",
                "args = get_args(args) "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f4637850",
            "metadata": {},
            "outputs": [],
            "source": [
                "from get_args import get_args\n",
                "args = [\n",
                "\"--dataset\",\"lsun_no_tranform\",\n",
                "\"--image_size\",\"256\",\n",
                "\"--exp\",\"vq-f8\",\n",
                "\"--num_channels\",\"4\",\n",
                "\"--num_channels_dae\",\"128\",\n",
                "\"--num_timesteps\",\"4\",\n",
                "\"--num_res_blocks\",\"3\",\n",
                "\"--batch_size\",\"8\",\n",
                "\"--num_epoch\",\"1000\",\n",
                "\"--ngf\",\"64\",\n",
                "\"--nz\",\"50\",\n",
                "\"--z_emb_dim\",\"256\",\n",
                "\"--n_mlp\",\"4\",\n",
                "\"--embedding_type\",\"positional\",\n",
                "\"--use_ema\",\n",
                "\"--ema_decay\",\"0.999\",\n",
                "\"--r1_gamma\",\"1.\",\n",
                "\"--lr_d\",\"1.0e-4\",\n",
                "\"--lr_g\",\"2.0e-4\",\n",
                "\"--lazy_reg\",\"10\",\n",
                "\"--ch_mult\", \"1\", \"2\", \"2\", \"2\",\n",
                "\"--save_content\",\n",
                "\"--datadir\",\"data/lsun/\",\n",
                "\"--master_port\",\"6088\",\n",
                "\"--num_process_per_node\",\"1\",\n",
                "\"--save_content_every\",\"1\",\n",
                "\"--current_resolution\", \"32\",\n",
                "\"--attn_resolutions\", \"16\",\n",
                "\"--num_disc_layers\", \"4\",\n",
                "\"--scale_factor\", \"60.0\",\n",
                "\"--no_lr_decay\", \n",
                "\"--AutoEncoder_config\", \"autoencoder/config/vq-f8.yaml\", \n",
                "\"--AutoEncoder_ckpt\", \"autoencoder/weight/vq-f8.ckpt\", \n",
                "\"--rec_loss\",\n",
                "\"--sigmoid_learning\",\n",
                "]\n",
                "\n",
                "args = get_args(args) "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "69fe7e2a",
            "metadata": {},
            "outputs": [],
            "source": [
                "import argparse\n",
                "import os\n",
                "import shutil\n",
                "\n",
                "import numpy as np\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "import torch.optim as optim\n",
                "import torchvision\n",
                "from datasets_prep.dataset import create_dataset\n",
                "from diffusion import sample_from_model, sample_posterior, \\\n",
                "    q_sample_pairs, get_time_schedule, \\\n",
                "    Posterior_Coefficients, Diffusion_Coefficients\n",
                "#from DWT_IDWT.DWT_IDWT_layer import DWT_2D, IDWT_2D\n",
                "#from pytorch_wavelets import DWTForward, DWTInverse\n",
                "from torch.multiprocessing import Process\n",
                "from utils import init_processes, copy_source, broadcast_params\n",
                "import yaml\n",
                "\n",
                "from ldm.util import instantiate_from_config\n",
                "from omegaconf import OmegaConf\n",
                "import wandb\n",
                "\n",
                "def load_model_from_config(config_path, ckpt):\n",
                "    print(f\"Loading model from {ckpt}\")\n",
                "    config = OmegaConf.load(config_path)\n",
                "    pl_sd = torch.load(ckpt, map_location=\"cpu\")\n",
                "    #global_step = pl_sd[\"global_step\"]\n",
                "    sd = pl_sd[\"state_dict\"]\n",
                "    model = instantiate_from_config(config.model)\n",
                "    m, u = model.load_state_dict(sd, strict=False)\n",
                "    model = model.first_stage_model\n",
                "    model.cuda()\n",
                "    model.eval()\n",
                "    del m\n",
                "    del u\n",
                "    del pl_sd\n",
                "    return model\n",
                "\n",
                "def grad_penalty_call(args, D_real, x_t):\n",
                "    grad_real = torch.autograd.grad(\n",
                "        outputs=D_real.sum(), inputs=x_t, create_graph=True\n",
                "    )[0]\n",
                "    grad_penalty = (\n",
                "        grad_real.view(grad_real.size(0), -1).norm(2, dim=1) ** 2\n",
                "    ).mean()\n",
                "\n",
                "    grad_penalty = args.r1_gamma / 2 * grad_penalty\n",
                "    grad_penalty.backward()\n",
                "\n",
                "\n",
                "def train(rank, gpu, args):\n",
                "    from EMA import EMA\n",
                "    from score_sde.models.discriminator import Discriminator_large, Discriminator_small\n",
                "    from score_sde.models.ncsnpp_generator_adagn import NCSNpp, WaveletNCSNpp\n",
                "\n",
                "    torch.manual_seed(args.seed + rank)\n",
                "    torch.cuda.manual_seed(args.seed + rank)\n",
                "    torch.cuda.manual_seed_all(args.seed + rank)\n",
                "    device = torch.device('cuda:{}'.format(gpu))\n",
                "\n",
                "    batch_size = args.batch_size\n",
                "\n",
                "    nz = args.nz  # latent dimension\n",
                "\n",
                "    dataset = create_dataset(args)\n",
                "    train_sampler = torch.utils.data.distributed.DistributedSampler(dataset,\n",
                "                                                                    num_replicas=args.world_size,\n",
                "                                                                    rank=rank)\n",
                "    data_loader = torch.utils.data.DataLoader(dataset,\n",
                "                                              batch_size=batch_size,\n",
                "                                              shuffle=False,\n",
                "                                              num_workers=args.num_workers,\n",
                "                                              pin_memory=True,\n",
                "                                              sampler=train_sampler,\n",
                "                                              drop_last=True)\n",
                "    args.ori_image_size = args.image_size\n",
                "    args.image_size = args.current_resolution\n",
                "    G_NET_ZOO = {\"normal\": NCSNpp, \"wavelet\": WaveletNCSNpp}\n",
                "    gen_net = G_NET_ZOO[args.net_type]\n",
                "    disc_net = [Discriminator_small, Discriminator_large]\n",
                "    print(\"GEN: {}, DISC: {}\".format(gen_net, disc_net))\n",
                "    netG = gen_net(args).to(device)\n",
                "\n",
                "    if args.dataset in ['cifar10', 'stl10']:\n",
                "        netD = disc_net[0](nc=2 * args.num_channels, ngf=args.ngf,\n",
                "                           t_emb_dim=args.t_emb_dim,\n",
                "                           act=nn.LeakyReLU(0.2), num_layers=args.num_disc_layers).to(device)\n",
                "    else:\n",
                "        netD = disc_net[1](nc=2 * args.num_channels, ngf=args.ngf,\n",
                "                           t_emb_dim=args.t_emb_dim,\n",
                "                           act=nn.LeakyReLU(0.2), num_layers=args.num_disc_layers).to(device)\n",
                "\n",
                "    broadcast_params(netG.parameters())\n",
                "    broadcast_params(netD.parameters())\n",
                "\n",
                "    optimizerD = optim.Adam(filter(lambda p: p.requires_grad, netD.parameters(\n",
                "    )), lr=args.lr_d, betas=(args.beta1, args.beta2))\n",
                "    optimizerG = optim.Adam(filter(lambda p: p.requires_grad, netG.parameters(\n",
                "    )), lr=args.lr_g, betas=(args.beta1, args.beta2))\n",
                "\n",
                "    if args.use_ema:\n",
                "        optimizerG = EMA(optimizerG, ema_decay=args.ema_decay)\n",
                "\n",
                "    schedulerG = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
                "        optimizerG, args.num_epoch, eta_min=1e-5)\n",
                "    schedulerD = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
                "        optimizerD, args.num_epoch, eta_min=1e-5)\n",
                "\n",
                "    # ddp\n",
                "    netG = nn.parallel.DistributedDataParallel(\n",
                "        netG, device_ids=[gpu])\n",
                "    netD = nn.parallel.DistributedDataParallel(netD, device_ids=[gpu])\n",
                "\n",
                "    \"\"\"############### DELETE TO AVOID ERROR ###############\"\"\"\n",
                "    # Wavelet Pooling\n",
                "    #if not args.use_pytorch_wavelet:\n",
                "    #    dwt = DWT_2D(\"haar\")\n",
                "    #    iwt = IDWT_2D(\"haar\")\n",
                "    #else:\n",
                "    #    dwt = DWTForward(J=1, mode='zero', wave='haar').cuda()\n",
                "    #    iwt = DWTInverse(mode='zero', wave='haar').cuda()\n",
                "        \n",
                "    \n",
                "    #load encoder and decoder\n",
                "    config_path = args.AutoEncoder_config \n",
                "    ckpt_path = args.AutoEncoder_ckpt \n",
                "    \n",
                "    if args.dataset in ['cifar10', 'stl10'] or True:\n",
                "\n",
                "        with open(config_path, 'r') as file:\n",
                "            config = yaml.safe_load(file)\n",
                "        \n",
                "        AutoEncoder = instantiate_from_config(config['model'])\n",
                "        \n",
                "\n",
                "        checkpoint = torch.load(ckpt_path, map_location=device)\n",
                "        AutoEncoder.load_state_dict(checkpoint['state_dict'])\n",
                "        AutoEncoder.eval()\n",
                "        AutoEncoder.to(device)\n",
                "    \n",
                "    else:\n",
                "        AutoEncoder = load_model_from_config(config_path, ckpt_path)\n",
                "    \"\"\"############### END DELETING ###############\"\"\"\n",
                "    \n",
                "    num_levels = int(np.log2(args.ori_image_size // args.current_resolution))\n",
                "\n",
                "    exp = args.exp\n",
                "    parent_dir = \"./saved_info/{}\".format(args.dataset)\n",
                "\n",
                "    exp_path = os.path.join(parent_dir, exp)\n",
                "    if rank == 0:\n",
                "        if not os.path.exists(exp_path):\n",
                "            os.makedirs(exp_path)\n",
                "            copy_source(__file__, exp_path)\n",
                "            shutil.copytree('score_sde/models',\n",
                "                            os.path.join(exp_path, 'score_sde/models'))\n",
                "\n",
                "    coeff = Diffusion_Coefficients(args, device)\n",
                "    pos_coeff = Posterior_Coefficients(args, device)\n",
                "    T = get_time_schedule(args, device)\n",
                "\n",
                "    if args.resume or os.path.exists(os.path.join(exp_path, 'content.pth')):\n",
                "        checkpoint_file = os.path.join(exp_path, 'content.pth')\n",
                "        checkpoint = torch.load(checkpoint_file, map_location=device)\n",
                "        init_epoch = checkpoint['epoch']\n",
                "        epoch = init_epoch\n",
                "        # load G\n",
                "        netG.load_state_dict(checkpoint['netG_dict'])\n",
                "        #optimizerG.load_state_dict(checkpoint['optimizerG'])\n",
                "        schedulerG.load_state_dict(checkpoint['schedulerG'])\n",
                "        # load D\n",
                "        netD.load_state_dict(checkpoint['netD_dict'])\n",
                "        #optimizerD.load_state_dict(checkpoint['optimizerD'])\n",
                "        schedulerD.load_state_dict(checkpoint['schedulerD'])\n",
                "\n",
                "        global_step = checkpoint['global_step']\n",
                "        print(\"=> loaded checkpoint (epoch {})\"\n",
                "              .format(checkpoint['epoch']))\n",
                "    else:\n",
                "        global_step, epoch, init_epoch = 0, 0, 0\n",
                "\n",
                "    '''Sigmoid learning parameter'''\n",
                "    gamma = 6\n",
                "    beta = np.linspace(-gamma, gamma, args.num_epoch+1)\n",
                "    alpha = 1 - 1 / (1+np.exp(-beta))\n",
                "\n",
                "    # 拡張変換を定義 (例: ランダム水平反転とランダムシフト)\n",
                "    augment = torchvision.transforms.Compose([\n",
                "        torchvision.transforms.RandomHorizontalFlip(),\n",
                "        torchvision.transforms.RandomCrop(args.image_size, padding=4)\n",
                "    ])\n",
                "\n",
                "    for epoch in range(init_epoch, args.num_epoch + 1):\n",
                "        train_sampler.set_epoch(epoch)\n",
                "\n",
                "        for iteration, (x, y) in enumerate(data_loader):\n",
                "            for p in netD.parameters():\n",
                "                p.requires_grad = True\n",
                "            netD.zero_grad()\n",
                "\n",
                "            for p in netG.parameters():\n",
                "                p.requires_grad = False\n",
                "\n",
                "            # sample from p(x_0)\n",
                "            x0 = x.to(device, non_blocking=True)\n",
                "\n",
                "            x0_aug  = augment(x0)\n",
                "\n",
                "            \"\"\"################# Change here: Encoder #################\"\"\"\n",
                "            with torch.no_grad():\n",
                "                posterior = AutoEncoder.encode(x0)\n",
                "                posterior_aug = AutoEncoder.encode(x0_aug)\n",
                "                real_data = posterior.detach()\n",
                "                real_data_aug = posterior_aug.detach()\n",
                "            #print(\"MIN:{}, MAX:{}\".format(real_data.min(), real_data.max()))\n",
                "            real_data = real_data / args.scale_factor #300.0  # [-1, 1]\n",
                "            real_data_aug = real_data_aug / args.scale_factor #300.0  # [-1, 1]\n",
                "            \n",
                "            \n",
                "            #assert -1 <= real_data.min() < 0\n",
                "            #assert 0 < real_data.max() <= 1\n",
                "            \"\"\"################# End change: Encoder #################\"\"\"\n",
                "            # sample t\n",
                "            t = torch.randint(0, args.num_timesteps,\n",
                "                              (real_data.size(0),), device=device)\n",
                "\n",
                "            x_t, x_tp1 = q_sample_pairs(coeff, real_data, t)\n",
                "            x_t_aug, x_tp1_aug = q_sample_pairs(coeff, real_data_aug, t)\n",
                "            x_t.requires_grad = True\n",
                "            x_t_aug.requires_grad = True\n",
                "\n",
                "            # train with real\n",
                "            D_real = netD(x_t, t, x_tp1.detach()).view(-1)\n",
                "            D_real_aug = netD(x_t_aug, t, x_tp1_aug.detach()).view(-1)\n",
                "\n",
                "            if args.lazy_reg is None:\n",
                "                grad_penalty_call(args, D_real, x_t)\n",
                "                grad_penalty_call(args, D_real_aug, x_t_aug)\n",
                "            else:\n",
                "                if global_step % args.lazy_reg == 0:\n",
                "                    grad_penalty_call(args, D_real, x_t)\n",
                "                    grad_penalty_call(args, D_real_aug, x_t_aug)\n",
                "\n",
                "            # train with fake\n",
                "            latent_z = torch.randn(batch_size, nz, device=device)\n",
                "            x_0_predict = netG(x_tp1.detach(), t, latent_z)\n",
                "            x_pos_sample = sample_posterior(pos_coeff, x_0_predict, x_tp1, t)\n",
                "            x_pos_sample_aug = augment(x_pos_sample)\n",
                "\n",
                "            D_fake = netD(x_pos_sample, t, x_tp1_aug.detach()).view(-1)\n",
                "            D_fake_aug = netD(x_pos_sample_aug, t, x_tp1_aug.detach()).view(-1)\n",
                "            \n",
                "\n",
                "            # bCRの正則化項を追加 (λ_real, λ_fakeはハイパーパラメータ)\n",
                "            consistency_loss = ((D_fake - D_real) + args.lambda_real * F.mse_loss(D_real, D_real_aug) + args.lambda_fake * F.mse_loss(D_fake, D_fake_aug)).mean()\n",
                "\n",
                "            consistency_loss.backward()\n",
                "\n",
                "            errD = consistency_loss\n",
                "            # Update D\n",
                "            optimizerD.step()\n",
                "\n",
                "            # update G\n",
                "            for p in netD.parameters():\n",
                "                p.requires_grad = False\n",
                "\n",
                "            for p in netG.parameters():\n",
                "                p.requires_grad = True\n",
                "            netG.zero_grad()\n",
                "\n",
                "            t = torch.randint(0, args.num_timesteps,\n",
                "                              (real_data.size(0),), device=device)\n",
                "            x_t, x_tp1 = q_sample_pairs(coeff, real_data, t)\n",
                "\n",
                "            latent_z = torch.randn(batch_size, nz, device=device)\n",
                "            x_0_predict = netG(x_tp1.detach(), t, latent_z)\n",
                "            x_pos_sample = sample_posterior(pos_coeff, x_0_predict, x_tp1, t)\n",
                "\n",
                "            output = netD(x_pos_sample, t, x_tp1.detach()).view(-1)\n",
                "            errG = F.softplus(-output).mean()\n",
                "\n",
                "            # reconstructior loss\n",
                "            if args.sigmoid_learning and args.rec_loss:\n",
                "                ######alpha\n",
                "                rec_loss = F.l1_loss(x_0_predict, real_data)\n",
                "                errG = errG + alpha[epoch]*rec_loss\n",
                "\n",
                "            elif args.rec_loss and not args.sigmoid_learning:\n",
                "                rec_loss = F.l1_loss(x_0_predict, real_data)\n",
                "                errG = errG + rec_loss\n",
                "            \n",
                "\n",
                "            errG.backward()\n",
                "            optimizerG.step()\n",
                "\n",
                "            global_step += 1\n",
                "            if iteration % 100 == 0:\n",
                "                if rank == 0:\n",
                "                    if args.sigmoid_learning:\n",
                "                        print('epoch {} iteration{}, G Loss: {}, D Loss: {}, alpha: {}'.format(\n",
                "                            epoch, iteration, errG.item(), errD.item(), alpha[epoch]))\n",
                "                    elif args.rec_loss:\n",
                "                        print('epoch {} iteration{}, G Loss: {}, D Loss: {}, rec_loss: {}'.format(\n",
                "                            epoch, iteration, errG.item(), errD.item(), rec_loss.item()))\n",
                "                    else:   \n",
                "                        print('epoch {} iteration{}, G Loss: {}, D Loss: {}'.format(\n",
                "                            epoch, iteration, errG.item(), errD.item()))\n",
                "\n",
                "        if not args.no_lr_decay:\n",
                "\n",
                "            schedulerG.step()\n",
                "            schedulerD.step()\n",
                "\n",
                "        if rank == 0:\n",
                "            wandb.log({\"G_loss\": errG.item(), \"D_loss\": errD.item(), \"alpha\": alpha[epoch]})\n",
                "            ########################################\n",
                "            x_t_1 = torch.randn_like(posterior)\n",
                "            fake_sample = sample_from_model(\n",
                "                pos_coeff, netG, args.num_timesteps, x_t_1, T, args)\n",
                "\n",
                "            \"\"\"############## CHANGE HERE: DECODER ##############\"\"\"\n",
                "            fake_sample *= args.scale_factor #300\n",
                "            real_data *= args.scale_factor #300\n",
                "            with torch.no_grad():\n",
                "                fake_sample = AutoEncoder.decode(fake_sample)\n",
                "                real_data = AutoEncoder.decode(real_data)\n",
                "            \n",
                "            fake_sample = (torch.clamp(fake_sample, -1, 1) + 1) / 2  # 0-1\n",
                "            real_data = (torch.clamp(real_data, -1, 1) + 1) / 2  # 0-1 \n",
                "            \n",
                "            \"\"\"############## END HERE: DECODER ##############\"\"\"\n",
                "\n",
                "            torchvision.utils.save_image(fake_sample, os.path.join(\n",
                "                exp_path, 'sample_discrete_epoch_{}.png'.format(epoch)))\n",
                "            torchvision.utils.save_image(\n",
                "                real_data, os.path.join(exp_path, 'real_data.png'))\n",
                "\n",
                "            if args.save_content:\n",
                "                if epoch % args.save_content_every == 0:\n",
                "                    print('Saving content.')\n",
                "                    content = {'epoch': epoch + 1, 'global_step': global_step, 'args': args,\n",
                "                               'netG_dict': netG.state_dict(), 'optimizerG': optimizerG.state_dict(),\n",
                "                               'schedulerG': schedulerG.state_dict(), 'netD_dict': netD.state_dict(),\n",
                "                               'optimizerD': optimizerD.state_dict(), 'schedulerD': schedulerD.state_dict()}\n",
                "                    torch.save(content, os.path.join(exp_path, 'content.pth'))\n",
                "\n",
                "            if epoch % args.save_ckpt_every == 0:\n",
                "                if args.use_ema:\n",
                "                    optimizerG.swap_parameters_with_ema(\n",
                "                        store_params_in_ema=True)\n",
                "\n",
                "                torch.save(netG.state_dict(), os.path.join(\n",
                "                    exp_path, 'netG_{}.pth'.format(epoch)))\n",
                "                if args.use_ema:\n",
                "                    optimizerG.swap_parameters_with_ema(\n",
                "                        store_params_in_ema=True)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "iddgan",
            "language": "python",
            "name": "iddgan"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}