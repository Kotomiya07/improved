{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "081f93d1-7aac-4d6b-8fbf-da227f442a34",
            "metadata": {},
            "outputs": [],
            "source": [
                "from get_args import get_args\n",
                "\n",
                "args = [\"--dataset\", \"cifar10\", \"--exp\", \"test\", \"--num_channels\", \"4\", \"--num_channels_dae\", \"128\", \"--num_timesteps\", \"4\", \n",
                "\t\t\t\"--num_res_blocks\", \"2\", \"--batch_size\", \"256\", \"--num_epoch\", \"2000\", \"--ngf\", \"64\", \"--nz\", \"50\", \"--z_emb_dim\", \"256\", \"--n_mlp\", \"4\", \"--embedding_type\", \"positional\", \n",
                "\t\t\t\"--use_ema\", \"--ema_decay\", \"0.9999\", \"--r1_gamma\", \"0.02\", \"--lr_d\", \"1.25e-4\", \"--lr_g\", \"1.6e-4\", \"--lazy_reg\", \"15\", \n",
                "\t\t\t\"--ch_mult\", \"1\", \"2\", \"2\", \"--save_content\", \"--datadir\", \"./data/cifar-10\", \n",
                "\t\t\t\"--master_port\", \"6084\", \"--num_process_per_node\", \"1\", \"--save_ckpt_every\", \"25\", \n",
                "\t\t\t\"--current_resolution\", \"16\", \"--attn_resolutions\", \"32\", \"--num_disc_layers\", \"3\",  \"--scale_factor\", \"105.0\", \n",
                "\t\t\t\"--no_lr_decay\", \n",
                "            \"--AutoEncoder_config\", \"autoencoder/config/kl-f2.yaml\", \n",
                "            \"--AutoEncoder_ckpt\", \"autoencoder/weight/kl-f2.ckpt\", \n",
                "\t\t\t\"--rec_loss\",\n",
                "\t\t\t\"--sigmoid_learning\", \n",
                "       ]\n",
                "args = get_args(args)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2b2f41f1-e44e-40ce-84fa-99e55ae10403",
            "metadata": {},
            "outputs": [],
            "source": [
                "from get_args import get_args\n",
                "\n",
                "args = [\"--dataset\", \"afhq_cat\", \"--image_size\", \"64\", \"--exp\", \"test\", \"--num_channels\", \"4\", \"--num_channels_dae\", \"128\", \"--num_timesteps\", \"4\", \n",
                "\t\t\t\"--num_res_blocks\", \"2\", \"--batch_size\", \"32\", \"--num_epoch\", \"2000\", \"--ngf\", \"64\", \"--nz\", \"50\", \"--z_emb_dim\", \"256\", \"--n_mlp\", \"4\", \"--embedding_type\", \"positional\", \n",
                "\t\t\t\"--use_ema\", \"--ema_decay\", \"0.9999\", \"--r1_gamma\", \"0.02\", \"--lr_d\", \"1.25e-4\", \"--lr_g\", \"1.6e-4\", \"--lazy_reg\", \"15\", \n",
                "\t\t\t\"--ch_mult\", \"1\", \"2\", \"2\", \"--save_content\", \"--datadir\", \"./data/afhq\", \n",
                "\t\t\t\"--master_port\", \"6084\", \"--num_process_per_node\", \"1\", \"--save_ckpt_every\", \"25\", \n",
                "\t\t\t\"--current_resolution\", \"32\", \"--attn_resolutions\", \"32\", \"--num_disc_layers\", \"3\",  \"--scale_factor\", \"105.0\", \n",
                "\t\t\t\"--no_lr_decay\", \n",
                "            \"--AutoEncoder_config\", \"autoencoder/config/kl-f2.yaml\", \n",
                "            \"--AutoEncoder_ckpt\", \"autoencoder/weight/kl-f2.ckpt\", \n",
                "\t\t\t\"--rec_loss\",\n",
                "\t\t\t\"--sigmoid_learning\", \n",
                "       ]\n",
                "args = get_args(args)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "414e48d4-68ae-49af-a4ba-86470b9cf192",
            "metadata": {},
            "outputs": [],
            "source": [
                "import argparse\n",
                "import os\n",
                "import shutil\n",
                "\n",
                "import numpy as np\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "import torch.optim as optim\n",
                "import torchvision\n",
                "from datasets_prep.dataset import create_dataset\n",
                "from diffusion import sample_from_model, sample_posterior, \\\n",
                "    q_sample_pairs, get_time_schedule, \\\n",
                "    Posterior_Coefficients, Diffusion_Coefficients\n",
                "#from DWT_IDWT.DWT_IDWT_layer import DWT_2D, IDWT_2D\n",
                "#from pytorch_wavelets import DWTForward, DWTInverse\n",
                "from torch.multiprocessing import Process\n",
                "from utils import init_processes, copy_source, broadcast_params\n",
                "import yaml\n",
                "\n",
                "from ldm.util import instantiate_from_config\n",
                "from omegaconf import OmegaConf\n",
                "\n",
                "def load_model_from_config(config_path, ckpt):\n",
                "    print(f\"Loading model from {ckpt}\")\n",
                "    config = OmegaConf.load(config_path)\n",
                "    pl_sd = torch.load(ckpt, map_location=\"cpu\")\n",
                "    #global_step = pl_sd[\"global_step\"]\n",
                "    sd = pl_sd[\"state_dict\"]\n",
                "    model = instantiate_from_config(config.model)\n",
                "    m, u = model.load_state_dict(sd, strict=False)\n",
                "    model = model.first_stage_model\n",
                "    model.cuda()\n",
                "    model.eval()\n",
                "    del m\n",
                "    del u\n",
                "    del pl_sd\n",
                "    return model\n",
                "\n",
                "def grad_penalty_call(args, D_real, x_t):\n",
                "    grad_real = torch.autograd.grad(\n",
                "        outputs=D_real.sum(), inputs=x_t, create_graph=True\n",
                "    )[0]\n",
                "    grad_penalty = (\n",
                "        grad_real.view(grad_real.size(0), -1).norm(2, dim=1) ** 2\n",
                "    ).mean()\n",
                "\n",
                "    grad_penalty = args.r1_gamma / 2 * grad_penalty\n",
                "    grad_penalty.backward()\n",
                "\n",
                "\n",
                "# %%\n",
                "def train(rank, gpu, args):\n",
                "    from EMA import EMA\n",
                "    from score_sde.models.discriminator import Discriminator_large, Discriminator_small\n",
                "    from score_sde.models.ncsnpp_generator_adagn import NCSNpp, WaveletNCSNpp\n",
                "\n",
                "    torch.manual_seed(args.seed + rank)\n",
                "    torch.cuda.manual_seed(args.seed + rank)\n",
                "    torch.cuda.manual_seed_all(args.seed + rank)\n",
                "    device = torch.device('cuda:{}'.format(gpu))\n",
                "\n",
                "    batch_size = args.batch_size\n",
                "\n",
                "    nz = args.nz  # latent dimension\n",
                "\n",
                "    dataset = create_dataset(args)\n",
                "    train_sampler = torch.utils.data.distributed.DistributedSampler(dataset,\n",
                "                                                                    num_replicas=args.world_size,\n",
                "                                                                    rank=rank)\n",
                "    data_loader = torch.utils.data.DataLoader(dataset,\n",
                "                                              batch_size=batch_size,\n",
                "                                              shuffle=False,\n",
                "                                              num_workers=args.num_workers,\n",
                "                                              pin_memory=True,\n",
                "                                              sampler=train_sampler,\n",
                "                                              drop_last=True)\n",
                "    args.ori_image_size = args.image_size\n",
                "    args.image_size = args.current_resolution\n",
                "    G_NET_ZOO = {\"normal\": NCSNpp, \"wavelet\": WaveletNCSNpp}\n",
                "    gen_net = G_NET_ZOO[args.net_type]\n",
                "    disc_net = [Discriminator_small, Discriminator_large]\n",
                "    print(\"GEN: {}, DISC: {}\".format(gen_net, disc_net))\n",
                "    netG = gen_net(args).to(device)\n",
                "\n",
                "    if args.dataset in ['cifar10', 'stl10']:\n",
                "        netD = disc_net[0](nc=2 * args.num_channels, ngf=args.ngf,\n",
                "                           t_emb_dim=args.t_emb_dim,\n",
                "                           act=nn.LeakyReLU(0.2), num_layers=args.num_disc_layers).to(device)\n",
                "    else:\n",
                "        netD = disc_net[1](nc=2 * args.num_channels, ngf=args.ngf,\n",
                "                           t_emb_dim=args.t_emb_dim,\n",
                "                           act=nn.LeakyReLU(0.2), num_layers=args.num_disc_layers).to(device)\n",
                "\n",
                "    broadcast_params(netG.parameters())\n",
                "    broadcast_params(netD.parameters())\n",
                "\n",
                "    optimizerD = optim.Adam(filter(lambda p: p.requires_grad, netD.parameters(\n",
                "    )), lr=args.lr_d, betas=(args.beta1, args.beta2))\n",
                "    optimizerG = optim.Adam(filter(lambda p: p.requires_grad, netG.parameters(\n",
                "    )), lr=args.lr_g, betas=(args.beta1, args.beta2))\n",
                "\n",
                "    if args.use_ema:\n",
                "        optimizerG = EMA(optimizerG, ema_decay=args.ema_decay)\n",
                "\n",
                "    schedulerG = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
                "        optimizerG, args.num_epoch, eta_min=1e-5)\n",
                "    schedulerD = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
                "        optimizerD, args.num_epoch, eta_min=1e-5)\n",
                "\n",
                "    # ddp\n",
                "    netG = nn.parallel.DistributedDataParallel(\n",
                "        netG, device_ids=[gpu])\n",
                "    netD = nn.parallel.DistributedDataParallel(netD, device_ids=[gpu])\n",
                "\n",
                "    \"\"\"############### DELETE TO AVOID ERROR ###############\"\"\"\n",
                "    # Wavelet Pooling\n",
                "    #if not args.use_pytorch_wavelet:\n",
                "    #    dwt = DWT_2D(\"haar\")\n",
                "    #    iwt = IDWT_2D(\"haar\")\n",
                "    #else:\n",
                "    #    dwt = DWTForward(J=1, mode='zero', wave='haar').cuda()\n",
                "    #    iwt = DWTInverse(mode='zero', wave='haar').cuda()\n",
                "        \n",
                "    \n",
                "    #load encoder and decoder\n",
                "    config_path = args.AutoEncoder_config \n",
                "    ckpt_path = args.AutoEncoder_ckpt \n",
                "    \n",
                "    if args.dataset in ['cifar10', 'stl10', 'afhq_cat']:\n",
                "\n",
                "        with open(config_path, 'r') as file:\n",
                "            config = yaml.safe_load(file)\n",
                "        \n",
                "        AutoEncoder = instantiate_from_config(config['model'])\n",
                "        \n",
                "\n",
                "        checkpoint = torch.load(ckpt_path, map_location=device)\n",
                "        AutoEncoder.load_state_dict(checkpoint['state_dict'])\n",
                "        AutoEncoder.eval()\n",
                "        AutoEncoder.to(device)\n",
                "    \n",
                "    else:\n",
                "        AutoEncoder = load_model_from_config(config_path, ckpt_path)\n",
                "    \"\"\"############### END DELETING ###############\"\"\"\n",
                "    \n",
                "    num_levels = int(np.log2(args.ori_image_size // args.current_resolution))\n",
                "\n",
                "    exp = args.exp\n",
                "    parent_dir = \"./saved_info/{}\".format(args.dataset)\n",
                "\n",
                "    exp_path = os.path.join(parent_dir, exp)\n",
                "    if rank == 0:\n",
                "        if not os.path.exists(exp_path):\n",
                "            os.makedirs(exp_path)\n",
                "            copy_source(__file__, exp_path)\n",
                "            shutil.copytree('score_sde/models',\n",
                "                            os.path.join(exp_path, 'score_sde/models'))\n",
                "\n",
                "    coeff = Diffusion_Coefficients(args, device)\n",
                "    pos_coeff = Posterior_Coefficients(args, device)\n",
                "    T = get_time_schedule(args, device)\n",
                "\n",
                "    if args.resume or os.path.exists(os.path.join(exp_path, 'content.pth')):\n",
                "        checkpoint_file = os.path.join(exp_path, 'content.pth')\n",
                "        checkpoint = torch.load(checkpoint_file, map_location=device)\n",
                "        init_epoch = checkpoint['epoch']\n",
                "        epoch = init_epoch\n",
                "        # load G\n",
                "        netG.load_state_dict(checkpoint['netG_dict'])\n",
                "        #optimizerG.load_state_dict(checkpoint['optimizerG'])\n",
                "        schedulerG.load_state_dict(checkpoint['schedulerG'])\n",
                "        # load D\n",
                "        netD.load_state_dict(checkpoint['netD_dict'])\n",
                "        #optimizerD.load_state_dict(checkpoint['optimizerD'])\n",
                "        schedulerD.load_state_dict(checkpoint['schedulerD'])\n",
                "\n",
                "        global_step = checkpoint['global_step']\n",
                "        print(\"=> loaded checkpoint (epoch {})\"\n",
                "              .format(checkpoint['epoch']))\n",
                "    else:\n",
                "        global_step, epoch, init_epoch = 0, 0, 0\n",
                "\n",
                "    '''Sigmoid learning parameter'''\n",
                "    gamma = 6\n",
                "    beta = np.linspace(-gamma, gamma, args.num_epoch+1)\n",
                "    alpha = 1 - 1 / (1+np.exp(-beta))\n",
                "\n",
                "    for epoch in range(init_epoch, args.num_epoch + 1):\n",
                "        train_sampler.set_epoch(epoch)\n",
                "\n",
                "        for iteration, (x, y) in enumerate(data_loader):\n",
                "            for p in netD.parameters():\n",
                "                p.requires_grad = True\n",
                "            netD.zero_grad()\n",
                "\n",
                "            for p in netG.parameters():\n",
                "                p.requires_grad = False\n",
                "\n",
                "            # sample from p(x_0)\n",
                "            x0 = x.to(device, non_blocking=True)\n",
                "\n",
                "            \"\"\"################# Change here: Encoder #################\"\"\"\n",
                "            with torch.no_grad():\n",
                "                posterior = AutoEncoder.encode(x0)\n",
                "                real_data = posterior.sample().detach()\n",
                "            #print(\"MIN:{}, MAX:{}\".format(real_data.min(), real_data.max()))\n",
                "            real_data = real_data / args.scale_factor #300.0  # [-1, 1]\n",
                "            \n",
                "            \n",
                "            #assert -1 <= real_data.min() < 0\n",
                "            #assert 0 < real_data.max() <= 1\n",
                "            \"\"\"################# End change: Encoder #################\"\"\"\n",
                "            # sample t\n",
                "            t = torch.randint(0, args.num_timesteps,\n",
                "                              (real_data.size(0),), device=device)\n",
                "\n",
                "            x_t, x_tp1 = q_sample_pairs(coeff, real_data, t)\n",
                "            x_t.requires_grad = True\n",
                "\n",
                "            # train with real\n",
                "            D_real = netD(x_t, t, x_tp1.detach()).view(-1)\n",
                "            errD_real = F.softplus(-D_real).mean()\n",
                "\n",
                "            errD_real.backward(retain_graph=True)\n",
                "\n",
                "            if args.lazy_reg is None:\n",
                "                grad_penalty_call(args, D_real, x_t)\n",
                "            else:\n",
                "                if global_step % args.lazy_reg == 0:\n",
                "                    grad_penalty_call(args, D_real, x_t)\n",
                "\n",
                "            # train with fake\n",
                "            latent_z = torch.randn(batch_size, nz, device=device)\n",
                "            x_0_predict = netG(x_tp1.detach(), t, latent_z)\n",
                "            x_pos_sample = sample_posterior(pos_coeff, x_0_predict, x_tp1, t)\n",
                "\n",
                "            output = netD(x_pos_sample, t, x_tp1.detach()).view(-1)\n",
                "            errD_fake = F.softplus(output).mean()\n",
                "\n",
                "            errD_fake.backward()\n",
                "\n",
                "            errD = errD_real + errD_fake\n",
                "            # Update D\n",
                "            optimizerD.step()\n",
                "\n",
                "            # update G\n",
                "            for p in netD.parameters():\n",
                "                p.requires_grad = False\n",
                "\n",
                "            for p in netG.parameters():\n",
                "                p.requires_grad = True\n",
                "            netG.zero_grad()\n",
                "\n",
                "            t = torch.randint(0, args.num_timesteps,\n",
                "                              (real_data.size(0),), device=device)\n",
                "            x_t, x_tp1 = q_sample_pairs(coeff, real_data, t)\n",
                "\n",
                "            latent_z = torch.randn(batch_size, nz, device=device)\n",
                "            x_0_predict = netG(x_tp1.detach(), t, latent_z)\n",
                "            x_pos_sample = sample_posterior(pos_coeff, x_0_predict, x_tp1, t)\n",
                "\n",
                "            output = netD(x_pos_sample, t, x_tp1.detach()).view(-1)\n",
                "            errG = F.softplus(-output).mean()\n",
                "\n",
                "            # reconstructior loss\n",
                "            if args.sigmoid_learning and args.rec_loss:\n",
                "                ######alpha\n",
                "                rec_loss = F.l1_loss(x_0_predict, real_data)\n",
                "                errG = errG + alpha[epoch]*rec_loss\n",
                "\n",
                "            elif args.rec_loss and not args.sigmoid_learning:\n",
                "                rec_loss = F.l1_loss(x_0_predict, real_data)\n",
                "                errG = errG + rec_loss\n",
                "            \n",
                "\n",
                "            errG.backward()\n",
                "            optimizerG.step()\n",
                "\n",
                "            global_step += 1\n",
                "            if iteration % 100 == 0:\n",
                "                if rank == 0:\n",
                "                    if args.sigmoid_learning:\n",
                "                        print('epoch {} iteration{}, G Loss: {}, D Loss: {}, alpha: {}'.format(\n",
                "                            epoch, iteration, errG.item(), errD.item(), alpha[epoch]))\n",
                "                    elif args.rec_loss:\n",
                "                        print('epoch {} iteration{}, G Loss: {}, D Loss: {}, rec_loss: {}'.format(\n",
                "                            epoch, iteration, errG.item(), errD.item(), rec_loss.item()))\n",
                "                    else:   \n",
                "                        print('epoch {} iteration{}, G Loss: {}, D Loss: {}'.format(\n",
                "                            epoch, iteration, errG.item(), errD.item()))\n",
                "\n",
                "        if not args.no_lr_decay:\n",
                "\n",
                "            schedulerG.step()\n",
                "            schedulerD.step()\n",
                "\n",
                "        if rank == 0:\n",
                "            ########################################\n",
                "            x_t_1 = torch.randn_like(posterior.sample())\n",
                "            fake_sample = sample_from_model(\n",
                "                pos_coeff, netG, args.num_timesteps, x_t_1, T, args)\n",
                "\n",
                "            \"\"\"############## CHANGE HERE: DECODER ##############\"\"\"\n",
                "            fake_sample *= args.scale_factor #300\n",
                "            real_data *= args.scale_factor #300\n",
                "            with torch.no_grad():\n",
                "                fake_sample = AutoEncoder.decode(fake_sample)\n",
                "                real_data = AutoEncoder.decode(real_data)\n",
                "            \n",
                "            fake_sample = (torch.clamp(fake_sample, -1, 1) + 1) / 2  # 0-1\n",
                "            real_data = (torch.clamp(real_data, -1, 1) + 1) / 2  # 0-1 \n",
                "            \n",
                "            \"\"\"############## END HERE: DECODER ##############\"\"\"\n",
                "\n",
                "            torchvision.utils.save_image(fake_sample, os.path.join(\n",
                "                exp_path, 'sample_discrete_epoch_{}.png'.format(epoch)))\n",
                "            torchvision.utils.save_image(\n",
                "                real_data, os.path.join(exp_path, 'real_data.png'))\n",
                "\n",
                "            if args.save_content:\n",
                "                if epoch % args.save_content_every == 0:\n",
                "                    print('Saving content.')\n",
                "                    content = {'epoch': epoch + 1, 'global_step': global_step, 'args': args,\n",
                "                               'netG_dict': netG.state_dict(), 'optimizerG': optimizerG.state_dict(),\n",
                "                               'schedulerG': schedulerG.state_dict(), 'netD_dict': netD.state_dict(),\n",
                "                               'optimizerD': optimizerD.state_dict(), 'schedulerD': schedulerD.state_dict()}\n",
                "                    torch.save(content, os.path.join(exp_path, 'content.pth'))\n",
                "\n",
                "            if epoch % args.save_ckpt_every == 0:\n",
                "                if args.use_ema:\n",
                "                    optimizerG.swap_parameters_with_ema(\n",
                "                        store_params_in_ema=True)\n",
                "\n",
                "                torch.save(netG.state_dict(), os.path.join(\n",
                "                    exp_path, 'netG_{}.pth'.format(epoch)))\n",
                "                if args.use_ema:\n",
                "                    optimizerG.swap_parameters_with_ema(\n",
                "                        store_params_in_ema=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d17debf4-678d-48e4-94c3-015065223e7d",
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": [
                "print('starting in debug mode')\n",
                "init_processes(0, 1, train, args)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "66868cc0-650e-4d3b-8ed9-d9ce051a67c4",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "venv"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}