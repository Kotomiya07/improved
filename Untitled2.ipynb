{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "081f93d1-7aac-4d6b-8fbf-da227f442a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_args import get_args\n",
    "\n",
    "args = [\"--dataset\", \"cifar10\", \"--exp\", \"test\", \"--num_channels\", \"4\", \"--num_channels_dae\", \"128\", \"--num_timesteps\", \"4\", \n",
    "\t\t\t\"--num_res_blocks\", \"2\", \"--batch_size\", \"256\", \"--num_epoch\", \"2000\", \"--ngf\", \"64\", \"--nz\", \"50\", \"--z_emb_dim\", \"256\", \"--n_mlp\", \"4\", \"--embedding_type\", \"positional\", \n",
    "\t\t\t\"--use_ema\", \"--ema_decay\", \"0.9999\", \"--r1_gamma\", \"0.02\", \"--lr_d\", \"1.25e-4\", \"--lr_g\", \"1.6e-4\", \"--lazy_reg\", \"15\", \n",
    "\t\t\t\"--ch_mult\", \"1\", \"2\", \"2\", \"--save_content\", \"--datadir\", \"./data/cifar-10\", \n",
    "\t\t\t\"--master_port\", \"6084\", \"--num_process_per_node\", \"1\", \"--save_ckpt_every\", \"25\", \n",
    "\t\t\t\"--current_resolution\", \"16\", \"--attn_resolutions\", \"32\", \"--num_disc_layers\", \"3\",  \"--scale_factor\", \"105.0\", \n",
    "\t\t\t\"--no_lr_decay\", \n",
    "            \"--AutoEncoder_config\", \"autoencoder/config/kl-f2.yaml\", \n",
    "            \"--AutoEncoder_ckpt\", \"autoencoder/weight/kl-f2.ckpt\", \n",
    "\t\t\t\"--rec_loss\",\n",
    "\t\t\t\"--sigmoid_learning\", \n",
    "       ]\n",
    "args = get_args(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3e150ff-a647-4d14-b4d5-ab6d46fe22b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_args import get_args\n",
    "args = [\n",
    "\"--dataset\",\"afhq_cat\",\n",
    "\"--image_size\",\"64\",\n",
    "\"--exp\",\"test3\",\n",
    "\"--num_channels\",\"4\",\n",
    "\"--num_channels_dae\",\"128\",\n",
    "\"--num_timesteps\",\"4\",\n",
    "\"--num_res_blocks\",\"2\",\n",
    "\"--batch_size\",\"32\",\n",
    "\"--num_epoch\",\"2000\",\n",
    "\"--ngf\",\"64\",\n",
    "\"--nz\",\"50\",\n",
    "\"--z_emb_dim\",\"256\",\n",
    "\"--n_mlp\",\"4\",\n",
    "\"--embedding_type\",\"positional\",\n",
    "\"--use_ema\",\n",
    "\"--ema_decay\",\"0.9999\",\n",
    "\"--r1_gamma\",\"0.02\",\n",
    "\"--lr_d\",\"1.25e-4\",\n",
    "\"--lr_g\",\"1.6e-4\",\n",
    "\"--lazy_reg\",\"15\",\n",
    "\"--ch_mult\", \"1\", \"2\", \"2\", \"2\",\n",
    "\"--save_content\",\n",
    "\"--datadir\",\"data/afhq\",\n",
    "\"--master_port\",\"6086\",\n",
    "\"--num_process_per_node\",\"1\",\n",
    "\"--save_content_every\",\"1\",\n",
    "\"--current_resolution\", \"32\",\n",
    "\"--attn_resolutions\", \"32\",\n",
    "\"--num_disc_layers\", \"3\",\n",
    "\"--scale_factor\", \"60.0\",\n",
    "\"--no_lr_decay\", \n",
    "\"--AutoEncoder_config\", \"autoencoder/config/kl-f2.yaml\", \n",
    "\"--AutoEncoder_ckpt\", \"autoencoder/weight/kl-f2.ckpt\", \n",
    "\"--rec_loss\",\n",
    "\"--sigmoid_learning\",\n",
    "]\n",
    "\n",
    "args = get_args(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "414e48d4-68ae-49af-a4ba-86470b9cf192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from datasets_prep.dataset import create_dataset\n",
    "from diffusion import sample_from_model, sample_posterior, \\\n",
    "    q_sample_pairs, get_time_schedule, \\\n",
    "    Posterior_Coefficients, Diffusion_Coefficients\n",
    "#from DWT_IDWT.DWT_IDWT_layer import DWT_2D, IDWT_2D\n",
    "#from pytorch_wavelets import DWTForward, DWTInverse\n",
    "from torch.multiprocessing import Process\n",
    "from utils import init_processes, copy_source, broadcast_params\n",
    "import yaml\n",
    "\n",
    "from ldm.util import instantiate_from_config\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "def load_model_from_config(config_path, ckpt):\n",
    "    print(f\"Loading model from {ckpt}\")\n",
    "    config = OmegaConf.load(config_path)\n",
    "    pl_sd = torch.load(ckpt, map_location=\"cpu\")\n",
    "    #global_step = pl_sd[\"global_step\"]\n",
    "    sd = pl_sd[\"state_dict\"]\n",
    "    model = instantiate_from_config(config.model)\n",
    "    m, u = model.load_state_dict(sd, strict=False)\n",
    "    model = model.first_stage_model\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    del m\n",
    "    del u\n",
    "    del pl_sd\n",
    "    return model\n",
    "\n",
    "def grad_penalty_call(args, D_real, x_t):\n",
    "    grad_real = torch.autograd.grad(\n",
    "        outputs=D_real.sum(), inputs=x_t, create_graph=True\n",
    "    )[0]\n",
    "    grad_penalty = (\n",
    "        grad_real.view(grad_real.size(0), -1).norm(2, dim=1) ** 2\n",
    "    ).mean()\n",
    "\n",
    "    grad_penalty = args.r1_gamma / 2 * grad_penalty\n",
    "    grad_penalty.backward()\n",
    "\n",
    "\n",
    "# %%\n",
    "def train(rank, gpu, args):\n",
    "    from EMA import EMA\n",
    "    from score_sde.models.discriminator import Discriminator_large, Discriminator_small\n",
    "    from score_sde.models.ncsnpp_generator_adagn import NCSNpp, WaveletNCSNpp\n",
    "\n",
    "    torch.manual_seed(args.seed + rank)\n",
    "    torch.cuda.manual_seed(args.seed + rank)\n",
    "    torch.cuda.manual_seed_all(args.seed + rank)\n",
    "    device = torch.device('cuda:{}'.format(gpu))\n",
    "\n",
    "    batch_size = args.batch_size\n",
    "\n",
    "    nz = args.nz  # latent dimension\n",
    "\n",
    "    dataset = create_dataset(args)\n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(dataset,\n",
    "                                                                    num_replicas=args.world_size,\n",
    "                                                                    rank=rank)\n",
    "    data_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=False,\n",
    "                                              num_workers=args.num_workers,\n",
    "                                              pin_memory=True,\n",
    "                                              sampler=train_sampler,\n",
    "                                              drop_last=True)\n",
    "    args.ori_image_size = args.image_size\n",
    "    args.image_size = args.current_resolution\n",
    "    G_NET_ZOO = {\"normal\": NCSNpp, \"wavelet\": WaveletNCSNpp}\n",
    "    gen_net = G_NET_ZOO[args.net_type]\n",
    "    disc_net = [Discriminator_small, Discriminator_large]\n",
    "    print(\"GEN: {}, DISC: {}\".format(gen_net, disc_net))\n",
    "    netG = gen_net(args).to(device)\n",
    "\n",
    "    if args.dataset in ['cifar10', 'stl10']:\n",
    "        netD = disc_net[0](nc=2 * args.num_channels, ngf=args.ngf,\n",
    "                           t_emb_dim=args.t_emb_dim,\n",
    "                           act=nn.LeakyReLU(0.2), num_layers=args.num_disc_layers).to(device)\n",
    "    else:\n",
    "        netD = disc_net[1](nc=2 * args.num_channels, ngf=args.ngf,\n",
    "                           t_emb_dim=args.t_emb_dim,\n",
    "                           act=nn.LeakyReLU(0.2), num_layers=args.num_disc_layers).to(device)\n",
    "\n",
    "    broadcast_params(netG.parameters())\n",
    "    broadcast_params(netD.parameters())\n",
    "\n",
    "    optimizerD = optim.Adam(filter(lambda p: p.requires_grad, netD.parameters(\n",
    "    )), lr=args.lr_d, betas=(args.beta1, args.beta2))\n",
    "    optimizerG = optim.Adam(filter(lambda p: p.requires_grad, netG.parameters(\n",
    "    )), lr=args.lr_g, betas=(args.beta1, args.beta2))\n",
    "\n",
    "    if args.use_ema:\n",
    "        optimizerG = EMA(optimizerG, ema_decay=args.ema_decay)\n",
    "\n",
    "    schedulerG = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizerG, args.num_epoch, eta_min=1e-5)\n",
    "    schedulerD = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizerD, args.num_epoch, eta_min=1e-5)\n",
    "\n",
    "    # ddp\n",
    "    netG = nn.parallel.DistributedDataParallel(\n",
    "        netG, device_ids=[gpu], find_unused_parameters=True)\n",
    "    netD = nn.parallel.DistributedDataParallel(netD, device_ids=[gpu])\n",
    "\n",
    "    \"\"\"############### DELETE TO AVOID ERROR ###############\"\"\"\n",
    "    # Wavelet Pooling\n",
    "    #if not args.use_pytorch_wavelet:\n",
    "    #    dwt = DWT_2D(\"haar\")\n",
    "    #    iwt = IDWT_2D(\"haar\")\n",
    "    #else:\n",
    "    #    dwt = DWTForward(J=1, mode='zero', wave='haar').cuda()\n",
    "    #    iwt = DWTInverse(mode='zero', wave='haar').cuda()\n",
    "        \n",
    "    \n",
    "    #load encoder and decoder\n",
    "    config_path = args.AutoEncoder_config \n",
    "    ckpt_path = args.AutoEncoder_ckpt \n",
    "    \n",
    "    if args.dataset in ['cifar10', 'stl10', 'afhq_cat']:\n",
    "\n",
    "        with open(config_path, 'r') as file:\n",
    "            config = yaml.safe_load(file)\n",
    "        \n",
    "        AutoEncoder = instantiate_from_config(config['model'])\n",
    "        \n",
    "\n",
    "        checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "        AutoEncoder.load_state_dict(checkpoint['state_dict'])\n",
    "        AutoEncoder.eval()\n",
    "        AutoEncoder.to(device)\n",
    "    \n",
    "    else:\n",
    "        AutoEncoder = load_model_from_config(config_path, ckpt_path)\n",
    "    \"\"\"############### END DELETING ###############\"\"\"\n",
    "    \n",
    "    num_levels = int(np.log2(args.ori_image_size // args.current_resolution))\n",
    "\n",
    "    exp = args.exp\n",
    "    parent_dir = \"./saved_info/{}\".format(args.dataset)\n",
    "\n",
    "    exp_path = os.path.join(parent_dir, exp)\n",
    "    if rank == 0:\n",
    "        if not os.path.exists(exp_path):\n",
    "            os.makedirs(exp_path)\n",
    "            copy_source(__file__, exp_path)\n",
    "            shutil.copytree('score_sde/models',\n",
    "                            os.path.join(exp_path, 'score_sde/models'))\n",
    "\n",
    "    coeff = Diffusion_Coefficients(args, device)\n",
    "    pos_coeff = Posterior_Coefficients(args, device)\n",
    "    T = get_time_schedule(args, device)\n",
    "\n",
    "    if args.resume or os.path.exists(os.path.join(exp_path, 'content.pth')):\n",
    "        checkpoint_file = os.path.join(exp_path, 'content.pth')\n",
    "        checkpoint = torch.load(checkpoint_file, map_location=device)\n",
    "        init_epoch = checkpoint['epoch']\n",
    "        epoch = init_epoch\n",
    "        # load G\n",
    "        netG.load_state_dict(checkpoint['netG_dict'])\n",
    "        #optimizerG.load_state_dict(checkpoint['optimizerG'])\n",
    "        schedulerG.load_state_dict(checkpoint['schedulerG'])\n",
    "        # load D\n",
    "        netD.load_state_dict(checkpoint['netD_dict'])\n",
    "        #optimizerD.load_state_dict(checkpoint['optimizerD'])\n",
    "        schedulerD.load_state_dict(checkpoint['schedulerD'])\n",
    "\n",
    "        global_step = checkpoint['global_step']\n",
    "        print(\"=> loaded checkpoint (epoch {})\"\n",
    "              .format(checkpoint['epoch']))\n",
    "    else:\n",
    "        global_step, epoch, init_epoch = 0, 0, 0\n",
    "\n",
    "    '''Sigmoid learning parameter'''\n",
    "    gamma = 6\n",
    "    beta = np.linspace(-gamma, gamma, args.num_epoch+1)\n",
    "    alpha = 1 - 1 / (1+np.exp(-beta))\n",
    "\n",
    "    for epoch in range(init_epoch, args.num_epoch + 1):\n",
    "        train_sampler.set_epoch(epoch)\n",
    "\n",
    "        for iteration, (x, y) in enumerate(data_loader):\n",
    "            for p in netD.parameters():\n",
    "                p.requires_grad = True\n",
    "            netD.zero_grad()\n",
    "\n",
    "            for p in netG.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "            # sample from p(x_0)\n",
    "            x0 = x.to(device, non_blocking=True)\n",
    "\n",
    "            \"\"\"################# Change here: Encoder #################\"\"\"\n",
    "            with torch.no_grad():\n",
    "                posterior = AutoEncoder.encode(x0)\n",
    "                real_data = posterior.sample().detach()\n",
    "            #print(\"MIN:{}, MAX:{}\".format(real_data.min(), real_data.max()))\n",
    "            real_data = real_data / args.scale_factor #300.0  # [-1, 1]\n",
    "            \n",
    "            \n",
    "            #assert -1 <= real_data.min() < 0\n",
    "            #assert 0 < real_data.max() <= 1\n",
    "            \"\"\"################# End change: Encoder #################\"\"\"\n",
    "            # sample t\n",
    "            t = torch.randint(0, args.num_timesteps,\n",
    "                              (real_data.size(0),), device=device)\n",
    "\n",
    "            x_t, x_tp1 = q_sample_pairs(coeff, real_data, t)\n",
    "            x_t.requires_grad = True\n",
    "\n",
    "            # train with real\n",
    "            D_real = netD(x_t, t, x_tp1.detach()).view(-1)\n",
    "            errD_real = F.softplus(-D_real).mean()\n",
    "\n",
    "            errD_real.backward(retain_graph=True)\n",
    "\n",
    "            if args.lazy_reg is None:\n",
    "                grad_penalty_call(args, D_real, x_t)\n",
    "            else:\n",
    "                if global_step % args.lazy_reg == 0:\n",
    "                    grad_penalty_call(args, D_real, x_t)\n",
    "\n",
    "            # train with fake\n",
    "            latent_z = torch.randn(batch_size, nz, device=device)\n",
    "            x_0_predict = netG(x_tp1.detach(), t, latent_z)\n",
    "            x_pos_sample = sample_posterior(pos_coeff, x_0_predict, x_tp1, t)\n",
    "\n",
    "            output = netD(x_pos_sample, t, x_tp1.detach()).view(-1)\n",
    "            errD_fake = F.softplus(output).mean()\n",
    "\n",
    "            errD_fake.backward()\n",
    "\n",
    "            errD = errD_real + errD_fake\n",
    "            # Update D\n",
    "            optimizerD.step()\n",
    "\n",
    "            # update G\n",
    "            for p in netD.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "            for p in netG.parameters():\n",
    "                p.requires_grad = True\n",
    "            netG.zero_grad()\n",
    "\n",
    "            t = torch.randint(0, args.num_timesteps,\n",
    "                              (real_data.size(0),), device=device)\n",
    "            x_t, x_tp1 = q_sample_pairs(coeff, real_data, t)\n",
    "\n",
    "            latent_z = torch.randn(batch_size, nz, device=device)\n",
    "            x_0_predict = netG(x_tp1.detach(), t, latent_z)\n",
    "            x_pos_sample = sample_posterior(pos_coeff, x_0_predict, x_tp1, t)\n",
    "\n",
    "            output = netD(x_pos_sample, t, x_tp1.detach()).view(-1)\n",
    "            errG = F.softplus(-output).mean()\n",
    "\n",
    "            # reconstructior loss\n",
    "            if args.sigmoid_learning and args.rec_loss:\n",
    "                ######alpha\n",
    "                rec_loss = F.l1_loss(x_0_predict, real_data)\n",
    "                errG = errG + alpha[epoch]*rec_loss\n",
    "\n",
    "            elif args.rec_loss and not args.sigmoid_learning:\n",
    "                rec_loss = F.l1_loss(x_0_predict, real_data)\n",
    "                errG = errG + rec_loss\n",
    "            \n",
    "\n",
    "            errG.backward()\n",
    "            optimizerG.step()\n",
    "\n",
    "            global_step += 1\n",
    "            if iteration % 100 == 0:\n",
    "                if rank == 0:\n",
    "                    if args.sigmoid_learning:\n",
    "                        print('epoch {} iteration{}, G Loss: {}, D Loss: {}, alpha: {}'.format(\n",
    "                            epoch, iteration, errG.item(), errD.item(), alpha[epoch]))\n",
    "                    elif args.rec_loss:\n",
    "                        print('epoch {} iteration{}, G Loss: {}, D Loss: {}, rec_loss: {}'.format(\n",
    "                            epoch, iteration, errG.item(), errD.item(), rec_loss.item()))\n",
    "                    else:   \n",
    "                        print('epoch {} iteration{}, G Loss: {}, D Loss: {}'.format(\n",
    "                            epoch, iteration, errG.item(), errD.item()))\n",
    "\n",
    "        if not args.no_lr_decay:\n",
    "\n",
    "            schedulerG.step()\n",
    "            schedulerD.step()\n",
    "\n",
    "        if rank == 0:\n",
    "            ########################################\n",
    "            x_t_1 = torch.randn_like(posterior.sample())\n",
    "            fake_sample = sample_from_model(\n",
    "                pos_coeff, netG, args.num_timesteps, x_t_1, T, args)\n",
    "\n",
    "            \"\"\"############## CHANGE HERE: DECODER ##############\"\"\"\n",
    "            fake_sample *= args.scale_factor #300\n",
    "            real_data *= args.scale_factor #300\n",
    "            with torch.no_grad():\n",
    "                fake_sample = AutoEncoder.decode(fake_sample)\n",
    "                real_data = AutoEncoder.decode(real_data)\n",
    "            \n",
    "            fake_sample = (torch.clamp(fake_sample, -1, 1) + 1) / 2  # 0-1\n",
    "            real_data = (torch.clamp(real_data, -1, 1) + 1) / 2  # 0-1 \n",
    "            \n",
    "            \"\"\"############## END HERE: DECODER ##############\"\"\"\n",
    "\n",
    "            torchvision.utils.save_image(fake_sample, os.path.join(\n",
    "                exp_path, 'sample_discrete_epoch_{}.png'.format(epoch)))\n",
    "            torchvision.utils.save_image(\n",
    "                real_data, os.path.join(exp_path, 'real_data.png'))\n",
    "\n",
    "            if args.save_content:\n",
    "                if epoch % args.save_content_every == 0:\n",
    "                    print('Saving content.')\n",
    "                    content = {'epoch': epoch + 1, 'global_step': global_step, 'args': args,\n",
    "                               'netG_dict': netG.state_dict(), 'optimizerG': optimizerG.state_dict(),\n",
    "                               'schedulerG': schedulerG.state_dict(), 'netD_dict': netD.state_dict(),\n",
    "                               'optimizerD': optimizerD.state_dict(), 'schedulerD': schedulerD.state_dict()}\n",
    "                    torch.save(content, os.path.join(exp_path, 'content.pth'))\n",
    "\n",
    "            if epoch % args.save_ckpt_every == 0:\n",
    "                if args.use_ema:\n",
    "                    optimizerG.swap_parameters_with_ema(\n",
    "                        store_params_in_ema=True)\n",
    "\n",
    "                torch.save(netG.state_dict(), os.path.join(\n",
    "                    exp_path, 'netG_{}.pth'.format(epoch)))\n",
    "                if args.use_ema:\n",
    "                    optimizerG.swap_parameters_with_ema(\n",
    "                        store_params_in_ema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17debf4-678d-48e4-94c3-015065223e7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting in debug mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/users/std/2021/21k0005/improved-ddgan/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEN: <class 'score_sde.models.ncsnpp_generator_adagn.NCSNpp'>, DISC: [<class 'score_sde.models.discriminator.Discriminator_small'>, <class 'score_sde.models.discriminator.Discriminator_large'>]\n",
      "making attention of type 'vanilla' with 256 in_channels\n",
      "making attention of type 'vanilla' with 256 in_channels\n",
      "making attention of type 'vanilla' with 256 in_channels\n",
      "Working with z of shape (1, 4, 16, 16) = 1024 dimensions.\n",
      "making attention of type 'vanilla' with 256 in_channels\n",
      "making attention of type 'vanilla' with 256 in_channels\n",
      "making attention of type 'vanilla' with 256 in_channels\n",
      "making attention of type 'vanilla' with 256 in_channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/users/std/2021/21k0005/improved-ddgan/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/scratch/users/std/2021/21k0005/improved-ddgan/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/users/std/2021/21k0005/improved-ddgan/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "[rank0]:[W reducer.cpp:1360] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 iteration0, G Loss: 0.1910160928964615, D Loss: 1.5979480743408203, alpha: 0.9975273768433652\n",
      "epoch 0 iteration100, G Loss: 2.4215950965881348, D Loss: 1.791154146194458, alpha: 0.9975273768433652\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 1 iteration0, G Loss: 0.9172810912132263, D Loss: 1.4077460765838623, alpha: 0.9975125335223958\n",
      "epoch 1 iteration100, G Loss: 1.7371193170547485, D Loss: 1.665456771850586, alpha: 0.9975125335223958\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 2 iteration0, G Loss: 0.6650135517120361, D Loss: 1.6448270082473755, alpha: 0.997497601319515\n",
      "epoch 2 iteration100, G Loss: 0.8998571634292603, D Loss: 1.4480290412902832, alpha: 0.997497601319515\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 3 iteration0, G Loss: 0.8345134854316711, D Loss: 1.3610022068023682, alpha: 0.9974825797051893\n",
      "epoch 3 iteration100, G Loss: 0.9882712960243225, D Loss: 1.3328356742858887, alpha: 0.9974825797051893\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 4 iteration0, G Loss: 2.6389365196228027, D Loss: 1.4761029481887817, alpha: 0.9974674681467623\n",
      "epoch 4 iteration100, G Loss: 1.1714154481887817, D Loss: 1.3947322368621826, alpha: 0.9974674681467623\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 5 iteration0, G Loss: 0.9958224296569824, D Loss: 1.3462533950805664, alpha: 0.9974522661084374\n",
      "epoch 5 iteration100, G Loss: 1.202440619468689, D Loss: 1.9458179473876953, alpha: 0.9974522661084374\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 6 iteration0, G Loss: 1.4020193815231323, D Loss: 1.4039428234100342, alpha: 0.9974369730512593\n",
      "epoch 6 iteration100, G Loss: 0.7660014033317566, D Loss: 1.3961520195007324, alpha: 0.9974369730512593\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 7 iteration0, G Loss: 0.5437386631965637, D Loss: 1.7483556270599365, alpha: 0.9974215884330963\n",
      "epoch 7 iteration100, G Loss: 1.2861526012420654, D Loss: 1.4825798273086548, alpha: 0.9974215884330963\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 8 iteration0, G Loss: 1.1497281789779663, D Loss: 1.308937907218933, alpha: 0.997406111708621\n",
      "epoch 8 iteration100, G Loss: 1.0756261348724365, D Loss: 1.339104175567627, alpha: 0.997406111708621\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 9 iteration0, G Loss: 0.7745867967605591, D Loss: 1.3474200963974, alpha: 0.997390542329293\n",
      "epoch 9 iteration100, G Loss: 0.8335154056549072, D Loss: 1.336227297782898, alpha: 0.997390542329293\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 10 iteration0, G Loss: 0.9177977442741394, D Loss: 1.4216160774230957, alpha: 0.9973748797433398\n",
      "epoch 10 iteration100, G Loss: 1.1068170070648193, D Loss: 1.399266242980957, alpha: 0.9973748797433398\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 11 iteration0, G Loss: 0.4571862816810608, D Loss: 1.4767029285430908, alpha: 0.9973591233957381\n",
      "epoch 11 iteration100, G Loss: 1.4422847032546997, D Loss: 1.4093513488769531, alpha: 0.9973591233957381\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 12 iteration0, G Loss: 1.0996185541152954, D Loss: 1.3369531631469727, alpha: 0.9973432727281952\n",
      "epoch 12 iteration100, G Loss: 0.7847529053688049, D Loss: 1.3248622417449951, alpha: 0.9973432727281952\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 13 iteration0, G Loss: 1.0988597869873047, D Loss: 1.2947735786437988, alpha: 0.9973273271791304\n",
      "epoch 13 iteration100, G Loss: 1.5022526979446411, D Loss: 1.4686174392700195, alpha: 0.9973273271791304\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 14 iteration0, G Loss: 0.929639458656311, D Loss: 1.7608470916748047, alpha: 0.9973112861836558\n",
      "epoch 14 iteration100, G Loss: 0.9039775729179382, D Loss: 1.4347827434539795, alpha: 0.9973112861836558\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 15 iteration0, G Loss: 1.6734973192214966, D Loss: 1.5423511266708374, alpha: 0.9972951491735572\n",
      "epoch 15 iteration100, G Loss: 0.9121431112289429, D Loss: 1.3298672437667847, alpha: 0.9972951491735572\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 16 iteration0, G Loss: 0.861204206943512, D Loss: 1.460544228553772, alpha: 0.9972789155772751\n",
      "epoch 16 iteration100, G Loss: 1.6068217754364014, D Loss: 1.3465650081634521, alpha: 0.9972789155772751\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 17 iteration0, G Loss: 2.076809883117676, D Loss: 1.5352526903152466, alpha: 0.9972625848198857\n",
      "epoch 17 iteration100, G Loss: 0.8732393383979797, D Loss: 1.349963903427124, alpha: 0.9972625848198857\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 18 iteration0, G Loss: 0.9824247360229492, D Loss: 1.3368420600891113, alpha: 0.997246156323081\n",
      "epoch 18 iteration100, G Loss: 0.7193225622177124, D Loss: 1.4359767436981201, alpha: 0.997246156323081\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 19 iteration0, G Loss: 0.49199753999710083, D Loss: 2.178065299987793, alpha: 0.9972296295051497\n",
      "epoch 19 iteration100, G Loss: 1.0384141206741333, D Loss: 1.486140251159668, alpha: 0.9972296295051497\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 20 iteration0, G Loss: 0.987459123134613, D Loss: 1.3597922325134277, alpha: 0.9972130037809577\n",
      "epoch 20 iteration100, G Loss: 1.047744870185852, D Loss: 1.386771321296692, alpha: 0.9972130037809577\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 21 iteration0, G Loss: 1.337325930595398, D Loss: 1.305467128753662, alpha: 0.9971962785619283\n",
      "epoch 21 iteration100, G Loss: 1.1739907264709473, D Loss: 1.2384881973266602, alpha: 0.9971962785619283\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 22 iteration0, G Loss: 0.9257129430770874, D Loss: 1.2958168983459473, alpha: 0.9971794532560223\n",
      "epoch 22 iteration100, G Loss: 0.9292540550231934, D Loss: 1.3247802257537842, alpha: 0.9971794532560223\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 23 iteration0, G Loss: 1.67599618434906, D Loss: 1.3304154872894287, alpha: 0.9971625272677183\n",
      "epoch 23 iteration100, G Loss: 1.1365784406661987, D Loss: 1.5478748083114624, alpha: 0.9971625272677183\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 24 iteration0, G Loss: 1.10249924659729, D Loss: 1.2739765644073486, alpha: 0.9971454999979927\n",
      "epoch 24 iteration100, G Loss: 1.994053840637207, D Loss: 1.3223309516906738, alpha: 0.9971454999979927\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 25 iteration0, G Loss: 1.4881285429000854, D Loss: 1.6153671741485596, alpha: 0.9971283708442996\n",
      "epoch 25 iteration100, G Loss: 0.9992223978042603, D Loss: 1.3514496088027954, alpha: 0.9971283708442996\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 26 iteration0, G Loss: 1.3848562240600586, D Loss: 1.3383185863494873, alpha: 0.9971111392005504\n",
      "epoch 26 iteration100, G Loss: 1.0326989889144897, D Loss: 1.4763548374176025, alpha: 0.9971111392005504\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 27 iteration0, G Loss: 0.9847499132156372, D Loss: 1.3932626247406006, alpha: 0.9970938044570938\n",
      "epoch 27 iteration100, G Loss: 1.258052945137024, D Loss: 1.3475308418273926, alpha: 0.9970938044570938\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 28 iteration0, G Loss: 0.8723728656768799, D Loss: 1.3777170181274414, alpha: 0.9970763660006952\n",
      "epoch 28 iteration100, G Loss: 0.9540896415710449, D Loss: 1.2799460887908936, alpha: 0.9970763660006952\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 29 iteration0, G Loss: 0.8472197651863098, D Loss: 1.366830587387085, alpha: 0.9970588232145158\n",
      "epoch 29 iteration100, G Loss: 0.9366998076438904, D Loss: 1.3813225030899048, alpha: 0.9970588232145158\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 30 iteration0, G Loss: 1.0758881568908691, D Loss: 1.303957462310791, alpha: 0.9970411754780928\n",
      "epoch 30 iteration100, G Loss: 0.8702118396759033, D Loss: 1.4372773170471191, alpha: 0.9970411754780928\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 31 iteration0, G Loss: 1.013394832611084, D Loss: 1.3415284156799316, alpha: 0.9970234221673178\n",
      "epoch 31 iteration100, G Loss: 0.863053023815155, D Loss: 1.4516980648040771, alpha: 0.9970234221673178\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 32 iteration0, G Loss: 1.0201112031936646, D Loss: 1.353471040725708, alpha: 0.9970055626544164\n",
      "epoch 32 iteration100, G Loss: 1.2193706035614014, D Loss: 1.304002046585083, alpha: 0.9970055626544164\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 33 iteration0, G Loss: 0.9178076386451721, D Loss: 1.4295275211334229, alpha: 0.9969875963079272\n",
      "epoch 33 iteration100, G Loss: 1.916161298751831, D Loss: 1.3493542671203613, alpha: 0.9969875963079272\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 34 iteration0, G Loss: 0.9205597043037415, D Loss: 1.4125474691390991, alpha: 0.9969695224926802\n",
      "epoch 34 iteration100, G Loss: 1.8607840538024902, D Loss: 1.3938391208648682, alpha: 0.9969695224926802\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 35 iteration0, G Loss: 1.530400037765503, D Loss: 1.6608163118362427, alpha: 0.9969513405697763\n",
      "epoch 35 iteration100, G Loss: 1.380983591079712, D Loss: 1.4414212703704834, alpha: 0.9969513405697763\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 36 iteration0, G Loss: 0.7257581353187561, D Loss: 1.341064214706421, alpha: 0.9969330498965654\n",
      "epoch 36 iteration100, G Loss: 0.9044972658157349, D Loss: 1.4812827110290527, alpha: 0.9969330498965654\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 37 iteration0, G Loss: 1.4569015502929688, D Loss: 1.3720595836639404, alpha: 0.9969146498266254\n",
      "epoch 37 iteration100, G Loss: 0.7710740566253662, D Loss: 1.3603246212005615, alpha: 0.9969146498266254\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 38 iteration0, G Loss: 1.6943200826644897, D Loss: 1.3443615436553955, alpha: 0.9968961397097401\n",
      "epoch 38 iteration100, G Loss: 1.109071969985962, D Loss: 1.4199786186218262, alpha: 0.9968961397097401\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 39 iteration0, G Loss: 1.0074046850204468, D Loss: 1.4074405431747437, alpha: 0.9968775188918781\n",
      "epoch 39 iteration100, G Loss: 0.9621743559837341, D Loss: 1.2851243019104004, alpha: 0.9968775188918781\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 40 iteration0, G Loss: 2.2170023918151855, D Loss: 1.6286637783050537, alpha: 0.9968587867151706\n",
      "epoch 40 iteration100, G Loss: 0.9403570890426636, D Loss: 1.3078796863555908, alpha: 0.9968587867151706\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 41 iteration0, G Loss: 0.8008682131767273, D Loss: 1.3067477941513062, alpha: 0.9968399425178895\n",
      "epoch 41 iteration100, G Loss: 0.9983688592910767, D Loss: 1.4445726871490479, alpha: 0.9968399425178895\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 42 iteration0, G Loss: 0.7798043489456177, D Loss: 1.5525007247924805, alpha: 0.9968209856344259\n",
      "epoch 42 iteration100, G Loss: 1.0519498586654663, D Loss: 1.3206731081008911, alpha: 0.9968209856344259\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 43 iteration0, G Loss: 0.9878890514373779, D Loss: 1.3291807174682617, alpha: 0.9968019153952671\n",
      "epoch 43 iteration100, G Loss: 0.983988881111145, D Loss: 1.6300314664840698, alpha: 0.9968019153952671\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 44 iteration0, G Loss: 1.0220986604690552, D Loss: 1.2385568618774414, alpha: 0.9967827311269749\n",
      "epoch 44 iteration100, G Loss: 0.6128252744674683, D Loss: 1.3993314504623413, alpha: 0.9967827311269749\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 45 iteration0, G Loss: 1.0450385808944702, D Loss: 1.3868521451950073, alpha: 0.9967634321521631\n",
      "epoch 45 iteration100, G Loss: 1.5298014879226685, D Loss: 1.3290767669677734, alpha: 0.9967634321521631\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 46 iteration0, G Loss: 1.2629855871200562, D Loss: 1.314028263092041, alpha: 0.9967440177894752\n",
      "epoch 46 iteration100, G Loss: 0.8717383742332458, D Loss: 1.4108591079711914, alpha: 0.9967440177894752\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 47 iteration0, G Loss: 0.9991406798362732, D Loss: 1.3763790130615234, alpha: 0.996724487353561\n",
      "epoch 47 iteration100, G Loss: 1.2156744003295898, D Loss: 1.3380753993988037, alpha: 0.996724487353561\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 48 iteration0, G Loss: 0.9678480625152588, D Loss: 1.383742094039917, alpha: 0.9967048401550548\n",
      "epoch 48 iteration100, G Loss: 1.057064414024353, D Loss: 1.3769830465316772, alpha: 0.9967048401550548\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 49 iteration0, G Loss: 1.0389786958694458, D Loss: 1.309625267982483, alpha: 0.9966850755005522\n",
      "epoch 49 iteration100, G Loss: 0.7682986259460449, D Loss: 1.9982507228851318, alpha: 0.9966850755005522\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 50 iteration0, G Loss: 0.7705880999565125, D Loss: 1.6762888431549072, alpha: 0.9966651926925867\n",
      "epoch 50 iteration100, G Loss: 1.299242615699768, D Loss: 1.5635485649108887, alpha: 0.9966651926925867\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 51 iteration0, G Loss: 1.4012033939361572, D Loss: 1.5815929174423218, alpha: 0.996645191029607\n",
      "epoch 51 iteration100, G Loss: 2.1758949756622314, D Loss: 1.3093105554580688, alpha: 0.996645191029607\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 52 iteration0, G Loss: 0.6870719790458679, D Loss: 1.3317809104919434, alpha: 0.9966250698059539\n",
      "epoch 52 iteration100, G Loss: 0.7624169588088989, D Loss: 1.272734522819519, alpha: 0.9966250698059539\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 53 iteration0, G Loss: 1.3948142528533936, D Loss: 1.3876893520355225, alpha: 0.9966048283118364\n",
      "epoch 53 iteration100, G Loss: 0.9989495873451233, D Loss: 1.373335361480713, alpha: 0.9966048283118364\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 54 iteration0, G Loss: 0.8769404888153076, D Loss: 1.4102628231048584, alpha: 0.9965844658333086\n",
      "epoch 54 iteration100, G Loss: 0.7562993168830872, D Loss: 1.3481659889221191, alpha: 0.9965844658333086\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 55 iteration0, G Loss: 0.9161584377288818, D Loss: 1.46720290184021, alpha: 0.9965639816522461\n",
      "epoch 55 iteration100, G Loss: 2.512873888015747, D Loss: 1.112054467201233, alpha: 0.9965639816522461\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 56 iteration0, G Loss: 0.893752932548523, D Loss: 1.3207257986068726, alpha: 0.9965433750463222\n",
      "epoch 56 iteration100, G Loss: 1.2995141744613647, D Loss: 1.4536335468292236, alpha: 0.9965433750463222\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 57 iteration0, G Loss: 1.1227420568466187, D Loss: 1.4062288999557495, alpha: 0.9965226452889837\n",
      "epoch 57 iteration100, G Loss: 0.867809534072876, D Loss: 1.3817694187164307, alpha: 0.9965226452889837\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 58 iteration0, G Loss: 1.2552136182785034, D Loss: 1.4076573848724365, alpha: 0.9965017916494276\n",
      "epoch 58 iteration100, G Loss: 0.9683583974838257, D Loss: 1.339376449584961, alpha: 0.9965017916494276\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 59 iteration0, G Loss: 1.9142366647720337, D Loss: 1.2184325456619263, alpha: 0.9964808133925762\n",
      "epoch 59 iteration100, G Loss: 1.3679835796356201, D Loss: 1.3061093091964722, alpha: 0.9964808133925762\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 60 iteration0, G Loss: 0.9834100008010864, D Loss: 1.4380784034729004, alpha: 0.9964597097790535\n",
      "epoch 60 iteration100, G Loss: 0.9421017169952393, D Loss: 1.291295051574707, alpha: 0.9964597097790535\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 61 iteration0, G Loss: 0.9534580111503601, D Loss: 1.3837138414382935, alpha: 0.9964384800651604\n",
      "epoch 61 iteration100, G Loss: 0.8541001081466675, D Loss: 1.4024238586425781, alpha: 0.9964384800651604\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 62 iteration0, G Loss: 1.1276718378067017, D Loss: 1.340299129486084, alpha: 0.9964171235028505\n",
      "epoch 62 iteration100, G Loss: 1.1639858484268188, D Loss: 1.5257056951522827, alpha: 0.9964171235028505\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 63 iteration0, G Loss: 0.8638678789138794, D Loss: 1.3086292743682861, alpha: 0.9963956393397052\n",
      "epoch 63 iteration100, G Loss: 0.9521434307098389, D Loss: 1.415266990661621, alpha: 0.9963956393397052\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 64 iteration0, G Loss: 1.0700199604034424, D Loss: 1.2935166358947754, alpha: 0.9963740268189091\n",
      "epoch 64 iteration100, G Loss: 1.198035478591919, D Loss: 1.4175313711166382, alpha: 0.9963740268189091\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 65 iteration0, G Loss: 0.9956461191177368, D Loss: 1.39602792263031, alpha: 0.996352285179225\n",
      "epoch 65 iteration100, G Loss: 1.0899282693862915, D Loss: 1.2131214141845703, alpha: 0.996352285179225\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 66 iteration0, G Loss: 1.6830253601074219, D Loss: 1.6674443483352661, alpha: 0.9963304136549692\n",
      "epoch 66 iteration100, G Loss: 1.2472089529037476, D Loss: 1.3660027980804443, alpha: 0.9963304136549692\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 67 iteration0, G Loss: 0.9758114814758301, D Loss: 1.1109404563903809, alpha: 0.9963084114759856\n",
      "epoch 67 iteration100, G Loss: 0.844146192073822, D Loss: 1.163015365600586, alpha: 0.9963084114759856\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 68 iteration0, G Loss: 1.1020300388336182, D Loss: 1.2471630573272705, alpha: 0.9962862778676213\n",
      "epoch 68 iteration100, G Loss: 1.1096810102462769, D Loss: 1.334596037864685, alpha: 0.9962862778676213\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 69 iteration0, G Loss: 0.7500141859054565, D Loss: 1.2868971824645996, alpha: 0.9962640120507004\n",
      "epoch 69 iteration100, G Loss: 1.0156913995742798, D Loss: 1.274876594543457, alpha: 0.9962640120507004\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 70 iteration0, G Loss: 1.4628052711486816, D Loss: 1.3482615947723389, alpha: 0.9962416132414992\n",
      "epoch 70 iteration100, G Loss: 1.9421734809875488, D Loss: 1.2884770631790161, alpha: 0.9962416132414992\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 71 iteration0, G Loss: 1.2219496965408325, D Loss: 1.3393230438232422, alpha: 0.9962190806517198\n",
      "epoch 71 iteration100, G Loss: 1.236377239227295, D Loss: 1.2159249782562256, alpha: 0.9962190806517198\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 72 iteration0, G Loss: 1.5650731325149536, D Loss: 1.325643539428711, alpha: 0.9961964134884649\n",
      "epoch 72 iteration100, G Loss: 1.2142447233200073, D Loss: 1.3197412490844727, alpha: 0.9961964134884649\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 73 iteration0, G Loss: 1.3336765766143799, D Loss: 1.2608546018600464, alpha: 0.9961736109542111\n",
      "epoch 73 iteration100, G Loss: 1.4447184801101685, D Loss: 1.279843807220459, alpha: 0.9961736109542111\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 74 iteration0, G Loss: 1.2821367979049683, D Loss: 1.2318439483642578, alpha: 0.9961506722467834\n",
      "epoch 74 iteration100, G Loss: 1.3098870515823364, D Loss: 1.3486613035202026, alpha: 0.9961506722467834\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 75 iteration0, G Loss: 1.6049606800079346, D Loss: 1.309981107711792, alpha: 0.9961275965593289\n",
      "epoch 75 iteration100, G Loss: 1.403041958808899, D Loss: 1.2200343608856201, alpha: 0.9961275965593289\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 76 iteration0, G Loss: 0.9299681186676025, D Loss: 1.2219771146774292, alpha: 0.9961043830802904\n",
      "epoch 76 iteration100, G Loss: 1.245540976524353, D Loss: 1.298771858215332, alpha: 0.9961043830802904\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 77 iteration0, G Loss: 1.2151066064834595, D Loss: 1.2732288837432861, alpha: 0.9960810309933794\n",
      "epoch 77 iteration100, G Loss: 0.9827873706817627, D Loss: 1.3576350212097168, alpha: 0.9960810309933794\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 78 iteration0, G Loss: 1.2407190799713135, D Loss: 1.169468879699707, alpha: 0.9960575394775504\n",
      "epoch 78 iteration100, G Loss: 0.7378765344619751, D Loss: 1.5085164308547974, alpha: 0.9960575394775504\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 79 iteration0, G Loss: 1.1136672496795654, D Loss: 1.3361271619796753, alpha: 0.996033907706973\n",
      "epoch 79 iteration100, G Loss: 1.5316362380981445, D Loss: 1.5486019849777222, alpha: 0.996033907706973\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 80 iteration0, G Loss: 1.1087361574172974, D Loss: 1.276216745376587, alpha: 0.9960101348510059\n",
      "epoch 80 iteration100, G Loss: 2.1065800189971924, D Loss: 1.2663532495498657, alpha: 0.9960101348510059\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 81 iteration0, G Loss: 0.832314670085907, D Loss: 1.3458770513534546, alpha: 0.9959862200741696\n",
      "epoch 81 iteration100, G Loss: 1.362358808517456, D Loss: 1.3541133403778076, alpha: 0.9959862200741696\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 82 iteration0, G Loss: 1.0522936582565308, D Loss: 1.1885919570922852, alpha: 0.9959621625361187\n",
      "epoch 82 iteration100, G Loss: 1.02851140499115, D Loss: 1.275001049041748, alpha: 0.9959621625361187\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 83 iteration0, G Loss: 0.849270761013031, D Loss: 1.3668553829193115, alpha: 0.9959379613916154\n",
      "epoch 83 iteration100, G Loss: 0.4946569502353668, D Loss: 1.263048529624939, alpha: 0.9959379613916154\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 84 iteration0, G Loss: 1.0442596673965454, D Loss: 1.1019365787506104, alpha: 0.9959136157905011\n",
      "epoch 84 iteration100, G Loss: 0.735486626625061, D Loss: 1.2122467756271362, alpha: 0.9959136157905011\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 85 iteration0, G Loss: 1.2510758638381958, D Loss: 1.3164258003234863, alpha: 0.9958891248776693\n",
      "epoch 85 iteration100, G Loss: 1.3770772218704224, D Loss: 1.2131576538085938, alpha: 0.9958891248776693\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 86 iteration0, G Loss: 0.749917209148407, D Loss: 1.1726109981536865, alpha: 0.9958644877930382\n",
      "epoch 86 iteration100, G Loss: 0.8622560501098633, D Loss: 1.9823551177978516, alpha: 0.9958644877930382\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 87 iteration0, G Loss: 1.8499634265899658, D Loss: 1.7234078645706177, alpha: 0.9958397036715217\n",
      "epoch 87 iteration100, G Loss: 1.1828984022140503, D Loss: 1.426867961883545, alpha: 0.9958397036715217\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 88 iteration0, G Loss: 1.3778131008148193, D Loss: 1.2251359224319458, alpha: 0.9958147716430024\n",
      "epoch 88 iteration100, G Loss: 0.943977952003479, D Loss: 1.2849845886230469, alpha: 0.9958147716430024\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 89 iteration0, G Loss: 0.8413410186767578, D Loss: 1.3889012336730957, alpha: 0.9957896908323025\n",
      "epoch 89 iteration100, G Loss: 1.093980312347412, D Loss: 1.098962426185608, alpha: 0.9957896908323025\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 90 iteration0, G Loss: 1.2698101997375488, D Loss: 1.243577480316162, alpha: 0.9957644603591566\n",
      "epoch 90 iteration100, G Loss: 0.6527689099311829, D Loss: 1.2966275215148926, alpha: 0.9957644603591566\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 91 iteration0, G Loss: 1.7416356801986694, D Loss: 1.0336055755615234, alpha: 0.9957390793381818\n",
      "epoch 91 iteration100, G Loss: 0.6961186528205872, D Loss: 1.247093915939331, alpha: 0.9957390793381818\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 92 iteration0, G Loss: 0.7112804055213928, D Loss: 1.3578530550003052, alpha: 0.9957135468788503\n",
      "epoch 92 iteration100, G Loss: 1.3598837852478027, D Loss: 1.272364616394043, alpha: 0.9957135468788503\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 93 iteration0, G Loss: 1.892794132232666, D Loss: 1.3485913276672363, alpha: 0.9956878620854597\n",
      "epoch 93 iteration100, G Loss: 1.1044965982437134, D Loss: 1.2348685264587402, alpha: 0.9956878620854597\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 94 iteration0, G Loss: 1.0548895597457886, D Loss: 1.4632846117019653, alpha: 0.9956620240571046\n",
      "epoch 94 iteration100, G Loss: 0.7194807529449463, D Loss: 1.44798743724823, alpha: 0.9956620240571046\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 95 iteration0, G Loss: 0.9329891204833984, D Loss: 1.3071051836013794, alpha: 0.9956360318876475\n",
      "epoch 95 iteration100, G Loss: 1.187981128692627, D Loss: 1.167540431022644, alpha: 0.9956360318876475\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 96 iteration0, G Loss: 0.6534550786018372, D Loss: 1.4950346946716309, alpha: 0.995609884665689\n",
      "epoch 96 iteration100, G Loss: 1.0529547929763794, D Loss: 1.3444623947143555, alpha: 0.995609884665689\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 97 iteration0, G Loss: 1.9246898889541626, D Loss: 1.0946402549743652, alpha: 0.9955835814745394\n",
      "epoch 97 iteration100, G Loss: 0.9761373996734619, D Loss: 1.4017146825790405, alpha: 0.9955835814745394\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 98 iteration0, G Loss: 1.2359938621520996, D Loss: 1.2001664638519287, alpha: 0.9955571213921881\n",
      "epoch 98 iteration100, G Loss: 0.9036486148834229, D Loss: 1.3714206218719482, alpha: 0.9955571213921881\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 99 iteration0, G Loss: 0.9525555968284607, D Loss: 1.2100774049758911, alpha: 0.9955305034912747\n",
      "epoch 99 iteration100, G Loss: 0.6191349029541016, D Loss: 1.3819235563278198, alpha: 0.9955305034912747\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 100 iteration0, G Loss: 1.2891955375671387, D Loss: 1.3755159378051758, alpha: 0.9955037268390589\n",
      "epoch 100 iteration100, G Loss: 0.9599674940109253, D Loss: 1.872506022453308, alpha: 0.9955037268390589\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 101 iteration0, G Loss: 1.0887434482574463, D Loss: 1.2605621814727783, alpha: 0.99547679049739\n",
      "epoch 101 iteration100, G Loss: 1.334281086921692, D Loss: 1.324193000793457, alpha: 0.99547679049739\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 102 iteration0, G Loss: 1.2880712747573853, D Loss: 1.0804879665374756, alpha: 0.9954496935226781\n",
      "epoch 102 iteration100, G Loss: 0.9760153293609619, D Loss: 1.2252893447875977, alpha: 0.9954496935226781\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 103 iteration0, G Loss: 1.1480597257614136, D Loss: 1.3765597343444824, alpha: 0.9954224349658624\n",
      "epoch 103 iteration100, G Loss: 1.2515498399734497, D Loss: 1.2429330348968506, alpha: 0.9954224349658624\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 104 iteration0, G Loss: 1.231377363204956, D Loss: 1.290461778640747, alpha: 0.9953950138723812\n",
      "epoch 104 iteration100, G Loss: 0.9631686806678772, D Loss: 1.3143906593322754, alpha: 0.9953950138723812\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 105 iteration0, G Loss: 1.6940598487854004, D Loss: 1.429856538772583, alpha: 0.9953674292821418\n",
      "epoch 105 iteration100, G Loss: 1.5079580545425415, D Loss: 1.4883582592010498, alpha: 0.9953674292821418\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 106 iteration0, G Loss: 1.2226938009262085, D Loss: 1.189838171005249, alpha: 0.9953396802294893\n",
      "epoch 106 iteration100, G Loss: 0.9327266216278076, D Loss: 1.4211844205856323, alpha: 0.9953396802294893\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 107 iteration0, G Loss: 1.5083458423614502, D Loss: 1.458986759185791, alpha: 0.9953117657431754\n",
      "epoch 107 iteration100, G Loss: 1.0220065116882324, D Loss: 1.248381495475769, alpha: 0.9953117657431754\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 108 iteration0, G Loss: 0.6926584243774414, D Loss: 1.2773265838623047, alpha: 0.9952836848463282\n",
      "epoch 108 iteration100, G Loss: 1.423586368560791, D Loss: 1.261828064918518, alpha: 0.9952836848463282\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 109 iteration0, G Loss: 1.5201997756958008, D Loss: 1.3979510068893433, alpha: 0.99525543655642\n",
      "epoch 109 iteration100, G Loss: 0.7775574326515198, D Loss: 1.1902179718017578, alpha: 0.99525543655642\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 110 iteration0, G Loss: 1.2385714054107666, D Loss: 1.2411653995513916, alpha: 0.9952270198852368\n",
      "epoch 110 iteration100, G Loss: 1.110825777053833, D Loss: 1.230257272720337, alpha: 0.9952270198852368\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 111 iteration0, G Loss: 0.9365814924240112, D Loss: 1.3089592456817627, alpha: 0.995198433838846\n",
      "epoch 111 iteration100, G Loss: 1.4876121282577515, D Loss: 1.2761582136154175, alpha: 0.995198433838846\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 112 iteration0, G Loss: 1.2359803915023804, D Loss: 1.397479772567749, alpha: 0.9951696774175651\n",
      "epoch 112 iteration100, G Loss: 1.414320945739746, D Loss: 1.1308009624481201, alpha: 0.9951696774175651\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 113 iteration0, G Loss: 1.0409035682678223, D Loss: 1.2200371026992798, alpha: 0.9951407496159302\n",
      "epoch 113 iteration100, G Loss: 1.4113270044326782, D Loss: 1.522934913635254, alpha: 0.9951407496159302\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 114 iteration0, G Loss: 1.1077721118927002, D Loss: 1.0771645307540894, alpha: 0.9951116494226631\n",
      "epoch 114 iteration100, G Loss: 1.1374351978302002, D Loss: 1.182259440422058, alpha: 0.9951116494226631\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 115 iteration0, G Loss: 2.580092191696167, D Loss: 2.2031965255737305, alpha: 0.9950823758206396\n",
      "epoch 115 iteration100, G Loss: 1.1133173704147339, D Loss: 1.1663625240325928, alpha: 0.9950823758206396\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 116 iteration0, G Loss: 1.6981712579727173, D Loss: 0.8805440664291382, alpha: 0.9950529277868578\n",
      "epoch 116 iteration100, G Loss: 2.2495388984680176, D Loss: 1.070338249206543, alpha: 0.9950529277868578\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 117 iteration0, G Loss: 1.1961675882339478, D Loss: 1.2197530269622803, alpha: 0.9950233042924043\n",
      "epoch 117 iteration100, G Loss: 1.276694893836975, D Loss: 1.2734037637710571, alpha: 0.9950233042924043\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 118 iteration0, G Loss: 1.2069737911224365, D Loss: 1.2674338817596436, alpha: 0.9949935043024226\n",
      "epoch 118 iteration100, G Loss: 1.3182387351989746, D Loss: 1.351619005203247, alpha: 0.9949935043024226\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 119 iteration0, G Loss: 0.97005295753479, D Loss: 1.3708442449569702, alpha: 0.9949635267760798\n",
      "epoch 119 iteration100, G Loss: 1.3709897994995117, D Loss: 1.205488681793213, alpha: 0.9949635267760798\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 120 iteration0, G Loss: 0.8457266092300415, D Loss: 1.360309362411499, alpha: 0.9949333706665338\n",
      "epoch 120 iteration100, G Loss: 0.9962816834449768, D Loss: 1.1673078536987305, alpha: 0.9949333706665338\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 121 iteration0, G Loss: 0.9226139783859253, D Loss: 1.3187155723571777, alpha: 0.9949030349208999\n",
      "epoch 121 iteration100, G Loss: 0.8440066576004028, D Loss: 1.1554611921310425, alpha: 0.9949030349208999\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 122 iteration0, G Loss: 1.7108039855957031, D Loss: 1.3003413677215576, alpha: 0.9948725184802181\n",
      "epoch 122 iteration100, G Loss: 1.197716236114502, D Loss: 1.199812650680542, alpha: 0.9948725184802181\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 123 iteration0, G Loss: 1.192132592201233, D Loss: 1.1836304664611816, alpha: 0.9948418202794187\n",
      "epoch 123 iteration100, G Loss: 2.285090684890747, D Loss: 1.2724534273147583, alpha: 0.9948418202794187\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 124 iteration0, G Loss: 1.0597543716430664, D Loss: 1.3357566595077515, alpha: 0.9948109392472895\n",
      "epoch 124 iteration100, G Loss: 1.307647466659546, D Loss: 1.3379840850830078, alpha: 0.9948109392472895\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 125 iteration0, G Loss: 2.4593260288238525, D Loss: 1.1911842823028564, alpha: 0.9947798743064415\n",
      "epoch 125 iteration100, G Loss: 1.5697376728057861, D Loss: 1.316082239151001, alpha: 0.9947798743064415\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 126 iteration0, G Loss: 1.411118984222412, D Loss: 1.2972681522369385, alpha: 0.9947486243732755\n",
      "epoch 126 iteration100, G Loss: 2.380340814590454, D Loss: 1.0373430252075195, alpha: 0.9947486243732755\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 127 iteration0, G Loss: 1.31471586227417, D Loss: 1.11911940574646, alpha: 0.994717188357947\n",
      "epoch 127 iteration100, G Loss: 1.82383394241333, D Loss: 1.6415406465530396, alpha: 0.994717188357947\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 128 iteration0, G Loss: 1.4838443994522095, D Loss: 1.5562670230865479, alpha: 0.9946855651643326\n",
      "epoch 128 iteration100, G Loss: 0.9910386800765991, D Loss: 1.4508225917816162, alpha: 0.9946855651643326\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 129 iteration0, G Loss: 1.5371477603912354, D Loss: 0.9115701913833618, alpha: 0.9946537536899958\n",
      "epoch 129 iteration100, G Loss: 1.2772296667099, D Loss: 1.194309949874878, alpha: 0.9946537536899958\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 130 iteration0, G Loss: 1.254160761833191, D Loss: 1.239776611328125, alpha: 0.9946217528261514\n",
      "epoch 130 iteration100, G Loss: 1.443385124206543, D Loss: 1.323879599571228, alpha: 0.9946217528261514\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 131 iteration0, G Loss: 1.2259382009506226, D Loss: 1.1015887260437012, alpha: 0.9945895614576316\n",
      "epoch 131 iteration100, G Loss: 1.3210268020629883, D Loss: 1.609612226486206, alpha: 0.9945895614576316\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 132 iteration0, G Loss: 1.6774535179138184, D Loss: 1.3797271251678467, alpha: 0.9945571784628505\n",
      "epoch 132 iteration100, G Loss: 1.2853776216506958, D Loss: 1.00877046585083, alpha: 0.9945571784628505\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 133 iteration0, G Loss: 0.9161839485168457, D Loss: 1.42500638961792, alpha: 0.9945246027137692\n",
      "epoch 133 iteration100, G Loss: 1.0340805053710938, D Loss: 1.2309529781341553, alpha: 0.9945246027137692\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 134 iteration0, G Loss: 1.6246551275253296, D Loss: 1.4055742025375366, alpha: 0.9944918330758603\n",
      "epoch 134 iteration100, G Loss: 1.0684698820114136, D Loss: 1.4197561740875244, alpha: 0.9944918330758603\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 135 iteration0, G Loss: 1.4400469064712524, D Loss: 0.9521632194519043, alpha: 0.9944588684080726\n",
      "epoch 135 iteration100, G Loss: 1.3252308368682861, D Loss: 1.3352477550506592, alpha: 0.9944588684080726\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 136 iteration0, G Loss: 1.2159851789474487, D Loss: 1.3985469341278076, alpha: 0.9944257075627952\n",
      "epoch 136 iteration100, G Loss: 1.274964690208435, D Loss: 1.2490458488464355, alpha: 0.9944257075627952\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 137 iteration0, G Loss: 1.4346920251846313, D Loss: 1.070275068283081, alpha: 0.994392349385822\n",
      "epoch 137 iteration100, G Loss: 1.4433343410491943, D Loss: 1.1112947463989258, alpha: 0.994392349385822\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 138 iteration0, G Loss: 1.3024134635925293, D Loss: 1.2914247512817383, alpha: 0.9943587927163153\n",
      "epoch 138 iteration100, G Loss: 2.0077004432678223, D Loss: 1.5572410821914673, alpha: 0.9943587927163153\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 139 iteration0, G Loss: 0.853666365146637, D Loss: 1.1671279668807983, alpha: 0.99432503638677\n",
      "epoch 139 iteration100, G Loss: 0.9965457916259766, D Loss: 1.4013779163360596, alpha: 0.99432503638677\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 140 iteration0, G Loss: 0.8541104197502136, D Loss: 1.6241731643676758, alpha: 0.9942910792229767\n",
      "epoch 140 iteration100, G Loss: 1.2205818891525269, D Loss: 1.3703961372375488, alpha: 0.9942910792229767\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 141 iteration0, G Loss: 0.7764196991920471, D Loss: 1.410089135169983, alpha: 0.9942569200439859\n",
      "epoch 141 iteration100, G Loss: 1.3147112131118774, D Loss: 1.183669090270996, alpha: 0.9942569200439859\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 142 iteration0, G Loss: 1.388945460319519, D Loss: 1.2607533931732178, alpha: 0.9942225576620709\n",
      "epoch 142 iteration100, G Loss: 1.356203317642212, D Loss: 1.2828785181045532, alpha: 0.9942225576620709\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 143 iteration0, G Loss: 0.9629521369934082, D Loss: 1.1119905710220337, alpha: 0.9941879908826907\n",
      "epoch 143 iteration100, G Loss: 0.6095144748687744, D Loss: 2.4648172855377197, alpha: 0.9941879908826907\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 144 iteration0, G Loss: 1.8511463403701782, D Loss: 1.23744535446167, alpha: 0.9941532185044534\n",
      "epoch 144 iteration100, G Loss: 1.4695767164230347, D Loss: 1.4192397594451904, alpha: 0.9941532185044534\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 145 iteration0, G Loss: 1.2530696392059326, D Loss: 1.2645390033721924, alpha: 0.9941182393190785\n",
      "epoch 145 iteration100, G Loss: 1.687155842781067, D Loss: 1.3754421472549438, alpha: 0.9941182393190785\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 146 iteration0, G Loss: 1.6564239263534546, D Loss: 1.335955023765564, alpha: 0.99408305211136\n",
      "epoch 146 iteration100, G Loss: 1.4053038358688354, D Loss: 1.2130857706069946, alpha: 0.99408305211136\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 147 iteration0, G Loss: 0.9932115077972412, D Loss: 1.4792208671569824, alpha: 0.9940476556591286\n",
      "epoch 147 iteration100, G Loss: 1.8579859733581543, D Loss: 1.307376742362976, alpha: 0.9940476556591286\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 148 iteration0, G Loss: 2.213970422744751, D Loss: 1.483346939086914, alpha: 0.9940120487332132\n",
      "epoch 148 iteration100, G Loss: 1.6282984018325806, D Loss: 0.9561702013015747, alpha: 0.9940120487332132\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 149 iteration0, G Loss: 0.8569661378860474, D Loss: 1.2212014198303223, alpha: 0.9939762300974047\n",
      "epoch 149 iteration100, G Loss: 0.908663272857666, D Loss: 1.0797243118286133, alpha: 0.9939762300974047\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 150 iteration0, G Loss: 0.9341819882392883, D Loss: 1.9124870300292969, alpha: 0.9939401985084159\n",
      "epoch 150 iteration100, G Loss: 1.9100935459136963, D Loss: 1.0745664834976196, alpha: 0.9939401985084159\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 151 iteration0, G Loss: 1.590873122215271, D Loss: 1.3129761219024658, alpha: 0.9939039527158445\n",
      "epoch 151 iteration100, G Loss: 1.6627146005630493, D Loss: 1.2195260524749756, alpha: 0.9939039527158445\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 152 iteration0, G Loss: 0.7445769309997559, D Loss: 2.0765483379364014, alpha: 0.9938674914621343\n",
      "epoch 152 iteration100, G Loss: 1.0926021337509155, D Loss: 1.1743214130401611, alpha: 0.9938674914621343\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 153 iteration0, G Loss: 1.6110721826553345, D Loss: 1.0775790214538574, alpha: 0.9938308134825361\n",
      "epoch 153 iteration100, G Loss: 1.5273975133895874, D Loss: 1.2941712141036987, alpha: 0.9938308134825361\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 154 iteration0, G Loss: 1.2551755905151367, D Loss: 0.9133037328720093, alpha: 0.9937939175050695\n",
      "epoch 154 iteration100, G Loss: 1.2561237812042236, D Loss: 1.1837666034698486, alpha: 0.9937939175050695\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 155 iteration0, G Loss: 1.5600416660308838, D Loss: 1.301741600036621, alpha: 0.9937568022504835\n",
      "epoch 155 iteration100, G Loss: 1.1338497400283813, D Loss: 1.2503023147583008, alpha: 0.9937568022504835\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 156 iteration0, G Loss: 1.0127394199371338, D Loss: 1.3556828498840332, alpha: 0.9937194664322172\n",
      "epoch 156 iteration100, G Loss: 1.530402660369873, D Loss: 1.230217695236206, alpha: 0.9937194664322172\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 157 iteration0, G Loss: 1.3172006607055664, D Loss: 1.2590248584747314, alpha: 0.9936819087563606\n",
      "epoch 157 iteration100, G Loss: 1.1830365657806396, D Loss: 1.3818254470825195, alpha: 0.9936819087563606\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 158 iteration0, G Loss: 1.5197982788085938, D Loss: 1.3185920715332031, alpha: 0.9936441279216154\n",
      "epoch 158 iteration100, G Loss: 1.3737647533416748, D Loss: 1.2436447143554688, alpha: 0.9936441279216154\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 159 iteration0, G Loss: 1.8212616443634033, D Loss: 1.1097517013549805, alpha: 0.9936061226192542\n",
      "epoch 159 iteration100, G Loss: 1.1582165956497192, D Loss: 1.1877365112304688, alpha: 0.9936061226192542\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 160 iteration0, G Loss: 1.2248505353927612, D Loss: 1.2088004350662231, alpha: 0.9935678915330813\n",
      "epoch 160 iteration100, G Loss: 1.6157655715942383, D Loss: 1.4050661325454712, alpha: 0.9935678915330813\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 161 iteration0, G Loss: 1.1306184530258179, D Loss: 1.2864998579025269, alpha: 0.9935294333393929\n",
      "epoch 161 iteration100, G Loss: 0.992128849029541, D Loss: 1.2356607913970947, alpha: 0.9935294333393929\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 162 iteration0, G Loss: 1.2308440208435059, D Loss: 1.2352876663208008, alpha: 0.9934907467069358\n",
      "epoch 162 iteration100, G Loss: 2.0900754928588867, D Loss: 1.199239730834961, alpha: 0.9934907467069358\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 163 iteration0, G Loss: 1.9869920015335083, D Loss: 1.0669926404953003, alpha: 0.9934518302968676\n",
      "epoch 163 iteration100, G Loss: 1.067868947982788, D Loss: 1.256643295288086, alpha: 0.9934518302968676\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 164 iteration0, G Loss: 1.3487465381622314, D Loss: 1.2493475675582886, alpha: 0.9934126827627158\n",
      "epoch 164 iteration100, G Loss: 1.0407814979553223, D Loss: 1.191542625427246, alpha: 0.9934126827627158\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 165 iteration0, G Loss: 1.5012906789779663, D Loss: 1.2776912450790405, alpha: 0.9933733027503371\n",
      "epoch 165 iteration100, G Loss: 1.425959587097168, D Loss: 1.0366004705429077, alpha: 0.9933733027503371\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 166 iteration0, G Loss: 1.08977472782135, D Loss: 1.209643840789795, alpha: 0.9933336888978759\n",
      "epoch 166 iteration100, G Loss: 1.7646652460098267, D Loss: 1.1554385423660278, alpha: 0.9933336888978759\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 167 iteration0, G Loss: 1.2146432399749756, D Loss: 1.1552797555923462, alpha: 0.9932938398357235\n",
      "epoch 167 iteration100, G Loss: 1.1134248971939087, D Loss: 1.0042188167572021, alpha: 0.9932938398357235\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 168 iteration0, G Loss: 0.8043373823165894, D Loss: 1.3152039051055908, alpha: 0.9932537541864765\n",
      "epoch 168 iteration100, G Loss: 1.519742488861084, D Loss: 1.2394219636917114, alpha: 0.9932537541864765\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 169 iteration0, G Loss: 1.404723882675171, D Loss: 1.1328588724136353, alpha: 0.9932134305648953\n",
      "epoch 169 iteration100, G Loss: 1.2078813314437866, D Loss: 1.8607330322265625, alpha: 0.9932134305648953\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 170 iteration0, G Loss: 1.7518508434295654, D Loss: 1.4024238586425781, alpha: 0.9931728675778618\n",
      "epoch 170 iteration100, G Loss: 1.2638283967971802, D Loss: 1.537712574005127, alpha: 0.9931728675778618\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 171 iteration0, G Loss: 1.4357211589813232, D Loss: 1.0075385570526123, alpha: 0.993132063824338\n",
      "epoch 171 iteration100, G Loss: 1.0237939357757568, D Loss: 1.3257346153259277, alpha: 0.993132063824338\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 172 iteration0, G Loss: 0.7543215751647949, D Loss: 1.0640959739685059, alpha: 0.9930910178953235\n",
      "epoch 172 iteration100, G Loss: 2.2446043491363525, D Loss: 1.5954679250717163, alpha: 0.9930910178953235\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 173 iteration0, G Loss: 1.0282992124557495, D Loss: 1.539250135421753, alpha: 0.9930497283738132\n",
      "epoch 173 iteration100, G Loss: 0.5789446234703064, D Loss: 1.0857499837875366, alpha: 0.9930497283738132\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 174 iteration0, G Loss: 1.5966928005218506, D Loss: 0.9256841540336609, alpha: 0.9930081938347545\n",
      "epoch 174 iteration100, G Loss: 1.4482531547546387, D Loss: 1.1986041069030762, alpha: 0.9930081938347545\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 175 iteration0, G Loss: 1.791526436805725, D Loss: 1.3466811180114746, alpha: 0.9929664128450049\n",
      "epoch 175 iteration100, G Loss: 1.73674738407135, D Loss: 1.3866490125656128, alpha: 0.9929664128450049\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 176 iteration0, G Loss: 1.8538106679916382, D Loss: 1.380448341369629, alpha: 0.9929243839632887\n",
      "epoch 176 iteration100, G Loss: 0.7655876874923706, D Loss: 1.4340903759002686, alpha: 0.9929243839632887\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 177 iteration0, G Loss: 1.9333698749542236, D Loss: 1.2346817255020142, alpha: 0.9928821057401542\n",
      "epoch 177 iteration100, G Loss: 3.04548716545105, D Loss: 1.738771915435791, alpha: 0.9928821057401542\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 178 iteration0, G Loss: 2.103890895843506, D Loss: 1.1941909790039062, alpha: 0.9928395767179302\n",
      "epoch 178 iteration100, G Loss: 1.2063627243041992, D Loss: 1.3037946224212646, alpha: 0.9928395767179302\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 179 iteration0, G Loss: 1.122464656829834, D Loss: 1.2515734434127808, alpha: 0.992796795430682\n",
      "epoch 179 iteration100, G Loss: 0.918687105178833, D Loss: 1.2807948589324951, alpha: 0.992796795430682\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 180 iteration0, G Loss: 1.2286206483840942, D Loss: 1.1316626071929932, alpha: 0.9927537604041685\n",
      "epoch 180 iteration100, G Loss: 1.4714910984039307, D Loss: 1.0655438899993896, alpha: 0.9927537604041685\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 181 iteration0, G Loss: 1.3038800954818726, D Loss: 0.9761139750480652, alpha: 0.9927104701557979\n",
      "epoch 181 iteration100, G Loss: 1.299980878829956, D Loss: 1.0295310020446777, alpha: 0.9927104701557979\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 182 iteration0, G Loss: 1.2959264516830444, D Loss: 1.0972925424575806, alpha: 0.9926669231945832\n",
      "epoch 182 iteration100, G Loss: 1.4727556705474854, D Loss: 1.094222068786621, alpha: 0.9926669231945832\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 183 iteration0, G Loss: 1.1811343431472778, D Loss: 1.1946278810501099, alpha: 0.9926231180210985\n",
      "epoch 183 iteration100, G Loss: 2.163806200027466, D Loss: 1.337829351425171, alpha: 0.9926231180210985\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 184 iteration0, G Loss: 2.0116381645202637, D Loss: 1.1933839321136475, alpha: 0.9925790531274342\n",
      "epoch 184 iteration100, G Loss: 1.746407151222229, D Loss: 2.196425437927246, alpha: 0.9925790531274342\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 185 iteration0, G Loss: 1.942520022392273, D Loss: 1.2268853187561035, alpha: 0.9925347269971523\n",
      "epoch 185 iteration100, G Loss: 1.6945064067840576, D Loss: 1.2933990955352783, alpha: 0.9925347269971523\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 186 iteration0, G Loss: 0.9900369644165039, D Loss: 1.5498055219650269, alpha: 0.9924901381052417\n",
      "epoch 186 iteration100, G Loss: 1.2925792932510376, D Loss: 1.2660033702850342, alpha: 0.9924901381052417\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 187 iteration0, G Loss: 1.0680683851242065, D Loss: 1.061588168144226, alpha: 0.9924452849180726\n",
      "epoch 187 iteration100, G Loss: 1.863377332687378, D Loss: 1.163913607597351, alpha: 0.9924452849180726\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 188 iteration0, G Loss: 0.8132296800613403, D Loss: 1.123150110244751, alpha: 0.9924001658933519\n",
      "epoch 188 iteration100, G Loss: 1.1132808923721313, D Loss: 1.1545917987823486, alpha: 0.9924001658933519\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 189 iteration0, G Loss: 0.9004244208335876, D Loss: 1.2284166812896729, alpha: 0.9923547794800773\n",
      "epoch 189 iteration100, G Loss: 2.8518574237823486, D Loss: 1.1514294147491455, alpha: 0.9923547794800773\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 190 iteration0, G Loss: 1.1383864879608154, D Loss: 1.27055025100708, alpha: 0.9923091241184917\n",
      "epoch 190 iteration100, G Loss: 1.2808201313018799, D Loss: 1.1280145645141602, alpha: 0.9923091241184917\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 191 iteration0, G Loss: 1.143111228942871, D Loss: 1.1973819732666016, alpha: 0.9922631982400372\n",
      "epoch 191 iteration100, G Loss: 0.9122638702392578, D Loss: 0.9549658298492432, alpha: 0.9922631982400372\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 192 iteration0, G Loss: 1.6400171518325806, D Loss: 1.3320351839065552, alpha: 0.9922170002673092\n",
      "epoch 192 iteration100, G Loss: 1.905819296836853, D Loss: 1.4449186325073242, alpha: 0.9922170002673092\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 193 iteration0, G Loss: 1.640495777130127, D Loss: 1.3217658996582031, alpha: 0.9921705286140102\n",
      "epoch 193 iteration100, G Loss: 1.0846115350723267, D Loss: 0.9742749929428101, alpha: 0.9921705286140102\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 194 iteration0, G Loss: 1.1622426509857178, D Loss: 1.3897322416305542, alpha: 0.9921237816849032\n",
      "epoch 194 iteration100, G Loss: 1.6214865446090698, D Loss: 1.3670729398727417, alpha: 0.9921237816849032\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 195 iteration0, G Loss: 1.059257984161377, D Loss: 1.2669641971588135, alpha: 0.992076757875765\n",
      "epoch 195 iteration100, G Loss: 0.6028786897659302, D Loss: 1.487999677658081, alpha: 0.992076757875765\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 196 iteration0, G Loss: 1.1028043031692505, D Loss: 1.1212612390518188, alpha: 0.9920294555733393\n",
      "epoch 196 iteration100, G Loss: 1.033748984336853, D Loss: 1.280737280845642, alpha: 0.9920294555733393\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 197 iteration0, G Loss: 1.5352274179458618, D Loss: 1.5233221054077148, alpha: 0.9919818731552897\n",
      "epoch 197 iteration100, G Loss: 2.11505126953125, D Loss: 1.4178802967071533, alpha: 0.9919818731552897\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 198 iteration0, G Loss: 2.097517967224121, D Loss: 1.2112884521484375, alpha: 0.9919340089901527\n",
      "epoch 198 iteration100, G Loss: 3.294426441192627, D Loss: 1.441526174545288, alpha: 0.9919340089901527\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 199 iteration0, G Loss: 1.2655690908432007, D Loss: 1.2876803874969482, alpha: 0.9918858614372899\n",
      "epoch 199 iteration100, G Loss: 1.0285565853118896, D Loss: 1.2706941366195679, alpha: 0.9918858614372899\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 200 iteration0, G Loss: 1.193613886833191, D Loss: 0.9812363982200623, alpha: 0.9918374288468401\n",
      "epoch 200 iteration100, G Loss: 0.9089905023574829, D Loss: 1.2173157930374146, alpha: 0.9918374288468401\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 201 iteration0, G Loss: 1.4377052783966064, D Loss: 1.1527810096740723, alpha: 0.9917887095596722\n",
      "epoch 201 iteration100, G Loss: 0.812044084072113, D Loss: 1.185592532157898, alpha: 0.9917887095596722\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 202 iteration0, G Loss: 0.9269099235534668, D Loss: 1.3553600311279297, alpha: 0.9917397019073367\n",
      "epoch 202 iteration100, G Loss: 2.3211944103240967, D Loss: 1.340820550918579, alpha: 0.9917397019073367\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 203 iteration0, G Loss: 1.482960820198059, D Loss: 1.1379165649414062, alpha: 0.9916904042120173\n",
      "epoch 203 iteration100, G Loss: 1.161865472793579, D Loss: 1.0924861431121826, alpha: 0.9916904042120173\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 204 iteration0, G Loss: 1.1454795598983765, D Loss: 1.600139856338501, alpha: 0.9916408147864824\n",
      "epoch 204 iteration100, G Loss: 1.2351188659667969, D Loss: 1.8366155624389648, alpha: 0.9916408147864824\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 205 iteration0, G Loss: 1.172339916229248, D Loss: 1.2709994316101074, alpha: 0.991590931934037\n",
      "epoch 205 iteration100, G Loss: 1.49981689453125, D Loss: 1.3356221914291382, alpha: 0.991590931934037\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 206 iteration0, G Loss: 1.3536546230316162, D Loss: 1.2123167514801025, alpha: 0.9915407539484734\n",
      "epoch 206 iteration100, G Loss: 1.244253158569336, D Loss: 1.3328566551208496, alpha: 0.9915407539484734\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 207 iteration0, G Loss: 0.9706780910491943, D Loss: 1.2685329914093018, alpha: 0.9914902791140221\n",
      "epoch 207 iteration100, G Loss: 1.37470543384552, D Loss: 1.1086199283599854, alpha: 0.9914902791140221\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 208 iteration0, G Loss: 0.9941080808639526, D Loss: 1.2146658897399902, alpha: 0.9914395057053028\n",
      "epoch 208 iteration100, G Loss: 1.5214266777038574, D Loss: 1.2200915813446045, alpha: 0.9914395057053028\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 209 iteration0, G Loss: 1.6500635147094727, D Loss: 1.169539451599121, alpha: 0.9913884319872747\n",
      "epoch 209 iteration100, G Loss: 0.7650877237319946, D Loss: 1.4044735431671143, alpha: 0.9913884319872747\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 210 iteration0, G Loss: 1.0075243711471558, D Loss: 1.4702816009521484, alpha: 0.9913370562151869\n",
      "epoch 210 iteration100, G Loss: 0.9587140679359436, D Loss: 1.1890050172805786, alpha: 0.9913370562151869\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 211 iteration0, G Loss: 0.9635573625564575, D Loss: 1.3610780239105225, alpha: 0.9912853766345285\n",
      "epoch 211 iteration100, G Loss: 2.3602519035339355, D Loss: 1.4622632265090942, alpha: 0.9912853766345285\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 212 iteration0, G Loss: 1.067266583442688, D Loss: 1.5121006965637207, alpha: 0.9912333914809791\n",
      "epoch 212 iteration100, G Loss: 1.157989501953125, D Loss: 1.2875950336456299, alpha: 0.9912333914809791\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 213 iteration0, G Loss: 1.8869212865829468, D Loss: 1.2559309005737305, alpha: 0.9911810989803573\n",
      "epoch 213 iteration100, G Loss: 1.4986746311187744, D Loss: 1.24344003200531, alpha: 0.9911810989803573\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 214 iteration0, G Loss: 0.8450883626937866, D Loss: 1.262043833732605, alpha: 0.9911284973485716\n",
      "epoch 214 iteration100, G Loss: 1.0255142450332642, D Loss: 1.6487319469451904, alpha: 0.9911284973485716\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 215 iteration0, G Loss: 1.8974848985671997, D Loss: 1.5408415794372559, alpha: 0.9910755847915687\n",
      "epoch 215 iteration100, G Loss: 0.6614208221435547, D Loss: 1.5033879280090332, alpha: 0.9910755847915687\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 216 iteration0, G Loss: 1.4129303693771362, D Loss: 1.3069350719451904, alpha: 0.9910223595052832\n",
      "epoch 216 iteration100, G Loss: 1.0409643650054932, D Loss: 1.4066441059112549, alpha: 0.9910223595052832\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 217 iteration0, G Loss: 1.0429432392120361, D Loss: 1.1186039447784424, alpha: 0.9909688196755864\n",
      "epoch 217 iteration100, G Loss: 1.3540689945220947, D Loss: 1.2300350666046143, alpha: 0.9909688196755864\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 218 iteration0, G Loss: 1.9474501609802246, D Loss: 1.3542311191558838, alpha: 0.9909149634782348\n",
      "epoch 218 iteration100, G Loss: 1.1177501678466797, D Loss: 1.2604169845581055, alpha: 0.9909149634782348\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 219 iteration0, G Loss: 1.3222333192825317, D Loss: 1.1434211730957031, alpha: 0.990860789078819\n",
      "epoch 219 iteration100, G Loss: 0.6310655474662781, D Loss: 1.341808795928955, alpha: 0.990860789078819\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 220 iteration0, G Loss: 0.9634420871734619, D Loss: 1.1720798015594482, alpha: 0.9908062946327119\n",
      "epoch 220 iteration100, G Loss: 1.4871159791946411, D Loss: 1.234397292137146, alpha: 0.9908062946327119\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 221 iteration0, G Loss: 2.174762010574341, D Loss: 1.44976806640625, alpha: 0.9907514782850164\n",
      "epoch 221 iteration100, G Loss: 1.6521329879760742, D Loss: 1.162388563156128, alpha: 0.9907514782850164\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 222 iteration0, G Loss: 1.0362329483032227, D Loss: 1.6508055925369263, alpha: 0.9906963381705141\n",
      "epoch 222 iteration100, G Loss: 2.2607851028442383, D Loss: 2.103029489517212, alpha: 0.9906963381705141\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 223 iteration0, G Loss: 1.7026528120040894, D Loss: 1.3275526762008667, alpha: 0.9906408724136121\n",
      "epoch 223 iteration100, G Loss: 1.8068780899047852, D Loss: 1.4795376062393188, alpha: 0.9906408724136121\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 224 iteration0, G Loss: 1.7213410139083862, D Loss: 1.1105048656463623, alpha: 0.9905850791282914\n",
      "epoch 224 iteration100, G Loss: 1.4823687076568604, D Loss: 1.219667673110962, alpha: 0.9905850791282914\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 225 iteration0, G Loss: 0.8461464643478394, D Loss: 1.267930030822754, alpha: 0.9905289564180539\n",
      "epoch 225 iteration100, G Loss: 1.074170708656311, D Loss: 1.2535154819488525, alpha: 0.9905289564180539\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 226 iteration0, G Loss: 1.8447723388671875, D Loss: 1.562657117843628, alpha: 0.990472502375869\n",
      "epoch 226 iteration100, G Loss: 1.3531080484390259, D Loss: 1.060080885887146, alpha: 0.990472502375869\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 227 iteration0, G Loss: 1.548513412475586, D Loss: 1.296118974685669, alpha: 0.9904157150841214\n",
      "epoch 227 iteration100, G Loss: 1.0744988918304443, D Loss: 1.193971037864685, alpha: 0.9904157150841214\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 228 iteration0, G Loss: 1.3397423028945923, D Loss: 1.3094819784164429, alpha: 0.9903585926145569\n",
      "epoch 228 iteration100, G Loss: 1.2427014112472534, D Loss: 1.3211841583251953, alpha: 0.9903585926145569\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 229 iteration0, G Loss: 0.6079546213150024, D Loss: 1.6675941944122314, alpha: 0.9903011330282299\n",
      "epoch 229 iteration100, G Loss: 1.3672550916671753, D Loss: 1.3321857452392578, alpha: 0.9903011330282299\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 230 iteration0, G Loss: 1.0012556314468384, D Loss: 1.1446324586868286, alpha: 0.9902433343754486\n",
      "epoch 230 iteration100, G Loss: 1.1264920234680176, D Loss: 1.2954132556915283, alpha: 0.9902433343754486\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 231 iteration0, G Loss: 1.2754148244857788, D Loss: 1.0738962888717651, alpha: 0.9901851946957222\n",
      "epoch 231 iteration100, G Loss: 1.3640908002853394, D Loss: 1.2647252082824707, alpha: 0.9901851946957222\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 232 iteration0, G Loss: 0.9976611137390137, D Loss: 1.3587298393249512, alpha: 0.990126712017706\n",
      "epoch 232 iteration100, G Loss: 0.7326564788818359, D Loss: 1.2519696950912476, alpha: 0.990126712017706\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 233 iteration0, G Loss: 0.8114065527915955, D Loss: 1.2446001768112183, alpha: 0.9900678843591474\n",
      "epoch 233 iteration100, G Loss: 1.4871705770492554, D Loss: 1.0836403369903564, alpha: 0.9900678843591474\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 234 iteration0, G Loss: 1.1085842847824097, D Loss: 1.734443187713623, alpha: 0.9900087097268315\n",
      "epoch 234 iteration100, G Loss: 1.8054300546646118, D Loss: 1.3957287073135376, alpha: 0.9900087097268315\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 235 iteration0, G Loss: 1.1566122770309448, D Loss: 1.2469841241836548, alpha: 0.9899491861165263\n",
      "epoch 235 iteration100, G Loss: 1.7964725494384766, D Loss: 1.3182462453842163, alpha: 0.9899491861165263\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 236 iteration0, G Loss: 0.9844945669174194, D Loss: 1.5123552083969116, alpha: 0.9898893115129276\n",
      "epoch 236 iteration100, G Loss: 1.500096321105957, D Loss: 0.9925307035446167, alpha: 0.9898893115129276\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 237 iteration0, G Loss: 1.3176419734954834, D Loss: 1.164685845375061, alpha: 0.9898290838896044\n",
      "epoch 237 iteration100, G Loss: 1.2907521724700928, D Loss: 1.4134178161621094, alpha: 0.9898290838896044\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 238 iteration0, G Loss: 1.3318145275115967, D Loss: 1.3408122062683105, alpha: 0.9897685012089434\n",
      "epoch 238 iteration100, G Loss: 1.2136030197143555, D Loss: 1.169813632965088, alpha: 0.9897685012089434\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 239 iteration0, G Loss: 1.1020616292953491, D Loss: 1.3060815334320068, alpha: 0.9897075614220929\n",
      "epoch 239 iteration100, G Loss: 0.5361629128456116, D Loss: 1.4222004413604736, alpha: 0.9897075614220929\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 240 iteration0, G Loss: 1.613765001296997, D Loss: 1.2564494609832764, alpha: 0.9896462624689083\n",
      "epoch 240 iteration100, G Loss: 1.1371264457702637, D Loss: 1.2389698028564453, alpha: 0.9896462624689083\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 241 iteration0, G Loss: 1.4713199138641357, D Loss: 1.2794790267944336, alpha: 0.9895846022778949\n",
      "epoch 241 iteration100, G Loss: 1.1128305196762085, D Loss: 1.5590564012527466, alpha: 0.9895846022778949\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 242 iteration0, G Loss: 0.8938066363334656, D Loss: 1.3888866901397705, alpha: 0.989522578766153\n",
      "epoch 242 iteration100, G Loss: 1.6541588306427002, D Loss: 1.244734525680542, alpha: 0.989522578766153\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 243 iteration0, G Loss: 0.6004644632339478, D Loss: 1.4270460605621338, alpha: 0.9894601898393207\n",
      "epoch 243 iteration100, G Loss: 0.8874020576477051, D Loss: 1.2072817087173462, alpha: 0.9894601898393207\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 244 iteration0, G Loss: 1.9697599411010742, D Loss: 1.5610144138336182, alpha: 0.9893974333915181\n",
      "epoch 244 iteration100, G Loss: 1.302858591079712, D Loss: 1.3114738464355469, alpha: 0.9893974333915181\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 245 iteration0, G Loss: 1.7090067863464355, D Loss: 1.4523545503616333, alpha: 0.98933430730529\n",
      "epoch 245 iteration100, G Loss: 1.209383249282837, D Loss: 1.2511909008026123, alpha: 0.98933430730529\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 246 iteration0, G Loss: 1.68150794506073, D Loss: 1.5883407592773438, alpha: 0.9892708094515494\n",
      "epoch 246 iteration100, G Loss: 0.8862825036048889, D Loss: 1.5581339597702026, alpha: 0.9892708094515494\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 247 iteration0, G Loss: 1.7395001649856567, D Loss: 1.0656640529632568, alpha: 0.9892069376895206\n",
      "epoch 247 iteration100, G Loss: 1.1712400913238525, D Loss: 1.360418438911438, alpha: 0.9892069376895206\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 248 iteration0, G Loss: 1.2778652906417847, D Loss: 1.32275390625, alpha: 0.9891426898666814\n",
      "epoch 248 iteration100, G Loss: 1.2782421112060547, D Loss: 1.4406366348266602, alpha: 0.9891426898666814\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 249 iteration0, G Loss: 1.441334843635559, D Loss: 1.3043454885482788, alpha: 0.9890780638187058\n",
      "epoch 249 iteration100, G Loss: 1.618969440460205, D Loss: 1.2489954233169556, alpha: 0.9890780638187058\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 250 iteration0, G Loss: 0.6197270750999451, D Loss: 1.7955372333526611, alpha: 0.9890130573694068\n",
      "epoch 250 iteration100, G Loss: 1.1531922817230225, D Loss: 1.3542588949203491, alpha: 0.9890130573694068\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 251 iteration0, G Loss: 0.8852628469467163, D Loss: 1.3364239931106567, alpha: 0.9889476683306779\n",
      "epoch 251 iteration100, G Loss: 1.6589359045028687, D Loss: 1.2069339752197266, alpha: 0.9889476683306779\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 252 iteration0, G Loss: 1.4891914129257202, D Loss: 1.2844021320343018, alpha: 0.9888818945024357\n",
      "epoch 252 iteration100, G Loss: 0.6139394044876099, D Loss: 1.8967794179916382, alpha: 0.9888818945024357\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 253 iteration0, G Loss: 1.2635809183120728, D Loss: 1.4184050559997559, alpha: 0.9888157336725607\n",
      "epoch 253 iteration100, G Loss: 1.4629592895507812, D Loss: 1.2315764427185059, alpha: 0.9888157336725607\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 254 iteration0, G Loss: 1.5448739528656006, D Loss: 1.3288685083389282, alpha: 0.9887491836168399\n",
      "epoch 254 iteration100, G Loss: 1.1267613172531128, D Loss: 1.3021209239959717, alpha: 0.9887491836168399\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 255 iteration0, G Loss: 2.4430692195892334, D Loss: 0.8999009728431702, alpha: 0.9886822420989076\n",
      "epoch 255 iteration100, G Loss: 1.7432498931884766, D Loss: 1.1079750061035156, alpha: 0.9886822420989076\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 256 iteration0, G Loss: 0.769781768321991, D Loss: 1.4569745063781738, alpha: 0.9886149068701868\n",
      "epoch 256 iteration100, G Loss: 1.1812505722045898, D Loss: 0.9579170346260071, alpha: 0.9886149068701868\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 257 iteration0, G Loss: 1.4174261093139648, D Loss: 1.350631833076477, alpha: 0.98854717566983\n",
      "epoch 257 iteration100, G Loss: 1.6427161693572998, D Loss: 1.1804494857788086, alpha: 0.98854717566983\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 258 iteration0, G Loss: 1.1246787309646606, D Loss: 1.1995009183883667, alpha: 0.9884790462246599\n",
      "epoch 258 iteration100, G Loss: 1.8366345167160034, D Loss: 1.251300573348999, alpha: 0.9884790462246599\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 259 iteration0, G Loss: 1.0358362197875977, D Loss: 1.1519179344177246, alpha: 0.9884105162491105\n",
      "epoch 259 iteration100, G Loss: 1.7946486473083496, D Loss: 1.0985794067382812, alpha: 0.9884105162491105\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 260 iteration0, G Loss: 0.8031700253486633, D Loss: 1.3137612342834473, alpha: 0.9883415834451669\n",
      "epoch 260 iteration100, G Loss: 1.2921251058578491, D Loss: 1.4313299655914307, alpha: 0.9883415834451669\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 261 iteration0, G Loss: 2.139277935028076, D Loss: 1.065436840057373, alpha: 0.9882722455023062\n",
      "epoch 261 iteration100, G Loss: 0.9557386636734009, D Loss: 1.1744924783706665, alpha: 0.9882722455023062\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 262 iteration0, G Loss: 1.566550850868225, D Loss: 1.4689878225326538, alpha: 0.9882025000974367\n",
      "epoch 262 iteration100, G Loss: 1.3472448587417603, D Loss: 1.1664049625396729, alpha: 0.9882025000974367\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 263 iteration0, G Loss: 0.8677992224693298, D Loss: 1.3395538330078125, alpha: 0.9881323448948387\n",
      "epoch 263 iteration100, G Loss: 1.0609325170516968, D Loss: 1.1285336017608643, alpha: 0.9881323448948387\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 264 iteration0, G Loss: 1.5560741424560547, D Loss: 1.2095502614974976, alpha: 0.9880617775461034\n",
      "epoch 264 iteration100, G Loss: 1.0534188747406006, D Loss: 1.3141229152679443, alpha: 0.9880617775461034\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 265 iteration0, G Loss: 0.6415752172470093, D Loss: 1.4425370693206787, alpha: 0.9879907956900726\n",
      "epoch 265 iteration100, G Loss: 1.966415286064148, D Loss: 1.4249505996704102, alpha: 0.9879907956900726\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 266 iteration0, G Loss: 1.1212204694747925, D Loss: 1.0112879276275635, alpha: 0.9879193969527783\n",
      "epoch 266 iteration100, G Loss: 1.234144687652588, D Loss: 1.2881944179534912, alpha: 0.9879193969527783\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 267 iteration0, G Loss: 1.3268018960952759, D Loss: 1.4048244953155518, alpha: 0.9878475789473815\n",
      "epoch 267 iteration100, G Loss: 1.6151258945465088, D Loss: 1.2841837406158447, alpha: 0.9878475789473815\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 268 iteration0, G Loss: 0.9699214100837708, D Loss: 1.2922296524047852, alpha: 0.9877753392741111\n",
      "epoch 268 iteration100, G Loss: 1.0440504550933838, D Loss: 1.2870908975601196, alpha: 0.9877753392741111\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 269 iteration0, G Loss: 1.15784752368927, D Loss: 1.211114764213562, alpha: 0.9877026755202027\n",
      "epoch 269 iteration100, G Loss: 1.3158173561096191, D Loss: 1.508588433265686, alpha: 0.9877026755202027\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 270 iteration0, G Loss: 1.3020144701004028, D Loss: 1.2635456323623657, alpha: 0.9876295852598376\n",
      "epoch 270 iteration100, G Loss: 0.8790497779846191, D Loss: 1.278512954711914, alpha: 0.9876295852598376\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 271 iteration0, G Loss: 1.2787361145019531, D Loss: 1.302206039428711, alpha: 0.9875560660540803\n",
      "epoch 271 iteration100, G Loss: 1.5258206129074097, D Loss: 2.586602210998535, alpha: 0.9875560660540803\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 272 iteration0, G Loss: 0.7352198958396912, D Loss: 1.2723318338394165, alpha: 0.9874821154508174\n",
      "epoch 272 iteration100, G Loss: 0.657767653465271, D Loss: 1.7765496969223022, alpha: 0.9874821154508174\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 273 iteration0, G Loss: 1.7379823923110962, D Loss: 1.2192620038986206, alpha: 0.9874077309846958\n",
      "epoch 273 iteration100, G Loss: 0.9901275038719177, D Loss: 1.2322053909301758, alpha: 0.9874077309846958\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 274 iteration0, G Loss: 0.8809946775436401, D Loss: 2.0880236625671387, alpha: 0.9873329101770595\n",
      "epoch 274 iteration100, G Loss: 1.0521034002304077, D Loss: 0.9303882718086243, alpha: 0.9873329101770595\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 275 iteration0, G Loss: 0.8690333366394043, D Loss: 1.2819976806640625, alpha: 0.9872576505358884\n",
      "epoch 275 iteration100, G Loss: 1.1747009754180908, D Loss: 1.3308966159820557, alpha: 0.9872576505358884\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 276 iteration0, G Loss: 1.9140383005142212, D Loss: 1.3706791400909424, alpha: 0.9871819495557353\n",
      "epoch 276 iteration100, G Loss: 0.9879846572875977, D Loss: 1.286298155784607, alpha: 0.9871819495557353\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 277 iteration0, G Loss: 1.5151820182800293, D Loss: 1.4741524457931519, alpha: 0.9871058047176633\n",
      "epoch 277 iteration100, G Loss: 0.8824005722999573, D Loss: 1.4488255977630615, alpha: 0.9871058047176633\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 278 iteration0, G Loss: 1.4137681722640991, D Loss: 1.3163223266601562, alpha: 0.9870292134891828\n",
      "epoch 278 iteration100, G Loss: 1.601007342338562, D Loss: 1.6736713647842407, alpha: 0.9870292134891828\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 279 iteration0, G Loss: 1.3314790725708008, D Loss: 1.230642318725586, alpha: 0.9869521733241887\n",
      "epoch 279 iteration100, G Loss: 1.0031644105911255, D Loss: 1.2984411716461182, alpha: 0.9869521733241887\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 280 iteration0, G Loss: 1.6288806200027466, D Loss: 1.363944172859192, alpha: 0.9868746816628972\n",
      "epoch 280 iteration100, G Loss: 1.8859227895736694, D Loss: 1.4466674327850342, alpha: 0.9868746816628972\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 281 iteration0, G Loss: 1.2848374843597412, D Loss: 1.2346946001052856, alpha: 0.9867967359317822\n",
      "epoch 281 iteration100, G Loss: 0.6606132388114929, D Loss: 1.2683210372924805, alpha: 0.9867967359317822\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 282 iteration0, G Loss: 0.7975071668624878, D Loss: 1.5804266929626465, alpha: 0.986718333543512\n",
      "epoch 282 iteration100, G Loss: 0.9724456667900085, D Loss: 1.3099961280822754, alpha: 0.986718333543512\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 283 iteration0, G Loss: 1.3372060060501099, D Loss: 1.0966168642044067, alpha: 0.9866394718968857\n",
      "epoch 283 iteration100, G Loss: 0.872628927230835, D Loss: 1.132210373878479, alpha: 0.9866394718968857\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 284 iteration0, G Loss: 1.7440322637557983, D Loss: 1.0727276802062988, alpha: 0.986560148376769\n",
      "epoch 284 iteration100, G Loss: 0.4052814841270447, D Loss: 1.3989522457122803, alpha: 0.986560148376769\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 285 iteration0, G Loss: 1.2919360399246216, D Loss: 0.9047075510025024, alpha: 0.9864803603540304\n",
      "epoch 285 iteration100, G Loss: 1.3301562070846558, D Loss: 1.14042329788208, alpha: 0.9864803603540304\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 286 iteration0, G Loss: 1.6440694332122803, D Loss: 1.293350100517273, alpha: 0.9864001051854769\n",
      "epoch 286 iteration100, G Loss: 3.0878632068634033, D Loss: 0.8969876766204834, alpha: 0.9864001051854769\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 287 iteration0, G Loss: 1.1736578941345215, D Loss: 1.1521869897842407, alpha: 0.9863193802137901\n",
      "epoch 287 iteration100, G Loss: 1.4364564418792725, D Loss: 1.5960991382598877, alpha: 0.9863193802137901\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 288 iteration0, G Loss: 1.6172208786010742, D Loss: 1.2481896877288818, alpha: 0.9862381827674608\n",
      "epoch 288 iteration100, G Loss: 0.7709828615188599, D Loss: 1.3488082885742188, alpha: 0.9862381827674608\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 289 iteration0, G Loss: 1.3193671703338623, D Loss: 1.400568962097168, alpha: 0.9861565101607251\n",
      "epoch 289 iteration100, G Loss: 1.607047438621521, D Loss: 1.0156598091125488, alpha: 0.9861565101607251\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 290 iteration0, G Loss: 1.3090429306030273, D Loss: 1.0370347499847412, alpha: 0.9860743596934997\n",
      "epoch 290 iteration100, G Loss: 0.8133254051208496, D Loss: 1.3548352718353271, alpha: 0.9860743596934997\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 291 iteration0, G Loss: 0.9418425559997559, D Loss: 1.1585160493850708, alpha: 0.9859917286513157\n",
      "epoch 291 iteration100, G Loss: 1.1682558059692383, D Loss: 1.4638744592666626, alpha: 0.9859917286513157\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 292 iteration0, G Loss: 0.9769264459609985, D Loss: 1.1995320320129395, alpha: 0.9859086143052553\n",
      "epoch 292 iteration100, G Loss: 1.3319122791290283, D Loss: 1.2673370838165283, alpha: 0.9859086143052553\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 293 iteration0, G Loss: 1.305713176727295, D Loss: 1.2457956075668335, alpha: 0.9858250139118848\n",
      "epoch 293 iteration100, G Loss: 1.4347331523895264, D Loss: 1.3258112668991089, alpha: 0.9858250139118848\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 294 iteration0, G Loss: 1.5542017221450806, D Loss: 1.1604655981063843, alpha: 0.9857409247131904\n",
      "epoch 294 iteration100, G Loss: 1.4601116180419922, D Loss: 0.9697068929672241, alpha: 0.9857409247131904\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 295 iteration0, G Loss: 1.6876709461212158, D Loss: 1.0435734987258911, alpha: 0.9856563439365119\n",
      "epoch 295 iteration100, G Loss: 1.4560679197311401, D Loss: 1.227165699005127, alpha: 0.9856563439365119\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 296 iteration0, G Loss: 0.7011497020721436, D Loss: 1.5121090412139893, alpha: 0.9855712687944772\n",
      "epoch 296 iteration100, G Loss: 0.8563131093978882, D Loss: 1.2908953428268433, alpha: 0.9855712687944772\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 297 iteration0, G Loss: 1.3149389028549194, D Loss: 1.2600806951522827, alpha: 0.9854856964849366\n",
      "epoch 297 iteration100, G Loss: 1.2199227809906006, D Loss: 1.3480470180511475, alpha: 0.9854856964849366\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 298 iteration0, G Loss: 0.9542988538742065, D Loss: 1.7588560581207275, alpha: 0.9853996241908963\n",
      "epoch 298 iteration100, G Loss: 1.5497736930847168, D Loss: 1.9143468141555786, alpha: 0.9853996241908963\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 299 iteration0, G Loss: 1.503243327140808, D Loss: 1.2154568433761597, alpha: 0.985313049080453\n",
      "epoch 299 iteration100, G Loss: 1.243664264678955, D Loss: 1.2545576095581055, alpha: 0.985313049080453\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 300 iteration0, G Loss: 1.1181983947753906, D Loss: 1.2368534803390503, alpha: 0.9852259683067269\n",
      "epoch 300 iteration100, G Loss: 1.2017093896865845, D Loss: 1.1443562507629395, alpha: 0.9852259683067269\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 301 iteration0, G Loss: 1.5785768032073975, D Loss: 1.5791223049163818, alpha: 0.9851383790077956\n",
      "epoch 301 iteration100, G Loss: 1.117153525352478, D Loss: 1.2853400707244873, alpha: 0.9851383790077956\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 302 iteration0, G Loss: 1.3097162246704102, D Loss: 1.185569405555725, alpha: 0.9850502783066273\n",
      "epoch 302 iteration100, G Loss: 1.4051344394683838, D Loss: 1.1770415306091309, alpha: 0.9850502783066273\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 303 iteration0, G Loss: 1.2150121927261353, D Loss: 1.2163419723510742, alpha: 0.9849616633110144\n",
      "epoch 303 iteration100, G Loss: 0.31949180364608765, D Loss: 1.4132020473480225, alpha: 0.9849616633110144\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 304 iteration0, G Loss: 1.054282784461975, D Loss: 1.2744266986846924, alpha: 0.9848725311135066\n",
      "epoch 304 iteration100, G Loss: 0.9774966835975647, D Loss: 1.3001389503479004, alpha: 0.9848725311135066\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 305 iteration0, G Loss: 1.4071435928344727, D Loss: 1.128582239151001, alpha: 0.9847828787913437\n",
      "epoch 305 iteration100, G Loss: 1.2710052728652954, D Loss: 1.049271821975708, alpha: 0.9847828787913437\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 306 iteration0, G Loss: 1.506516933441162, D Loss: 1.0224770307540894, alpha: 0.9846927034063887\n",
      "epoch 306 iteration100, G Loss: 1.0113497972488403, D Loss: 1.2996782064437866, alpha: 0.9846927034063887\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 307 iteration0, G Loss: 1.657383918762207, D Loss: 1.1467370986938477, alpha: 0.9846020020050607\n",
      "epoch 307 iteration100, G Loss: 2.5407631397247314, D Loss: 0.826866865158081, alpha: 0.9846020020050607\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 308 iteration0, G Loss: 2.6814844608306885, D Loss: 1.772768259048462, alpha: 0.984510771618267\n",
      "epoch 308 iteration100, G Loss: 1.1606647968292236, D Loss: 1.2481422424316406, alpha: 0.984510771618267\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 309 iteration0, G Loss: 0.8708277940750122, D Loss: 1.2062489986419678, alpha: 0.9844190092613365\n",
      "epoch 309 iteration100, G Loss: 1.0931386947631836, D Loss: 1.1764010190963745, alpha: 0.9844190092613365\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 310 iteration0, G Loss: 1.331241488456726, D Loss: 1.259278655052185, alpha: 0.9843267119339514\n",
      "epoch 310 iteration100, G Loss: 0.8511778116226196, D Loss: 1.1518561840057373, alpha: 0.9843267119339514\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 311 iteration0, G Loss: 1.092603087425232, D Loss: 1.3631823062896729, alpha: 0.9842338766200798\n",
      "epoch 311 iteration100, G Loss: 0.9093471169471741, D Loss: 1.1539126634597778, alpha: 0.9842338766200798\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 312 iteration0, G Loss: 1.608620524406433, D Loss: 1.1082758903503418, alpha: 0.9841405002879078\n",
      "epoch 312 iteration100, G Loss: 1.5961027145385742, D Loss: 1.324678659439087, alpha: 0.9841405002879078\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 313 iteration0, G Loss: 1.8535479307174683, D Loss: 1.5846161842346191, alpha: 0.9840465798897717\n",
      "epoch 313 iteration100, G Loss: 1.2479361295700073, D Loss: 1.3449753522872925, alpha: 0.9840465798897717\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 314 iteration0, G Loss: 2.302936553955078, D Loss: 1.141047716140747, alpha: 0.98395211236209\n",
      "epoch 314 iteration100, G Loss: 1.1389820575714111, D Loss: 1.2477245330810547, alpha: 0.98395211236209\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 315 iteration0, G Loss: 1.418973445892334, D Loss: 1.2264647483825684, alpha: 0.9838570946252948\n",
      "epoch 315 iteration100, G Loss: 1.2783639430999756, D Loss: 1.2874042987823486, alpha: 0.9838570946252948\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 316 iteration0, G Loss: 2.0349252223968506, D Loss: 0.9859635829925537, alpha: 0.9837615235837642\n",
      "epoch 316 iteration100, G Loss: 0.966076135635376, D Loss: 1.2578271627426147, alpha: 0.9837615235837642\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 317 iteration0, G Loss: 1.5643560886383057, D Loss: 1.1512200832366943, alpha: 0.9836653961257537\n",
      "epoch 317 iteration100, G Loss: 1.2519702911376953, D Loss: 1.0861825942993164, alpha: 0.9836653961257537\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 318 iteration0, G Loss: 1.1662039756774902, D Loss: 1.230560541152954, alpha: 0.9835687091233274\n",
      "epoch 318 iteration100, G Loss: 1.5893051624298096, D Loss: 0.9264736771583557, alpha: 0.9835687091233274\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 319 iteration0, G Loss: 1.3112245798110962, D Loss: 1.0294491052627563, alpha: 0.9834714594322902\n",
      "epoch 319 iteration100, G Loss: 1.6148021221160889, D Loss: 1.2712831497192383, alpha: 0.9834714594322902\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 320 iteration0, G Loss: 1.5440179109573364, D Loss: 1.037930965423584, alpha: 0.9833736438921183\n",
      "epoch 320 iteration100, G Loss: 2.1055445671081543, D Loss: 1.0005314350128174, alpha: 0.9833736438921183\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 321 iteration0, G Loss: 2.2270925045013428, D Loss: 1.3513814210891724, alpha: 0.9832752593258914\n",
      "epoch 321 iteration100, G Loss: 1.6971536874771118, D Loss: 1.4608726501464844, alpha: 0.9832752593258914\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 322 iteration0, G Loss: 1.215917944908142, D Loss: 1.148289442062378, alpha: 0.9831763025402231\n",
      "epoch 322 iteration100, G Loss: 1.284945011138916, D Loss: 1.1834661960601807, alpha: 0.9831763025402231\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 323 iteration0, G Loss: 1.3023784160614014, D Loss: 1.3506180047988892, alpha: 0.9830767703251925\n",
      "epoch 323 iteration100, G Loss: 1.7970490455627441, D Loss: 1.2338902950286865, alpha: 0.9830767703251925\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 324 iteration0, G Loss: 1.663085699081421, D Loss: 1.1312775611877441, alpha: 0.9829766594542746\n",
      "epoch 324 iteration100, G Loss: 1.3779865503311157, D Loss: 1.150075912475586, alpha: 0.9829766594542746\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 325 iteration0, G Loss: 1.609910011291504, D Loss: 1.0070393085479736, alpha: 0.9828759666842722\n",
      "epoch 325 iteration100, G Loss: 1.8479779958724976, D Loss: 1.6166436672210693, alpha: 0.9828759666842722\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 326 iteration0, G Loss: 2.3868231773376465, D Loss: 2.5452399253845215, alpha: 0.9827746887552462\n",
      "epoch 326 iteration100, G Loss: 0.9027421474456787, D Loss: 1.1535708904266357, alpha: 0.9827746887552462\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 327 iteration0, G Loss: 1.0492867231369019, D Loss: 1.4057255983352661, alpha: 0.9826728223904461\n",
      "epoch 327 iteration100, G Loss: 2.22308349609375, D Loss: 1.0820834636688232, alpha: 0.9826728223904461\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 328 iteration0, G Loss: 1.175857424736023, D Loss: 1.2186195850372314, alpha: 0.9825703642962413\n",
      "epoch 328 iteration100, G Loss: 1.5519808530807495, D Loss: 1.4301788806915283, alpha: 0.9825703642962413\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 329 iteration0, G Loss: 2.0884721279144287, D Loss: 1.3880060911178589, alpha: 0.9824673111620515\n",
      "epoch 329 iteration100, G Loss: 0.9727914929389954, D Loss: 1.187915563583374, alpha: 0.9824673111620515\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 330 iteration0, G Loss: 0.9167304039001465, D Loss: 1.1562501192092896, alpha: 0.9823636596602773\n",
      "epoch 330 iteration100, G Loss: 1.0972495079040527, D Loss: 1.158815860748291, alpha: 0.9823636596602773\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 331 iteration0, G Loss: 1.9805265665054321, D Loss: 0.9011250734329224, alpha: 0.9822594064462308\n",
      "epoch 331 iteration100, G Loss: 1.4667384624481201, D Loss: 1.2007685899734497, alpha: 0.9822594064462308\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 332 iteration0, G Loss: 0.7660006880760193, D Loss: 1.1545435190200806, alpha: 0.9821545481580658\n",
      "epoch 332 iteration100, G Loss: 1.4114412069320679, D Loss: 1.1874550580978394, alpha: 0.9821545481580658\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 333 iteration0, G Loss: 1.1703159809112549, D Loss: 1.1832902431488037, alpha: 0.9820490814167088\n",
      "epoch 333 iteration100, G Loss: 1.1846601963043213, D Loss: 1.1517186164855957, alpha: 0.9820490814167088\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 334 iteration0, G Loss: 0.8445055484771729, D Loss: 1.1153515577316284, alpha: 0.9819430028257886\n",
      "epoch 334 iteration100, G Loss: 1.3835610151290894, D Loss: 0.8750648498535156, alpha: 0.9819430028257886\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 335 iteration0, G Loss: 2.395533323287964, D Loss: 0.9628848433494568, alpha: 0.9818363089715675\n",
      "epoch 335 iteration100, G Loss: 0.9874773621559143, D Loss: 1.186513066291809, alpha: 0.9818363089715675\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 336 iteration0, G Loss: 1.2605396509170532, D Loss: 1.2966575622558594, alpha: 0.9817289964228708\n",
      "epoch 336 iteration100, G Loss: 0.9035601615905762, D Loss: 1.4300708770751953, alpha: 0.9817289964228708\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 337 iteration0, G Loss: 1.0459024906158447, D Loss: 1.3580007553100586, alpha: 0.9816210617310175\n",
      "epoch 337 iteration100, G Loss: 1.5315645933151245, D Loss: 1.281446933746338, alpha: 0.9816210617310175\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 338 iteration0, G Loss: 1.077560544013977, D Loss: 1.274735927581787, alpha: 0.9815125014297503\n",
      "epoch 338 iteration100, G Loss: 0.8787984848022461, D Loss: 1.5573335886001587, alpha: 0.9815125014297503\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 339 iteration0, G Loss: 0.6789124608039856, D Loss: 1.072762370109558, alpha: 0.981403312035166\n",
      "epoch 339 iteration100, G Loss: 1.3932000398635864, D Loss: 1.138752818107605, alpha: 0.981403312035166\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 340 iteration0, G Loss: 1.7289396524429321, D Loss: 1.4885029792785645, alpha: 0.9812934900456454\n",
      "epoch 340 iteration100, G Loss: 1.205834984779358, D Loss: 1.4142155647277832, alpha: 0.9812934900456454\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 341 iteration0, G Loss: 1.5963581800460815, D Loss: 1.144162893295288, alpha: 0.9811830319417836\n",
      "epoch 341 iteration100, G Loss: 1.6739095449447632, D Loss: 1.1491469144821167, alpha: 0.9811830319417836\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 342 iteration0, G Loss: 1.8092466592788696, D Loss: 1.829395055770874, alpha: 0.9810719341863199\n",
      "epoch 342 iteration100, G Loss: 0.9828884601593018, D Loss: 1.0916218757629395, alpha: 0.9810719341863199\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 343 iteration0, G Loss: 1.2933398485183716, D Loss: 1.191311240196228, alpha: 0.9809601932240681\n",
      "epoch 343 iteration100, G Loss: 1.1621006727218628, D Loss: 1.3212158679962158, alpha: 0.9809601932240681\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 344 iteration0, G Loss: 2.3955795764923096, D Loss: 1.4344372749328613, alpha: 0.9808478054818466\n",
      "epoch 344 iteration100, G Loss: 1.3099089860916138, D Loss: 1.1756012439727783, alpha: 0.9808478054818466\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 345 iteration0, G Loss: 1.0144304037094116, D Loss: 1.3289960622787476, alpha: 0.9807347673684084\n",
      "epoch 345 iteration100, G Loss: 1.3305519819259644, D Loss: 1.2895512580871582, alpha: 0.9807347673684084\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 346 iteration0, G Loss: 1.5116240978240967, D Loss: 1.5589971542358398, alpha: 0.9806210752743707\n",
      "epoch 346 iteration100, G Loss: 0.527802586555481, D Loss: 1.3434886932373047, alpha: 0.9806210752743707\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 347 iteration0, G Loss: 0.793310821056366, D Loss: 1.2438459396362305, alpha: 0.9805067255721459\n",
      "epoch 347 iteration100, G Loss: 1.3745672702789307, D Loss: 1.1100199222564697, alpha: 0.9805067255721459\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 348 iteration0, G Loss: 2.187650680541992, D Loss: 1.2240357398986816, alpha: 0.9803917146158709\n",
      "epoch 348 iteration100, G Loss: 1.0763795375823975, D Loss: 1.2968119382858276, alpha: 0.9803917146158709\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 349 iteration0, G Loss: 2.1202714443206787, D Loss: 1.3076680898666382, alpha: 0.9802760387413375\n",
      "epoch 349 iteration100, G Loss: 1.4041173458099365, D Loss: 1.4303661584854126, alpha: 0.9802760387413375\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 350 iteration0, G Loss: 1.4796792268753052, D Loss: 1.1433861255645752, alpha: 0.9801596942659225\n",
      "epoch 350 iteration100, G Loss: 2.0538508892059326, D Loss: 1.4307878017425537, alpha: 0.9801596942659225\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 351 iteration0, G Loss: 1.9426469802856445, D Loss: 1.2436916828155518, alpha: 0.9800426774885175\n",
      "epoch 351 iteration100, G Loss: 1.1498870849609375, D Loss: 1.1415069103240967, alpha: 0.9800426774885175\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 352 iteration0, G Loss: 1.0268971920013428, D Loss: 1.2347149848937988, alpha: 0.9799249846894594\n",
      "epoch 352 iteration100, G Loss: 1.6042540073394775, D Loss: 1.244182825088501, alpha: 0.9799249846894594\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 353 iteration0, G Loss: 1.358731746673584, D Loss: 1.1699767112731934, alpha: 0.9798066121304606\n",
      "epoch 353 iteration100, G Loss: 1.2740330696105957, D Loss: 1.0421570539474487, alpha: 0.9798066121304606\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 354 iteration0, G Loss: 0.8923170566558838, D Loss: 1.4337871074676514, alpha: 0.9796875560545386\n",
      "epoch 354 iteration100, G Loss: 0.822848916053772, D Loss: 1.667434811592102, alpha: 0.9796875560545386\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 355 iteration0, G Loss: 0.8485471606254578, D Loss: 1.3377838134765625, alpha: 0.979567812685947\n",
      "epoch 355 iteration100, G Loss: 2.97042179107666, D Loss: 1.0425257682800293, alpha: 0.979567812685947\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 356 iteration0, G Loss: 1.6855577230453491, D Loss: 1.3639419078826904, alpha: 0.9794473782301051\n",
      "epoch 356 iteration100, G Loss: 0.7931848764419556, D Loss: 0.9968643188476562, alpha: 0.9794473782301051\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 357 iteration0, G Loss: 1.5614748001098633, D Loss: 1.3345738649368286, alpha: 0.9793262488735286\n",
      "epoch 357 iteration100, G Loss: 1.1420222520828247, D Loss: 1.1757229566574097, alpha: 0.9793262488735286\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 358 iteration0, G Loss: 1.2116868495941162, D Loss: 1.0596933364868164, alpha: 0.97920442078376\n",
      "epoch 358 iteration100, G Loss: 0.8702231049537659, D Loss: 1.180717945098877, alpha: 0.97920442078376\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 359 iteration0, G Loss: 1.548607587814331, D Loss: 1.1988346576690674, alpha: 0.9790818901092987\n",
      "epoch 359 iteration100, G Loss: 1.8017675876617432, D Loss: 1.0389139652252197, alpha: 0.9790818901092987\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 360 iteration0, G Loss: 1.6343812942504883, D Loss: 1.1129322052001953, alpha: 0.9789586529795318\n",
      "epoch 360 iteration100, G Loss: 1.097903847694397, D Loss: 1.1099860668182373, alpha: 0.9789586529795318\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 361 iteration0, G Loss: 1.6881580352783203, D Loss: 1.316866159439087, alpha: 0.9788347055046641\n",
      "epoch 361 iteration100, G Loss: 1.3244447708129883, D Loss: 1.1368190050125122, alpha: 0.9788347055046641\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 362 iteration0, G Loss: 1.7318987846374512, D Loss: 1.2021474838256836, alpha: 0.9787100437756497\n",
      "epoch 362 iteration100, G Loss: 1.4047863483428955, D Loss: 1.2058547735214233, alpha: 0.9787100437756497\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 363 iteration0, G Loss: 1.2495492696762085, D Loss: 1.0805914402008057, alpha: 0.9785846638641217\n",
      "epoch 363 iteration100, G Loss: 0.8802561163902283, D Loss: 1.8081295490264893, alpha: 0.9785846638641217\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 364 iteration0, G Loss: 0.740756094455719, D Loss: 1.3556525707244873, alpha: 0.9784585618223235\n",
      "epoch 364 iteration100, G Loss: 1.0427019596099854, D Loss: 1.1667895317077637, alpha: 0.9784585618223235\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 365 iteration0, G Loss: 0.8883969783782959, D Loss: 1.165708303451538, alpha: 0.9783317336830395\n",
      "epoch 365 iteration100, G Loss: 1.9278924465179443, D Loss: 1.1757386922836304, alpha: 0.9783317336830395\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 366 iteration0, G Loss: 1.4860917329788208, D Loss: 1.6474041938781738, alpha: 0.9782041754595261\n",
      "epoch 366 iteration100, G Loss: 0.9500831961631775, D Loss: 1.02978515625, alpha: 0.9782041754595261\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 367 iteration0, G Loss: 0.8439002633094788, D Loss: 1.202858328819275, alpha: 0.9780758831454427\n",
      "epoch 367 iteration100, G Loss: 1.388468623161316, D Loss: 1.0442888736724854, alpha: 0.9780758831454427\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 368 iteration0, G Loss: 1.6710652112960815, D Loss: 1.2290325164794922, alpha: 0.977946852714783\n",
      "epoch 368 iteration100, G Loss: 1.5224993228912354, D Loss: 1.0723038911819458, alpha: 0.977946852714783\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 369 iteration0, G Loss: 1.844934105873108, D Loss: 1.3572931289672852, alpha: 0.977817080121806\n",
      "epoch 369 iteration100, G Loss: 1.5075877904891968, D Loss: 1.1827082633972168, alpha: 0.977817080121806\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 370 iteration0, G Loss: 0.6491626501083374, D Loss: 1.0269889831542969, alpha: 0.9776865613009678\n",
      "epoch 370 iteration100, G Loss: 1.3547780513763428, D Loss: 1.029211401939392, alpha: 0.9776865613009678\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 371 iteration0, G Loss: 1.5460413694381714, D Loss: 1.3979535102844238, alpha: 0.9775552921668526\n",
      "epoch 371 iteration100, G Loss: 1.4678524732589722, D Loss: 1.334211826324463, alpha: 0.9775552921668526\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 372 iteration0, G Loss: 0.8413150310516357, D Loss: 1.1858747005462646, alpha: 0.9774232686141044\n",
      "epoch 372 iteration100, G Loss: 1.177860975265503, D Loss: 1.2088781595230103, alpha: 0.9774232686141044\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 373 iteration0, G Loss: 1.5601717233657837, D Loss: 1.2512328624725342, alpha: 0.9772904865173597\n",
      "epoch 373 iteration100, G Loss: 0.7542783617973328, D Loss: 1.3455311059951782, alpha: 0.9772904865173597\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 374 iteration0, G Loss: 1.7973860502243042, D Loss: 1.23586106300354, alpha: 0.977156941731178\n",
      "epoch 374 iteration100, G Loss: 1.3381915092468262, D Loss: 1.2759546041488647, alpha: 0.977156941731178\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 375 iteration0, G Loss: 1.542299509048462, D Loss: 1.314598560333252, alpha: 0.9770226300899744\n",
      "epoch 375 iteration100, G Loss: 0.8481993079185486, D Loss: 1.4755444526672363, alpha: 0.9770226300899744\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 376 iteration0, G Loss: 1.0279351472854614, D Loss: 1.3380918502807617, alpha: 0.9768875474079524\n",
      "epoch 376 iteration100, G Loss: 0.7131544351577759, D Loss: 1.2707724571228027, alpha: 0.9768875474079524\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 377 iteration0, G Loss: 0.8685424327850342, D Loss: 1.4503320455551147, alpha: 0.9767516894790355\n",
      "epoch 377 iteration100, G Loss: 2.279663562774658, D Loss: 1.3004838228225708, alpha: 0.9767516894790355\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 378 iteration0, G Loss: 1.811507225036621, D Loss: 1.1452146768569946, alpha: 0.9766150520767999\n",
      "epoch 378 iteration100, G Loss: 1.3123853206634521, D Loss: 0.8530954122543335, alpha: 0.9766150520767999\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 379 iteration0, G Loss: 2.0221469402313232, D Loss: 1.2145487070083618, alpha: 0.9764776309544076\n",
      "epoch 379 iteration100, G Loss: 1.0580369234085083, D Loss: 1.2791774272918701, alpha: 0.9764776309544076\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 380 iteration0, G Loss: 0.8125321269035339, D Loss: 1.711449384689331, alpha: 0.9763394218445388\n",
      "epoch 380 iteration100, G Loss: 1.0133239030838013, D Loss: 1.3364770412445068, alpha: 0.9763394218445388\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 381 iteration0, G Loss: 1.2320759296417236, D Loss: 1.275639533996582, alpha: 0.976200420459325\n",
      "epoch 381 iteration100, G Loss: 1.7476476430892944, D Loss: 1.3545863628387451, alpha: 0.976200420459325\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 382 iteration0, G Loss: 1.67133629322052, D Loss: 1.21506667137146, alpha: 0.9760606224902827\n",
      "epoch 382 iteration100, G Loss: 1.4743001461029053, D Loss: 1.3963408470153809, alpha: 0.9760606224902827\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 383 iteration0, G Loss: 0.9320357441902161, D Loss: 1.2930917739868164, alpha: 0.9759200236082463\n",
      "epoch 383 iteration100, G Loss: 1.2819550037384033, D Loss: 1.1038248538970947, alpha: 0.9759200236082463\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 384 iteration0, G Loss: 1.7978965044021606, D Loss: 1.319313883781433, alpha: 0.9757786194633021\n",
      "epoch 384 iteration100, G Loss: 2.115374803543091, D Loss: 1.2980087995529175, alpha: 0.9757786194633021\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 385 iteration0, G Loss: 1.5007377862930298, D Loss: 1.1880214214324951, alpha: 0.9756364056847221\n",
      "epoch 385 iteration100, G Loss: 2.658343553543091, D Loss: 1.5321719646453857, alpha: 0.9756364056847221\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 386 iteration0, G Loss: 0.5109784603118896, D Loss: 1.6227692365646362, alpha: 0.9754933778808983\n",
      "epoch 386 iteration100, G Loss: 1.2520495653152466, D Loss: 1.0233725309371948, alpha: 0.9754933778808983\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 387 iteration0, G Loss: 1.9545409679412842, D Loss: 1.5306220054626465, alpha: 0.9753495316392763\n",
      "epoch 387 iteration100, G Loss: 0.9661998748779297, D Loss: 1.336381196975708, alpha: 0.9753495316392763\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 388 iteration0, G Loss: 1.8767013549804688, D Loss: 0.9072274565696716, alpha: 0.9752048625262908\n",
      "epoch 388 iteration100, G Loss: 1.3034336566925049, D Loss: 1.0366530418395996, alpha: 0.9752048625262908\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 389 iteration0, G Loss: 1.9349135160446167, D Loss: 1.9581876993179321, alpha: 0.9750593660872999\n",
      "epoch 389 iteration100, G Loss: 1.251634120941162, D Loss: 1.4408459663391113, alpha: 0.9750593660872999\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 390 iteration0, G Loss: 1.7045693397521973, D Loss: 1.2242496013641357, alpha: 0.9749130378465202\n",
      "epoch 390 iteration100, G Loss: 1.5796751976013184, D Loss: 1.5401184558868408, alpha: 0.9749130378465202\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 391 iteration0, G Loss: 1.5603126287460327, D Loss: 1.4773383140563965, alpha: 0.974765873306962\n",
      "epoch 391 iteration100, G Loss: 0.9904046058654785, D Loss: 1.2989596128463745, alpha: 0.974765873306962\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 392 iteration0, G Loss: 3.240900754928589, D Loss: 1.379205346107483, alpha: 0.974617867950365\n",
      "epoch 392 iteration100, G Loss: 1.1600162982940674, D Loss: 1.322128415107727, alpha: 0.974617867950365\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 393 iteration0, G Loss: 1.5701804161071777, D Loss: 1.3416321277618408, alpha: 0.9744690172371344\n",
      "epoch 393 iteration100, G Loss: 2.5403895378112793, D Loss: 1.4637222290039062, alpha: 0.9744690172371344\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 394 iteration0, G Loss: 0.9817003011703491, D Loss: 1.33060622215271, alpha: 0.9743193166062767\n",
      "epoch 394 iteration100, G Loss: 1.2710609436035156, D Loss: 1.2131133079528809, alpha: 0.9743193166062767\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 395 iteration0, G Loss: 1.0754685401916504, D Loss: 1.1530014276504517, alpha: 0.9741687614753359\n",
      "epoch 395 iteration100, G Loss: 1.9228084087371826, D Loss: 1.2163469791412354, alpha: 0.9741687614753359\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 396 iteration0, G Loss: 1.6483707427978516, D Loss: 1.359189748764038, alpha: 0.9740173472403311\n",
      "epoch 396 iteration100, G Loss: 0.8176198601722717, D Loss: 1.2868419885635376, alpha: 0.9740173472403311\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 397 iteration0, G Loss: 0.5586717128753662, D Loss: 1.5671956539154053, alpha: 0.9738650692756922\n",
      "epoch 397 iteration100, G Loss: 1.1071854829788208, D Loss: 1.1675477027893066, alpha: 0.9738650692756922\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 398 iteration0, G Loss: 1.0670719146728516, D Loss: 1.1446682214736938, alpha: 0.9737119229341985\n",
      "epoch 398 iteration100, G Loss: 2.1424262523651123, D Loss: 1.2530673742294312, alpha: 0.9737119229341985\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 399 iteration0, G Loss: 1.214051604270935, D Loss: 1.2761446237564087, alpha: 0.9735579035469157\n",
      "epoch 399 iteration100, G Loss: 1.1576387882232666, D Loss: 1.1937897205352783, alpha: 0.9735579035469157\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 400 iteration0, G Loss: 1.3149741888046265, D Loss: 1.016136646270752, alpha: 0.9734030064231342\n",
      "epoch 400 iteration100, G Loss: 1.5633295774459839, D Loss: 1.3855507373809814, alpha: 0.9734030064231342\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 401 iteration0, G Loss: 1.2503736019134521, D Loss: 1.1418930292129517, alpha: 0.9732472268503066\n",
      "epoch 401 iteration100, G Loss: 1.0963592529296875, D Loss: 0.9869853258132935, alpha: 0.9732472268503066\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 402 iteration0, G Loss: 0.9977116584777832, D Loss: 1.1040685176849365, alpha: 0.9730905600939879\n",
      "epoch 402 iteration100, G Loss: 1.3552114963531494, D Loss: 1.1184027194976807, alpha: 0.9730905600939879\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 403 iteration0, G Loss: 1.3722528219223022, D Loss: 2.0044021606445312, alpha: 0.972933001397773\n",
      "epoch 403 iteration100, G Loss: 1.132218360900879, D Loss: 0.9896483421325684, alpha: 0.972933001397773\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 404 iteration0, G Loss: 1.5491082668304443, D Loss: 1.0857484340667725, alpha: 0.9727745459832368\n",
      "epoch 404 iteration100, G Loss: 1.8050687313079834, D Loss: 1.3866254091262817, alpha: 0.9727745459832368\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 405 iteration0, G Loss: 1.2686959505081177, D Loss: 1.153629183769226, alpha: 0.9726151890498743\n",
      "epoch 405 iteration100, G Loss: 1.0323835611343384, D Loss: 1.567538857460022, alpha: 0.9726151890498743\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 406 iteration0, G Loss: 1.3280143737792969, D Loss: 1.3721779584884644, alpha: 0.9724549257750401\n",
      "epoch 406 iteration100, G Loss: 1.1655532121658325, D Loss: 1.2521700859069824, alpha: 0.9724549257750401\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 407 iteration0, G Loss: 2.6043553352355957, D Loss: 1.4203107357025146, alpha: 0.9722937513138894\n",
      "epoch 407 iteration100, G Loss: 1.3861697912216187, D Loss: 1.2014832496643066, alpha: 0.9722937513138894\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 408 iteration0, G Loss: 0.995151937007904, D Loss: 0.9017228484153748, alpha: 0.9721316607993185\n",
      "epoch 408 iteration100, G Loss: 0.6375359892845154, D Loss: 1.894850254058838, alpha: 0.9721316607993185\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 409 iteration0, G Loss: 0.5731893181800842, D Loss: 1.5702697038650513, alpha: 0.9719686493419065\n",
      "epoch 409 iteration100, G Loss: 1.646803617477417, D Loss: 0.9350039958953857, alpha: 0.9719686493419065\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 410 iteration0, G Loss: 0.8345021605491638, D Loss: 1.1890136003494263, alpha: 0.9718047120298574\n",
      "epoch 410 iteration100, G Loss: 0.7489055395126343, D Loss: 1.244652271270752, alpha: 0.9718047120298574\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 411 iteration0, G Loss: 1.9933468103408813, D Loss: 1.0753310918807983, alpha: 0.9716398439289416\n",
      "epoch 411 iteration100, G Loss: 0.8323336243629456, D Loss: 1.342095136642456, alpha: 0.9716398439289416\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 412 iteration0, G Loss: 1.7090688943862915, D Loss: 1.1043016910552979, alpha: 0.9714740400824391\n",
      "epoch 412 iteration100, G Loss: 1.2989884614944458, D Loss: 1.4272143840789795, alpha: 0.9714740400824391\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 413 iteration0, G Loss: 1.0288704633712769, D Loss: 1.0978423357009888, alpha: 0.9713072955110821\n",
      "epoch 413 iteration100, G Loss: 1.1255769729614258, D Loss: 1.6317318677902222, alpha: 0.9713072955110821\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 414 iteration0, G Loss: 1.1372034549713135, D Loss: 1.2690367698669434, alpha: 0.9711396052129992\n",
      "epoch 414 iteration100, G Loss: 1.8818116188049316, D Loss: 1.0989229679107666, alpha: 0.9711396052129992\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 415 iteration0, G Loss: 0.9957098364830017, D Loss: 1.4867496490478516, alpha: 0.9709709641636592\n",
      "epoch 415 iteration100, G Loss: 1.4187958240509033, D Loss: 1.3646187782287598, alpha: 0.9709709641636592\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 416 iteration0, G Loss: 1.0519518852233887, D Loss: 1.7485157251358032, alpha: 0.9708013673158152\n",
      "epoch 416 iteration100, G Loss: 1.262692928314209, D Loss: 1.038300633430481, alpha: 0.9708013673158152\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 417 iteration0, G Loss: 1.9503209590911865, D Loss: 1.0931856632232666, alpha: 0.9706308095994504\n",
      "epoch 417 iteration100, G Loss: 2.2359402179718018, D Loss: 1.1313893795013428, alpha: 0.9706308095994504\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 418 iteration0, G Loss: 1.5851740837097168, D Loss: 1.190955638885498, alpha: 0.9704592859217226\n",
      "epoch 418 iteration100, G Loss: 1.6327639818191528, D Loss: 1.1242917776107788, alpha: 0.9704592859217226\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 419 iteration0, G Loss: 0.8722495436668396, D Loss: 1.5224761962890625, alpha: 0.9702867911669113\n",
      "epoch 419 iteration100, G Loss: 1.0955954790115356, D Loss: 1.3375658988952637, alpha: 0.9702867911669113\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 420 iteration0, G Loss: 1.099928855895996, D Loss: 1.1726469993591309, alpha: 0.9701133201963638\n",
      "epoch 420 iteration100, G Loss: 1.4300343990325928, D Loss: 1.2942280769348145, alpha: 0.9701133201963638\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 421 iteration0, G Loss: 0.8951770663261414, D Loss: 1.1569629907608032, alpha: 0.9699388678484417\n",
      "epoch 421 iteration100, G Loss: 1.5376183986663818, D Loss: 1.066744327545166, alpha: 0.9699388678484417\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 422 iteration0, G Loss: 1.0831656455993652, D Loss: 0.9168537259101868, alpha: 0.9697634289384699\n",
      "epoch 422 iteration100, G Loss: 2.025102138519287, D Loss: 2.049724817276001, alpha: 0.9697634289384699\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 423 iteration0, G Loss: 0.7980780601501465, D Loss: 1.4125745296478271, alpha: 0.9695869982586831\n",
      "epoch 423 iteration100, G Loss: 1.5886207818984985, D Loss: 1.1982083320617676, alpha: 0.9695869982586831\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 424 iteration0, G Loss: 1.139540195465088, D Loss: 1.0945546627044678, alpha: 0.9694095705781761\n",
      "epoch 424 iteration100, G Loss: 1.1759095191955566, D Loss: 1.4373936653137207, alpha: 0.9694095705781761\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 425 iteration0, G Loss: 1.5885437726974487, D Loss: 1.004584550857544, alpha: 0.969231140642852\n",
      "epoch 425 iteration100, G Loss: 1.4505034685134888, D Loss: 1.2656797170639038, alpha: 0.969231140642852\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 426 iteration0, G Loss: 0.9998024702072144, D Loss: 1.4147980213165283, alpha: 0.9690517031753728\n",
      "epoch 426 iteration100, G Loss: 1.0229698419570923, D Loss: 1.2006518840789795, alpha: 0.9690517031753728\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 427 iteration0, G Loss: 0.93382328748703, D Loss: 1.552509069442749, alpha: 0.9688712528751097\n",
      "epoch 427 iteration100, G Loss: 1.2715733051300049, D Loss: 1.0775916576385498, alpha: 0.9688712528751097\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 428 iteration0, G Loss: 2.356387138366699, D Loss: 0.8226741552352905, alpha: 0.968689784418094\n",
      "epoch 428 iteration100, G Loss: 1.261651635169983, D Loss: 1.1286226511001587, alpha: 0.968689784418094\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 429 iteration0, G Loss: 0.9102622270584106, D Loss: 1.085103154182434, alpha: 0.9685072924569692\n",
      "epoch 429 iteration100, G Loss: 1.4167425632476807, D Loss: 1.4261432886123657, alpha: 0.9685072924569692\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 430 iteration0, G Loss: 2.0392496585845947, D Loss: 1.4238526821136475, alpha: 0.9683237716209436\n",
      "epoch 430 iteration100, G Loss: 1.2613966464996338, D Loss: 0.9886661171913147, alpha: 0.9683237716209436\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 431 iteration0, G Loss: 1.715762734413147, D Loss: 1.4182370901107788, alpha: 0.9681392165157425\n",
      "epoch 431 iteration100, G Loss: 1.621357798576355, D Loss: 0.9677945375442505, alpha: 0.9681392165157425\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 432 iteration0, G Loss: 1.6064547300338745, D Loss: 1.233458161354065, alpha: 0.9679536217235628\n",
      "epoch 432 iteration100, G Loss: 0.9421260952949524, D Loss: 1.4525299072265625, alpha: 0.9679536217235628\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 433 iteration0, G Loss: 1.4887365102767944, D Loss: 1.34108567237854, alpha: 0.9677669818030268\n",
      "epoch 433 iteration100, G Loss: 0.6480473279953003, D Loss: 1.3414660692214966, alpha: 0.9677669818030268\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 434 iteration0, G Loss: 1.2792079448699951, D Loss: 1.1061007976531982, alpha: 0.9675792912891376\n",
      "epoch 434 iteration100, G Loss: 1.185859203338623, D Loss: 1.1965993642807007, alpha: 0.9675792912891376\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 435 iteration0, G Loss: 1.322934627532959, D Loss: 1.1206902265548706, alpha: 0.9673905446932344\n",
      "epoch 435 iteration100, G Loss: 0.9989566802978516, D Loss: 1.256536841392517, alpha: 0.9673905446932344\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 436 iteration0, G Loss: 1.1221431493759155, D Loss: 1.437654733657837, alpha: 0.9672007365029498\n",
      "epoch 436 iteration100, G Loss: 0.9893169403076172, D Loss: 1.194537878036499, alpha: 0.9672007365029498\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 437 iteration0, G Loss: 1.497424840927124, D Loss: 1.1779701709747314, alpha: 0.9670098611821661\n",
      "epoch 437 iteration100, G Loss: 1.4960229396820068, D Loss: 1.3031198978424072, alpha: 0.9670098611821661\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 438 iteration0, G Loss: 0.9698996543884277, D Loss: 1.3355916738510132, alpha: 0.9668179131709738\n",
      "epoch 438 iteration100, G Loss: 1.9545191526412964, D Loss: 1.2528269290924072, alpha: 0.9668179131709738\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 439 iteration0, G Loss: 0.9509428143501282, D Loss: 1.3500702381134033, alpha: 0.9666248868856298\n",
      "epoch 439 iteration100, G Loss: 1.763526201248169, D Loss: 1.107656717300415, alpha: 0.9666248868856298\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 440 iteration0, G Loss: 1.9402769804000854, D Loss: 1.3505672216415405, alpha: 0.9664307767185175\n",
      "epoch 440 iteration100, G Loss: 1.0596415996551514, D Loss: 1.0655796527862549, alpha: 0.9664307767185175\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 441 iteration0, G Loss: 1.195335865020752, D Loss: 1.3325812816619873, alpha: 0.9662355770381064\n",
      "epoch 441 iteration100, G Loss: 1.252098560333252, D Loss: 1.1894510984420776, alpha: 0.9662355770381064\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 442 iteration0, G Loss: 1.389366626739502, D Loss: 1.1535472869873047, alpha: 0.9660392821889131\n",
      "epoch 442 iteration100, G Loss: 1.4850969314575195, D Loss: 1.3838403224945068, alpha: 0.9660392821889131\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 443 iteration0, G Loss: 1.4132657051086426, D Loss: 1.4551337957382202, alpha: 0.965841886491464\n",
      "epoch 443 iteration100, G Loss: 1.5937342643737793, D Loss: 1.3193362951278687, alpha: 0.965841886491464\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 444 iteration0, G Loss: 1.3352528810501099, D Loss: 0.9913173913955688, alpha: 0.9656433842422564\n",
      "epoch 444 iteration100, G Loss: 1.4719486236572266, D Loss: 1.401768445968628, alpha: 0.9656433842422564\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 445 iteration0, G Loss: 1.8099944591522217, D Loss: 1.2168753147125244, alpha: 0.9654437697137235\n",
      "epoch 445 iteration100, G Loss: 1.8524806499481201, D Loss: 1.1797878742218018, alpha: 0.9654437697137235\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 446 iteration0, G Loss: 0.7381435632705688, D Loss: 1.4435697793960571, alpha: 0.9652430371541975\n",
      "epoch 446 iteration100, G Loss: 1.03474760055542, D Loss: 1.6470946073532104, alpha: 0.9652430371541975\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 447 iteration0, G Loss: 1.827398419380188, D Loss: 1.2474610805511475, alpha: 0.9650411807878754\n",
      "epoch 447 iteration100, G Loss: 1.2610721588134766, D Loss: 1.3010125160217285, alpha: 0.9650411807878754\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 448 iteration0, G Loss: 1.20575749874115, D Loss: 1.2186386585235596, alpha: 0.9648381948147847\n",
      "epoch 448 iteration100, G Loss: 0.8250718712806702, D Loss: 1.6103153228759766, alpha: 0.9648381948147847\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 449 iteration0, G Loss: 1.8490458726882935, D Loss: 1.263290524482727, alpha: 0.9646340734107508\n",
      "epoch 449 iteration100, G Loss: 0.6044867634773254, D Loss: 1.8402249813079834, alpha: 0.9646340734107508\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 450 iteration0, G Loss: 2.217989206314087, D Loss: 1.2477028369903564, alpha: 0.9644288107273639\n",
      "epoch 450 iteration100, G Loss: 1.6986989974975586, D Loss: 1.0263535976409912, alpha: 0.9644288107273639\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 451 iteration0, G Loss: 1.8731915950775146, D Loss: 1.0892317295074463, alpha: 0.9642224008919484\n",
      "epoch 451 iteration100, G Loss: 1.2903506755828857, D Loss: 1.1599302291870117, alpha: 0.9642224008919484\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 452 iteration0, G Loss: 1.1660664081573486, D Loss: 1.5780789852142334, alpha: 0.9640148380075328\n",
      "epoch 452 iteration100, G Loss: 1.372926115989685, D Loss: 1.2620904445648193, alpha: 0.9640148380075328\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 453 iteration0, G Loss: 1.6482008695602417, D Loss: 1.2090016603469849, alpha: 0.9638061161528193\n",
      "epoch 453 iteration100, G Loss: 0.9371433258056641, D Loss: 1.036739468574524, alpha: 0.9638061161528193\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 454 iteration0, G Loss: 2.2939887046813965, D Loss: 1.1076017618179321, alpha: 0.9635962293821563\n",
      "epoch 454 iteration100, G Loss: 1.0372782945632935, D Loss: 1.1010740995407104, alpha: 0.9635962293821563\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 455 iteration0, G Loss: 0.7714906930923462, D Loss: 1.9133156538009644, alpha: 0.9633851717255101\n",
      "epoch 455 iteration100, G Loss: 1.631134271621704, D Loss: 1.2217938899993896, alpha: 0.9633851717255101\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 456 iteration0, G Loss: 1.2359662055969238, D Loss: 1.0876004695892334, alpha: 0.9631729371884394\n",
      "epoch 456 iteration100, G Loss: 2.30594801902771, D Loss: 1.6301449537277222, alpha: 0.9631729371884394\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 457 iteration0, G Loss: 2.159358263015747, D Loss: 1.134531021118164, alpha: 0.9629595197520688\n",
      "epoch 457 iteration100, G Loss: 1.3597638607025146, D Loss: 1.0306971073150635, alpha: 0.9629595197520688\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 458 iteration0, G Loss: 1.1878700256347656, D Loss: 1.03226900100708, alpha: 0.962744913373065\n",
      "epoch 458 iteration100, G Loss: 1.2371668815612793, D Loss: 1.5835505723953247, alpha: 0.962744913373065\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 459 iteration0, G Loss: 1.410352110862732, D Loss: 1.1425011157989502, alpha: 0.962529111983613\n",
      "epoch 459 iteration100, G Loss: 1.6919946670532227, D Loss: 1.336395502090454, alpha: 0.962529111983613\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 460 iteration0, G Loss: 1.6372792720794678, D Loss: 1.5176403522491455, alpha: 0.9623121094913941\n",
      "epoch 460 iteration100, G Loss: 1.2210030555725098, D Loss: 1.1947722434997559, alpha: 0.9623121094913941\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 461 iteration0, G Loss: 0.9580379724502563, D Loss: 1.1850934028625488, alpha: 0.9620938997795639\n",
      "epoch 461 iteration100, G Loss: 1.979697823524475, D Loss: 1.5378751754760742, alpha: 0.9620938997795639\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 462 iteration0, G Loss: 0.9141225814819336, D Loss: 1.4261417388916016, alpha: 0.9618744767067332\n",
      "epoch 462 iteration100, G Loss: 1.5138925313949585, D Loss: 1.2460459470748901, alpha: 0.9618744767067332\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 463 iteration0, G Loss: 1.3976072072982788, D Loss: 1.3043456077575684, alpha: 0.9616538341069474\n",
      "epoch 463 iteration100, G Loss: 1.636965036392212, D Loss: 1.1961281299591064, alpha: 0.9616538341069474\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 464 iteration0, G Loss: 1.2891206741333008, D Loss: 1.2745931148529053, alpha: 0.9614319657896698\n",
      "epoch 464 iteration100, G Loss: 1.4317035675048828, D Loss: 1.2103444337844849, alpha: 0.9614319657896698\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 465 iteration0, G Loss: 0.9574834108352661, D Loss: 1.2838544845581055, alpha: 0.9612088655397639\n",
      "epoch 465 iteration100, G Loss: 1.628212571144104, D Loss: 1.1577706336975098, alpha: 0.9612088655397639\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 466 iteration0, G Loss: 1.6073105335235596, D Loss: 1.0083236694335938, alpha: 0.9609845271174783\n",
      "epoch 466 iteration100, G Loss: 3.4922375679016113, D Loss: 1.5916975736618042, alpha: 0.9609845271174783\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 467 iteration0, G Loss: 0.7947908043861389, D Loss: 1.580670952796936, alpha: 0.9607589442584311\n",
      "epoch 467 iteration100, G Loss: 1.4521591663360596, D Loss: 1.4550422430038452, alpha: 0.9607589442584311\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 468 iteration0, G Loss: 1.5943511724472046, D Loss: 1.2750273942947388, alpha: 0.9605321106735979\n",
      "epoch 468 iteration100, G Loss: 1.4756125211715698, D Loss: 1.175570011138916, alpha: 0.9605321106735979\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 469 iteration0, G Loss: 2.6371347904205322, D Loss: 1.0656132698059082, alpha: 0.9603040200492985\n",
      "epoch 469 iteration100, G Loss: 2.520355463027954, D Loss: 1.3569107055664062, alpha: 0.9603040200492985\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 470 iteration0, G Loss: 1.2671581506729126, D Loss: 1.2794692516326904, alpha: 0.9600746660471862\n",
      "epoch 470 iteration100, G Loss: 1.6607171297073364, D Loss: 1.261224627494812, alpha: 0.9600746660471862\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 471 iteration0, G Loss: 1.6031904220581055, D Loss: 1.0983970165252686, alpha: 0.9598440423042385\n",
      "epoch 471 iteration100, G Loss: 1.3559215068817139, D Loss: 1.0291252136230469, alpha: 0.9598440423042385\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 472 iteration0, G Loss: 0.9747613668441772, D Loss: 1.1586122512817383, alpha: 0.959612142432748\n",
      "epoch 472 iteration100, G Loss: 2.8668832778930664, D Loss: 1.339074969291687, alpha: 0.959612142432748\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 473 iteration0, G Loss: 1.321991205215454, D Loss: 1.09187650680542, alpha: 0.9593789600203156\n",
      "epoch 473 iteration100, G Loss: 1.5871343612670898, D Loss: 1.0550737380981445, alpha: 0.9593789600203156\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 474 iteration0, G Loss: 0.993541955947876, D Loss: 1.2186102867126465, alpha: 0.9591444886298444\n",
      "epoch 474 iteration100, G Loss: 2.3229103088378906, D Loss: 1.2421653270721436, alpha: 0.9591444886298444\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 475 iteration0, G Loss: 0.8816101551055908, D Loss: 1.2692166566848755, alpha: 0.958908721799535\n",
      "epoch 475 iteration100, G Loss: 1.555496096611023, D Loss: 1.0469133853912354, alpha: 0.958908721799535\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 476 iteration0, G Loss: 1.1361336708068848, D Loss: 1.2802094221115112, alpha: 0.9586716530428824\n",
      "epoch 476 iteration100, G Loss: 1.4171618223190308, D Loss: 1.2003127336502075, alpha: 0.9586716530428824\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 477 iteration0, G Loss: 1.2535626888275146, D Loss: 1.083927869796753, alpha: 0.9584332758486738\n",
      "epoch 477 iteration100, G Loss: 0.9250844120979309, D Loss: 1.2027652263641357, alpha: 0.9584332758486738\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 478 iteration0, G Loss: 2.2869322299957275, D Loss: 1.22933828830719, alpha: 0.9581935836809882\n",
      "epoch 478 iteration100, G Loss: 1.039998173713684, D Loss: 1.221567153930664, alpha: 0.9581935836809882\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 479 iteration0, G Loss: 1.0880489349365234, D Loss: 1.1920400857925415, alpha: 0.957952569979197\n",
      "epoch 479 iteration100, G Loss: 1.632876992225647, D Loss: 1.0476093292236328, alpha: 0.957952569979197\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 480 iteration0, G Loss: 1.4145959615707397, D Loss: 0.9508059024810791, alpha: 0.9577102281579662\n",
      "epoch 480 iteration100, G Loss: 1.5263642072677612, D Loss: 1.200522780418396, alpha: 0.9577102281579662\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 481 iteration0, G Loss: 1.4702035188674927, D Loss: 1.377966046333313, alpha: 0.9574665516072602\n",
      "epoch 481 iteration100, G Loss: 1.6685971021652222, D Loss: 2.1768338680267334, alpha: 0.9574665516072602\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 482 iteration0, G Loss: 0.893609881401062, D Loss: 1.3490796089172363, alpha: 0.9572215336923464\n",
      "epoch 482 iteration100, G Loss: 1.9168336391448975, D Loss: 1.2502673864364624, alpha: 0.9572215336923464\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 483 iteration0, G Loss: 2.1113176345825195, D Loss: 1.2388982772827148, alpha: 0.9569751677538021\n",
      "epoch 483 iteration100, G Loss: 1.6015998125076294, D Loss: 1.0793060064315796, alpha: 0.9569751677538021\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 484 iteration0, G Loss: 1.5084244012832642, D Loss: 1.1836557388305664, alpha: 0.9567274471075219\n",
      "epoch 484 iteration100, G Loss: 2.424642562866211, D Loss: 1.1331452131271362, alpha: 0.9567274471075219\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 485 iteration0, G Loss: 1.130392074584961, D Loss: 1.0739765167236328, alpha: 0.9564783650447278\n",
      "epoch 485 iteration100, G Loss: 1.3031538724899292, D Loss: 0.7095943689346313, alpha: 0.9564783650447278\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 486 iteration0, G Loss: 0.8312115669250488, D Loss: 1.2197080850601196, alpha: 0.9562279148319796\n",
      "epoch 486 iteration100, G Loss: 1.2816951274871826, D Loss: 1.0453927516937256, alpha: 0.9562279148319796\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 487 iteration0, G Loss: 1.221676230430603, D Loss: 1.034914493560791, alpha: 0.9559760897111875\n",
      "epoch 487 iteration100, G Loss: 0.9928191304206848, D Loss: 0.8348819613456726, alpha: 0.9559760897111875\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 488 iteration0, G Loss: 2.1078426837921143, D Loss: 1.745164394378662, alpha: 0.9557228828996265\n",
      "epoch 488 iteration100, G Loss: 2.067258358001709, D Loss: 1.4035277366638184, alpha: 0.9557228828996265\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 489 iteration0, G Loss: 1.5701261758804321, D Loss: 1.401140809059143, alpha: 0.955468287589951\n",
      "epoch 489 iteration100, G Loss: 1.2194291353225708, D Loss: 0.9918212890625, alpha: 0.955468287589951\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 490 iteration0, G Loss: 1.5853232145309448, D Loss: 1.3213660717010498, alpha: 0.9552122969502133\n",
      "epoch 490 iteration100, G Loss: 1.459606409072876, D Loss: 1.2156898975372314, alpha: 0.9552122969502133\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 491 iteration0, G Loss: 1.039089560508728, D Loss: 0.9347582459449768, alpha: 0.9549549041238813\n",
      "epoch 491 iteration100, G Loss: 1.4631626605987549, D Loss: 2.5803074836730957, alpha: 0.9549549041238813\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 492 iteration0, G Loss: 0.837446928024292, D Loss: 1.1200642585754395, alpha: 0.9546961022298595\n",
      "epoch 492 iteration100, G Loss: 0.8583699464797974, D Loss: 1.2655246257781982, alpha: 0.9546961022298595\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 493 iteration0, G Loss: 2.0873801708221436, D Loss: 0.8683960437774658, alpha: 0.9544358843625106\n",
      "epoch 493 iteration100, G Loss: 1.7323914766311646, D Loss: 1.2459959983825684, alpha: 0.9544358843625106\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 494 iteration0, G Loss: 1.4079657793045044, D Loss: 1.2529165744781494, alpha: 0.95417424359168\n",
      "epoch 494 iteration100, G Loss: 1.7375240325927734, D Loss: 1.2809596061706543, alpha: 0.95417424359168\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 495 iteration0, G Loss: 1.0279738903045654, D Loss: 1.0376884937286377, alpha: 0.9539111729627203\n",
      "epoch 495 iteration100, G Loss: 1.4354023933410645, D Loss: 1.283111333847046, alpha: 0.9539111729627203\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 496 iteration0, G Loss: 0.8116105198860168, D Loss: 1.2784335613250732, alpha: 0.9536466654965192\n",
      "epoch 496 iteration100, G Loss: 1.4210439920425415, D Loss: 1.386268973350525, alpha: 0.9536466654965192\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 497 iteration0, G Loss: 0.9080331921577454, D Loss: 1.322995662689209, alpha: 0.9533807141895276\n",
      "epoch 497 iteration100, G Loss: 1.2209672927856445, D Loss: 0.9104636907577515, alpha: 0.9533807141895276\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 498 iteration0, G Loss: 1.1120504140853882, D Loss: 1.175611972808838, alpha: 0.9531133120137913\n",
      "epoch 498 iteration100, G Loss: 1.7749968767166138, D Loss: 1.1257553100585938, alpha: 0.9531133120137913\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 499 iteration0, G Loss: 0.8354560732841492, D Loss: 1.3800894021987915, alpha: 0.9528444519169822\n",
      "epoch 499 iteration100, G Loss: 2.2425413131713867, D Loss: 1.1330516338348389, alpha: 0.9528444519169822\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 500 iteration0, G Loss: 1.4408562183380127, D Loss: 0.8591414093971252, alpha: 0.9525741268224333\n",
      "epoch 500 iteration100, G Loss: 1.6080068349838257, D Loss: 1.1018403768539429, alpha: 0.9525741268224333\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 501 iteration0, G Loss: 1.802727222442627, D Loss: 1.102051019668579, alpha: 0.9523023296291744\n",
      "epoch 501 iteration100, G Loss: 1.9765833616256714, D Loss: 1.1456315517425537, alpha: 0.9523023296291744\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 502 iteration0, G Loss: 0.8271976113319397, D Loss: 1.3781261444091797, alpha: 0.9520290532119702\n",
      "epoch 502 iteration100, G Loss: 1.7521874904632568, D Loss: 1.1162978410720825, alpha: 0.9520290532119702\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 503 iteration0, G Loss: 1.3118020296096802, D Loss: 1.309122085571289, alpha: 0.9517542904213597\n",
      "epoch 503 iteration100, G Loss: 1.7803987264633179, D Loss: 1.3227245807647705, alpha: 0.9517542904213597\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 504 iteration0, G Loss: 1.7047851085662842, D Loss: 1.3285086154937744, alpha: 0.9514780340836981\n",
      "epoch 504 iteration100, G Loss: 1.1470004320144653, D Loss: 1.2794861793518066, alpha: 0.9514780340836981\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 505 iteration0, G Loss: 1.7324140071868896, D Loss: 1.212087631225586, alpha: 0.9512002770012\n",
      "epoch 505 iteration100, G Loss: 1.3832157850265503, D Loss: 0.9703015089035034, alpha: 0.9512002770012\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 506 iteration0, G Loss: 1.4636338949203491, D Loss: 1.098341464996338, alpha: 0.9509210119519851\n",
      "epoch 506 iteration100, G Loss: 1.738213300704956, D Loss: 1.2347923517227173, alpha: 0.9509210119519851\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 507 iteration0, G Loss: 1.347785472869873, D Loss: 1.4073567390441895, alpha: 0.9506402316901252\n",
      "epoch 507 iteration100, G Loss: 1.68971848487854, D Loss: 1.3134520053863525, alpha: 0.9506402316901252\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 508 iteration0, G Loss: 0.8061713576316833, D Loss: 1.426878809928894, alpha: 0.9503579289456944\n",
      "epoch 508 iteration100, G Loss: 1.722258448600769, D Loss: 1.226853847503662, alpha: 0.9503579289456944\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 509 iteration0, G Loss: 1.2940211296081543, D Loss: 1.355846881866455, alpha: 0.9500740964248193\n",
      "epoch 509 iteration100, G Loss: 0.8857154250144958, D Loss: 1.1387677192687988, alpha: 0.9500740964248193\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 510 iteration0, G Loss: 1.0374292135238647, D Loss: 1.5049493312835693, alpha: 0.9497887268097335\n",
      "epoch 510 iteration100, G Loss: 1.4887360334396362, D Loss: 0.912784218788147, alpha: 0.9497887268097335\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 511 iteration0, G Loss: 1.7431715726852417, D Loss: 1.388986349105835, alpha: 0.9495018127588318\n",
      "epoch 511 iteration100, G Loss: 1.7436869144439697, D Loss: 0.9512941241264343, alpha: 0.9495018127588318\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 512 iteration0, G Loss: 1.1236536502838135, D Loss: 1.316030740737915, alpha: 0.9492133469067291\n",
      "epoch 512 iteration100, G Loss: 1.1300288438796997, D Loss: 1.454770565032959, alpha: 0.9492133469067291\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 513 iteration0, G Loss: 1.711329460144043, D Loss: 1.2242501974105835, alpha: 0.9489233218643187\n",
      "epoch 513 iteration100, G Loss: 1.028732419013977, D Loss: 1.1675548553466797, alpha: 0.9489233218643187\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 514 iteration0, G Loss: 2.145933151245117, D Loss: 1.5181339979171753, alpha: 0.9486317302188345\n",
      "epoch 514 iteration100, G Loss: 0.8337219953536987, D Loss: 1.5323710441589355, alpha: 0.9486317302188345\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 515 iteration0, G Loss: 1.2211865186691284, D Loss: 1.1513913869857788, alpha: 0.9483385645339152\n",
      "epoch 515 iteration100, G Loss: 0.847258448600769, D Loss: 1.161095380783081, alpha: 0.9483385645339152\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 516 iteration0, G Loss: 1.651511549949646, D Loss: 1.1375133991241455, alpha: 0.9480438173496692\n",
      "epoch 516 iteration100, G Loss: 2.6921281814575195, D Loss: 1.9414221048355103, alpha: 0.9480438173496692\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 517 iteration0, G Loss: 1.0673952102661133, D Loss: 0.9705151319503784, alpha: 0.9477474811827441\n",
      "epoch 517 iteration100, G Loss: 1.4665920734405518, D Loss: 2.1298787593841553, alpha: 0.9477474811827441\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 518 iteration0, G Loss: 1.5619757175445557, D Loss: 1.7352330684661865, alpha: 0.9474495485263958\n",
      "epoch 518 iteration100, G Loss: 2.3107945919036865, D Loss: 1.1992007493972778, alpha: 0.9474495485263958\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 519 iteration0, G Loss: 1.746293544769287, D Loss: 0.9801998138427734, alpha: 0.947150011850562\n",
      "epoch 519 iteration100, G Loss: 0.9387986660003662, D Loss: 1.4651598930358887, alpha: 0.947150011850562\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 520 iteration0, G Loss: 1.5671522617340088, D Loss: 1.1458991765975952, alpha: 0.9468488636019363\n",
      "epoch 520 iteration100, G Loss: 1.8860137462615967, D Loss: 0.8774288892745972, alpha: 0.9468488636019363\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 521 iteration0, G Loss: 1.2945126295089722, D Loss: 1.108435869216919, alpha: 0.9465460962040458\n",
      "epoch 521 iteration100, G Loss: 1.452143907546997, D Loss: 1.214124083518982, alpha: 0.9465460962040458\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 522 iteration0, G Loss: 1.0974311828613281, D Loss: 1.4096746444702148, alpha: 0.9462417020573307\n",
      "epoch 522 iteration100, G Loss: 1.5542488098144531, D Loss: 1.3209078311920166, alpha: 0.9462417020573307\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 523 iteration0, G Loss: 2.122652769088745, D Loss: 1.2088292837142944, alpha: 0.945935673539225\n",
      "epoch 523 iteration100, G Loss: 1.4102246761322021, D Loss: 1.2976421117782593, alpha: 0.945935673539225\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 524 iteration0, G Loss: 1.2419955730438232, D Loss: 1.0706478357315063, alpha: 0.9456280030042419\n",
      "epoch 524 iteration100, G Loss: 1.7051773071289062, D Loss: 0.9503039121627808, alpha: 0.9456280030042419\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 525 iteration0, G Loss: 1.538745641708374, D Loss: 1.1633822917938232, alpha: 0.9453186827840593\n",
      "epoch 525 iteration100, G Loss: 1.4261839389801025, D Loss: 1.3190228939056396, alpha: 0.9453186827840593\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 526 iteration0, G Loss: 1.040045976638794, D Loss: 1.0820770263671875, alpha: 0.9450077051876089\n",
      "epoch 526 iteration100, G Loss: 1.1443119049072266, D Loss: 1.1558725833892822, alpha: 0.9450077051876089\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 527 iteration0, G Loss: 2.040318489074707, D Loss: 1.2600321769714355, alpha: 0.9446950625011679\n",
      "epoch 527 iteration100, G Loss: 1.3716449737548828, D Loss: 1.2480741739273071, alpha: 0.9446950625011679\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 528 iteration0, G Loss: 1.7524584531784058, D Loss: 0.9315367341041565, alpha: 0.9443807469884519\n",
      "epoch 528 iteration100, G Loss: 1.8413079977035522, D Loss: 1.0810539722442627, alpha: 0.9443807469884519\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 529 iteration0, G Loss: 1.0196245908737183, D Loss: 1.1783952713012695, alpha: 0.944064750890712\n",
      "epoch 529 iteration100, G Loss: 2.48028826713562, D Loss: 1.0980205535888672, alpha: 0.944064750890712\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 530 iteration0, G Loss: 2.0804619789123535, D Loss: 1.1314890384674072, alpha: 0.9437470664268326\n",
      "epoch 530 iteration100, G Loss: 2.23297381401062, D Loss: 1.215248703956604, alpha: 0.9437470664268326\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 531 iteration0, G Loss: 1.5472816228866577, D Loss: 1.2197325229644775, alpha: 0.9434276857934336\n",
      "epoch 531 iteration100, G Loss: 1.3915399312973022, D Loss: 1.297577142715454, alpha: 0.9434276857934336\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 532 iteration0, G Loss: 1.759339451789856, D Loss: 1.1523066759109497, alpha: 0.9431066011649731\n",
      "epoch 532 iteration100, G Loss: 1.1006184816360474, D Loss: 1.6981852054595947, alpha: 0.9431066011649731\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 533 iteration0, G Loss: 1.3894588947296143, D Loss: 1.0528255701065063, alpha: 0.9427838046938548\n",
      "epoch 533 iteration100, G Loss: 2.224642038345337, D Loss: 1.2064121961593628, alpha: 0.9427838046938548\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 534 iteration0, G Loss: 1.8741886615753174, D Loss: 1.4656853675842285, alpha: 0.9424592885105357\n",
      "epoch 534 iteration100, G Loss: 1.2491614818572998, D Loss: 1.1017539501190186, alpha: 0.9424592885105357\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 535 iteration0, G Loss: 0.7555976510047913, D Loss: 1.2091155052185059, alpha: 0.942133044723639\n",
      "epoch 535 iteration100, G Loss: 1.7093249559402466, D Loss: 1.2393314838409424, alpha: 0.942133044723639\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 536 iteration0, G Loss: 1.1630144119262695, D Loss: 1.1182823181152344, alpha: 0.9418050654200673\n",
      "epoch 536 iteration100, G Loss: 1.483321189880371, D Loss: 1.083549976348877, alpha: 0.9418050654200673\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 537 iteration0, G Loss: 0.9437922835350037, D Loss: 0.923498272895813, alpha: 0.94147534266512\n",
      "epoch 537 iteration100, G Loss: 1.8503680229187012, D Loss: 1.0366917848587036, alpha: 0.94147534266512\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 538 iteration0, G Loss: 0.9296655654907227, D Loss: 0.9792659282684326, alpha: 0.9411438685026128\n",
      "epoch 538 iteration100, G Loss: 1.5046300888061523, D Loss: 1.1423190832138062, alpha: 0.9411438685026128\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 539 iteration0, G Loss: 0.7834629416465759, D Loss: 1.0984816551208496, alpha: 0.9408106349549997\n",
      "epoch 539 iteration100, G Loss: 1.241131067276001, D Loss: 0.8088654279708862, alpha: 0.9408106349549997\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 540 iteration0, G Loss: 1.78984534740448, D Loss: 1.0217604637145996, alpha: 0.9404756340234984\n",
      "epoch 540 iteration100, G Loss: 1.055567979812622, D Loss: 1.069075584411621, alpha: 0.9404756340234984\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 541 iteration0, G Loss: 2.226532220840454, D Loss: 1.2005817890167236, alpha: 0.9401388576882185\n",
      "epoch 541 iteration100, G Loss: 1.8093841075897217, D Loss: 1.0560667514801025, alpha: 0.9401388576882185\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 542 iteration0, G Loss: 1.6888580322265625, D Loss: 1.1859583854675293, alpha: 0.9398002979082909\n",
      "epoch 542 iteration100, G Loss: 1.7999231815338135, D Loss: 1.3944917917251587, alpha: 0.9398002979082909\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 543 iteration0, G Loss: 1.7937103509902954, D Loss: 1.1924145221710205, alpha: 0.9394599466220029\n",
      "epoch 543 iteration100, G Loss: 2.070974588394165, D Loss: 1.3695168495178223, alpha: 0.9394599466220029\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 544 iteration0, G Loss: 1.4050710201263428, D Loss: 1.035510778427124, alpha: 0.9391177957469332\n",
      "epoch 544 iteration100, G Loss: 2.206233501434326, D Loss: 1.7764421701431274, alpha: 0.9391177957469332\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 545 iteration0, G Loss: 1.10384202003479, D Loss: 1.057408094406128, alpha: 0.938773837180092\n",
      "epoch 545 iteration100, G Loss: 0.959489107131958, D Loss: 1.0979385375976562, alpha: 0.938773837180092\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 546 iteration0, G Loss: 0.940259575843811, D Loss: 1.1889721155166626, alpha: 0.9384280627980626\n",
      "epoch 546 iteration100, G Loss: 1.1498056650161743, D Loss: 1.371056079864502, alpha: 0.9384280627980626\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 547 iteration0, G Loss: 1.1863254308700562, D Loss: 0.8825217485427856, alpha: 0.9380804644571467\n",
      "epoch 547 iteration100, G Loss: 1.3208612203598022, D Loss: 1.381615161895752, alpha: 0.9380804644571467\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 548 iteration0, G Loss: 1.316784143447876, D Loss: 1.1870001554489136, alpha: 0.9377310339935125\n",
      "epoch 548 iteration100, G Loss: 0.9366825819015503, D Loss: 1.2408802509307861, alpha: 0.9377310339935125\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 549 iteration0, G Loss: 1.3930680751800537, D Loss: 0.8609468936920166, alpha: 0.9373797632233458\n",
      "epoch 549 iteration100, G Loss: 1.539505124092102, D Loss: 1.0292036533355713, alpha: 0.9373797632233458\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 550 iteration0, G Loss: 1.35408353805542, D Loss: 1.138920545578003, alpha: 0.9370266439430035\n",
      "epoch 550 iteration100, G Loss: 2.0414059162139893, D Loss: 1.3228909969329834, alpha: 0.9370266439430035\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 551 iteration0, G Loss: 2.30735182762146, D Loss: 1.5890742540359497, alpha: 0.9366716679291713\n",
      "epoch 551 iteration100, G Loss: 1.2192004919052124, D Loss: 1.1294190883636475, alpha: 0.9366716679291713\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 552 iteration0, G Loss: 1.2908883094787598, D Loss: 1.3937662839889526, alpha: 0.9363148269390238\n",
      "epoch 552 iteration100, G Loss: 1.9601850509643555, D Loss: 1.6547369956970215, alpha: 0.9363148269390238\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 553 iteration0, G Loss: 1.59568190574646, D Loss: 1.1908764839172363, alpha: 0.9359561127103874\n",
      "epoch 553 iteration100, G Loss: 2.5790624618530273, D Loss: 1.5443310737609863, alpha: 0.9359561127103874\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 554 iteration0, G Loss: 2.4854795932769775, D Loss: 1.3548442125320435, alpha: 0.9355955169619067\n",
      "epoch 554 iteration100, G Loss: 2.292490005493164, D Loss: 0.9304823875427246, alpha: 0.9355955169619067\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 555 iteration0, G Loss: 1.951208233833313, D Loss: 0.9465912580490112, alpha: 0.9352330313932145\n",
      "epoch 555 iteration100, G Loss: 1.6734223365783691, D Loss: 1.0730617046356201, alpha: 0.9352330313932145\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 556 iteration0, G Loss: 0.7243376970291138, D Loss: 1.5586944818496704, alpha: 0.934868647685104\n",
      "epoch 556 iteration100, G Loss: 1.1846946477890015, D Loss: 1.2362757921218872, alpha: 0.934868647685104\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 557 iteration0, G Loss: 2.510672092437744, D Loss: 1.4382548332214355, alpha: 0.9345023574997053\n",
      "epoch 557 iteration100, G Loss: 1.687448501586914, D Loss: 1.2718725204467773, alpha: 0.9345023574997053\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 558 iteration0, G Loss: 1.2736262083053589, D Loss: 1.1539759635925293, alpha: 0.9341341524806636\n",
      "epoch 558 iteration100, G Loss: 2.409276008605957, D Loss: 0.804237425327301, alpha: 0.9341341524806636\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 559 iteration0, G Loss: 1.4638543128967285, D Loss: 0.8185584545135498, alpha: 0.9337640242533225\n",
      "epoch 559 iteration100, G Loss: 0.8338261842727661, D Loss: 1.3843753337860107, alpha: 0.9337640242533225\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 560 iteration0, G Loss: 1.339117169380188, D Loss: 1.2126160860061646, alpha: 0.9333919644249093\n",
      "epoch 560 iteration100, G Loss: 1.012258768081665, D Loss: 1.3426294326782227, alpha: 0.9333919644249093\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 561 iteration0, G Loss: 2.0533924102783203, D Loss: 1.085722804069519, alpha: 0.9330179645847241\n",
      "epoch 561 iteration100, G Loss: 1.37117338180542, D Loss: 1.007455825805664, alpha: 0.9330179645847241\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 562 iteration0, G Loss: 1.8641959428787231, D Loss: 0.9113485217094421, alpha: 0.9326420163043319\n",
      "epoch 562 iteration100, G Loss: 1.37705659866333, D Loss: 1.3767662048339844, alpha: 0.9326420163043319\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 563 iteration0, G Loss: 1.789770245552063, D Loss: 1.3079144954681396, alpha: 0.9322641111377585\n",
      "epoch 563 iteration100, G Loss: 1.8578433990478516, D Loss: 1.485236406326294, alpha: 0.9322641111377585\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 564 iteration0, G Loss: 0.7492765188217163, D Loss: 1.2577482461929321, alpha: 0.9318842406216898\n",
      "epoch 564 iteration100, G Loss: 1.3981126546859741, D Loss: 1.2028934955596924, alpha: 0.9318842406216898\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 565 iteration0, G Loss: 0.9630891680717468, D Loss: 0.8914784789085388, alpha: 0.9315023962756739\n",
      "epoch 565 iteration100, G Loss: 1.791398525238037, D Loss: 1.3212568759918213, alpha: 0.9315023962756739\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 566 iteration0, G Loss: 1.6015050411224365, D Loss: 1.650580883026123, alpha: 0.9311185696023273\n",
      "epoch 566 iteration100, G Loss: 1.200068473815918, D Loss: 1.3609774112701416, alpha: 0.9311185696023273\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 567 iteration0, G Loss: 1.8194001913070679, D Loss: 1.2326476573944092, alpha: 0.9307327520875442\n",
      "epoch 567 iteration100, G Loss: 2.660254716873169, D Loss: 1.2133644819259644, alpha: 0.9307327520875442\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 568 iteration0, G Loss: 0.9548299312591553, D Loss: 2.0073022842407227, alpha: 0.9303449352007099\n",
      "epoch 568 iteration100, G Loss: 1.9746044874191284, D Loss: 1.293721318244934, alpha: 0.9303449352007099\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 569 iteration0, G Loss: 0.7188516855239868, D Loss: 1.190100908279419, alpha: 0.9299551103949163\n",
      "epoch 569 iteration100, G Loss: 3.1772255897521973, D Loss: 1.6402077674865723, alpha: 0.9299551103949163\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 570 iteration0, G Loss: 0.7039191722869873, D Loss: 1.054152250289917, alpha: 0.9295632691071829\n",
      "epoch 570 iteration100, G Loss: 1.4029979705810547, D Loss: 1.1249028444290161, alpha: 0.9295632691071829\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 571 iteration0, G Loss: 1.6764649152755737, D Loss: 1.1284693479537964, alpha: 0.92916940275868\n",
      "epoch 571 iteration100, G Loss: 2.1294665336608887, D Loss: 1.1405271291732788, alpha: 0.92916940275868\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 572 iteration0, G Loss: 1.3720920085906982, D Loss: 1.292365550994873, alpha: 0.9287735027549558\n",
      "epoch 572 iteration100, G Loss: 1.7743427753448486, D Loss: 1.434951663017273, alpha: 0.9287735027549558\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 573 iteration0, G Loss: 1.4717837572097778, D Loss: 1.139336347579956, alpha: 0.9283755604861677\n",
      "epoch 573 iteration100, G Loss: 1.3575260639190674, D Loss: 1.054365873336792, alpha: 0.9283755604861677\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 574 iteration0, G Loss: 1.9625818729400635, D Loss: 1.370025634765625, alpha: 0.9279755673273157\n",
      "epoch 574 iteration100, G Loss: 1.5251682996749878, D Loss: 1.0956372022628784, alpha: 0.9279755673273157\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 575 iteration0, G Loss: 1.2827060222625732, D Loss: 1.1698684692382812, alpha: 0.9275735146384823\n",
      "epoch 575 iteration100, G Loss: 1.1173888444900513, D Loss: 0.8194780349731445, alpha: 0.9275735146384823\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 576 iteration0, G Loss: 1.1293257474899292, D Loss: 1.0095405578613281, alpha: 0.9271693937650729\n",
      "epoch 576 iteration100, G Loss: 1.3634265661239624, D Loss: 1.6517102718353271, alpha: 0.9271693937650729\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 577 iteration0, G Loss: 1.0964226722717285, D Loss: 1.324399471282959, alpha: 0.9267631960380622\n",
      "epoch 577 iteration100, G Loss: 0.5928146839141846, D Loss: 1.3592290878295898, alpha: 0.9267631960380622\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 578 iteration0, G Loss: 2.706751585006714, D Loss: 1.086384892463684, alpha: 0.9263549127742438\n",
      "epoch 578 iteration100, G Loss: 2.8216137886047363, D Loss: 1.4970901012420654, alpha: 0.9263549127742438\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 579 iteration0, G Loss: 1.0918408632278442, D Loss: 1.191103219985962, alpha: 0.9259445352764824\n",
      "epoch 579 iteration100, G Loss: 1.7931325435638428, D Loss: 1.1478703022003174, alpha: 0.9259445352764824\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 580 iteration0, G Loss: 1.5755929946899414, D Loss: 0.8941924571990967, alpha: 0.9255320548339719\n",
      "epoch 580 iteration100, G Loss: 2.2582621574401855, D Loss: 1.083383321762085, alpha: 0.9255320548339719\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 581 iteration0, G Loss: 1.333837866783142, D Loss: 0.8771814107894897, alpha: 0.9251174627224962\n",
      "epoch 581 iteration100, G Loss: 2.383241891860962, D Loss: 1.2289083003997803, alpha: 0.9251174627224962\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 582 iteration0, G Loss: 2.428105354309082, D Loss: 1.3123857975006104, alpha: 0.9247007502046931\n",
      "epoch 582 iteration100, G Loss: 1.6143838167190552, D Loss: 1.027378797531128, alpha: 0.9247007502046931\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 583 iteration0, G Loss: 1.415624976158142, D Loss: 1.475346565246582, alpha: 0.924281908530324\n",
      "epoch 583 iteration100, G Loss: 0.9218951463699341, D Loss: 1.207223892211914, alpha: 0.924281908530324\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 584 iteration0, G Loss: 1.7359848022460938, D Loss: 1.1428444385528564, alpha: 0.9238609289365459\n",
      "epoch 584 iteration100, G Loss: 1.030180811882019, D Loss: 1.101129174232483, alpha: 0.9238609289365459\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 585 iteration0, G Loss: 1.5903968811035156, D Loss: 1.0365101099014282, alpha: 0.9234378026481879\n",
      "epoch 585 iteration100, G Loss: 1.4270350933074951, D Loss: 1.2282438278198242, alpha: 0.9234378026481879\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 586 iteration0, G Loss: 1.2455140352249146, D Loss: 1.3363288640975952, alpha: 0.923012520878032\n",
      "epoch 586 iteration100, G Loss: 1.069760799407959, D Loss: 1.203064203262329, alpha: 0.923012520878032\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 587 iteration0, G Loss: 1.5699940919876099, D Loss: 1.5123484134674072, alpha: 0.9225850748270976\n",
      "epoch 587 iteration100, G Loss: 1.473027229309082, D Loss: 1.0135326385498047, alpha: 0.9225850748270976\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 588 iteration0, G Loss: 2.858642339706421, D Loss: 1.9192135334014893, alpha: 0.92215545568493\n",
      "epoch 588 iteration100, G Loss: 0.9116053581237793, D Loss: 0.8749638795852661, alpha: 0.92215545568493\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 589 iteration0, G Loss: 2.0051753520965576, D Loss: 1.0283868312835693, alpha: 0.9217236546298927\n",
      "epoch 589 iteration100, G Loss: 2.110034227371216, D Loss: 1.1375577449798584, alpha: 0.9217236546298927\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 590 iteration0, G Loss: 0.9211956262588501, D Loss: 1.076636791229248, alpha: 0.9212896628294648\n",
      "epoch 590 iteration100, G Loss: 1.5679411888122559, D Loss: 1.3769526481628418, alpha: 0.9212896628294648\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 591 iteration0, G Loss: 1.6096993684768677, D Loss: 1.1062638759613037, alpha: 0.9208534714405409\n",
      "epoch 591 iteration100, G Loss: 0.999413251876831, D Loss: 1.0012519359588623, alpha: 0.9208534714405409\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 592 iteration0, G Loss: 1.7622349262237549, D Loss: 0.8561665415763855, alpha: 0.9204150716097369\n",
      "epoch 592 iteration100, G Loss: 2.0177667140960693, D Loss: 1.4430760145187378, alpha: 0.9204150716097369\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 593 iteration0, G Loss: 1.0938799381256104, D Loss: 1.5788367986679077, alpha: 0.9199744544736984\n",
      "epoch 593 iteration100, G Loss: 1.5222704410552979, D Loss: 1.1811857223510742, alpha: 0.9199744544736984\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 594 iteration0, G Loss: 1.6779801845550537, D Loss: 1.1126819849014282, alpha: 0.9195316111594145\n",
      "epoch 594 iteration100, G Loss: 1.824552059173584, D Loss: 1.415527582168579, alpha: 0.9195316111594145\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 595 iteration0, G Loss: 2.7145864963531494, D Loss: 1.2283155918121338, alpha: 0.9190865327845347\n",
      "epoch 595 iteration100, G Loss: 1.4417321681976318, D Loss: 1.1713261604309082, alpha: 0.9190865327845347\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 596 iteration0, G Loss: 0.8629728555679321, D Loss: 1.232701301574707, alpha: 0.918639210457691\n",
      "epoch 596 iteration100, G Loss: 1.146524429321289, D Loss: 1.3090219497680664, alpha: 0.918639210457691\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 597 iteration0, G Loss: 1.5715358257293701, D Loss: 1.2820218801498413, alpha: 0.918189635278824\n",
      "epoch 597 iteration100, G Loss: 1.6649729013442993, D Loss: 0.9317119121551514, alpha: 0.918189635278824\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 598 iteration0, G Loss: 0.896911084651947, D Loss: 1.3612401485443115, alpha: 0.9177377983395127\n",
      "epoch 598 iteration100, G Loss: 1.1176259517669678, D Loss: 1.2977051734924316, alpha: 0.9177377983395127\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 599 iteration0, G Loss: 3.777792453765869, D Loss: 1.282593011856079, alpha: 0.9172836907233093\n",
      "epoch 599 iteration100, G Loss: 0.9108401536941528, D Loss: 0.8485721945762634, alpha: 0.9172836907233093\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 600 iteration0, G Loss: 1.3412842750549316, D Loss: 1.3709903955459595, alpha: 0.9168273035060777\n",
      "epoch 600 iteration100, G Loss: 1.6255691051483154, D Loss: 1.1708786487579346, alpha: 0.9168273035060777\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 601 iteration0, G Loss: 1.4447352886199951, D Loss: 1.3119605779647827, alpha: 0.9163686277563372\n",
      "epoch 601 iteration100, G Loss: 1.1548656225204468, D Loss: 1.5187373161315918, alpha: 0.9163686277563372\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 602 iteration0, G Loss: 1.189277172088623, D Loss: 1.2777149677276611, alpha: 0.9159076545356102\n",
      "epoch 602 iteration100, G Loss: 1.092078447341919, D Loss: 1.1640746593475342, alpha: 0.9159076545356102\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 603 iteration0, G Loss: 1.2602910995483398, D Loss: 0.8874703049659729, alpha: 0.9154443748987733\n",
      "epoch 603 iteration100, G Loss: 1.2884578704833984, D Loss: 1.1246864795684814, alpha: 0.9154443748987733\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 604 iteration0, G Loss: 1.1399551630020142, D Loss: 1.650683879852295, alpha: 0.9149787798944143\n",
      "epoch 604 iteration100, G Loss: 1.5714857578277588, D Loss: 1.1027239561080933, alpha: 0.9149787798944143\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 605 iteration0, G Loss: 1.7688699960708618, D Loss: 0.985228955745697, alpha: 0.9145108605651935\n",
      "epoch 605 iteration100, G Loss: 0.8269656300544739, D Loss: 1.741365671157837, alpha: 0.9145108605651935\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 606 iteration0, G Loss: 1.2891931533813477, D Loss: 1.1400220394134521, alpha: 0.9140406079482077\n",
      "epoch 606 iteration100, G Loss: 2.393894910812378, D Loss: 1.053346037864685, alpha: 0.9140406079482077\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 607 iteration0, G Loss: 1.7611980438232422, D Loss: 1.1116623878479004, alpha: 0.9135680130753614\n",
      "epoch 607 iteration100, G Loss: 1.0507932901382446, D Loss: 0.8879594206809998, alpha: 0.9135680130753614\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 608 iteration0, G Loss: 1.0829734802246094, D Loss: 0.8681182861328125, alpha: 0.91309306697374\n",
      "epoch 608 iteration100, G Loss: 1.1639702320098877, D Loss: 1.4239968061447144, alpha: 0.91309306697374\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 609 iteration0, G Loss: 2.622256278991699, D Loss: 1.0313584804534912, alpha: 0.9126157606659895\n",
      "epoch 609 iteration100, G Loss: 1.7301139831542969, D Loss: 1.3007116317749023, alpha: 0.9126157606659895\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 610 iteration0, G Loss: 1.9456868171691895, D Loss: 0.9513574838638306, alpha: 0.9121360851706988\n",
      "epoch 610 iteration100, G Loss: 0.9100878238677979, D Loss: 1.077570915222168, alpha: 0.9121360851706988\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 611 iteration0, G Loss: 0.9641095399856567, D Loss: 1.2492568492889404, alpha: 0.9116540315027887\n",
      "epoch 611 iteration100, G Loss: 1.4311888217926025, D Loss: 1.1069490909576416, alpha: 0.9116540315027887\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 612 iteration0, G Loss: 1.4735262393951416, D Loss: 1.2555007934570312, alpha: 0.9111695906739038\n",
      "epoch 612 iteration100, G Loss: 0.8878355026245117, D Loss: 1.3372316360473633, alpha: 0.9111695906739038\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 613 iteration0, G Loss: 2.2354609966278076, D Loss: 1.2870702743530273, alpha: 0.9106827536928102\n",
      "epoch 613 iteration100, G Loss: 0.9928192496299744, D Loss: 1.1065682172775269, alpha: 0.9106827536928102\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 614 iteration0, G Loss: 2.3642501831054688, D Loss: 1.024402379989624, alpha: 0.9101935115657962\n",
      "epoch 614 iteration100, G Loss: 1.2212237119674683, D Loss: 1.0845165252685547, alpha: 0.9101935115657962\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 615 iteration0, G Loss: 1.1888959407806396, D Loss: 1.3129085302352905, alpha: 0.9097018552970801\n",
      "epoch 615 iteration100, G Loss: 1.462640643119812, D Loss: 1.3471416234970093, alpha: 0.9097018552970801\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 616 iteration0, G Loss: 2.9941647052764893, D Loss: 1.2303617000579834, alpha: 0.9092077758892203\n",
      "epoch 616 iteration100, G Loss: 1.8448466062545776, D Loss: 1.270256519317627, alpha: 0.9092077758892203\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 617 iteration0, G Loss: 1.3041033744812012, D Loss: 1.231999158859253, alpha: 0.9087112643435313\n",
      "epoch 617 iteration100, G Loss: 0.8044129014015198, D Loss: 1.4226547479629517, alpha: 0.9087112643435313\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 618 iteration0, G Loss: 1.5648747682571411, D Loss: 0.8305811285972595, alpha: 0.9082123116605046\n",
      "epoch 618 iteration100, G Loss: 2.5792837142944336, D Loss: 0.9142191410064697, alpha: 0.9082123116605046\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 619 iteration0, G Loss: 1.4471412897109985, D Loss: 1.0275535583496094, alpha: 0.9077109088402335\n",
      "epoch 619 iteration100, G Loss: 1.4435008764266968, D Loss: 0.8893656730651855, alpha: 0.9077109088402335\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 620 iteration0, G Loss: 1.934776782989502, D Loss: 1.4842805862426758, alpha: 0.9072070468828429\n",
      "epoch 620 iteration100, G Loss: 1.1161117553710938, D Loss: 0.8843628764152527, alpha: 0.9072070468828429\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 621 iteration0, G Loss: 1.4613744020462036, D Loss: 1.4474196434020996, alpha: 0.9067007167889249\n",
      "epoch 621 iteration100, G Loss: 2.403575897216797, D Loss: 1.3273065090179443, alpha: 0.9067007167889249\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 622 iteration0, G Loss: 1.3319753408432007, D Loss: 0.9933560490608215, alpha: 0.9061919095599771\n",
      "epoch 622 iteration100, G Loss: 1.8205291032791138, D Loss: 0.9766976833343506, alpha: 0.9061919095599771\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 623 iteration0, G Loss: 2.5463900566101074, D Loss: 1.6338529586791992, alpha: 0.9056806161988479\n",
      "epoch 623 iteration100, G Loss: 1.7859618663787842, D Loss: 0.8609456419944763, alpha: 0.9056806161988479\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 624 iteration0, G Loss: 1.8572362661361694, D Loss: 1.1570357084274292, alpha: 0.9051668277101852\n",
      "epoch 624 iteration100, G Loss: 1.6422184705734253, D Loss: 1.2762452363967896, alpha: 0.9051668277101852\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 625 iteration0, G Loss: 2.009685516357422, D Loss: 1.706173062324524, alpha: 0.9046505351008906\n",
      "epoch 625 iteration100, G Loss: 2.682906150817871, D Loss: 0.9891818165779114, alpha: 0.9046505351008906\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 626 iteration0, G Loss: 1.639267086982727, D Loss: 0.9850281476974487, alpha: 0.9041317293805773\n",
      "epoch 626 iteration100, G Loss: 1.7430726289749146, D Loss: 1.3197085857391357, alpha: 0.9041317293805773\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 627 iteration0, G Loss: 1.596381664276123, D Loss: 1.1029534339904785, alpha: 0.9036104015620353\n",
      "epoch 627 iteration100, G Loss: 1.9668495655059814, D Loss: 0.9136915802955627, alpha: 0.9036104015620353\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 628 iteration0, G Loss: 1.3400331735610962, D Loss: 0.6154333353042603, alpha: 0.9030865426616987\n",
      "epoch 628 iteration100, G Loss: 1.7678227424621582, D Loss: 1.220198154449463, alpha: 0.9030865426616987\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 629 iteration0, G Loss: 1.0485237836837769, D Loss: 1.42183256149292, alpha: 0.9025601437001196\n",
      "epoch 629 iteration100, G Loss: 1.7476985454559326, D Loss: 1.1372404098510742, alpha: 0.9025601437001196\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 630 iteration0, G Loss: 1.3954832553863525, D Loss: 1.3311643600463867, alpha: 0.902031195702446\n",
      "epoch 630 iteration100, G Loss: 2.1052350997924805, D Loss: 1.128733515739441, alpha: 0.902031195702446\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 631 iteration0, G Loss: 1.3151168823242188, D Loss: 1.1237239837646484, alpha: 0.901499689698906\n",
      "epoch 631 iteration100, G Loss: 1.7690227031707764, D Loss: 0.8785435557365417, alpha: 0.901499689698906\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 632 iteration0, G Loss: 0.7270787954330444, D Loss: 1.6301498413085938, alpha: 0.9009656167252947\n",
      "epoch 632 iteration100, G Loss: 2.220377206802368, D Loss: 1.5483232736587524, alpha: 0.9009656167252947\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 633 iteration0, G Loss: 1.3810076713562012, D Loss: 1.246910810470581, alpha: 0.9004289678234686\n",
      "epoch 633 iteration100, G Loss: 2.184680938720703, D Loss: 1.0281693935394287, alpha: 0.9004289678234686\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 634 iteration0, G Loss: 1.1222249269485474, D Loss: 1.0222358703613281, alpha: 0.8998897340418424\n",
      "epoch 634 iteration100, G Loss: 2.366161823272705, D Loss: 1.0140917301177979, alpha: 0.8998897340418424\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 635 iteration0, G Loss: 1.0451000928878784, D Loss: 1.2062709331512451, alpha: 0.8993479064358931\n",
      "epoch 635 iteration100, G Loss: 2.0013322830200195, D Loss: 1.093604564666748, alpha: 0.8993479064358931\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 636 iteration0, G Loss: 0.871156632900238, D Loss: 1.2266104221343994, alpha: 0.8988034760686675\n",
      "epoch 636 iteration100, G Loss: 1.8616667985916138, D Loss: 1.3208270072937012, alpha: 0.8988034760686675\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 637 iteration0, G Loss: 2.662715435028076, D Loss: 0.9413629770278931, alpha: 0.8982564340112953\n",
      "epoch 637 iteration100, G Loss: 1.1276905536651611, D Loss: 1.2269792556762695, alpha: 0.8982564340112953\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 638 iteration0, G Loss: 1.5153026580810547, D Loss: 1.0527997016906738, alpha: 0.8977067713435066\n",
      "epoch 638 iteration100, G Loss: 1.0159261226654053, D Loss: 0.9570120573043823, alpha: 0.8977067713435066\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 639 iteration0, G Loss: 1.7656071186065674, D Loss: 1.142927885055542, alpha: 0.8971544791541564\n",
      "epoch 639 iteration100, G Loss: 1.7445619106292725, D Loss: 0.8898765444755554, alpha: 0.8971544791541564\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 640 iteration0, G Loss: 2.2417306900024414, D Loss: 1.01439368724823, alpha: 0.8965995485417504\n",
      "epoch 640 iteration100, G Loss: 2.654338836669922, D Loss: 1.1113498210906982, alpha: 0.8965995485417504\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 641 iteration0, G Loss: 1.937744140625, D Loss: 1.281788945198059, alpha: 0.8960419706149801\n",
      "epoch 641 iteration100, G Loss: 1.4297916889190674, D Loss: 0.9271499514579773, alpha: 0.8960419706149801\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 642 iteration0, G Loss: 0.7868325114250183, D Loss: 0.8519773483276367, alpha: 0.8954817364932596\n",
      "epoch 642 iteration100, G Loss: 1.5747628211975098, D Loss: 0.9947783946990967, alpha: 0.8954817364932596\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 643 iteration0, G Loss: 1.6234979629516602, D Loss: 0.9287451505661011, alpha: 0.8949188373072692\n",
      "epoch 643 iteration100, G Loss: 1.4084157943725586, D Loss: 1.2965795993804932, alpha: 0.8949188373072692\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 644 iteration0, G Loss: 1.9128739833831787, D Loss: 2.1879489421844482, alpha: 0.8943532641995036\n",
      "epoch 644 iteration100, G Loss: 2.710041046142578, D Loss: 1.118765950202942, alpha: 0.8943532641995036\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 645 iteration0, G Loss: 2.32865571975708, D Loss: 1.062586784362793, alpha: 0.8937850083248244\n",
      "epoch 645 iteration100, G Loss: 1.4343193769454956, D Loss: 0.9247605800628662, alpha: 0.8937850083248244\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 646 iteration0, G Loss: 1.557482123374939, D Loss: 1.4851375818252563, alpha: 0.8932140608510197\n",
      "epoch 646 iteration100, G Loss: 0.8968881368637085, D Loss: 1.3279595375061035, alpha: 0.8932140608510197\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 647 iteration0, G Loss: 1.3546898365020752, D Loss: 1.173166275024414, alpha: 0.8926404129593662\n",
      "epoch 647 iteration100, G Loss: 1.5687148571014404, D Loss: 1.6341438293457031, alpha: 0.8926404129593662\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 648 iteration0, G Loss: 1.8543646335601807, D Loss: 1.176018238067627, alpha: 0.8920640558451981\n",
      "epoch 648 iteration100, G Loss: 2.177448272705078, D Loss: 1.1442835330963135, alpha: 0.8920640558451981\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 649 iteration0, G Loss: 1.2401318550109863, D Loss: 1.259421706199646, alpha: 0.8914849807184801\n",
      "epoch 649 iteration100, G Loss: 1.3376851081848145, D Loss: 1.2388689517974854, alpha: 0.8914849807184801\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 650 iteration0, G Loss: 1.4328105449676514, D Loss: 1.5134518146514893, alpha: 0.8909031788043871\n",
      "epoch 650 iteration100, G Loss: 0.44631463289260864, D Loss: 1.4340884685516357, alpha: 0.8909031788043871\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 651 iteration0, G Loss: 2.1015827655792236, D Loss: 1.0536620616912842, alpha: 0.8903186413438859\n",
      "epoch 651 iteration100, G Loss: 0.8897713422775269, D Loss: 0.9747447967529297, alpha: 0.8903186413438859\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 652 iteration0, G Loss: 1.4043277502059937, D Loss: 1.189713478088379, alpha: 0.8897313595943259\n",
      "epoch 652 iteration100, G Loss: 1.5007038116455078, D Loss: 0.977864682674408, alpha: 0.8897313595943259\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 653 iteration0, G Loss: 1.9713748693466187, D Loss: 1.2894179821014404, alpha: 0.8891413248300313\n",
      "epoch 653 iteration100, G Loss: 1.0704177618026733, D Loss: 0.9264489412307739, alpha: 0.8891413248300313\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 654 iteration0, G Loss: 1.8937418460845947, D Loss: 0.891860842704773, alpha: 0.8885485283429004\n",
      "epoch 654 iteration100, G Loss: 0.8274714946746826, D Loss: 1.0928189754486084, alpha: 0.8885485283429004\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 655 iteration0, G Loss: 1.6848212480545044, D Loss: 1.0408833026885986, alpha: 0.8879529614430097\n",
      "epoch 655 iteration100, G Loss: 1.3406124114990234, D Loss: 0.9418039321899414, alpha: 0.8879529614430097\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 656 iteration0, G Loss: 0.8740427494049072, D Loss: 1.2309744358062744, alpha: 0.8873546154592227\n",
      "epoch 656 iteration100, G Loss: 2.8344504833221436, D Loss: 1.2103089094161987, alpha: 0.8873546154592227\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 657 iteration0, G Loss: 1.4555034637451172, D Loss: 1.2880244255065918, alpha: 0.8867534817398037\n",
      "epoch 657 iteration100, G Loss: 2.5999250411987305, D Loss: 1.1656980514526367, alpha: 0.8867534817398037\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 658 iteration0, G Loss: 2.015979528427124, D Loss: 1.2402610778808594, alpha: 0.8861495516530374\n",
      "epoch 658 iteration100, G Loss: 2.0993776321411133, D Loss: 1.2432317733764648, alpha: 0.8861495516530374\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 659 iteration0, G Loss: 1.7379956245422363, D Loss: 1.4689369201660156, alpha: 0.8855428165878523\n",
      "epoch 659 iteration100, G Loss: 1.6050138473510742, D Loss: 1.0051920413970947, alpha: 0.8855428165878523\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 660 iteration0, G Loss: 1.0862295627593994, D Loss: 1.0198582410812378, alpha: 0.8849332679544502\n",
      "epoch 660 iteration100, G Loss: 1.3619459867477417, D Loss: 1.207131028175354, alpha: 0.8849332679544502\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 661 iteration0, G Loss: 1.8408281803131104, D Loss: 1.3086246252059937, alpha: 0.8843208971849409\n",
      "epoch 661 iteration100, G Loss: 1.4936639070510864, D Loss: 1.270815372467041, alpha: 0.8843208971849409\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 662 iteration0, G Loss: 1.4012303352355957, D Loss: 0.7658183574676514, alpha: 0.883705695733981\n",
      "epoch 662 iteration100, G Loss: 1.435448408126831, D Loss: 1.1855406761169434, alpha: 0.883705695733981\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 663 iteration0, G Loss: 0.8702884316444397, D Loss: 1.3109195232391357, alpha: 0.8830876550794178\n",
      "epoch 663 iteration100, G Loss: 2.1105897426605225, D Loss: 1.125377893447876, alpha: 0.8830876550794178\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 664 iteration0, G Loss: 1.5664329528808594, D Loss: 0.9362594485282898, alpha: 0.88246676672294\n",
      "epoch 664 iteration100, G Loss: 2.4646005630493164, D Loss: 1.0161712169647217, alpha: 0.88246676672294\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 665 iteration0, G Loss: 1.8953461647033691, D Loss: 0.9839851260185242, alpha: 0.8818430221907304\n",
      "epoch 665 iteration100, G Loss: 0.9069645404815674, D Loss: 1.4094517230987549, alpha: 0.8818430221907304\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 666 iteration0, G Loss: 1.4072822332382202, D Loss: 1.163550853729248, alpha: 0.8812164130341268\n",
      "epoch 666 iteration100, G Loss: 0.9612175226211548, D Loss: 1.3823257684707642, alpha: 0.8812164130341268\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 667 iteration0, G Loss: 1.1466021537780762, D Loss: 1.2831904888153076, alpha: 0.8805869308302849\n",
      "epoch 667 iteration100, G Loss: 2.4103665351867676, D Loss: 1.0159854888916016, alpha: 0.8805869308302849\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 668 iteration0, G Loss: 2.106266736984253, D Loss: 1.278266429901123, alpha: 0.8799545671828493\n",
      "epoch 668 iteration100, G Loss: 1.5082225799560547, D Loss: 0.8412033915519714, alpha: 0.8799545671828493\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 669 iteration0, G Loss: 1.2355763912200928, D Loss: 1.1545846462249756, alpha: 0.8793193137226258\n",
      "epoch 669 iteration100, G Loss: 2.0225720405578613, D Loss: 1.4420828819274902, alpha: 0.8793193137226258\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 670 iteration0, G Loss: 1.3818259239196777, D Loss: 0.8898124098777771, alpha: 0.8786811621082631\n",
      "epoch 670 iteration100, G Loss: 1.4545364379882812, D Loss: 1.3247926235198975, alpha: 0.8786811621082631\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 671 iteration0, G Loss: 2.881127119064331, D Loss: 1.1619877815246582, alpha: 0.8780401040269349\n",
      "epoch 671 iteration100, G Loss: 0.478851318359375, D Loss: 1.50831937789917, alpha: 0.8780401040269349\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 672 iteration0, G Loss: 1.5124311447143555, D Loss: 1.2053778171539307, alpha: 0.8773961311950302\n",
      "epoch 672 iteration100, G Loss: 1.3015567064285278, D Loss: 1.3240392208099365, alpha: 0.8773961311950302\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 673 iteration0, G Loss: 2.4248898029327393, D Loss: 0.9114032983779907, alpha: 0.8767492353588473\n",
      "epoch 673 iteration100, G Loss: 1.3659799098968506, D Loss: 1.0836148262023926, alpha: 0.8767492353588473\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 674 iteration0, G Loss: 2.562228202819824, D Loss: 1.2294636964797974, alpha: 0.8760994082952922\n",
      "epoch 674 iteration100, G Loss: 1.7263593673706055, D Loss: 1.3238054513931274, alpha: 0.8760994082952922\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 675 iteration0, G Loss: 2.5769336223602295, D Loss: 1.0296127796173096, alpha: 0.8754466418125836\n",
      "epoch 675 iteration100, G Loss: 1.5082335472106934, D Loss: 0.9191799163818359, alpha: 0.8754466418125836\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 676 iteration0, G Loss: 1.9601577520370483, D Loss: 1.2855875492095947, alpha: 0.8747909277509601\n",
      "epoch 676 iteration100, G Loss: 0.902873158454895, D Loss: 1.1156220436096191, alpha: 0.8747909277509601\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 677 iteration0, G Loss: 1.7871439456939697, D Loss: 1.12040376663208, alpha: 0.8741322579833951\n",
      "epoch 677 iteration100, G Loss: 2.073057174682617, D Loss: 1.0372101068496704, alpha: 0.8741322579833951\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 678 iteration0, G Loss: 2.3921990394592285, D Loss: 1.2721736431121826, alpha: 0.8734706244163147\n",
      "epoch 678 iteration100, G Loss: 1.4547088146209717, D Loss: 1.422940969467163, alpha: 0.8734706244163147\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 679 iteration0, G Loss: 1.1313945055007935, D Loss: 1.2572526931762695, alpha: 0.8728060189903207\n",
      "epoch 679 iteration100, G Loss: 2.003892421722412, D Loss: 1.0111112594604492, alpha: 0.8728060189903207\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 680 iteration0, G Loss: 1.9666029214859009, D Loss: 0.705127477645874, alpha: 0.8721384336809187\n",
      "epoch 680 iteration100, G Loss: 1.2026143074035645, D Loss: 1.2939854860305786, alpha: 0.8721384336809187\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 681 iteration0, G Loss: 0.5775175094604492, D Loss: 1.5630227327346802, alpha: 0.871467860499251\n",
      "epoch 681 iteration100, G Loss: 1.1006077527999878, D Loss: 1.0990495681762695, alpha: 0.871467860499251\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 682 iteration0, G Loss: 0.7563612461090088, D Loss: 1.621851921081543, alpha: 0.8707942914928337\n",
      "epoch 682 iteration100, G Loss: 0.6225694417953491, D Loss: 1.5146448612213135, alpha: 0.8707942914928337\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 683 iteration0, G Loss: 1.4244792461395264, D Loss: 1.1123168468475342, alpha: 0.8701177187462997\n",
      "epoch 683 iteration100, G Loss: 2.121371269226074, D Loss: 0.9320487380027771, alpha: 0.8701177187462997\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 684 iteration0, G Loss: 1.8675174713134766, D Loss: 1.373400092124939, alpha: 0.869438134382144\n",
      "epoch 684 iteration100, G Loss: 2.150815010070801, D Loss: 1.1435092687606812, alpha: 0.869438134382144\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 685 iteration0, G Loss: 0.8140947818756104, D Loss: 1.3529537916183472, alpha: 0.8687555305614766\n",
      "epoch 685 iteration100, G Loss: 1.7180064916610718, D Loss: 1.6392803192138672, alpha: 0.8687555305614766\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 686 iteration0, G Loss: 3.285804033279419, D Loss: 1.323400616645813, alpha: 0.868069899484778\n",
      "epoch 686 iteration100, G Loss: 0.8761118054389954, D Loss: 1.2523934841156006, alpha: 0.868069899484778\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 687 iteration0, G Loss: 1.3395771980285645, D Loss: 1.2166659832000732, alpha: 0.8673812333926596\n",
      "epoch 687 iteration100, G Loss: 2.04110050201416, D Loss: 1.2794039249420166, alpha: 0.8673812333926596\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 688 iteration0, G Loss: 2.5647313594818115, D Loss: 0.9376839399337769, alpha: 0.8666895245666295\n",
      "epoch 688 iteration100, G Loss: 1.5272730588912964, D Loss: 1.3226404190063477, alpha: 0.8666895245666295\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 689 iteration0, G Loss: 1.4157578945159912, D Loss: 1.032625675201416, alpha: 0.8659947653298621\n",
      "epoch 689 iteration100, G Loss: 2.642509698867798, D Loss: 1.1067430973052979, alpha: 0.8659947653298621\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 690 iteration0, G Loss: 1.7602823972702026, D Loss: 0.9707805514335632, alpha: 0.865296948047972\n",
      "epoch 690 iteration100, G Loss: 1.6250666379928589, D Loss: 0.9931065440177917, alpha: 0.865296948047972\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 691 iteration0, G Loss: 1.9849648475646973, D Loss: 1.111031413078308, alpha: 0.8645960651297927\n",
      "epoch 691 iteration100, G Loss: 2.5393693447113037, D Loss: 1.3392847776412964, alpha: 0.8645960651297927\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 692 iteration0, G Loss: 1.7772902250289917, D Loss: 0.9237094521522522, alpha: 0.8638921090281604\n",
      "epoch 692 iteration100, G Loss: 1.1685569286346436, D Loss: 1.154503583908081, alpha: 0.8638921090281604\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 693 iteration0, G Loss: 1.1230387687683105, D Loss: 1.0395867824554443, alpha: 0.8631850722407007\n",
      "epoch 693 iteration100, G Loss: 1.7741488218307495, D Loss: 0.8428595066070557, alpha: 0.8631850722407007\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 694 iteration0, G Loss: 1.280017375946045, D Loss: 0.8587614893913269, alpha: 0.862474947310621\n",
      "epoch 694 iteration100, G Loss: 2.395887613296509, D Loss: 0.985934853553772, alpha: 0.862474947310621\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 695 iteration0, G Loss: 1.7523311376571655, D Loss: 1.0370278358459473, alpha: 0.861761726827506\n",
      "epoch 695 iteration100, G Loss: 0.9158483147621155, D Loss: 1.1757395267486572, alpha: 0.861761726827506\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 696 iteration0, G Loss: 1.990959644317627, D Loss: 1.3470244407653809, alpha: 0.8610454034281185\n",
      "epoch 696 iteration100, G Loss: 1.3114848136901855, D Loss: 0.8771705627441406, alpha: 0.8610454034281185\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 697 iteration0, G Loss: 1.1365776062011719, D Loss: 0.8731030821800232, alpha: 0.8603259697972045\n",
      "epoch 697 iteration100, G Loss: 1.9757798910140991, D Loss: 1.1065727472305298, alpha: 0.8603259697972045\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 698 iteration0, G Loss: 2.47357177734375, D Loss: 0.8414894342422485, alpha: 0.8596034186683009\n",
      "epoch 698 iteration100, G Loss: 1.635965347290039, D Loss: 1.1718363761901855, alpha: 0.8596034186683009\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 699 iteration0, G Loss: 1.2473984956741333, D Loss: 1.3111218214035034, alpha: 0.8588777428245492\n",
      "epoch 699 iteration100, G Loss: 1.1945011615753174, D Loss: 1.2155002355575562, alpha: 0.8588777428245492\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 700 iteration0, G Loss: 1.7095035314559937, D Loss: 1.052340030670166, alpha: 0.8581489350995122\n",
      "epoch 700 iteration100, G Loss: 1.159242868423462, D Loss: 1.11708402633667, alpha: 0.8581489350995122\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 701 iteration0, G Loss: 0.7991862297058105, D Loss: 1.1236029863357544, alpha: 0.8574169883779953\n",
      "epoch 701 iteration100, G Loss: 1.9064277410507202, D Loss: 1.2409559488296509, alpha: 0.8574169883779953\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 702 iteration0, G Loss: 0.855459451675415, D Loss: 1.2617437839508057, alpha: 0.8566818955968716\n",
      "epoch 702 iteration100, G Loss: 1.5301001071929932, D Loss: 0.9698488712310791, alpha: 0.8566818955968716\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 703 iteration0, G Loss: 1.3060314655303955, D Loss: 1.1516880989074707, alpha: 0.85594364974591\n",
      "epoch 703 iteration100, G Loss: 1.7841143608093262, D Loss: 1.301993727684021, alpha: 0.85594364974591\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 704 iteration0, G Loss: 1.956037163734436, D Loss: 1.4263694286346436, alpha: 0.8552022438686094\n",
      "epoch 704 iteration100, G Loss: 2.6454601287841797, D Loss: 0.9026949405670166, alpha: 0.8552022438686094\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 705 iteration0, G Loss: 2.3384695053100586, D Loss: 1.273322582244873, alpha: 0.8544576710630347\n",
      "epoch 705 iteration100, G Loss: 2.010253667831421, D Loss: 1.1636865139007568, alpha: 0.8544576710630347\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 706 iteration0, G Loss: 1.588689923286438, D Loss: 1.1078009605407715, alpha: 0.8537099244826571\n",
      "epoch 706 iteration100, G Loss: 1.9671013355255127, D Loss: 1.3431458473205566, alpha: 0.8537099244826571\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 707 iteration0, G Loss: 0.9398061037063599, D Loss: 1.3702030181884766, alpha: 0.8529589973371989\n",
      "epoch 707 iteration100, G Loss: 1.404011845588684, D Loss: 1.015611171722412, alpha: 0.8529589973371989\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 708 iteration0, G Loss: 0.6959141492843628, D Loss: 1.135251522064209, alpha: 0.852204882893481\n",
      "epoch 708 iteration100, G Loss: 0.7252280712127686, D Loss: 1.54770827293396, alpha: 0.852204882893481\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 709 iteration0, G Loss: 2.008450746536255, D Loss: 1.0350725650787354, alpha: 0.8514475744762745\n",
      "epoch 709 iteration100, G Loss: 1.0748659372329712, D Loss: 1.2319645881652832, alpha: 0.8514475744762745\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 710 iteration0, G Loss: 1.868513584136963, D Loss: 2.252652883529663, alpha: 0.8506870654691563\n",
      "epoch 710 iteration100, G Loss: 1.462106466293335, D Loss: 1.5237147808074951, alpha: 0.8506870654691563\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 711 iteration0, G Loss: 1.2743961811065674, D Loss: 0.9226123094558716, alpha: 0.8499233493153666\n",
      "epoch 711 iteration100, G Loss: 1.2246057987213135, D Loss: 1.3569390773773193, alpha: 0.8499233493153666\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 712 iteration0, G Loss: 0.7604957222938538, D Loss: 1.2960361242294312, alpha: 0.8491564195186722\n",
      "epoch 712 iteration100, G Loss: 1.2294948101043701, D Loss: 1.1648640632629395, alpha: 0.8491564195186722\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 713 iteration0, G Loss: 1.390010952949524, D Loss: 1.0151867866516113, alpha: 0.848386269644231\n",
      "epoch 713 iteration100, G Loss: 2.5552823543548584, D Loss: 0.9005135297775269, alpha: 0.848386269644231\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 714 iteration0, G Loss: 1.6761798858642578, D Loss: 1.1792875528335571, alpha: 0.8476128933194615\n",
      "epoch 714 iteration100, G Loss: 1.2824455499649048, D Loss: 1.249247670173645, alpha: 0.8476128933194615\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 715 iteration0, G Loss: 2.8568782806396484, D Loss: 1.0654675960540771, alpha: 0.8468362842349137\n",
      "epoch 715 iteration100, G Loss: 1.7157708406448364, D Loss: 1.4133975505828857, alpha: 0.8468362842349137\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 716 iteration0, G Loss: 1.6069376468658447, D Loss: 0.9924706220626831, alpha: 0.8460564361451456\n",
      "epoch 716 iteration100, G Loss: 1.6770755052566528, D Loss: 1.128861427307129, alpha: 0.8460564361451456\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 717 iteration0, G Loss: 1.6323060989379883, D Loss: 1.1697838306427002, alpha: 0.8452733428696002\n",
      "epoch 717 iteration100, G Loss: 1.872128963470459, D Loss: 0.950339674949646, alpha: 0.8452733428696002\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 718 iteration0, G Loss: 1.9504050016403198, D Loss: 1.318636178970337, alpha: 0.8444869982934881\n",
      "epoch 718 iteration100, G Loss: 1.1792970895767212, D Loss: 0.8322012424468994, alpha: 0.8444869982934881\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 719 iteration0, G Loss: 2.767503261566162, D Loss: 1.160375714302063, alpha: 0.8436973963686705\n",
      "epoch 719 iteration100, G Loss: 1.622468113899231, D Loss: 1.0802116394042969, alpha: 0.8436973963686705\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 720 iteration0, G Loss: 1.632110357284546, D Loss: 1.0989124774932861, alpha: 0.8429045311145472\n",
      "epoch 720 iteration100, G Loss: 1.8788132667541504, D Loss: 1.1771293878555298, alpha: 0.8429045311145472\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 721 iteration0, G Loss: 1.679524302482605, D Loss: 1.4668020009994507, alpha: 0.8421083966189471\n",
      "epoch 721 iteration100, G Loss: 1.7609832286834717, D Loss: 1.0932742357254028, alpha: 0.8421083966189471\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 722 iteration0, G Loss: 1.4752402305603027, D Loss: 1.251729130744934, alpha: 0.8413089870390198\n",
      "epoch 722 iteration100, G Loss: 2.045518159866333, D Loss: 1.3190510272979736, alpha: 0.8413089870390198\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 723 iteration0, G Loss: 1.4860371351242065, D Loss: 1.003363013267517, alpha: 0.8405062966021317\n",
      "epoch 723 iteration100, G Loss: 1.3115959167480469, D Loss: 1.1875731945037842, alpha: 0.8405062966021317\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 724 iteration0, G Loss: 1.7323336601257324, D Loss: 1.1557987928390503, alpha: 0.8397003196067644\n",
      "epoch 724 iteration100, G Loss: 1.1279575824737549, D Loss: 1.3292591571807861, alpha: 0.8397003196067644\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 725 iteration0, G Loss: 1.707152009010315, D Loss: 1.2173197269439697, alpha: 0.8388910504234147\n",
      "epoch 725 iteration100, G Loss: 1.3629103899002075, D Loss: 1.0658221244812012, alpha: 0.8388910504234147\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 726 iteration0, G Loss: 2.7637763023376465, D Loss: 1.0880606174468994, alpha: 0.8380784834954982\n",
      "epoch 726 iteration100, G Loss: 1.4399957656860352, D Loss: 1.4024760723114014, alpha: 0.8380784834954982\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 727 iteration0, G Loss: 1.6165275573730469, D Loss: 0.9766440987586975, alpha: 0.8372626133402539\n",
      "epoch 727 iteration100, G Loss: 1.723345398902893, D Loss: 0.8978701233863831, alpha: 0.8372626133402539\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 728 iteration0, G Loss: 2.451261520385742, D Loss: 1.2429819107055664, alpha: 0.8364434345496531\n",
      "epoch 728 iteration100, G Loss: 0.8580676317214966, D Loss: 1.104377269744873, alpha: 0.8364434345496531\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 729 iteration0, G Loss: 1.0361862182617188, D Loss: 1.044952154159546, alpha: 0.8356209417913083\n",
      "epoch 729 iteration100, G Loss: 1.8469853401184082, D Loss: 1.1411551237106323, alpha: 0.8356209417913083\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 730 iteration0, G Loss: 2.7021095752716064, D Loss: 1.1767834424972534, alpha: 0.8347951298093854\n",
      "epoch 730 iteration100, G Loss: 3.8486711978912354, D Loss: 1.128791332244873, alpha: 0.8347951298093854\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 731 iteration0, G Loss: 1.9874814748764038, D Loss: 0.8873296976089478, alpha: 0.8339659934255179\n",
      "epoch 731 iteration100, G Loss: 1.3728429079055786, D Loss: 1.3419189453125, alpha: 0.8339659934255179\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 732 iteration0, G Loss: 0.9952539205551147, D Loss: 1.0833848714828491, alpha: 0.8331335275397229\n",
      "epoch 732 iteration100, G Loss: 2.041719436645508, D Loss: 1.1756696701049805, alpha: 0.8331335275397229\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 733 iteration0, G Loss: 1.3709533214569092, D Loss: 0.9184209108352661, alpha: 0.8322977271313189\n",
      "epoch 733 iteration100, G Loss: 1.4286305904388428, D Loss: 1.3166428804397583, alpha: 0.8322977271313189\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 734 iteration0, G Loss: 1.3702996969223022, D Loss: 0.7090314626693726, alpha: 0.8314585872598446\n",
      "epoch 734 iteration100, G Loss: 1.8540846109390259, D Loss: 0.7130419015884399, alpha: 0.8314585872598446\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 735 iteration0, G Loss: 1.9173063039779663, D Loss: 1.2459863424301147, alpha: 0.8306161030659813\n",
      "epoch 735 iteration100, G Loss: 0.6198103427886963, D Loss: 1.766791582107544, alpha: 0.8306161030659813\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 736 iteration0, G Loss: 1.3070448637008667, D Loss: 1.1388343572616577, alpha: 0.8297702697724747\n",
      "epoch 736 iteration100, G Loss: 2.1237308979034424, D Loss: 1.040194034576416, alpha: 0.8297702697724747\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 737 iteration0, G Loss: 2.4188411235809326, D Loss: 0.9195234775543213, alpha: 0.82892108268506\n",
      "epoch 737 iteration100, G Loss: 2.383129596710205, D Loss: 0.822987973690033, alpha: 0.82892108268506\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 738 iteration0, G Loss: 1.1095397472381592, D Loss: 0.7383133172988892, alpha: 0.8280685371933862\n",
      "epoch 738 iteration100, G Loss: 1.3329734802246094, D Loss: 1.3976500034332275, alpha: 0.8280685371933862\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 739 iteration0, G Loss: 2.041139602661133, D Loss: 1.993440866470337, alpha: 0.8272126287719443\n",
      "epoch 739 iteration100, G Loss: 1.5912855863571167, D Loss: 0.9803531765937805, alpha: 0.8272126287719443\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 740 iteration0, G Loss: 1.1393824815750122, D Loss: 1.2110190391540527, alpha: 0.8263533529809949\n",
      "epoch 740 iteration100, G Loss: 1.3166115283966064, D Loss: 1.095703363418579, alpha: 0.8263533529809949\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 741 iteration0, G Loss: 1.0403366088867188, D Loss: 1.1313825845718384, alpha: 0.8254907054674968\n",
      "epoch 741 iteration100, G Loss: 0.4298137426376343, D Loss: 1.5178866386413574, alpha: 0.8254907054674968\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 742 iteration0, G Loss: 1.464365005493164, D Loss: 1.5005311965942383, alpha: 0.8246246819660374\n",
      "epoch 742 iteration100, G Loss: 1.235507845878601, D Loss: 1.5896636247634888, alpha: 0.8246246819660374\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 743 iteration0, G Loss: 2.1020052433013916, D Loss: 1.4098825454711914, alpha: 0.8237552782997641\n",
      "epoch 743 iteration100, G Loss: 1.5230392217636108, D Loss: 1.154154658317566, alpha: 0.8237552782997641\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 744 iteration0, G Loss: 1.8210264444351196, D Loss: 1.147566556930542, alpha: 0.8228824903813154\n",
      "epoch 744 iteration100, G Loss: 2.4385530948638916, D Loss: 1.2052899599075317, alpha: 0.8228824903813154\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 745 iteration0, G Loss: 1.7854198217391968, D Loss: 1.1431748867034912, alpha: 0.8220063142137535\n",
      "epoch 745 iteration100, G Loss: 1.028975009918213, D Loss: 1.2290583848953247, alpha: 0.8220063142137535\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 746 iteration0, G Loss: 1.7483079433441162, D Loss: 0.8372806310653687, alpha: 0.8211267458914967\n",
      "epoch 746 iteration100, G Loss: 2.6064162254333496, D Loss: 1.032729148864746, alpha: 0.8211267458914967\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 747 iteration0, G Loss: 1.0454741716384888, D Loss: 1.5546362400054932, alpha: 0.8202437816012536\n",
      "epoch 747 iteration100, G Loss: 1.4933809041976929, D Loss: 1.0953000783920288, alpha: 0.8202437816012536\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 748 iteration0, G Loss: 1.5676498413085938, D Loss: 1.1243929862976074, alpha: 0.8193574176229559\n",
      "epoch 748 iteration100, G Loss: 1.881148338317871, D Loss: 1.4089031219482422, alpha: 0.8193574176229559\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 749 iteration0, G Loss: 2.2443740367889404, D Loss: 1.0362298488616943, alpha: 0.8184676503306926\n",
      "epoch 749 iteration100, G Loss: 2.811584949493408, D Loss: 0.7759271860122681, alpha: 0.8184676503306926\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 750 iteration0, G Loss: 1.0122562646865845, D Loss: 1.3584747314453125, alpha: 0.8175744761936437\n",
      "epoch 750 iteration100, G Loss: 2.0937447547912598, D Loss: 1.0066108703613281, alpha: 0.8175744761936437\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 751 iteration0, G Loss: 1.9133577346801758, D Loss: 1.1039295196533203, alpha: 0.8166778917770144\n",
      "epoch 751 iteration100, G Loss: 1.4369581937789917, D Loss: 0.8229231834411621, alpha: 0.8166778917770144\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 752 iteration0, G Loss: 2.071280002593994, D Loss: 1.0346100330352783, alpha: 0.8157778937429687\n",
      "epoch 752 iteration100, G Loss: 0.9302627444267273, D Loss: 1.416661262512207, alpha: 0.8157778937429687\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 753 iteration0, G Loss: 1.5709160566329956, D Loss: 1.0779533386230469, alpha: 0.8148744788515628\n",
      "epoch 753 iteration100, G Loss: 1.3911199569702148, D Loss: 1.001737117767334, alpha: 0.8148744788515628\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 754 iteration0, G Loss: 1.7378311157226562, D Loss: 1.1663825511932373, alpha: 0.813967643961678\n",
      "epoch 754 iteration100, G Loss: 1.679118037223816, D Loss: 1.1592872142791748, alpha: 0.813967643961678\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 755 iteration0, G Loss: 2.0891034603118896, D Loss: 1.1813042163848877, alpha: 0.8130573860319537\n",
      "epoch 755 iteration100, G Loss: 1.1422901153564453, D Loss: 1.3135955333709717, alpha: 0.8130573860319537\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 756 iteration0, G Loss: 2.2829930782318115, D Loss: 1.190293550491333, alpha: 0.812143702121719\n",
      "epoch 756 iteration100, G Loss: 0.7496588826179504, D Loss: 0.9784725904464722, alpha: 0.812143702121719\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 757 iteration0, G Loss: 1.7514513731002808, D Loss: 1.031385898590088, alpha: 0.8112265893919247\n",
      "epoch 757 iteration100, G Loss: 1.47190260887146, D Loss: 1.1469507217407227, alpha: 0.8112265893919247\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 758 iteration0, G Loss: 1.8671355247497559, D Loss: 1.401427149772644, alpha: 0.8103060451060722\n",
      "epoch 758 iteration100, G Loss: 0.9725958108901978, D Loss: 1.252148985862732, alpha: 0.8103060451060722\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 759 iteration0, G Loss: 1.0000653266906738, D Loss: 2.2417984008789062, alpha: 0.8093820666311443\n",
      "epoch 759 iteration100, G Loss: 0.5690761208534241, D Loss: 1.5837641954421997, alpha: 0.8093820666311443\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 760 iteration0, G Loss: 2.8501696586608887, D Loss: 0.8717635869979858, alpha: 0.8084546514385325\n",
      "epoch 760 iteration100, G Loss: 0.9828717112541199, D Loss: 1.3372690677642822, alpha: 0.8084546514385325\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 761 iteration0, G Loss: 2.0952792167663574, D Loss: 1.3312147855758667, alpha: 0.8075237971049642\n",
      "epoch 761 iteration100, G Loss: 2.73948335647583, D Loss: 0.9953892827033997, alpha: 0.8075237971049642\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 762 iteration0, G Loss: 1.5149344205856323, D Loss: 0.9813572764396667, alpha: 0.8065895013134284\n",
      "epoch 762 iteration100, G Loss: 2.3593757152557373, D Loss: 0.9787095189094543, alpha: 0.8065895013134284\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 763 iteration0, G Loss: 1.548874020576477, D Loss: 1.08204984664917, alpha: 0.8056517618540996\n",
      "epoch 763 iteration100, G Loss: 1.4514211416244507, D Loss: 0.9146275520324707, alpha: 0.8056517618540996\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 764 iteration0, G Loss: 0.7897258996963501, D Loss: 1.474153757095337, alpha: 0.8047105766252601\n",
      "epoch 764 iteration100, G Loss: 1.8354321718215942, D Loss: 1.0387651920318604, alpha: 0.8047105766252601\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 765 iteration0, G Loss: 0.992598831653595, D Loss: 1.1030033826828003, alpha: 0.8037659436342209\n",
      "epoch 765 iteration100, G Loss: 1.4811105728149414, D Loss: 1.0461047887802124, alpha: 0.8037659436342209\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 766 iteration0, G Loss: 1.579544186592102, D Loss: 0.9578022956848145, alpha: 0.8028178609982396\n",
      "epoch 766 iteration100, G Loss: 2.527245283126831, D Loss: 1.2379482984542847, alpha: 0.8028178609982396\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 767 iteration0, G Loss: 1.2393999099731445, D Loss: 0.8807404637336731, alpha: 0.8018663269454381\n",
      "epoch 767 iteration100, G Loss: 1.2182121276855469, D Loss: 0.9013856649398804, alpha: 0.8018663269454381\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 768 iteration0, G Loss: 1.1058965921401978, D Loss: 0.8707119226455688, alpha: 0.8009113398157162\n",
      "epoch 768 iteration100, G Loss: 2.2053380012512207, D Loss: 1.1308962106704712, alpha: 0.8009113398157162\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 769 iteration0, G Loss: 1.5751484632492065, D Loss: 1.0585358142852783, alpha: 0.7999528980616638\n",
      "epoch 769 iteration100, G Loss: 1.9573571681976318, D Loss: 0.945305347442627, alpha: 0.7999528980616638\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 770 iteration0, G Loss: 0.9043014645576477, D Loss: 1.2399896383285522, alpha: 0.7989910002494707\n",
      "epoch 770 iteration100, G Loss: 0.8834932446479797, D Loss: 1.534059762954712, alpha: 0.7989910002494707\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 771 iteration0, G Loss: 3.1020448207855225, D Loss: 1.0011422634124756, alpha: 0.798025645059833\n",
      "epoch 771 iteration100, G Loss: 2.0196378231048584, D Loss: 1.2829951047897339, alpha: 0.798025645059833\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 772 iteration0, G Loss: 1.3162190914154053, D Loss: 1.2026853561401367, alpha: 0.7970568312888584\n",
      "epoch 772 iteration100, G Loss: 2.2323081493377686, D Loss: 1.14271879196167, alpha: 0.7970568312888584\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 773 iteration0, G Loss: 3.4297733306884766, D Loss: 0.9194847941398621, alpha: 0.796084557848966\n",
      "epoch 773 iteration100, G Loss: 1.1738898754119873, D Loss: 1.1564562320709229, alpha: 0.796084557848966\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 774 iteration0, G Loss: 1.9726183414459229, D Loss: 0.8116593956947327, alpha: 0.7951088237697856\n",
      "epoch 774 iteration100, G Loss: 1.328153133392334, D Loss: 0.9656564593315125, alpha: 0.7951088237697856\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 775 iteration0, G Loss: 1.2688974142074585, D Loss: 0.9572764039039612, alpha: 0.7941296281990526\n",
      "epoch 775 iteration100, G Loss: 3.268124580383301, D Loss: 1.6621150970458984, alpha: 0.7941296281990526\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 776 iteration0, G Loss: 2.4752159118652344, D Loss: 1.186263918876648, alpha: 0.7931469704034991\n",
      "epoch 776 iteration100, G Loss: 1.298788070678711, D Loss: 1.0111160278320312, alpha: 0.7931469704034991\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 777 iteration0, G Loss: 1.2162728309631348, D Loss: 0.9915953874588013, alpha: 0.7921608497697423\n",
      "epoch 777 iteration100, G Loss: 1.6184524297714233, D Loss: 0.9451735615730286, alpha: 0.7921608497697423\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 778 iteration0, G Loss: 1.34382164478302, D Loss: 1.3170392513275146, alpha: 0.7911712658051694\n",
      "epoch 778 iteration100, G Loss: 1.7336881160736084, D Loss: 1.0903762578964233, alpha: 0.7911712658051694\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 779 iteration0, G Loss: 2.607290267944336, D Loss: 1.0005614757537842, alpha: 0.790178218138818\n",
      "epoch 779 iteration100, G Loss: 1.6475368738174438, D Loss: 1.320863127708435, alpha: 0.790178218138818\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 780 iteration0, G Loss: 0.7164052724838257, D Loss: 1.1687452793121338, alpha: 0.789181706522253\n",
      "epoch 780 iteration100, G Loss: 2.409868001937866, D Loss: 1.0498191118240356, alpha: 0.789181706522253\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 781 iteration0, G Loss: 2.198591947555542, D Loss: 1.0444705486297607, alpha: 0.7881817308304386\n",
      "epoch 781 iteration100, G Loss: 2.918933391571045, D Loss: 0.8135136365890503, alpha: 0.7881817308304386\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 782 iteration0, G Loss: 2.2686471939086914, D Loss: 0.8770709037780762, alpha: 0.7871782910626082\n",
      "epoch 782 iteration100, G Loss: 1.3400722742080688, D Loss: 0.8236260414123535, alpha: 0.7871782910626082\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 783 iteration0, G Loss: 2.111488103866577, D Loss: 0.8678514957427979, alpha: 0.7861713873431267\n",
      "epoch 783 iteration100, G Loss: 1.5553933382034302, D Loss: 0.8815515041351318, alpha: 0.7861713873431267\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 784 iteration0, G Loss: 1.1197679042816162, D Loss: 1.1067215204238892, alpha: 0.7851610199223515\n",
      "epoch 784 iteration100, G Loss: 1.6228573322296143, D Loss: 1.38494873046875, alpha: 0.7851610199223515\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 785 iteration0, G Loss: 0.9180954098701477, D Loss: 1.099435806274414, alpha: 0.7841471891774854\n",
      "epoch 785 iteration100, G Loss: 0.7881622910499573, D Loss: 0.9859625101089478, alpha: 0.7841471891774854\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 786 iteration0, G Loss: 1.5731124877929688, D Loss: 1.1077840328216553, alpha: 0.7831298956134283\n",
      "epoch 786 iteration100, G Loss: 1.5091933012008667, D Loss: 1.1210702657699585, alpha: 0.7831298956134283\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 787 iteration0, G Loss: 0.9437527060508728, D Loss: 0.8827217817306519, alpha: 0.7821091398636207\n",
      "epoch 787 iteration100, G Loss: 3.324366569519043, D Loss: 0.9362103939056396, alpha: 0.7821091398636207\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 788 iteration0, G Loss: 2.0948548316955566, D Loss: 0.9865771532058716, alpha: 0.7810849226908843\n",
      "epoch 788 iteration100, G Loss: 1.9157735109329224, D Loss: 1.049115538597107, alpha: 0.7810849226908843\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 789 iteration0, G Loss: 1.4071331024169922, D Loss: 0.7409298419952393, alpha: 0.7800572449882548\n",
      "epoch 789 iteration100, G Loss: 1.4825875759124756, D Loss: 1.0877249240875244, alpha: 0.7800572449882548\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 790 iteration0, G Loss: 1.978212833404541, D Loss: 0.6675411462783813, alpha: 0.7790261077798122\n",
      "epoch 790 iteration100, G Loss: 1.5593997240066528, D Loss: 1.055286169052124, alpha: 0.7790261077798122\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 791 iteration0, G Loss: 1.37067711353302, D Loss: 1.5047695636749268, alpha: 0.7779915122215029\n",
      "epoch 791 iteration100, G Loss: 2.1302804946899414, D Loss: 1.026409387588501, alpha: 0.7779915122215029\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 792 iteration0, G Loss: 1.8291432857513428, D Loss: 1.0720276832580566, alpha: 0.7769534596019573\n",
      "epoch 792 iteration100, G Loss: 2.3407392501831055, D Loss: 1.1511638164520264, alpha: 0.7769534596019573\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 793 iteration0, G Loss: 2.0054328441619873, D Loss: 0.6904033422470093, alpha: 0.7759119513433005\n",
      "epoch 793 iteration100, G Loss: 2.781635046005249, D Loss: 1.372724175453186, alpha: 0.7759119513433005\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 794 iteration0, G Loss: 0.7441354393959045, D Loss: 1.1489251852035522, alpha: 0.7748669890019579\n",
      "epoch 794 iteration100, G Loss: 1.7226651906967163, D Loss: 0.9242326021194458, alpha: 0.7748669890019579\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 795 iteration0, G Loss: 1.4519259929656982, D Loss: 1.0233829021453857, alpha: 0.7738185742694538\n",
      "epoch 795 iteration100, G Loss: 1.9950535297393799, D Loss: 1.1144495010375977, alpha: 0.7738185742694538\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 796 iteration0, G Loss: 2.1573216915130615, D Loss: 1.695623517036438, alpha: 0.7727667089732031\n",
      "epoch 796 iteration100, G Loss: 1.023314118385315, D Loss: 1.0312707424163818, alpha: 0.7727667089732031\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 797 iteration0, G Loss: 1.2175672054290771, D Loss: 0.9104520082473755, alpha: 0.7717113950772974\n",
      "epoch 797 iteration100, G Loss: 1.8779592514038086, D Loss: 0.9538697600364685, alpha: 0.7717113950772974\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 798 iteration0, G Loss: 2.389932155609131, D Loss: 0.908965528011322, alpha: 0.7706526346832835\n",
      "epoch 798 iteration100, G Loss: 1.6346182823181152, D Loss: 0.8186955451965332, alpha: 0.7706526346832835\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 799 iteration0, G Loss: 1.1708705425262451, D Loss: 1.0392636060714722, alpha: 0.7695904300309351\n",
      "epoch 799 iteration100, G Loss: 1.990178108215332, D Loss: 1.1112785339355469, alpha: 0.7695904300309351\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 800 iteration0, G Loss: 0.6961785554885864, D Loss: 0.8464779853820801, alpha: 0.7685247834990176\n",
      "epoch 800 iteration100, G Loss: 2.173475742340088, D Loss: 1.2416446208953857, alpha: 0.7685247834990176\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 801 iteration0, G Loss: 1.2658277750015259, D Loss: 1.2985352277755737, alpha: 0.7674556976060448\n",
      "epoch 801 iteration100, G Loss: 1.9818941354751587, D Loss: 0.9670534729957581, alpha: 0.7674556976060448\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 802 iteration0, G Loss: 2.369433641433716, D Loss: 1.2832821607589722, alpha: 0.7663831750110291\n",
      "epoch 802 iteration100, G Loss: 2.8727307319641113, D Loss: 1.2617456912994385, alpha: 0.7663831750110291\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 803 iteration0, G Loss: 1.8732186555862427, D Loss: 0.8554283380508423, alpha: 0.7653072185142237\n",
      "epoch 803 iteration100, G Loss: 1.2003021240234375, D Loss: 0.8465572595596313, alpha: 0.7653072185142237\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 804 iteration0, G Loss: 1.3177849054336548, D Loss: 1.1629676818847656, alpha: 0.7642278310578563\n",
      "epoch 804 iteration100, G Loss: 1.8403301239013672, D Loss: 1.392112135887146, alpha: 0.7642278310578563\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 805 iteration0, G Loss: 1.0619900226593018, D Loss: 1.0076947212219238, alpha: 0.7631450157268554\n",
      "epoch 805 iteration100, G Loss: 2.0249831676483154, D Loss: 0.7227433919906616, alpha: 0.7631450157268554\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 806 iteration0, G Loss: 1.506195306777954, D Loss: 1.170819640159607, alpha: 0.7620587757495692\n",
      "epoch 806 iteration100, G Loss: 1.3781980276107788, D Loss: 1.0985461473464966, alpha: 0.7620587757495692\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 807 iteration0, G Loss: 1.7722387313842773, D Loss: 1.560961127281189, alpha: 0.7609691144984745\n",
      "epoch 807 iteration100, G Loss: 1.668247103691101, D Loss: 0.9563849568367004, alpha: 0.7609691144984745\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 808 iteration0, G Loss: 1.3574419021606445, D Loss: 0.61418616771698, alpha: 0.7598760354908782\n",
      "epoch 808 iteration100, G Loss: 1.7619026899337769, D Loss: 1.0142598152160645, alpha: 0.7598760354908782\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 809 iteration0, G Loss: 1.629765272140503, D Loss: 1.1678118705749512, alpha: 0.7587795423896097\n",
      "epoch 809 iteration100, G Loss: 3.210848331451416, D Loss: 1.364007830619812, alpha: 0.7587795423896097\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 810 iteration0, G Loss: 1.3036956787109375, D Loss: 1.2285407781600952, alpha: 0.7576796390037048\n",
      "epoch 810 iteration100, G Loss: 2.2473106384277344, D Loss: 0.9668194055557251, alpha: 0.7576796390037048\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 811 iteration0, G Loss: 3.6223866939544678, D Loss: 0.8749440908432007, alpha: 0.7565763292890808\n",
      "epoch 811 iteration100, G Loss: 2.2923340797424316, D Loss: 0.7763456106185913, alpha: 0.7565763292890808\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 812 iteration0, G Loss: 2.548602342605591, D Loss: 0.8923243284225464, alpha: 0.7554696173492006\n",
      "epoch 812 iteration100, G Loss: 1.4812850952148438, D Loss: 1.1824721097946167, alpha: 0.7554696173492006\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 813 iteration0, G Loss: 1.6367886066436768, D Loss: 1.0440593957901, alpha: 0.7543595074357307\n",
      "epoch 813 iteration100, G Loss: 1.5430554151535034, D Loss: 0.8587766289710999, alpha: 0.7543595074357307\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 814 iteration0, G Loss: 3.143195152282715, D Loss: 1.1562833786010742, alpha: 0.7532460039491866\n",
      "epoch 814 iteration100, G Loss: 2.102213144302368, D Loss: 1.0119869709014893, alpha: 0.7532460039491866\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 815 iteration0, G Loss: 2.691706657409668, D Loss: 1.586134672164917, alpha: 0.7521291114395702\n",
      "epoch 815 iteration100, G Loss: 1.2162666320800781, D Loss: 1.080216407775879, alpha: 0.7521291114395702\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 816 iteration0, G Loss: 1.5552901029586792, D Loss: 1.034700632095337, alpha: 0.7510088346069963\n",
      "epoch 816 iteration100, G Loss: 2.2941622734069824, D Loss: 0.9011152982711792, alpha: 0.7510088346069963\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 817 iteration0, G Loss: 1.498047113418579, D Loss: 0.9580590128898621, alpha: 0.7498851783023105\n",
      "epoch 817 iteration100, G Loss: 2.1199965476989746, D Loss: 1.0847718715667725, alpha: 0.7498851783023105\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 818 iteration0, G Loss: 1.7772858142852783, D Loss: 1.2806646823883057, alpha: 0.7487581475276954\n",
      "epoch 818 iteration100, G Loss: 1.4273838996887207, D Loss: 1.0070850849151611, alpha: 0.7487581475276954\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 819 iteration0, G Loss: 2.609464406967163, D Loss: 1.5916969776153564, alpha: 0.7476277474372675\n",
      "epoch 819 iteration100, G Loss: 1.8943358659744263, D Loss: 0.8477692008018494, alpha: 0.7476277474372675\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 820 iteration0, G Loss: 1.901425838470459, D Loss: 1.116006851196289, alpha: 0.7464939833376623\n",
      "epoch 820 iteration100, G Loss: 1.9836137294769287, D Loss: 1.2347197532653809, alpha: 0.7464939833376623\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 821 iteration0, G Loss: 1.8439748287200928, D Loss: 1.2248426675796509, alpha: 0.7453568606886103\n",
      "epoch 821 iteration100, G Loss: 2.6152429580688477, D Loss: 0.8387859463691711, alpha: 0.7453568606886103\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 822 iteration0, G Loss: 2.080545663833618, D Loss: 1.3356044292449951, alpha: 0.7442163851035011\n",
      "epoch 822 iteration100, G Loss: 1.8752506971359253, D Loss: 1.253729224205017, alpha: 0.7442163851035011\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 823 iteration0, G Loss: 2.1629014015197754, D Loss: 1.2101151943206787, alpha: 0.7430725623499372\n",
      "epoch 823 iteration100, G Loss: 0.6745090484619141, D Loss: 1.1979484558105469, alpha: 0.7430725623499372\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n",
      "epoch 824 iteration0, G Loss: 2.924025774002075, D Loss: 1.5054867267608643, alpha: 0.7419253983502743\n",
      "epoch 824 iteration100, G Loss: 2.0783658027648926, D Loss: 0.7728160619735718, alpha: 0.7419253983502743\n",
      "OUTTTT\n",
      "OUTTTT\n",
      "Saving content.\n"
     ]
    }
   ],
   "source": [
    "print('starting in debug mode')\n",
    "init_processes(0, 1, train, args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
