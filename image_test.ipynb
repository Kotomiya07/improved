{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from datasets_prep.dataset import create_dataset\n",
    "from diffusion import sample_from_model, sample_posterior, \\\n",
    "    q_sample_pairs, get_time_schedule, \\\n",
    "    Posterior_Coefficients, Diffusion_Coefficients\n",
    "#from DWT_IDWT.DWT_IDWT_layer import DWT_2D, IDWT_2D\n",
    "#from pytorch_wavelets import DWTForward, DWTInverse\n",
    "from torch.multiprocessing import Process\n",
    "from utils import init_processes, copy_source, broadcast_params\n",
    "import yaml\n",
    "\n",
    "from ldm.util import instantiate_from_config\n",
    "from omegaconf import OmegaConf\n",
    "import wandb\n",
    "from copy import deepcopy\n",
    "from collections import OrderedDict\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "@torch.no_grad()\n",
    "def update_ema(ema_model, model, decay=0.9999):\n",
    "    \"\"\"\n",
    "    Step the EMA model towards the current model.\n",
    "    \"\"\"\n",
    "    ema_params = OrderedDict(ema_model.named_parameters())\n",
    "    model_params = OrderedDict(model.named_parameters())\n",
    "\n",
    "    for name, param in model_params.items():\n",
    "        name = name.replace(\"module.\", \"\")\n",
    "        # TODO: Consider applying only to params that require_grad to avoid small numerical changes of pos_embed\n",
    "        ema_params[name].mul_(decay).add_(param.data, alpha=1 - decay)\n",
    "\n",
    "def requires_grad(model, flag=True):\n",
    "    \"\"\"\n",
    "    Set requires_grad flag for all parameters in a model.\n",
    "    \"\"\"\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = flag\n",
    "\n",
    "def load_model_from_config(config_path, ckpt):\n",
    "    print(f\"Loading model from {ckpt}\")\n",
    "    config = OmegaConf.load(config_path)\n",
    "    pl_sd = torch.load(ckpt, map_location=\"cpu\")\n",
    "    #global_step = pl_sd[\"global_step\"]\n",
    "    sd = pl_sd[\"state_dict\"]\n",
    "    model = instantiate_from_config(config.model)\n",
    "    m, u = model.load_state_dict(sd, strict=False)\n",
    "    model = model.first_stage_model\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    del m\n",
    "    del u\n",
    "    del pl_sd\n",
    "    return model\n",
    "\n",
    "def grad_penalty_call(args, D_real, x_t):\n",
    "    grad_real = torch.autograd.grad(\n",
    "        outputs=D_real.sum(), inputs=x_t, create_graph=True\n",
    "    )[0]\n",
    "    grad_penalty = (\n",
    "        grad_real.view(grad_real.size(0), -1).norm(2, dim=1) ** 2\n",
    "    ).mean()\n",
    "\n",
    "    grad_penalty = args.r1_gamma / 2 * grad_penalty\n",
    "    grad_penalty.backward()\n",
    "\n",
    "\n",
    "# %%\n",
    "def train(rank, gpu, args):\n",
    "    from EMA import EMA\n",
    "    from score_sde.models.discriminator import Discriminator_large, Discriminator_small\n",
    "    from score_sde.models.ncsnpp_generator_adagn import NCSNpp, WaveletNCSNpp\n",
    "\n",
    "    torch.manual_seed(args.seed + rank)\n",
    "    torch.cuda.manual_seed(args.seed + rank)\n",
    "    torch.cuda.manual_seed_all(args.seed + rank)\n",
    "    device = torch.device('cuda:{}'.format(gpu))\n",
    "\n",
    "    batch_size = args.batch_size\n",
    "\n",
    "    nz = args.nz  # latent dimension\n",
    "\n",
    "    dataset = create_dataset(args)\n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(dataset,\n",
    "                                                                    num_replicas=args.world_size,\n",
    "                                                                    rank=rank)\n",
    "    data_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=False,\n",
    "                                              num_workers=args.num_workers,\n",
    "                                              pin_memory=True,\n",
    "                                              sampler=train_sampler,\n",
    "                                              drop_last=True)\n",
    "    args.ori_image_size = args.image_size\n",
    "    args.image_size = args.current_resolution\n",
    "    G_NET_ZOO = {\"normal\": NCSNpp, \"wavelet\": WaveletNCSNpp}\n",
    "    gen_net = G_NET_ZOO[args.net_type]\n",
    "    disc_net = [Discriminator_small, Discriminator_large]\n",
    "    print(\"GEN: {}, DISC: {}\".format(gen_net, disc_net))\n",
    "    netG = gen_net(args).to(device)\n",
    "    print(\"model loaded!\")\n",
    "\n",
    "    if args.dataset in ['cifar10', 'stl10']:\n",
    "        netD = disc_net[0](nc=2 * args.num_channels, ngf=args.ngf,\n",
    "                           t_emb_dim=args.t_emb_dim,\n",
    "                           act=nn.LeakyReLU(0.2), num_layers=args.num_disc_layers).to(device)\n",
    "    else:\n",
    "        netD = disc_net[1](nc=2 * args.num_channels, ngf=args.ngf,\n",
    "                           t_emb_dim=args.t_emb_dim,\n",
    "                           act=nn.LeakyReLU(0.2), num_layers=args.num_disc_layers).to(device)\n",
    "\n",
    "    broadcast_params(netG.parameters())\n",
    "    broadcast_params(netD.parameters())\n",
    "\n",
    "    optimizerD = optim.Adam(filter(lambda p: p.requires_grad, netD.parameters(\n",
    "    )), lr=args.lr_d, betas=(args.beta1, args.beta2))\n",
    "    optimizerG = optim.Adam(filter(lambda p: p.requires_grad, netG.parameters(\n",
    "    )), lr=args.lr_g, betas=(args.beta1, args.beta2))\n",
    "\n",
    "    if args.use_ema:\n",
    "        optimizerG = EMA(optimizerG, ema_decay=args.ema_decay)\n",
    "    \n",
    "    #ema = deepcopy(netG).to(device)  # Create an EMA of the model for use after training\n",
    "    #requires_grad(ema, False)\n",
    "\n",
    "    schedulerG = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizerG, args.num_epoch, eta_min=1e-5)\n",
    "    schedulerD = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizerD, args.num_epoch, eta_min=1e-5)\n",
    "\n",
    "    # ddp\n",
    "    netG = nn.parallel.DistributedDataParallel(\n",
    "        netG, device_ids=[gpu])\n",
    "    netD = nn.parallel.DistributedDataParallel(netD, device_ids=[gpu])\n",
    "\n",
    "    \"\"\"############### DELETE TO AVOID ERROR ###############\"\"\"\n",
    "    # Wavelet Pooling\n",
    "    #if not args.use_pytorch_wavelet:\n",
    "    #    dwt = DWT_2D(\"haar\")\n",
    "    #    iwt = IDWT_2D(\"haar\")\n",
    "    #else:\n",
    "    #    dwt = DWTForward(J=1, mode='zero', wave='haar').cuda()\n",
    "    #    iwt = DWTInverse(mode='zero', wave='haar').cuda()\n",
    "        \n",
    "    \n",
    "    #load encoder and decoder\n",
    "    config_path = args.AutoEncoder_config \n",
    "    ckpt_path = args.AutoEncoder_ckpt \n",
    "    \n",
    "    #if args.dataset in ['cifar10', 'stl10', 'afhq_cat']:\n",
    "\n",
    "    with open(config_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "    AutoEncoder = instantiate_from_config(config['model'])\n",
    "\n",
    "\n",
    "    checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "    AutoEncoder.load_state_dict(checkpoint['state_dict'])\n",
    "    AutoEncoder.eval()\n",
    "    AutoEncoder.to(device)\n",
    "    \n",
    "    #else:\n",
    "    #    AutoEncoder = load_model_from_config(config_path, ckpt_path)\n",
    "    \"\"\"############### END DELETING ###############\"\"\"\n",
    "    \n",
    "    num_levels = int(np.log2(args.ori_image_size // args.current_resolution))\n",
    "\n",
    "    exp = args.exp\n",
    "    parent_dir = \"./saved_info/{}\".format(args.dataset)\n",
    "\n",
    "    exp_path = os.path.join(parent_dir, exp)\n",
    "    if rank == 0:\n",
    "        if not os.path.exists(exp_path):\n",
    "            os.makedirs(exp_path)\n",
    "            copy_source(__file__, exp_path)\n",
    "            shutil.copytree('score_sde/models',\n",
    "                            os.path.join(exp_path, 'score_sde/models'))\n",
    "\n",
    "    coeff = Diffusion_Coefficients(args, device)\n",
    "    pos_coeff = Posterior_Coefficients(args, device)\n",
    "    T = get_time_schedule(args, device)\n",
    "\n",
    "    if args.resume or os.path.exists(os.path.join(exp_path, 'content.pth')):\n",
    "        checkpoint_file = os.path.join(exp_path, 'content.pth')\n",
    "        checkpoint = torch.load(checkpoint_file, map_location=device)\n",
    "        init_epoch = checkpoint['epoch']\n",
    "        epoch = init_epoch\n",
    "        # load G\n",
    "        netG.load_state_dict(checkpoint['netG_dict'])\n",
    "        #optimizerG.load_state_dict(checkpoint['optimizerG'])\n",
    "        schedulerG.load_state_dict(checkpoint['schedulerG'])\n",
    "        # load D\n",
    "        netD.load_state_dict(checkpoint['netD_dict'])\n",
    "        #optimizerD.load_state_dict(checkpoint['optimizerD'])\n",
    "        schedulerD.load_state_dict(checkpoint['schedulerD'])\n",
    "\n",
    "        global_step = checkpoint['global_step']\n",
    "        print(\"=> loaded checkpoint (epoch {})\"\n",
    "              .format(checkpoint['epoch']))\n",
    "    else:\n",
    "        global_step, epoch, init_epoch = 0, 0, 0\n",
    "\n",
    "    '''Sigmoid learning parameter'''\n",
    "    gamma = 6\n",
    "    beta = np.linspace(-gamma, gamma, args.num_epoch+1)\n",
    "    if args.alpha_type == \"tanh\":\n",
    "        alpha = 1 - 0.5 * (1 + np.tanh(beta))\n",
    "    elif args.alpha_type == \"sigmoid\":\n",
    "        alpha = 1 - 1 / (1+np.exp(-beta))\n",
    "    elif args.alpha_type == \"sinarctan\":\n",
    "        alpha = (1 - (beta / np.sqrt(1 + beta**2))) * 0.5\n",
    "    else:\n",
    "        alpha = 1 - 1 / (1+np.exp(-beta))\n",
    "    \n",
    "    #update_ema(ema, netG, decay=0)  # Ensure EMA is initialized with synced weights\n",
    "    #ema.eval()\n",
    "\n",
    "    print(f\"AutoEncoder Parameters: {sum(p.numel() for p in AutoEncoder.parameters()):,}\")\n",
    "    print(f\"Generator Parameters: {sum(p.numel() for p in netG.parameters()):,}\")\n",
    "    print(f\"Discriminator Parameters: {sum(p.numel() for p in netD.parameters()):,}\")\n",
    "\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "    start_epoch = torch.cuda.Event(enable_timing=True)\n",
    "    end_epoch = torch.cuda.Event(enable_timing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in range(init_epoch, args.num_epoch + 1):\n",
    "    train_sampler.set_epoch(epoch)\n",
    "    start_epoch.record()\n",
    "    for iteration, (x, y) in enumerate(data_loader):\n",
    "        start.record()\n",
    "        for p in netD.parameters():\n",
    "            p.requires_grad = True\n",
    "        netD.zero_grad()\n",
    "\n",
    "        for p in netG.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        # sample from p(x_0)\n",
    "        x0 = x.to(device, non_blocking=True)\n",
    "\n",
    "        \"\"\"################# Change here: Encoder #################\"\"\"\n",
    "        with torch.no_grad():\n",
    "            posterior = AutoEncoder.encode(x0)\n",
    "            real_data = posterior.sample().detach()\n",
    "        #print(\"MIN:{}, MAX:{}\".format(real_data.min(), real_data.max()))\n",
    "        real_data = real_data / args.scale_factor #300.0  # [-1, 1]\n",
    "        \n",
    "        \n",
    "        #assert -1 <= real_data.min() < 0\n",
    "        #assert 0 < real_data.max() <= 1\n",
    "        \"\"\"################# End change: Encoder #################\"\"\"\n",
    "        # sample t\n",
    "        t = torch.randint(0, args.num_timesteps,\n",
    "                            (real_data.size(0),), device=device)\n",
    "\n",
    "        x_t, x_tp1 = q_sample_pairs(coeff, real_data, t)\n",
    "        x_t.requires_grad = True\n",
    "\n",
    "        # train with real\n",
    "        D_real = netD(x_t, t, x_tp1.detach()).view(-1)\n",
    "        errD_real = F.softplus(-D_real).mean()\n",
    "\n",
    "        errD_real.backward(retain_graph=True)\n",
    "\n",
    "        if args.lazy_reg is None:\n",
    "            grad_penalty_call(args, D_real, x_t)\n",
    "        else:\n",
    "            if global_step % args.lazy_reg == 0:\n",
    "                grad_penalty_call(args, D_real, x_t)\n",
    "\n",
    "        # train with fake\n",
    "        latent_z = torch.randn(batch_size, nz, device=device)\n",
    "        x_0_predict = netG(x_tp1.detach(), t, latent_z)\n",
    "        x_pos_sample = sample_posterior(pos_coeff, x_0_predict, x_tp1, t)\n",
    "\n",
    "        output = netD(x_pos_sample, t, x_tp1.detach()).view(-1)\n",
    "        errD_fake = F.softplus(output).mean()\n",
    "\n",
    "        errD_fake.backward()\n",
    "\n",
    "        errD = errD_real + errD_fake\n",
    "        # Update D\n",
    "        optimizerD.step()\n",
    "\n",
    "        # update G\n",
    "        for p in netD.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        for p in netG.parameters():\n",
    "            p.requires_grad = True\n",
    "        netG.zero_grad()\n",
    "\n",
    "        t = torch.randint(0, args.num_timesteps,\n",
    "                            (real_data.size(0),), device=device)\n",
    "        x_t, x_tp1 = q_sample_pairs(coeff, real_data, t)\n",
    "\n",
    "        latent_z = torch.randn(batch_size, nz, device=device)\n",
    "        x_0_predict = netG(x_tp1.detach(), t, latent_z)\n",
    "        x_pos_sample = sample_posterior(pos_coeff, x_0_predict, x_tp1, t)\n",
    "\n",
    "        output = netD(x_pos_sample, t, x_tp1.detach()).view(-1)\n",
    "        errG = F.softplus(-output).mean()\n",
    "\n",
    "        # reconstructior loss\n",
    "        if args.sigmoid_learning and args.rec_loss:\n",
    "            ######alpha\n",
    "            rec_loss = F.l1_loss(x_0_predict, real_data)\n",
    "            errG = errG + alpha[epoch]*rec_loss\n",
    "\n",
    "        elif args.rec_loss and not args.sigmoid_learning:\n",
    "            rec_loss = F.l1_loss(x_0_predict, real_data)\n",
    "            errG = errG + rec_loss\n",
    "        \n",
    "\n",
    "        errG.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "        end.record()\n",
    "        torch.cuda.synchronize()\n",
    "        #print(\"\\rIteration time: {:.0f} ms\".format(start.elapsed_time(end)), end=\"\")\n",
    "\n",
    "\n",
    "        global_step += 1\n",
    "        #if iteration % 100 == 0:\n",
    "        if rank == 0:\n",
    "            iter_time = start.elapsed_time(end)\n",
    "            if args.sigmoid_learning:\n",
    "                print('\\r[#{:05}][#{:04}][{:04.0f}ms] G Loss[{:.4f}] D Loss[{:.4f}] alpha[{:.4f}]'.format(\n",
    "                    epoch, iteration, iter_time, errG.item(), errD.item(), alpha[epoch]), end=\"\")\n",
    "            elif args.rec_loss:\n",
    "                print('\\r[#{:05}][#{:04}][{:04.0f}ms] G Loss[{:.4f}] D Loss[{:.4f}] rec_loss[{:.4f}]'.format(\n",
    "                    epoch, iteration, iter_time, errG.item(), errD.item(), rec_loss.item()), end=\"\")\n",
    "            else:   \n",
    "                print('\\r[#{:05}][#{:04}][{:04.0f}ms] G Loss[{:.4f}] D Loss[{:.4f}]'.format(\n",
    "                    epoch, iteration, iter_time, errG.item(), errD.item()), end=\"\")\n",
    "\n",
    "            wandb.log({\"G_loss_iter\": errG.item(), \"D_loss_iter\": errD.item(), \"iter_time\": iter_time})\n",
    "\n",
    "    if not args.no_lr_decay:\n",
    "\n",
    "        schedulerG.step()\n",
    "        schedulerD.step()\n",
    "\n",
    "    if rank == 0:\n",
    "        end_epoch.record()\n",
    "        torch.cuda.synchronize()\n",
    "        epoch_time = start_epoch.elapsed_time(end_epoch)\n",
    "        print(\"\\nEpoch time: {:.3f} s\".format(epoch_time / 1000))\n",
    "        wandb.log({\"G_loss\": errG.item(), \"D_loss\": errD.item(), \"alpha\": alpha[epoch], \"epoch_time\": epoch_time / 1000})\n",
    "        ########################################\n",
    "        x_t_1 = torch.randn_like(posterior.sample())\n",
    "        fake_sample = sample_from_model(\n",
    "            pos_coeff, netG, args.num_timesteps, x_t_1, T, args)\n",
    "\n",
    "        \"\"\"############## CHANGE HERE: DECODER ##############\"\"\"\n",
    "        fake_sample *= args.scale_factor #300\n",
    "        real_data *= args.scale_factor #300\n",
    "        with torch.no_grad():\n",
    "            fake_sample = AutoEncoder.decode(fake_sample)\n",
    "            real_data = AutoEncoder.decode(real_data)\n",
    "        \n",
    "        fake_sample = (torch.clamp(fake_sample, -1, 1) + 1) / 2  # 0-1\n",
    "        real_data = (torch.clamp(real_data, -1, 1) + 1) / 2  # 0-1 \n",
    "        \n",
    "        \"\"\"############## END HERE: DECODER ##############\"\"\"\n",
    "\n",
    "        torchvision.utils.save_image(fake_sample, os.path.join(\n",
    "            exp_path, 'sample_discrete_epoch_{}.png'.format(epoch)))\n",
    "        torchvision.utils.save_image(\n",
    "            real_data, os.path.join(exp_path, 'real_data.png'))\n",
    "        \n",
    "        # TODO: wandbに画像を保存\n",
    "        wandb.log({\"fake_sample\": [wandb.Image(fake_sample[:4])], \"real_data\": [wandb.Image(real_data[:4])]})\n",
    "        \n",
    "\n",
    "        if args.save_content:\n",
    "            if epoch % args.save_content_every == 0:\n",
    "                print('\\nSaving content.')\n",
    "                content = {'epoch': epoch + 1, 'global_step': global_step, 'args': args,\n",
    "                            'netG_dict': netG.state_dict(), 'optimizerG': optimizerG.state_dict(),\n",
    "                            'schedulerG': schedulerG.state_dict(), 'netD_dict': netD.state_dict(),\n",
    "                            'optimizerD': optimizerD.state_dict(), 'schedulerD': schedulerD.state_dict()}\n",
    "                torch.save(content, os.path.join(exp_path, 'content.pth'))\n",
    "\n",
    "        if epoch % args.save_ckpt_every == 0:\n",
    "            if args.use_ema:\n",
    "                optimizerG.swap_parameters_with_ema(\n",
    "                    store_params_in_ema=True)\n",
    "\n",
    "            torch.save(netG.state_dict(), os.path.join(\n",
    "                exp_path, 'netG_{}.pth'.format(epoch)))\n",
    "            if args.use_ema:\n",
    "                optimizerG.swap_parameters_with_ema(\n",
    "                    store_params_in_ema=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
