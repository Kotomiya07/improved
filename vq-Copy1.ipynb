{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "860d3f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_args import get_args\n",
    "args = [\"--dataset\", \"cifar10\", \"--exp\", \"vq-f4-scale-factor-6\", \"--num_channels\", \"3\", \"--num_channels_dae\", \"128\", \"--num_timesteps\", \"4\", \n",
    "\t\t\t\"--num_res_blocks\", \"2\", \"--batch_size\", \"256\", \"--num_epoch\", \"2000\", \"--ngf\", \"64\", \"--nz\", \"50\", \"--z_emb_dim\", \"256\", \"--n_mlp\", \"4\", \"--embedding_type\", \"positional\", \n",
    "\t\t\t\"--use_ema\", \"--ema_decay\", \"0.9999\", \"--r1_gamma\", \"0.02\", \"--lr_d\", \"1.25e-4\", \"--lr_g\", \"1.6e-4\", \"--lazy_reg\", \"15\", \n",
    "\t\t\t\"--ch_mult\", \"1\", \"2\", \"2\", \"--save_content\", \"--datadir\", \"./data/cifar-10\", \n",
    "\t\t\t\"--master_port\", \"6084\", \"--num_process_per_node\", \"1\", \"--save_ckpt_every\", \"25\", \n",
    "\t\t\t\"--current_resolution\", \"16\", \"--attn_resolutions\", \"32\", \"--num_disc_layers\", \"4\",  \"--scale_factor\", \"6.0\", \n",
    "\t\t\t\"--no_lr_decay\", \n",
    "            \"--AutoEncoder_config\", \"autoencoder/config/vq-f4.yaml\", \n",
    "            \"--AutoEncoder_ckpt\", \"autoencoder/weight/vq-f4.ckpt\", \n",
    "\t\t\t\"--rec_loss\",\n",
    "\t\t\t\"--sigmoid_learning\", \n",
    "       ]\n",
    "\n",
    "args = get_args(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1506c761",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/std/2021/21k0005/anaconda3/envs/iddgan/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from datasets_prep.dataset import create_dataset\n",
    "from diffusion import sample_from_model, sample_posterior, \\\n",
    "    q_sample_pairs, get_time_schedule, \\\n",
    "    Posterior_Coefficients, Diffusion_Coefficients\n",
    "#from DWT_IDWT.DWT_IDWT_layer import DWT_2D, IDWT_2D\n",
    "#from pytorch_wavelets import DWTForward, DWTInverse\n",
    "from torch.multiprocessing import Process\n",
    "from utils import init_processes, copy_source, broadcast_params\n",
    "import yaml\n",
    "\n",
    "from ldm.util import instantiate_from_config\n",
    "from omegaconf import OmegaConf\n",
    "import wandb\n",
    "\n",
    "def load_model_from_config(config_path, ckpt):\n",
    "    print(f\"Loading model from {ckpt}\")\n",
    "    config = OmegaConf.load(config_path)\n",
    "    pl_sd = torch.load(ckpt, map_location=\"cpu\")\n",
    "    #global_step = pl_sd[\"global_step\"]\n",
    "    sd = pl_sd[\"state_dict\"]\n",
    "    model = instantiate_from_config(config.model)\n",
    "    m, u = model.load_state_dict(sd, strict=False)\n",
    "    model = model.first_stage_model\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    del m\n",
    "    del u\n",
    "    del pl_sd\n",
    "    return model\n",
    "\n",
    "def grad_penalty_call(args, D_real, x_t):\n",
    "    grad_real = torch.autograd.grad(\n",
    "        outputs=D_real.sum(), inputs=x_t, create_graph=True\n",
    "    )[0]\n",
    "    grad_penalty = (\n",
    "        grad_real.view(grad_real.size(0), -1).norm(2, dim=1) ** 2\n",
    "    ).mean()\n",
    "\n",
    "    grad_penalty = args.r1_gamma / 2 * grad_penalty\n",
    "    grad_penalty.backward()\n",
    "\n",
    "\n",
    "# %%\n",
    "def train(rank, gpu, args):\n",
    "    from EMA import EMA\n",
    "    from score_sde.models.discriminator import Discriminator_large, Discriminator_small\n",
    "    from score_sde.models.ncsnpp_generator_adagn import NCSNpp, WaveletNCSNpp\n",
    "\n",
    "    torch.manual_seed(args.seed + rank)\n",
    "    torch.cuda.manual_seed(args.seed + rank)\n",
    "    torch.cuda.manual_seed_all(args.seed + rank)\n",
    "    device = torch.device('cuda:{}'.format(gpu))\n",
    "\n",
    "    batch_size = args.batch_size\n",
    "\n",
    "    nz = args.nz  # latent dimension\n",
    "\n",
    "    dataset = create_dataset(args)\n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(dataset,\n",
    "                                                                    num_replicas=args.world_size,\n",
    "                                                                    rank=rank)\n",
    "    data_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=False,\n",
    "                                              num_workers=args.num_workers,\n",
    "                                              pin_memory=True,\n",
    "                                              sampler=train_sampler,\n",
    "                                              drop_last=True)\n",
    "    args.ori_image_size = args.image_size\n",
    "    args.image_size = args.current_resolution\n",
    "    G_NET_ZOO = {\"normal\": NCSNpp, \"wavelet\": WaveletNCSNpp}\n",
    "    gen_net = G_NET_ZOO[args.net_type]\n",
    "    disc_net = [Discriminator_small, Discriminator_large]\n",
    "    print(\"GEN: {}, DISC: {}\".format(gen_net, disc_net))\n",
    "    netG = gen_net(args).to(device)\n",
    "\n",
    "    if args.dataset in ['cifar10', 'stl10']:\n",
    "        netD = disc_net[0](nc=2 * args.num_channels, ngf=args.ngf,\n",
    "                           t_emb_dim=args.t_emb_dim,\n",
    "                           act=nn.LeakyReLU(0.2), num_layers=args.num_disc_layers).to(device)\n",
    "    else:\n",
    "        netD = disc_net[1](nc=2 * args.num_channels, ngf=args.ngf,\n",
    "                           t_emb_dim=args.t_emb_dim,\n",
    "                           act=nn.LeakyReLU(0.2), num_layers=args.num_disc_layers).to(device)\n",
    "\n",
    "    broadcast_params(netG.parameters())\n",
    "    broadcast_params(netD.parameters())\n",
    "\n",
    "    optimizerD = optim.Adam(filter(lambda p: p.requires_grad, netD.parameters(\n",
    "    )), lr=args.lr_d, betas=(args.beta1, args.beta2))\n",
    "    optimizerG = optim.Adam(filter(lambda p: p.requires_grad, netG.parameters(\n",
    "    )), lr=args.lr_g, betas=(args.beta1, args.beta2))\n",
    "\n",
    "    if args.use_ema:\n",
    "        optimizerG = EMA(optimizerG, ema_decay=args.ema_decay)\n",
    "\n",
    "    schedulerG = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizerG, args.num_epoch, eta_min=1e-5)\n",
    "    schedulerD = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizerD, args.num_epoch, eta_min=1e-5)\n",
    "\n",
    "    # ddp\n",
    "    netG = nn.parallel.DistributedDataParallel(\n",
    "        netG, device_ids=[gpu], find_unused_parameters=True)\n",
    "    netD = nn.parallel.DistributedDataParallel(netD, device_ids=[gpu])\n",
    "\n",
    "    \"\"\"############### DELETE TO AVOID ERROR ###############\"\"\"\n",
    "    # Wavelet Pooling\n",
    "    #if not args.use_pytorch_wavelet:\n",
    "    #    dwt = DWT_2D(\"haar\")\n",
    "    #    iwt = IDWT_2D(\"haar\")\n",
    "    #else:\n",
    "    #    dwt = DWTForward(J=1, mode='zero', wave='haar').cuda()\n",
    "    #    iwt = DWTInverse(mode='zero', wave='haar').cuda()\n",
    "        \n",
    "    \n",
    "    #load encoder and decoder\n",
    "    config_path = args.AutoEncoder_config \n",
    "    ckpt_path = args.AutoEncoder_ckpt \n",
    "    \n",
    "    if args.dataset in ['cifar10', 'stl10'] or True:\n",
    "\n",
    "        with open(config_path, 'r') as file:\n",
    "            config = yaml.safe_load(file)\n",
    "        \n",
    "        AutoEncoder = instantiate_from_config(config['model'])\n",
    "        \n",
    "\n",
    "        checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "        AutoEncoder.load_state_dict(checkpoint['state_dict'])\n",
    "        AutoEncoder.eval()\n",
    "        AutoEncoder.to(device)\n",
    "    \n",
    "    else:\n",
    "        AutoEncoder = load_model_from_config(config_path, ckpt_path)\n",
    "    \"\"\"############### END DELETING ###############\"\"\"\n",
    "    \n",
    "    num_levels = int(np.log2(args.ori_image_size // args.current_resolution))\n",
    "\n",
    "    exp = args.exp\n",
    "    parent_dir = \"./saved_info/{}\".format(args.dataset)\n",
    "\n",
    "    exp_path = os.path.join(parent_dir, exp)\n",
    "    if rank == 0:\n",
    "        if not os.path.exists(exp_path):\n",
    "            os.makedirs(exp_path)\n",
    "            copy_source(__file__, exp_path)\n",
    "            shutil.copytree('score_sde/models',\n",
    "                            os.path.join(exp_path, 'score_sde/models'))\n",
    "\n",
    "    coeff = Diffusion_Coefficients(args, device)\n",
    "    pos_coeff = Posterior_Coefficients(args, device)\n",
    "    T = get_time_schedule(args, device)\n",
    "\n",
    "    if args.resume or os.path.exists(os.path.join(exp_path, 'content.pth')):\n",
    "        checkpoint_file = os.path.join(exp_path, 'content.pth')\n",
    "        checkpoint = torch.load(checkpoint_file, map_location=device)\n",
    "        init_epoch = checkpoint['epoch']\n",
    "        epoch = init_epoch\n",
    "        # load G\n",
    "        netG.load_state_dict(checkpoint['netG_dict'])\n",
    "        #optimizerG.load_state_dict(checkpoint['optimizerG'])\n",
    "        schedulerG.load_state_dict(checkpoint['schedulerG'])\n",
    "        # load D\n",
    "        netD.load_state_dict(checkpoint['netD_dict'])\n",
    "        #optimizerD.load_state_dict(checkpoint['optimizerD'])\n",
    "        schedulerD.load_state_dict(checkpoint['schedulerD'])\n",
    "\n",
    "        global_step = checkpoint['global_step']\n",
    "        print(\"=> loaded checkpoint (epoch {})\"\n",
    "              .format(checkpoint['epoch']))\n",
    "    else:\n",
    "        global_step, epoch, init_epoch = 0, 0, 0\n",
    "\n",
    "    '''Sigmoid learning parameter'''\n",
    "    gamma = 6\n",
    "    beta = np.linspace(-gamma, gamma, args.num_epoch+1)\n",
    "    alpha = 1 - 1 / (1+np.exp(-beta))\n",
    "\n",
    "    for epoch in range(init_epoch, args.num_epoch + 1):\n",
    "        train_sampler.set_epoch(epoch)\n",
    "\n",
    "        for iteration, (x, y) in enumerate(data_loader):\n",
    "            for p in netD.parameters():\n",
    "                p.requires_grad = True\n",
    "            netD.zero_grad()\n",
    "\n",
    "            for p in netG.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "            # sample from p(x_0)\n",
    "            x0 = x.to(device, non_blocking=True)\n",
    "\n",
    "            \"\"\"################# Change here: Encoder #################\"\"\"\n",
    "            with torch.no_grad():\n",
    "                posterior = AutoEncoder.encode(x0)\n",
    "                real_data = posterior.detach()\n",
    "            #print(\"MIN:{}, MAX:{}\".format(real_data.min(), real_data.max()))\n",
    "            real_data = real_data / args.scale_factor #300.0  # [-1, 1]\n",
    "            \n",
    "            \n",
    "            #assert -1 <= real_data.min() < 0\n",
    "            #assert 0 < real_data.max() <= 1\n",
    "            \"\"\"################# End change: Encoder #################\"\"\"\n",
    "            # sample t\n",
    "            t = torch.randint(0, args.num_timesteps,\n",
    "                              (real_data.size(0),), device=device)\n",
    "\n",
    "            x_t, x_tp1 = q_sample_pairs(coeff, real_data, t)\n",
    "            x_t.requires_grad = True\n",
    "\n",
    "            # train with real\n",
    "            D_real = netD(x_t, t, x_tp1.detach()).view(-1)\n",
    "            errD_real = F.softplus(-D_real).mean()\n",
    "\n",
    "            errD_real.backward(retain_graph=True)\n",
    "\n",
    "            if args.lazy_reg is None:\n",
    "                grad_penalty_call(args, D_real, x_t)\n",
    "            else:\n",
    "                if global_step % args.lazy_reg == 0:\n",
    "                    grad_penalty_call(args, D_real, x_t)\n",
    "\n",
    "            # train with fake\n",
    "            latent_z = torch.randn(batch_size, nz, device=device)\n",
    "            x_0_predict = netG(x_tp1.detach(), t, latent_z)\n",
    "            x_pos_sample = sample_posterior(pos_coeff, x_0_predict, x_tp1, t)\n",
    "\n",
    "            output = netD(x_pos_sample, t, x_tp1.detach()).view(-1)\n",
    "            errD_fake = F.softplus(output).mean()\n",
    "\n",
    "            errD_fake.backward()\n",
    "\n",
    "            errD = errD_real + errD_fake\n",
    "            # Update D\n",
    "            optimizerD.step()\n",
    "\n",
    "            # update G\n",
    "            for p in netD.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "            for p in netG.parameters():\n",
    "                p.requires_grad = True\n",
    "            netG.zero_grad()\n",
    "\n",
    "            t = torch.randint(0, args.num_timesteps,\n",
    "                              (real_data.size(0),), device=device)\n",
    "            x_t, x_tp1 = q_sample_pairs(coeff, real_data, t)\n",
    "\n",
    "            latent_z = torch.randn(batch_size, nz, device=device)\n",
    "            x_0_predict = netG(x_tp1.detach(), t, latent_z)\n",
    "            x_pos_sample = sample_posterior(pos_coeff, x_0_predict, x_tp1, t)\n",
    "\n",
    "            output = netD(x_pos_sample, t, x_tp1.detach()).view(-1)\n",
    "            errG = F.softplus(-output).mean()\n",
    "\n",
    "            # reconstructior loss\n",
    "            if args.sigmoid_learning and args.rec_loss:\n",
    "                ######alpha\n",
    "                rec_loss = F.l1_loss(x_0_predict, real_data)\n",
    "                errG = errG + alpha[epoch]*rec_loss\n",
    "\n",
    "            elif args.rec_loss and not args.sigmoid_learning:\n",
    "                rec_loss = F.l1_loss(x_0_predict, real_data)\n",
    "                errG = errG + rec_loss\n",
    "            \n",
    "\n",
    "            errG.backward()\n",
    "            optimizerG.step()\n",
    "\n",
    "            global_step += 1\n",
    "            if iteration % 100 == 0:\n",
    "                if rank == 0:\n",
    "                    if args.sigmoid_learning:\n",
    "                        print('epoch {} iteration{}, G Loss: {}, D Loss: {}, alpha: {}'.format(\n",
    "                            epoch, iteration, errG.item(), errD.item(), alpha[epoch]))\n",
    "                    elif args.rec_loss:\n",
    "                        print('epoch {} iteration{}, G Loss: {}, D Loss: {}, rec_loss: {}'.format(\n",
    "                            epoch, iteration, errG.item(), errD.item(), rec_loss.item()))\n",
    "                    else:   \n",
    "                        print('epoch {} iteration{}, G Loss: {}, D Loss: {}'.format(\n",
    "                            epoch, iteration, errG.item(), errD.item()))\n",
    "\n",
    "        if not args.no_lr_decay:\n",
    "\n",
    "            schedulerG.step()\n",
    "            schedulerD.step()\n",
    "\n",
    "        if rank == 0:\n",
    "            wandb.log({\"G_loss\": errG.item(), \"D_loss\": errD.item(), \"alpha\": alpha[epoch]})\n",
    "            ########################################\n",
    "            x_t_1 = torch.randn_like(posterior)\n",
    "            fake_sample = sample_from_model(\n",
    "                pos_coeff, netG, args.num_timesteps, x_t_1, T, args)\n",
    "\n",
    "            \"\"\"############## CHANGE HERE: DECODER ##############\"\"\"\n",
    "            fake_sample *= args.scale_factor #300\n",
    "            real_data *= args.scale_factor #300\n",
    "            with torch.no_grad():\n",
    "                fake_sample = AutoEncoder.decode(fake_sample)\n",
    "                real_data = AutoEncoder.decode(real_data)\n",
    "            \n",
    "            fake_sample = (torch.clamp(fake_sample, -1, 1) + 1) / 2  # 0-1\n",
    "            real_data = (torch.clamp(real_data, -1, 1) + 1) / 2  # 0-1 \n",
    "            \n",
    "            \"\"\"############## END HERE: DECODER ##############\"\"\"\n",
    "\n",
    "            torchvision.utils.save_image(fake_sample, os.path.join(\n",
    "                exp_path, 'sample_discrete_epoch_{}.png'.format(epoch)))\n",
    "            torchvision.utils.save_image(\n",
    "                real_data, os.path.join(exp_path, 'real_data.png'))\n",
    "\n",
    "            if args.save_content:\n",
    "                if epoch % args.save_content_every == 0:\n",
    "                    print('Saving content.')\n",
    "                    content = {'epoch': epoch + 1, 'global_step': global_step, 'args': args,\n",
    "                               'netG_dict': netG.state_dict(), 'optimizerG': optimizerG.state_dict(),\n",
    "                               'schedulerG': schedulerG.state_dict(), 'netD_dict': netD.state_dict(),\n",
    "                               'optimizerD': optimizerD.state_dict(), 'schedulerD': schedulerD.state_dict()}\n",
    "                    torch.save(content, os.path.join(exp_path, 'content.pth'))\n",
    "\n",
    "            if epoch % args.save_ckpt_every == 0:\n",
    "                if args.use_ema:\n",
    "                    optimizerG.swap_parameters_with_ema(\n",
    "                        store_params_in_ema=True)\n",
    "\n",
    "                torch.save(netG.state_dict(), os.path.join(\n",
    "                    exp_path, 'netG_{}.pth'.format(epoch)))\n",
    "                if args.use_ema:\n",
    "                    optimizerG.swap_parameters_with_ema(\n",
    "                        store_params_in_ema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aab468f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkotomiya07\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/users/std/2021/21k0005/improved-ddgan/wandb/run-20241012_154938-i9bxnpg8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kotomiya07/TEST/runs/i9bxnpg8' target=\"_blank\">vq-f4-scale-factor-6</a></strong> to <a href='https://wandb.ai/kotomiya07/TEST' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kotomiya07/TEST' target=\"_blank\">https://wandb.ai/kotomiya07/TEST</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kotomiya07/TEST/runs/i9bxnpg8' target=\"_blank\">https://wandb.ai/kotomiya07/TEST/runs/i9bxnpg8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/kotomiya07/TEST/runs/i9bxnpg8?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f0349d934c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "            project=\"TEST\",\n",
    "            name=args.exp,\n",
    "            config={\n",
    "                \"dataset\": args.dataset,\n",
    "                \"image_size\": args.image_size,\n",
    "                \"channels\": args.num_channels,\n",
    "                \"channels_dae\": args.num_channels_dae,\n",
    "                \"ch_nult\": args.ch_mult,\n",
    "                \"timesteps\": args.num_timesteps,\n",
    "                \"res_blocks\": args.num_res_blocks,\n",
    "                \"nz\": args.nz,\n",
    "                \"epochs\": args.num_epoch,\n",
    "                \"ngf\": args.ngf,\n",
    "                \"lr_g\": args.lr_g,\n",
    "                \"lr_d\": args.lr_d,\n",
    "                \"batch_size\": args.batch_size,\n",
    "                \"r1_gamma\": args.r1_gamma,\n",
    "                \"lazy_reg\": args.lazy_reg,\n",
    "                \"embedding_type\": args.embedding_type,\n",
    "                \"use_ema\": args.use_ema,\n",
    "                \"ema_decay\": args.ema_decay,\n",
    "                \"no_lr_decay\": args.no_lr_decay,\n",
    "                \"z_emb_dim\": args.z_emb_dim,\n",
    "                \"attn_resolutions\": args.attn_resolutions,\n",
    "                \"use_pytorch_wavelet\": args.use_pytorch_wavelet,\n",
    "                \"rec_loss\": args.rec_loss,\n",
    "                \"net_type\": args.net_type,\n",
    "                \"num_disc_layers\": args.num_disc_layers,\n",
    "                \"no_use_fbn\": args.no_use_fbn,\n",
    "                \"no_use_freq\": args.no_use_freq,\n",
    "                \"no_use_residual\": args.no_use_residual,\n",
    "                \"scale_factor\": args.scale_factor,\n",
    "                \"AutoEncoder_config\": args.AutoEncoder_config,\n",
    "                \"AutoEncoder_ckpt\": args.AutoEncoder_ckpt,\n",
    "                \"sigmoid_learning\": args.sigmoid_learning,\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61fa8857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting in debug mode\n",
      "Files already downloaded and verified\n",
      "GEN: <class 'score_sde.models.ncsnpp_generator_adagn.NCSNpp'>, DISC: [<class 'score_sde.models.discriminator.Discriminator_small'>, <class 'score_sde.models.discriminator.Discriminator_large'>]\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Working with z of shape (1, 3, 64, 64) = 12288 dimensions.\n",
      "making attention of type 'vanilla' with 512 in_channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/std/2021/21k0005/anaconda3/envs/iddgan/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/users/std/2021/21k0005/anaconda3/envs/iddgan/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank0]:[W reducer.cpp:1360] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 iteration0, G Loss: 0.8527848720550537, D Loss: 1.3862943649291992, alpha: 0.9975273768433652\n",
      "epoch 0 iteration100, G Loss: 0.8507814407348633, D Loss: 1.3850209712982178, alpha: 0.9975273768433652\n",
      "Saving content.\n",
      "epoch 1 iteration0, G Loss: 0.857864499092102, D Loss: 1.3856494426727295, alpha: 0.9975125335223958\n",
      "epoch 1 iteration100, G Loss: 0.7886791825294495, D Loss: 1.4038503170013428, alpha: 0.9975125335223958\n",
      "epoch 2 iteration0, G Loss: 0.8975395560264587, D Loss: 1.3789077997207642, alpha: 0.997497601319515\n",
      "epoch 2 iteration100, G Loss: 0.8452986478805542, D Loss: 1.3862720727920532, alpha: 0.997497601319515\n",
      "epoch 3 iteration0, G Loss: 0.8611730337142944, D Loss: 1.3824682235717773, alpha: 0.9974825797051893\n",
      "epoch 3 iteration100, G Loss: 0.867152214050293, D Loss: 1.3867359161376953, alpha: 0.9974825797051893\n",
      "epoch 4 iteration0, G Loss: 0.8584197759628296, D Loss: 1.3893022537231445, alpha: 0.9974674681467623\n",
      "epoch 4 iteration100, G Loss: 0.8552899360656738, D Loss: 1.3843700885772705, alpha: 0.9974674681467623\n",
      "epoch 5 iteration0, G Loss: 0.8606977462768555, D Loss: 1.3867313861846924, alpha: 0.9974522661084374\n",
      "epoch 5 iteration100, G Loss: 0.9155349135398865, D Loss: 1.3905466794967651, alpha: 0.9974522661084374\n",
      "epoch 6 iteration0, G Loss: 0.8887772560119629, D Loss: 1.3854165077209473, alpha: 0.9974369730512593\n",
      "epoch 6 iteration100, G Loss: 0.8640153408050537, D Loss: 1.3840593099594116, alpha: 0.9974369730512593\n",
      "epoch 7 iteration0, G Loss: 0.8884920477867126, D Loss: 1.3811750411987305, alpha: 0.9974215884330963\n",
      "epoch 7 iteration100, G Loss: 0.8608558177947998, D Loss: 1.3873225450515747, alpha: 0.9974215884330963\n",
      "epoch 8 iteration0, G Loss: 0.8475298881530762, D Loss: 1.381788969039917, alpha: 0.997406111708621\n",
      "epoch 8 iteration100, G Loss: 0.8861370086669922, D Loss: 1.385801911354065, alpha: 0.997406111708621\n",
      "epoch 9 iteration0, G Loss: 0.8886111378669739, D Loss: 1.3822667598724365, alpha: 0.997390542329293\n",
      "epoch 9 iteration100, G Loss: 0.8585973381996155, D Loss: 1.3828145265579224, alpha: 0.997390542329293\n",
      "epoch 10 iteration0, G Loss: 0.863434910774231, D Loss: 1.3861883878707886, alpha: 0.9973748797433398\n",
      "epoch 10 iteration100, G Loss: 0.8694503307342529, D Loss: 1.3793858289718628, alpha: 0.9973748797433398\n",
      "epoch 11 iteration0, G Loss: 0.8754296898841858, D Loss: 1.3801990747451782, alpha: 0.9973591233957381\n",
      "epoch 11 iteration100, G Loss: 0.8896167278289795, D Loss: 1.4131534099578857, alpha: 0.9973591233957381\n",
      "epoch 12 iteration0, G Loss: 0.8761376142501831, D Loss: 1.3847053050994873, alpha: 0.9973432727281952\n",
      "epoch 12 iteration100, G Loss: 0.8720781803131104, D Loss: 1.382555365562439, alpha: 0.9973432727281952\n",
      "epoch 13 iteration0, G Loss: 0.8816017508506775, D Loss: 1.375281810760498, alpha: 0.9973273271791304\n",
      "epoch 13 iteration100, G Loss: 0.863737940788269, D Loss: 1.389286756515503, alpha: 0.9973273271791304\n",
      "epoch 14 iteration0, G Loss: 0.88142991065979, D Loss: 1.3682855367660522, alpha: 0.9973112861836558\n",
      "epoch 14 iteration100, G Loss: 0.8480492234230042, D Loss: 1.3874475955963135, alpha: 0.9973112861836558\n",
      "epoch 15 iteration0, G Loss: 0.859893262386322, D Loss: 1.3855211734771729, alpha: 0.9972951491735572\n",
      "epoch 15 iteration100, G Loss: 0.8906317949295044, D Loss: 1.3934110403060913, alpha: 0.9972951491735572\n",
      "epoch 16 iteration0, G Loss: 0.8561333417892456, D Loss: 1.389439344406128, alpha: 0.9972789155772751\n",
      "epoch 16 iteration100, G Loss: 0.8769404888153076, D Loss: 1.3814647197723389, alpha: 0.9972789155772751\n",
      "epoch 17 iteration0, G Loss: 0.8833956718444824, D Loss: 1.3863918781280518, alpha: 0.9972625848198857\n",
      "epoch 17 iteration100, G Loss: 0.833672046661377, D Loss: 1.4035255908966064, alpha: 0.9972625848198857\n",
      "epoch 18 iteration0, G Loss: 0.7748363018035889, D Loss: 1.3674782514572144, alpha: 0.997246156323081\n",
      "epoch 18 iteration100, G Loss: 0.8976598978042603, D Loss: 1.3894431591033936, alpha: 0.997246156323081\n",
      "epoch 19 iteration0, G Loss: 0.870532751083374, D Loss: 1.3903526067733765, alpha: 0.9972296295051497\n",
      "epoch 19 iteration100, G Loss: 0.7909831404685974, D Loss: 1.3901572227478027, alpha: 0.9972296295051497\n",
      "epoch 20 iteration0, G Loss: 0.8815504908561707, D Loss: 1.3846206665039062, alpha: 0.9972130037809577\n",
      "epoch 20 iteration100, G Loss: 0.8659591674804688, D Loss: 1.3591896295547485, alpha: 0.9972130037809577\n",
      "epoch 21 iteration0, G Loss: 0.8914480209350586, D Loss: 1.3884565830230713, alpha: 0.9971962785619283\n",
      "epoch 21 iteration100, G Loss: 0.8660619854927063, D Loss: 1.3810477256774902, alpha: 0.9971962785619283\n",
      "epoch 22 iteration0, G Loss: 0.8348953723907471, D Loss: 1.392304539680481, alpha: 0.9971794532560223\n",
      "epoch 22 iteration100, G Loss: 0.8844699859619141, D Loss: 1.3839912414550781, alpha: 0.9971794532560223\n",
      "epoch 23 iteration0, G Loss: 0.8742361068725586, D Loss: 1.3893206119537354, alpha: 0.9971625272677183\n",
      "epoch 23 iteration100, G Loss: 0.8615405559539795, D Loss: 1.3861570358276367, alpha: 0.9971625272677183\n",
      "epoch 24 iteration0, G Loss: 0.8578065037727356, D Loss: 1.3560682535171509, alpha: 0.9971454999979927\n",
      "epoch 24 iteration100, G Loss: 0.8906393051147461, D Loss: 1.3892309665679932, alpha: 0.9971454999979927\n",
      "epoch 25 iteration0, G Loss: 0.8465849161148071, D Loss: 1.3848776817321777, alpha: 0.9971283708442996\n",
      "epoch 25 iteration100, G Loss: 0.8715816140174866, D Loss: 1.3784877061843872, alpha: 0.9971283708442996\n",
      "epoch 26 iteration0, G Loss: 0.850035548210144, D Loss: 1.380387783050537, alpha: 0.9971111392005504\n",
      "epoch 26 iteration100, G Loss: 0.8781235814094543, D Loss: 1.377402663230896, alpha: 0.9971111392005504\n",
      "epoch 27 iteration0, G Loss: 0.8692599534988403, D Loss: 1.3836252689361572, alpha: 0.9970938044570938\n",
      "epoch 27 iteration100, G Loss: 0.8840511441230774, D Loss: 1.3783609867095947, alpha: 0.9970938044570938\n",
      "epoch 28 iteration0, G Loss: 0.9396367073059082, D Loss: 1.3725340366363525, alpha: 0.9970763660006952\n",
      "epoch 28 iteration100, G Loss: 0.8786900043487549, D Loss: 1.3835580348968506, alpha: 0.9970763660006952\n",
      "epoch 29 iteration0, G Loss: 0.852796196937561, D Loss: 1.3813741207122803, alpha: 0.9970588232145158\n",
      "epoch 29 iteration100, G Loss: 0.8663166761398315, D Loss: 1.3859671354293823, alpha: 0.9970588232145158\n",
      "epoch 30 iteration0, G Loss: 0.8461459875106812, D Loss: 1.38503098487854, alpha: 0.9970411754780928\n",
      "epoch 30 iteration100, G Loss: 0.890459418296814, D Loss: 1.3791329860687256, alpha: 0.9970411754780928\n",
      "epoch 31 iteration0, G Loss: 0.8554266691207886, D Loss: 1.396122932434082, alpha: 0.9970234221673178\n",
      "epoch 31 iteration100, G Loss: 0.8695846199989319, D Loss: 1.382676362991333, alpha: 0.9970234221673178\n",
      "epoch 32 iteration0, G Loss: 0.8486170768737793, D Loss: 1.3630214929580688, alpha: 0.9970055626544164\n",
      "epoch 32 iteration100, G Loss: 0.8755044341087341, D Loss: 1.3923907279968262, alpha: 0.9970055626544164\n",
      "epoch 33 iteration0, G Loss: 0.8944031000137329, D Loss: 1.376132607460022, alpha: 0.9969875963079272\n",
      "epoch 33 iteration100, G Loss: 0.8566898107528687, D Loss: 1.3793575763702393, alpha: 0.9969875963079272\n",
      "epoch 34 iteration0, G Loss: 0.8610644340515137, D Loss: 1.38065767288208, alpha: 0.9969695224926802\n",
      "epoch 34 iteration100, G Loss: 0.84025639295578, D Loss: 1.3985782861709595, alpha: 0.9969695224926802\n",
      "epoch 35 iteration0, G Loss: 0.8997189998626709, D Loss: 1.3868937492370605, alpha: 0.9969513405697763\n",
      "epoch 35 iteration100, G Loss: 0.8586474061012268, D Loss: 1.3892501592636108, alpha: 0.9969513405697763\n",
      "epoch 36 iteration0, G Loss: 0.9066774249076843, D Loss: 1.3847768306732178, alpha: 0.9969330498965654\n",
      "epoch 36 iteration100, G Loss: 0.8852444887161255, D Loss: 1.4016996622085571, alpha: 0.9969330498965654\n",
      "epoch 37 iteration0, G Loss: 0.8658692240715027, D Loss: 1.3828849792480469, alpha: 0.9969146498266254\n",
      "epoch 37 iteration100, G Loss: 0.8918859362602234, D Loss: 1.3911265134811401, alpha: 0.9969146498266254\n",
      "epoch 38 iteration0, G Loss: 0.8574339151382446, D Loss: 1.390855312347412, alpha: 0.9968961397097401\n",
      "epoch 38 iteration100, G Loss: 0.8636778593063354, D Loss: 1.3833633661270142, alpha: 0.9968961397097401\n",
      "epoch 39 iteration0, G Loss: 0.8734884262084961, D Loss: 1.3888888359069824, alpha: 0.9968775188918781\n",
      "epoch 39 iteration100, G Loss: 0.8694617748260498, D Loss: 1.385612964630127, alpha: 0.9968775188918781\n",
      "epoch 40 iteration0, G Loss: 0.8827279806137085, D Loss: 1.3852707147598267, alpha: 0.9968587867151706\n",
      "epoch 40 iteration100, G Loss: 0.8492176532745361, D Loss: 1.3769270181655884, alpha: 0.9968587867151706\n",
      "epoch 41 iteration0, G Loss: 0.8724074363708496, D Loss: 1.3690755367279053, alpha: 0.9968399425178895\n",
      "epoch 41 iteration100, G Loss: 0.8695591688156128, D Loss: 1.3875277042388916, alpha: 0.9968399425178895\n",
      "epoch 42 iteration0, G Loss: 0.8926066160202026, D Loss: 1.3886115550994873, alpha: 0.9968209856344259\n",
      "epoch 42 iteration100, G Loss: 0.90604567527771, D Loss: 1.3582923412322998, alpha: 0.9968209856344259\n",
      "epoch 43 iteration0, G Loss: 0.830338180065155, D Loss: 1.4061119556427002, alpha: 0.9968019153952671\n",
      "epoch 43 iteration100, G Loss: 0.8560236692428589, D Loss: 1.384848952293396, alpha: 0.9968019153952671\n",
      "epoch 44 iteration0, G Loss: 0.8612076640129089, D Loss: 1.380963921546936, alpha: 0.9967827311269749\n",
      "epoch 44 iteration100, G Loss: 0.8934236764907837, D Loss: 1.3815973997116089, alpha: 0.9967827311269749\n",
      "epoch 45 iteration0, G Loss: 0.8645753860473633, D Loss: 1.3853294849395752, alpha: 0.9967634321521631\n",
      "epoch 45 iteration100, G Loss: 0.8785209059715271, D Loss: 1.398315668106079, alpha: 0.9967634321521631\n",
      "epoch 46 iteration0, G Loss: 0.8878899812698364, D Loss: 1.409700632095337, alpha: 0.9967440177894752\n",
      "epoch 46 iteration100, G Loss: 0.8407077789306641, D Loss: 1.3849778175354004, alpha: 0.9967440177894752\n",
      "epoch 47 iteration0, G Loss: 0.8758147358894348, D Loss: 1.3804596662521362, alpha: 0.996724487353561\n",
      "epoch 47 iteration100, G Loss: 0.844090461730957, D Loss: 1.3888306617736816, alpha: 0.996724487353561\n",
      "epoch 48 iteration0, G Loss: 0.8539659976959229, D Loss: 1.386976957321167, alpha: 0.9967048401550548\n",
      "epoch 48 iteration100, G Loss: 0.8934535980224609, D Loss: 1.3812036514282227, alpha: 0.9967048401550548\n",
      "epoch 49 iteration0, G Loss: 0.8979640603065491, D Loss: 1.3794934749603271, alpha: 0.9966850755005522\n",
      "epoch 49 iteration100, G Loss: 0.8656721711158752, D Loss: 1.3866264820098877, alpha: 0.9966850755005522\n",
      "epoch 50 iteration0, G Loss: 0.8880859613418579, D Loss: 1.3964166641235352, alpha: 0.9966651926925867\n",
      "epoch 50 iteration100, G Loss: 0.8721844553947449, D Loss: 1.3879622220993042, alpha: 0.9966651926925867\n",
      "Saving content.\n",
      "epoch 51 iteration0, G Loss: 0.8696524500846863, D Loss: 1.3804166316986084, alpha: 0.996645191029607\n",
      "epoch 51 iteration100, G Loss: 0.8861675262451172, D Loss: 1.398643970489502, alpha: 0.996645191029607\n",
      "epoch 52 iteration0, G Loss: 0.8650856018066406, D Loss: 1.3950296640396118, alpha: 0.9966250698059539\n",
      "epoch 52 iteration100, G Loss: 0.8488092422485352, D Loss: 1.3792616128921509, alpha: 0.9966250698059539\n",
      "epoch 53 iteration0, G Loss: 0.8848938941955566, D Loss: 1.3731539249420166, alpha: 0.9966048283118364\n",
      "epoch 53 iteration100, G Loss: 0.8803249001502991, D Loss: 1.3776521682739258, alpha: 0.9966048283118364\n",
      "epoch 54 iteration0, G Loss: 0.8806939125061035, D Loss: 1.3715049028396606, alpha: 0.9965844658333086\n",
      "epoch 54 iteration100, G Loss: 0.8470321297645569, D Loss: 1.3845783472061157, alpha: 0.9965844658333086\n",
      "epoch 55 iteration0, G Loss: 0.8783913254737854, D Loss: 1.3741252422332764, alpha: 0.9965639816522461\n",
      "epoch 55 iteration100, G Loss: 0.8908261060714722, D Loss: 1.3856840133666992, alpha: 0.9965639816522461\n",
      "epoch 56 iteration0, G Loss: 0.8214921951293945, D Loss: 1.3756442070007324, alpha: 0.9965433750463222\n",
      "epoch 56 iteration100, G Loss: 0.9191509485244751, D Loss: 1.3746250867843628, alpha: 0.9965433750463222\n",
      "epoch 57 iteration0, G Loss: 0.8641682267189026, D Loss: 1.3940787315368652, alpha: 0.9965226452889837\n",
      "epoch 57 iteration100, G Loss: 0.8548247814178467, D Loss: 1.386797547340393, alpha: 0.9965226452889837\n",
      "epoch 58 iteration0, G Loss: 0.8702573776245117, D Loss: 1.387589931488037, alpha: 0.9965017916494276\n",
      "epoch 58 iteration100, G Loss: 0.8628557324409485, D Loss: 1.3811750411987305, alpha: 0.9965017916494276\n",
      "epoch 59 iteration0, G Loss: 0.8714849352836609, D Loss: 1.3818738460540771, alpha: 0.9964808133925762\n",
      "epoch 59 iteration100, G Loss: 0.8947016000747681, D Loss: 1.3864643573760986, alpha: 0.9964808133925762\n",
      "epoch 60 iteration0, G Loss: 0.8594892621040344, D Loss: 1.3983619213104248, alpha: 0.9964597097790535\n",
      "epoch 60 iteration100, G Loss: 0.8721207976341248, D Loss: 1.3903324604034424, alpha: 0.9964597097790535\n",
      "epoch 61 iteration0, G Loss: 0.8580923676490784, D Loss: 1.3864977359771729, alpha: 0.9964384800651604\n",
      "epoch 61 iteration100, G Loss: 0.8653770685195923, D Loss: 1.389647364616394, alpha: 0.9964384800651604\n",
      "epoch 62 iteration0, G Loss: 0.8862814903259277, D Loss: 1.3846417665481567, alpha: 0.9964171235028505\n",
      "epoch 62 iteration100, G Loss: 0.8846157193183899, D Loss: 1.3882215023040771, alpha: 0.9964171235028505\n",
      "epoch 63 iteration0, G Loss: 0.8713713884353638, D Loss: 1.378861665725708, alpha: 0.9963956393397052\n",
      "epoch 63 iteration100, G Loss: 0.848486065864563, D Loss: 1.389729380607605, alpha: 0.9963956393397052\n",
      "epoch 64 iteration0, G Loss: 0.8874268531799316, D Loss: 1.3774189949035645, alpha: 0.9963740268189091\n",
      "epoch 64 iteration100, G Loss: 0.8550949692726135, D Loss: 1.3856629133224487, alpha: 0.9963740268189091\n",
      "epoch 65 iteration0, G Loss: 0.879783570766449, D Loss: 1.3841028213500977, alpha: 0.996352285179225\n",
      "epoch 65 iteration100, G Loss: 0.8919869661331177, D Loss: 1.3827638626098633, alpha: 0.996352285179225\n",
      "epoch 66 iteration0, G Loss: 0.8735765218734741, D Loss: 1.3949360847473145, alpha: 0.9963304136549692\n",
      "epoch 66 iteration100, G Loss: 0.8792405128479004, D Loss: 1.388946771621704, alpha: 0.9963304136549692\n",
      "epoch 67 iteration0, G Loss: 0.8410211205482483, D Loss: 1.3709092140197754, alpha: 0.9963084114759856\n",
      "epoch 67 iteration100, G Loss: 0.8867090940475464, D Loss: 1.38213312625885, alpha: 0.9963084114759856\n",
      "epoch 68 iteration0, G Loss: 0.8598921298980713, D Loss: 1.375736117362976, alpha: 0.9962862778676213\n",
      "epoch 68 iteration100, G Loss: 0.8958396315574646, D Loss: 1.3781405687332153, alpha: 0.9962862778676213\n",
      "epoch 69 iteration0, G Loss: 0.8892271518707275, D Loss: 1.387108564376831, alpha: 0.9962640120507004\n",
      "epoch 69 iteration100, G Loss: 0.9147235751152039, D Loss: 1.3714425563812256, alpha: 0.9962640120507004\n",
      "epoch 70 iteration0, G Loss: 0.8875176906585693, D Loss: 1.4041754007339478, alpha: 0.9962416132414992\n",
      "epoch 70 iteration100, G Loss: 0.8696867227554321, D Loss: 1.3874629735946655, alpha: 0.9962416132414992\n",
      "epoch 71 iteration0, G Loss: 0.8694806098937988, D Loss: 1.3727467060089111, alpha: 0.9962190806517198\n",
      "epoch 71 iteration100, G Loss: 0.8895260095596313, D Loss: 1.3712273836135864, alpha: 0.9962190806517198\n",
      "epoch 72 iteration0, G Loss: 0.9058194160461426, D Loss: 1.3656680583953857, alpha: 0.9961964134884649\n",
      "epoch 72 iteration100, G Loss: 0.904683530330658, D Loss: 1.384385108947754, alpha: 0.9961964134884649\n",
      "epoch 73 iteration0, G Loss: 0.9066240787506104, D Loss: 1.3857121467590332, alpha: 0.9961736109542111\n",
      "epoch 73 iteration100, G Loss: 0.8715456128120422, D Loss: 1.3728766441345215, alpha: 0.9961736109542111\n",
      "epoch 74 iteration0, G Loss: 0.8584436178207397, D Loss: 1.3972554206848145, alpha: 0.9961506722467834\n",
      "epoch 74 iteration100, G Loss: 0.8820206522941589, D Loss: 1.3833789825439453, alpha: 0.9961506722467834\n",
      "epoch 75 iteration0, G Loss: 0.8873211145401001, D Loss: 1.3831794261932373, alpha: 0.9961275965593289\n",
      "epoch 75 iteration100, G Loss: 0.8655344247817993, D Loss: 1.3829989433288574, alpha: 0.9961275965593289\n",
      "epoch 76 iteration0, G Loss: 0.853630542755127, D Loss: 1.3768444061279297, alpha: 0.9961043830802904\n",
      "epoch 76 iteration100, G Loss: 0.8957149982452393, D Loss: 1.3748035430908203, alpha: 0.9961043830802904\n",
      "epoch 77 iteration0, G Loss: 0.8621360659599304, D Loss: 1.3854337930679321, alpha: 0.9960810309933794\n",
      "epoch 77 iteration100, G Loss: 0.8708683252334595, D Loss: 1.3914767503738403, alpha: 0.9960810309933794\n",
      "epoch 78 iteration0, G Loss: 1.058504581451416, D Loss: 1.412087321281433, alpha: 0.9960575394775504\n",
      "epoch 78 iteration100, G Loss: 0.8550273180007935, D Loss: 1.3824059963226318, alpha: 0.9960575394775504\n",
      "epoch 79 iteration0, G Loss: 0.8842566609382629, D Loss: 1.360994577407837, alpha: 0.996033907706973\n",
      "epoch 79 iteration100, G Loss: 0.9330905079841614, D Loss: 1.3653831481933594, alpha: 0.996033907706973\n",
      "epoch 80 iteration0, G Loss: 0.9416113495826721, D Loss: 1.4191923141479492, alpha: 0.9960101348510059\n",
      "epoch 80 iteration100, G Loss: 0.8440722227096558, D Loss: 1.3797483444213867, alpha: 0.9960101348510059\n",
      "epoch 81 iteration0, G Loss: 0.9172096252441406, D Loss: 1.3783142566680908, alpha: 0.9959862200741696\n",
      "epoch 81 iteration100, G Loss: 0.9317518472671509, D Loss: 1.3648288249969482, alpha: 0.9959862200741696\n",
      "epoch 82 iteration0, G Loss: 0.9028375148773193, D Loss: 1.3902183771133423, alpha: 0.9959621625361187\n",
      "epoch 82 iteration100, G Loss: 0.862667441368103, D Loss: 1.396695852279663, alpha: 0.9959621625361187\n",
      "epoch 83 iteration0, G Loss: 1.0161786079406738, D Loss: 1.454801321029663, alpha: 0.9959379613916154\n",
      "epoch 83 iteration100, G Loss: 0.803609311580658, D Loss: 1.3966975212097168, alpha: 0.9959379613916154\n",
      "epoch 84 iteration0, G Loss: 0.8036934733390808, D Loss: 1.3890702724456787, alpha: 0.9959136157905011\n",
      "epoch 84 iteration100, G Loss: 0.8997228145599365, D Loss: 1.38191819190979, alpha: 0.9959136157905011\n",
      "epoch 85 iteration0, G Loss: 0.8557480573654175, D Loss: 1.3780642747879028, alpha: 0.9958891248776693\n",
      "epoch 85 iteration100, G Loss: 0.9339640736579895, D Loss: 1.3846943378448486, alpha: 0.9958891248776693\n",
      "epoch 86 iteration0, G Loss: 0.9059860110282898, D Loss: 1.3715850114822388, alpha: 0.9958644877930382\n",
      "epoch 86 iteration100, G Loss: 1.0021178722381592, D Loss: 1.3724555969238281, alpha: 0.9958644877930382\n",
      "epoch 87 iteration0, G Loss: 0.8858799934387207, D Loss: 1.3699593544006348, alpha: 0.9958397036715217\n",
      "epoch 87 iteration100, G Loss: 0.9291512370109558, D Loss: 1.37071692943573, alpha: 0.9958397036715217\n",
      "epoch 88 iteration0, G Loss: 0.8785818815231323, D Loss: 1.3818385601043701, alpha: 0.9958147716430024\n",
      "epoch 88 iteration100, G Loss: 0.8731311559677124, D Loss: 1.38932204246521, alpha: 0.9958147716430024\n",
      "epoch 89 iteration0, G Loss: 0.8687186241149902, D Loss: 1.3878369331359863, alpha: 0.9957896908323025\n",
      "epoch 89 iteration100, G Loss: 0.9054991006851196, D Loss: 1.3530791997909546, alpha: 0.9957896908323025\n",
      "epoch 90 iteration0, G Loss: 0.912471354007721, D Loss: 1.4123773574829102, alpha: 0.9957644603591566\n",
      "epoch 90 iteration100, G Loss: 0.8795363903045654, D Loss: 1.3680757284164429, alpha: 0.9957644603591566\n",
      "epoch 91 iteration0, G Loss: 0.9238561987876892, D Loss: 1.3845634460449219, alpha: 0.9957390793381818\n",
      "epoch 91 iteration100, G Loss: 0.9046344757080078, D Loss: 1.3728652000427246, alpha: 0.9957390793381818\n",
      "epoch 92 iteration0, G Loss: 0.9122183918952942, D Loss: 1.3832948207855225, alpha: 0.9957135468788503\n",
      "epoch 92 iteration100, G Loss: 0.8574981689453125, D Loss: 1.3853733539581299, alpha: 0.9957135468788503\n",
      "epoch 93 iteration0, G Loss: 0.9548338651657104, D Loss: 1.3548147678375244, alpha: 0.9956878620854597\n",
      "epoch 93 iteration100, G Loss: 0.8454958200454712, D Loss: 1.3834781646728516, alpha: 0.9956878620854597\n",
      "epoch 94 iteration0, G Loss: 0.9335751533508301, D Loss: 1.3780364990234375, alpha: 0.9956620240571046\n",
      "epoch 94 iteration100, G Loss: 0.8785855770111084, D Loss: 1.3748581409454346, alpha: 0.9956620240571046\n",
      "epoch 95 iteration0, G Loss: 0.8912595510482788, D Loss: 1.394582748413086, alpha: 0.9956360318876475\n",
      "epoch 95 iteration100, G Loss: 0.8676126003265381, D Loss: 1.3950345516204834, alpha: 0.9956360318876475\n",
      "epoch 96 iteration0, G Loss: 0.8906469345092773, D Loss: 1.3832166194915771, alpha: 0.995609884665689\n",
      "epoch 96 iteration100, G Loss: 0.9088315963745117, D Loss: 1.3973602056503296, alpha: 0.995609884665689\n",
      "epoch 97 iteration0, G Loss: 0.8746094703674316, D Loss: 1.3926467895507812, alpha: 0.9955835814745394\n",
      "epoch 97 iteration100, G Loss: 0.8564540147781372, D Loss: 1.3946071863174438, alpha: 0.9955835814745394\n",
      "epoch 98 iteration0, G Loss: 0.9173009395599365, D Loss: 1.4060274362564087, alpha: 0.9955571213921881\n",
      "epoch 98 iteration100, G Loss: 0.8438669443130493, D Loss: 1.3894299268722534, alpha: 0.9955571213921881\n",
      "epoch 99 iteration0, G Loss: 0.9478929042816162, D Loss: 1.3706109523773193, alpha: 0.9955305034912747\n",
      "epoch 99 iteration100, G Loss: 0.8917782306671143, D Loss: 1.3965938091278076, alpha: 0.9955305034912747\n",
      "epoch 100 iteration0, G Loss: 0.9148578643798828, D Loss: 1.406693935394287, alpha: 0.9955037268390589\n",
      "epoch 100 iteration100, G Loss: 0.8485424518585205, D Loss: 1.3969106674194336, alpha: 0.9955037268390589\n",
      "Saving content.\n",
      "epoch 101 iteration0, G Loss: 0.8670814037322998, D Loss: 1.3732516765594482, alpha: 0.99547679049739\n",
      "epoch 101 iteration100, G Loss: 0.8762813210487366, D Loss: 1.3711448907852173, alpha: 0.99547679049739\n",
      "epoch 102 iteration0, G Loss: 0.9716233015060425, D Loss: 1.3923280239105225, alpha: 0.9954496935226781\n",
      "epoch 102 iteration100, G Loss: 0.9201177358627319, D Loss: 1.3757514953613281, alpha: 0.9954496935226781\n",
      "epoch 103 iteration0, G Loss: 0.8952188491821289, D Loss: 1.383955478668213, alpha: 0.9954224349658624\n",
      "epoch 103 iteration100, G Loss: 0.9213655591011047, D Loss: 1.3604390621185303, alpha: 0.9954224349658624\n",
      "epoch 104 iteration0, G Loss: 1.0901694297790527, D Loss: 1.3844892978668213, alpha: 0.9953950138723812\n",
      "epoch 104 iteration100, G Loss: 0.8966636657714844, D Loss: 1.3814302682876587, alpha: 0.9953950138723812\n",
      "epoch 105 iteration0, G Loss: 1.1098040342330933, D Loss: 1.3655340671539307, alpha: 0.9953674292821418\n",
      "epoch 105 iteration100, G Loss: 0.8951294422149658, D Loss: 1.385845422744751, alpha: 0.9953674292821418\n",
      "epoch 106 iteration0, G Loss: 0.9345894455909729, D Loss: 1.353479027748108, alpha: 0.9953396802294893\n",
      "epoch 106 iteration100, G Loss: 0.8917512893676758, D Loss: 1.3964868783950806, alpha: 0.9953396802294893\n",
      "epoch 107 iteration0, G Loss: 0.8748683333396912, D Loss: 1.3821592330932617, alpha: 0.9953117657431754\n",
      "epoch 107 iteration100, G Loss: 0.8400141000747681, D Loss: 1.4090489149093628, alpha: 0.9953117657431754\n",
      "epoch 108 iteration0, G Loss: 0.9444398283958435, D Loss: 1.3860251903533936, alpha: 0.9952836848463282\n",
      "epoch 108 iteration100, G Loss: 0.8223000764846802, D Loss: 1.3777108192443848, alpha: 0.9952836848463282\n",
      "epoch 109 iteration0, G Loss: 0.8800063133239746, D Loss: 1.3761956691741943, alpha: 0.99525543655642\n",
      "epoch 109 iteration100, G Loss: 0.9438931345939636, D Loss: 1.371165156364441, alpha: 0.99525543655642\n",
      "epoch 110 iteration0, G Loss: 0.8773390054702759, D Loss: 1.3900718688964844, alpha: 0.9952270198852368\n",
      "epoch 110 iteration100, G Loss: 0.8633583784103394, D Loss: 1.3845574855804443, alpha: 0.9952270198852368\n",
      "epoch 111 iteration0, G Loss: 0.8385962247848511, D Loss: 1.378508448600769, alpha: 0.995198433838846\n",
      "epoch 111 iteration100, G Loss: 0.8722618818283081, D Loss: 1.380773901939392, alpha: 0.995198433838846\n",
      "epoch 112 iteration0, G Loss: 0.8722008466720581, D Loss: 1.3875887393951416, alpha: 0.9951696774175651\n",
      "epoch 112 iteration100, G Loss: 0.8424961566925049, D Loss: 1.3855592012405396, alpha: 0.9951696774175651\n",
      "epoch 113 iteration0, G Loss: 0.9068396687507629, D Loss: 1.3930397033691406, alpha: 0.9951407496159302\n",
      "epoch 113 iteration100, G Loss: 0.8729391098022461, D Loss: 1.350598931312561, alpha: 0.9951407496159302\n",
      "epoch 114 iteration0, G Loss: 0.8736661672592163, D Loss: 1.365344762802124, alpha: 0.9951116494226631\n",
      "epoch 114 iteration100, G Loss: 0.8872949481010437, D Loss: 1.3791675567626953, alpha: 0.9951116494226631\n",
      "epoch 115 iteration0, G Loss: 0.8560842275619507, D Loss: 1.3957856893539429, alpha: 0.9950823758206396\n",
      "epoch 115 iteration100, G Loss: 0.8393470644950867, D Loss: 1.4057810306549072, alpha: 0.9950823758206396\n",
      "epoch 116 iteration0, G Loss: 0.9396311044692993, D Loss: 1.3799726963043213, alpha: 0.9950529277868578\n",
      "epoch 116 iteration100, G Loss: 0.9096260070800781, D Loss: 1.3789710998535156, alpha: 0.9950529277868578\n",
      "epoch 117 iteration0, G Loss: 0.9858691692352295, D Loss: 1.421771764755249, alpha: 0.9950233042924043\n",
      "epoch 117 iteration100, G Loss: 0.8741301894187927, D Loss: 1.392319679260254, alpha: 0.9950233042924043\n",
      "epoch 118 iteration0, G Loss: 0.8632734417915344, D Loss: 1.3758413791656494, alpha: 0.9949935043024226\n",
      "epoch 118 iteration100, G Loss: 0.8807472586631775, D Loss: 1.397098422050476, alpha: 0.9949935043024226\n",
      "epoch 119 iteration0, G Loss: 0.8610104918479919, D Loss: 1.3771436214447021, alpha: 0.9949635267760798\n",
      "epoch 119 iteration100, G Loss: 0.9966983199119568, D Loss: 1.3867545127868652, alpha: 0.9949635267760798\n",
      "epoch 120 iteration0, G Loss: 0.9488304257392883, D Loss: 1.4613614082336426, alpha: 0.9949333706665338\n",
      "epoch 120 iteration100, G Loss: 0.8911733627319336, D Loss: 1.378312587738037, alpha: 0.9949333706665338\n",
      "epoch 121 iteration0, G Loss: 0.8883689045906067, D Loss: 1.3875141143798828, alpha: 0.9949030349208999\n",
      "epoch 121 iteration100, G Loss: 0.979587972164154, D Loss: 1.4022550582885742, alpha: 0.9949030349208999\n",
      "epoch 122 iteration0, G Loss: 0.8277193903923035, D Loss: 1.3838346004486084, alpha: 0.9948725184802181\n",
      "epoch 122 iteration100, G Loss: 0.854803204536438, D Loss: 1.3754169940948486, alpha: 0.9948725184802181\n",
      "epoch 123 iteration0, G Loss: 0.8718618750572205, D Loss: 1.3769587278366089, alpha: 0.9948418202794187\n",
      "epoch 123 iteration100, G Loss: 0.8929415941238403, D Loss: 1.3613756895065308, alpha: 0.9948418202794187\n",
      "epoch 124 iteration0, G Loss: 0.8545290231704712, D Loss: 1.3859972953796387, alpha: 0.9948109392472895\n",
      "epoch 124 iteration100, G Loss: 0.8439650535583496, D Loss: 1.3850164413452148, alpha: 0.9948109392472895\n",
      "epoch 125 iteration0, G Loss: 0.9084215760231018, D Loss: 1.3731480836868286, alpha: 0.9947798743064415\n",
      "epoch 125 iteration100, G Loss: 0.8565865755081177, D Loss: 1.388716459274292, alpha: 0.9947798743064415\n",
      "epoch 126 iteration0, G Loss: 0.9111884236335754, D Loss: 1.3767105340957642, alpha: 0.9947486243732755\n",
      "epoch 126 iteration100, G Loss: 0.919527530670166, D Loss: 1.370124101638794, alpha: 0.9947486243732755\n",
      "epoch 127 iteration0, G Loss: 0.9949063658714294, D Loss: 1.4001576900482178, alpha: 0.994717188357947\n",
      "epoch 127 iteration100, G Loss: 0.8214718103408813, D Loss: 1.3869125843048096, alpha: 0.994717188357947\n",
      "epoch 128 iteration0, G Loss: 0.9380204677581787, D Loss: 1.3681567907333374, alpha: 0.9946855651643326\n",
      "epoch 128 iteration100, G Loss: 0.8618957996368408, D Loss: 1.37750244140625, alpha: 0.9946855651643326\n",
      "epoch 129 iteration0, G Loss: 0.8393526673316956, D Loss: 1.3687173128128052, alpha: 0.9946537536899958\n",
      "epoch 129 iteration100, G Loss: 0.931782066822052, D Loss: 1.3463270664215088, alpha: 0.9946537536899958\n",
      "epoch 130 iteration0, G Loss: 0.9524983167648315, D Loss: 1.400996208190918, alpha: 0.9946217528261514\n",
      "epoch 130 iteration100, G Loss: 0.7410410642623901, D Loss: 1.3565843105316162, alpha: 0.9946217528261514\n",
      "epoch 131 iteration0, G Loss: 0.8853580355644226, D Loss: 1.387999176979065, alpha: 0.9945895614576316\n",
      "epoch 131 iteration100, G Loss: 0.9376933574676514, D Loss: 1.4164350032806396, alpha: 0.9945895614576316\n",
      "epoch 132 iteration0, G Loss: 0.9095954895019531, D Loss: 1.3968019485473633, alpha: 0.9945571784628505\n",
      "epoch 132 iteration100, G Loss: 0.874778151512146, D Loss: 1.378218650817871, alpha: 0.9945571784628505\n",
      "epoch 133 iteration0, G Loss: 0.9031981229782104, D Loss: 1.3717586994171143, alpha: 0.9945246027137692\n",
      "epoch 133 iteration100, G Loss: 0.9144992828369141, D Loss: 1.3798906803131104, alpha: 0.9945246027137692\n",
      "epoch 134 iteration0, G Loss: 0.9295105934143066, D Loss: 1.3645410537719727, alpha: 0.9944918330758603\n",
      "epoch 134 iteration100, G Loss: 0.9464898109436035, D Loss: 1.375258445739746, alpha: 0.9944918330758603\n",
      "epoch 135 iteration0, G Loss: 0.8607615232467651, D Loss: 1.4011027812957764, alpha: 0.9944588684080726\n",
      "epoch 135 iteration100, G Loss: 0.9710792303085327, D Loss: 1.3939263820648193, alpha: 0.9944588684080726\n",
      "epoch 136 iteration0, G Loss: 0.9686329364776611, D Loss: 1.3654816150665283, alpha: 0.9944257075627952\n",
      "epoch 136 iteration100, G Loss: 0.8840039968490601, D Loss: 1.3631277084350586, alpha: 0.9944257075627952\n",
      "epoch 137 iteration0, G Loss: 0.868577241897583, D Loss: 1.3724480867385864, alpha: 0.994392349385822\n",
      "epoch 137 iteration100, G Loss: 0.8952062129974365, D Loss: 1.354398488998413, alpha: 0.994392349385822\n",
      "epoch 138 iteration0, G Loss: 0.8658769130706787, D Loss: 1.3884117603302002, alpha: 0.9943587927163153\n",
      "epoch 138 iteration100, G Loss: 0.8784564733505249, D Loss: 1.3609378337860107, alpha: 0.9943587927163153\n",
      "epoch 139 iteration0, G Loss: 0.8693852424621582, D Loss: 1.3871263265609741, alpha: 0.99432503638677\n",
      "epoch 139 iteration100, G Loss: 0.8923335671424866, D Loss: 1.4012939929962158, alpha: 0.99432503638677\n",
      "epoch 140 iteration0, G Loss: 0.8977526426315308, D Loss: 1.3743786811828613, alpha: 0.9942910792229767\n",
      "epoch 140 iteration100, G Loss: 0.7808772325515747, D Loss: 1.3713330030441284, alpha: 0.9942910792229767\n",
      "epoch 141 iteration0, G Loss: 0.8268107175827026, D Loss: 1.393782377243042, alpha: 0.9942569200439859\n",
      "epoch 141 iteration100, G Loss: 0.9006326794624329, D Loss: 1.375084400177002, alpha: 0.9942569200439859\n",
      "epoch 142 iteration0, G Loss: 0.9152301549911499, D Loss: 1.4009164571762085, alpha: 0.9942225576620709\n",
      "epoch 142 iteration100, G Loss: 0.8902920484542847, D Loss: 1.3799257278442383, alpha: 0.9942225576620709\n",
      "epoch 143 iteration0, G Loss: 0.7922767400741577, D Loss: 1.3929399251937866, alpha: 0.9941879908826907\n",
      "epoch 143 iteration100, G Loss: 0.9269473552703857, D Loss: 1.3736906051635742, alpha: 0.9941879908826907\n",
      "epoch 144 iteration0, G Loss: 0.8590160012245178, D Loss: 1.3739978075027466, alpha: 0.9941532185044534\n",
      "epoch 144 iteration100, G Loss: 0.9914189577102661, D Loss: 1.3692725896835327, alpha: 0.9941532185044534\n",
      "epoch 145 iteration0, G Loss: 0.9075413346290588, D Loss: 1.3937933444976807, alpha: 0.9941182393190785\n",
      "epoch 145 iteration100, G Loss: 0.8556119799613953, D Loss: 1.3808653354644775, alpha: 0.9941182393190785\n",
      "epoch 146 iteration0, G Loss: 0.8853857517242432, D Loss: 1.3823978900909424, alpha: 0.99408305211136\n",
      "epoch 146 iteration100, G Loss: 0.8669815063476562, D Loss: 1.3803021907806396, alpha: 0.99408305211136\n",
      "epoch 147 iteration0, G Loss: 0.9614155292510986, D Loss: 1.384657382965088, alpha: 0.9940476556591286\n",
      "epoch 147 iteration100, G Loss: 0.8759291768074036, D Loss: 1.3585742712020874, alpha: 0.9940476556591286\n",
      "epoch 148 iteration0, G Loss: 0.8246245384216309, D Loss: 1.4014878273010254, alpha: 0.9940120487332132\n",
      "epoch 148 iteration100, G Loss: 0.9273547530174255, D Loss: 1.41517972946167, alpha: 0.9940120487332132\n",
      "epoch 149 iteration0, G Loss: 0.9952372312545776, D Loss: 1.4352340698242188, alpha: 0.9939762300974047\n",
      "epoch 149 iteration100, G Loss: 0.8872963786125183, D Loss: 1.381240725517273, alpha: 0.9939762300974047\n",
      "epoch 150 iteration0, G Loss: 0.9103865623474121, D Loss: 1.3722264766693115, alpha: 0.9939401985084159\n",
      "epoch 150 iteration100, G Loss: 0.8861071467399597, D Loss: 1.3969690799713135, alpha: 0.9939401985084159\n",
      "Saving content.\n",
      "epoch 151 iteration0, G Loss: 0.864393949508667, D Loss: 1.3831238746643066, alpha: 0.9939039527158445\n",
      "epoch 151 iteration100, G Loss: 0.8519476652145386, D Loss: 1.3683215379714966, alpha: 0.9939039527158445\n",
      "epoch 152 iteration0, G Loss: 0.9038628339767456, D Loss: 1.3783271312713623, alpha: 0.9938674914621343\n",
      "epoch 152 iteration100, G Loss: 0.903573751449585, D Loss: 1.3991320133209229, alpha: 0.9938674914621343\n",
      "epoch 153 iteration0, G Loss: 0.9413484334945679, D Loss: 1.3812026977539062, alpha: 0.9938308134825361\n",
      "epoch 153 iteration100, G Loss: 0.8833335638046265, D Loss: 1.3987045288085938, alpha: 0.9938308134825361\n",
      "epoch 154 iteration0, G Loss: 0.9637301564216614, D Loss: 1.3539739847183228, alpha: 0.9937939175050695\n",
      "epoch 154 iteration100, G Loss: 0.9503226280212402, D Loss: 1.3889636993408203, alpha: 0.9937939175050695\n",
      "epoch 155 iteration0, G Loss: 0.9182044863700867, D Loss: 1.37807035446167, alpha: 0.9937568022504835\n",
      "epoch 155 iteration100, G Loss: 0.9031717777252197, D Loss: 1.3860447406768799, alpha: 0.9937568022504835\n",
      "epoch 156 iteration0, G Loss: 0.9114812612533569, D Loss: 1.3779494762420654, alpha: 0.9937194664322172\n",
      "epoch 156 iteration100, G Loss: 0.9150892496109009, D Loss: 1.3713264465332031, alpha: 0.9937194664322172\n",
      "epoch 157 iteration0, G Loss: 0.8364844918251038, D Loss: 1.3722972869873047, alpha: 0.9936819087563606\n",
      "epoch 157 iteration100, G Loss: 0.9006689190864563, D Loss: 1.383164405822754, alpha: 0.9936819087563606\n",
      "epoch 158 iteration0, G Loss: 0.8615770936012268, D Loss: 1.3902214765548706, alpha: 0.9936441279216154\n",
      "epoch 158 iteration100, G Loss: 0.853173017501831, D Loss: 1.3903475999832153, alpha: 0.9936441279216154\n",
      "epoch 159 iteration0, G Loss: 0.82305508852005, D Loss: 1.3849618434906006, alpha: 0.9936061226192542\n",
      "epoch 159 iteration100, G Loss: 0.864357590675354, D Loss: 1.381195306777954, alpha: 0.9936061226192542\n",
      "epoch 160 iteration0, G Loss: 0.9028403759002686, D Loss: 1.3923192024230957, alpha: 0.9935678915330813\n",
      "epoch 160 iteration100, G Loss: 0.979250967502594, D Loss: 1.386672854423523, alpha: 0.9935678915330813\n",
      "epoch 161 iteration0, G Loss: 0.8864927291870117, D Loss: 1.3921939134597778, alpha: 0.9935294333393929\n",
      "epoch 161 iteration100, G Loss: 0.8467581272125244, D Loss: 1.3843046426773071, alpha: 0.9935294333393929\n",
      "epoch 162 iteration0, G Loss: 0.8699989914894104, D Loss: 1.3802409172058105, alpha: 0.9934907467069358\n",
      "epoch 162 iteration100, G Loss: 1.002940058708191, D Loss: 1.401430368423462, alpha: 0.9934907467069358\n",
      "epoch 163 iteration0, G Loss: 0.9551907777786255, D Loss: 1.3974462747573853, alpha: 0.9934518302968676\n",
      "epoch 163 iteration100, G Loss: 0.8982828855514526, D Loss: 1.3718533515930176, alpha: 0.9934518302968676\n",
      "epoch 164 iteration0, G Loss: 0.900809109210968, D Loss: 1.3735878467559814, alpha: 0.9934126827627158\n",
      "epoch 164 iteration100, G Loss: 0.8724434971809387, D Loss: 1.3886141777038574, alpha: 0.9934126827627158\n",
      "epoch 165 iteration0, G Loss: 0.8912699818611145, D Loss: 1.376365303993225, alpha: 0.9933733027503371\n",
      "epoch 165 iteration100, G Loss: 0.9194496870040894, D Loss: 1.4079874753952026, alpha: 0.9933733027503371\n",
      "epoch 166 iteration0, G Loss: 0.8883597254753113, D Loss: 1.3820184469223022, alpha: 0.9933336888978759\n",
      "epoch 166 iteration100, G Loss: 0.8686449527740479, D Loss: 1.3648326396942139, alpha: 0.9933336888978759\n",
      "epoch 167 iteration0, G Loss: 0.8818275332450867, D Loss: 1.3911538124084473, alpha: 0.9932938398357235\n",
      "epoch 167 iteration100, G Loss: 0.8629709482192993, D Loss: 1.374939203262329, alpha: 0.9932938398357235\n",
      "epoch 168 iteration0, G Loss: 0.8421307802200317, D Loss: 1.372828722000122, alpha: 0.9932537541864765\n",
      "epoch 168 iteration100, G Loss: 0.8742973804473877, D Loss: 1.3866462707519531, alpha: 0.9932537541864765\n",
      "epoch 169 iteration0, G Loss: 0.9349453449249268, D Loss: 1.3829052448272705, alpha: 0.9932134305648953\n",
      "epoch 169 iteration100, G Loss: 0.842244029045105, D Loss: 1.387459397315979, alpha: 0.9932134305648953\n",
      "epoch 170 iteration0, G Loss: 0.9127495884895325, D Loss: 1.3818769454956055, alpha: 0.9931728675778618\n",
      "epoch 170 iteration100, G Loss: 0.9373822808265686, D Loss: 1.415266752243042, alpha: 0.9931728675778618\n",
      "epoch 171 iteration0, G Loss: 0.8680056929588318, D Loss: 1.3965762853622437, alpha: 0.993132063824338\n",
      "epoch 171 iteration100, G Loss: 0.8762322664260864, D Loss: 1.371173620223999, alpha: 0.993132063824338\n",
      "epoch 172 iteration0, G Loss: 0.8747241497039795, D Loss: 1.3753981590270996, alpha: 0.9930910178953235\n",
      "epoch 172 iteration100, G Loss: 0.9082856774330139, D Loss: 1.376166820526123, alpha: 0.9930910178953235\n",
      "epoch 173 iteration0, G Loss: 0.8347516655921936, D Loss: 1.3889940977096558, alpha: 0.9930497283738132\n",
      "epoch 173 iteration100, G Loss: 0.9030689597129822, D Loss: 1.376123309135437, alpha: 0.9930497283738132\n",
      "epoch 174 iteration0, G Loss: 0.9578326940536499, D Loss: 1.3552075624465942, alpha: 0.9930081938347545\n",
      "epoch 174 iteration100, G Loss: 0.8906052112579346, D Loss: 1.3804765939712524, alpha: 0.9930081938347545\n",
      "epoch 175 iteration0, G Loss: 0.9253953695297241, D Loss: 1.3831758499145508, alpha: 0.9929664128450049\n",
      "epoch 175 iteration100, G Loss: 0.9182034730911255, D Loss: 1.3802039623260498, alpha: 0.9929664128450049\n",
      "epoch 176 iteration0, G Loss: 0.930743396282196, D Loss: 1.3832297325134277, alpha: 0.9929243839632887\n",
      "epoch 176 iteration100, G Loss: 0.9153196811676025, D Loss: 1.3481820821762085, alpha: 0.9929243839632887\n",
      "epoch 177 iteration0, G Loss: 0.899290144443512, D Loss: 1.4201327562332153, alpha: 0.9928821057401542\n",
      "epoch 177 iteration100, G Loss: 0.9298267960548401, D Loss: 1.4392393827438354, alpha: 0.9928821057401542\n",
      "epoch 178 iteration0, G Loss: 0.8961987495422363, D Loss: 1.3835947513580322, alpha: 0.9928395767179302\n",
      "epoch 178 iteration100, G Loss: 0.9005853533744812, D Loss: 1.3721709251403809, alpha: 0.9928395767179302\n",
      "epoch 179 iteration0, G Loss: 0.8999749422073364, D Loss: 1.4001508951187134, alpha: 0.992796795430682\n",
      "epoch 179 iteration100, G Loss: 0.886674165725708, D Loss: 1.391486406326294, alpha: 0.992796795430682\n",
      "epoch 180 iteration0, G Loss: 0.8591785430908203, D Loss: 1.3757004737854004, alpha: 0.9927537604041685\n",
      "epoch 180 iteration100, G Loss: 0.9651504158973694, D Loss: 1.3586347103118896, alpha: 0.9927537604041685\n",
      "epoch 181 iteration0, G Loss: 0.884943962097168, D Loss: 1.3603929281234741, alpha: 0.9927104701557979\n",
      "epoch 181 iteration100, G Loss: 0.865272045135498, D Loss: 1.3928865194320679, alpha: 0.9927104701557979\n",
      "epoch 182 iteration0, G Loss: 0.759766697883606, D Loss: 1.3610203266143799, alpha: 0.9926669231945832\n",
      "epoch 182 iteration100, G Loss: 0.9049745202064514, D Loss: 1.3291624784469604, alpha: 0.9926669231945832\n",
      "epoch 183 iteration0, G Loss: 0.8470324277877808, D Loss: 1.3702218532562256, alpha: 0.9926231180210985\n",
      "epoch 183 iteration100, G Loss: 0.8864184617996216, D Loss: 1.366781234741211, alpha: 0.9926231180210985\n",
      "epoch 184 iteration0, G Loss: 0.8824657797813416, D Loss: 1.370115041732788, alpha: 0.9925790531274342\n",
      "epoch 184 iteration100, G Loss: 0.9478521943092346, D Loss: 1.3843886852264404, alpha: 0.9925790531274342\n",
      "epoch 185 iteration0, G Loss: 0.8588500022888184, D Loss: 1.38274085521698, alpha: 0.9925347269971523\n",
      "epoch 185 iteration100, G Loss: 0.9243437647819519, D Loss: 1.3743199110031128, alpha: 0.9925347269971523\n",
      "epoch 186 iteration0, G Loss: 0.9329389929771423, D Loss: 1.3811135292053223, alpha: 0.9924901381052417\n",
      "epoch 186 iteration100, G Loss: 1.0246418714523315, D Loss: 1.3802602291107178, alpha: 0.9924901381052417\n",
      "epoch 187 iteration0, G Loss: 0.9233415126800537, D Loss: 1.3917324542999268, alpha: 0.9924452849180726\n",
      "epoch 187 iteration100, G Loss: 0.9131662249565125, D Loss: 1.3620436191558838, alpha: 0.9924452849180726\n",
      "epoch 188 iteration0, G Loss: 0.908324122428894, D Loss: 1.3897663354873657, alpha: 0.9924001658933519\n",
      "epoch 188 iteration100, G Loss: 0.875133752822876, D Loss: 1.3788925409317017, alpha: 0.9924001658933519\n",
      "epoch 189 iteration0, G Loss: 0.8265936374664307, D Loss: 1.3798654079437256, alpha: 0.9923547794800773\n",
      "epoch 189 iteration100, G Loss: 0.9199592471122742, D Loss: 1.4055441617965698, alpha: 0.9923547794800773\n",
      "epoch 190 iteration0, G Loss: 0.9237208366394043, D Loss: 1.380685567855835, alpha: 0.9923091241184917\n",
      "epoch 190 iteration100, G Loss: 0.8601189255714417, D Loss: 1.3898351192474365, alpha: 0.9923091241184917\n",
      "epoch 191 iteration0, G Loss: 0.8829999566078186, D Loss: 1.3813177347183228, alpha: 0.9922631982400372\n",
      "epoch 191 iteration100, G Loss: 0.9007574915885925, D Loss: 1.3738163709640503, alpha: 0.9922631982400372\n",
      "epoch 192 iteration0, G Loss: 0.9151742458343506, D Loss: 1.3730411529541016, alpha: 0.9922170002673092\n",
      "epoch 192 iteration100, G Loss: 0.8360910415649414, D Loss: 1.3785518407821655, alpha: 0.9922170002673092\n",
      "epoch 193 iteration0, G Loss: 0.8434542417526245, D Loss: 1.4013596773147583, alpha: 0.9921705286140102\n",
      "epoch 193 iteration100, G Loss: 0.8727371096611023, D Loss: 1.383691430091858, alpha: 0.9921705286140102\n",
      "epoch 194 iteration0, G Loss: 0.9464897513389587, D Loss: 1.3877685070037842, alpha: 0.9921237816849032\n",
      "epoch 194 iteration100, G Loss: 0.9387192726135254, D Loss: 1.386194109916687, alpha: 0.9921237816849032\n",
      "epoch 195 iteration0, G Loss: 0.8854141235351562, D Loss: 1.3908592462539673, alpha: 0.992076757875765\n",
      "epoch 195 iteration100, G Loss: 0.8991982340812683, D Loss: 1.3880996704101562, alpha: 0.992076757875765\n",
      "epoch 196 iteration0, G Loss: 0.8905684351921082, D Loss: 1.3906877040863037, alpha: 0.9920294555733393\n",
      "epoch 196 iteration100, G Loss: 0.9129408597946167, D Loss: 1.3648643493652344, alpha: 0.9920294555733393\n",
      "epoch 197 iteration0, G Loss: 0.9113001823425293, D Loss: 1.390061378479004, alpha: 0.9919818731552897\n",
      "epoch 197 iteration100, G Loss: 0.8915083408355713, D Loss: 1.3667993545532227, alpha: 0.9919818731552897\n",
      "epoch 198 iteration0, G Loss: 0.8997783064842224, D Loss: 1.3936281204223633, alpha: 0.9919340089901527\n",
      "epoch 198 iteration100, G Loss: 0.8780527114868164, D Loss: 1.4102908372879028, alpha: 0.9919340089901527\n",
      "epoch 199 iteration0, G Loss: 0.9097672700881958, D Loss: 1.379587173461914, alpha: 0.9918858614372899\n",
      "epoch 199 iteration100, G Loss: 0.9180123209953308, D Loss: 1.3531092405319214, alpha: 0.9918858614372899\n",
      "epoch 200 iteration0, G Loss: 0.9311356544494629, D Loss: 1.3869651556015015, alpha: 0.9918374288468401\n",
      "epoch 200 iteration100, G Loss: 0.9163528680801392, D Loss: 1.3750855922698975, alpha: 0.9918374288468401\n",
      "Saving content.\n",
      "epoch 201 iteration0, G Loss: 0.8492549657821655, D Loss: 1.391274333000183, alpha: 0.9917887095596722\n",
      "epoch 201 iteration100, G Loss: 0.903802752494812, D Loss: 1.39352548122406, alpha: 0.9917887095596722\n",
      "epoch 202 iteration0, G Loss: 0.8594391942024231, D Loss: 1.3674776554107666, alpha: 0.9917397019073367\n",
      "epoch 202 iteration100, G Loss: 0.8631163239479065, D Loss: 1.398209571838379, alpha: 0.9917397019073367\n",
      "epoch 203 iteration0, G Loss: 0.9224331974983215, D Loss: 1.365769863128662, alpha: 0.9916904042120173\n",
      "epoch 203 iteration100, G Loss: 0.9792255759239197, D Loss: 1.3911596536636353, alpha: 0.9916904042120173\n",
      "epoch 204 iteration0, G Loss: 0.9273372888565063, D Loss: 1.3874714374542236, alpha: 0.9916408147864824\n",
      "epoch 204 iteration100, G Loss: 0.8705620765686035, D Loss: 1.381837010383606, alpha: 0.9916408147864824\n",
      "epoch 205 iteration0, G Loss: 0.9799174666404724, D Loss: 1.4265632629394531, alpha: 0.991590931934037\n",
      "epoch 205 iteration100, G Loss: 0.838083803653717, D Loss: 1.3782835006713867, alpha: 0.991590931934037\n",
      "epoch 206 iteration0, G Loss: 0.8853223323822021, D Loss: 1.37582528591156, alpha: 0.9915407539484734\n",
      "epoch 206 iteration100, G Loss: 0.8573476672172546, D Loss: 1.4071345329284668, alpha: 0.9915407539484734\n",
      "epoch 207 iteration0, G Loss: 0.9127370119094849, D Loss: 1.379035472869873, alpha: 0.9914902791140221\n",
      "epoch 207 iteration100, G Loss: 0.9376260042190552, D Loss: 1.3769227266311646, alpha: 0.9914902791140221\n",
      "epoch 208 iteration0, G Loss: 0.8760519623756409, D Loss: 1.3781778812408447, alpha: 0.9914395057053028\n",
      "epoch 208 iteration100, G Loss: 0.9202746152877808, D Loss: 1.3750354051589966, alpha: 0.9914395057053028\n",
      "epoch 209 iteration0, G Loss: 0.8455872535705566, D Loss: 1.3528971672058105, alpha: 0.9913884319872747\n",
      "epoch 209 iteration100, G Loss: 0.8915850520133972, D Loss: 1.385636806488037, alpha: 0.9913884319872747\n",
      "epoch 210 iteration0, G Loss: 0.8800488114356995, D Loss: 1.3767213821411133, alpha: 0.9913370562151869\n",
      "epoch 210 iteration100, G Loss: 0.8785289525985718, D Loss: 1.3895444869995117, alpha: 0.9913370562151869\n",
      "epoch 211 iteration0, G Loss: 0.9082144498825073, D Loss: 1.372999668121338, alpha: 0.9912853766345285\n",
      "epoch 211 iteration100, G Loss: 0.906121551990509, D Loss: 1.369922399520874, alpha: 0.9912853766345285\n",
      "epoch 212 iteration0, G Loss: 0.8245187997817993, D Loss: 1.3636058568954468, alpha: 0.9912333914809791\n",
      "epoch 212 iteration100, G Loss: 0.8950408697128296, D Loss: 1.3729796409606934, alpha: 0.9912333914809791\n",
      "epoch 213 iteration0, G Loss: 0.8324748873710632, D Loss: 1.3768622875213623, alpha: 0.9911810989803573\n",
      "epoch 213 iteration100, G Loss: 0.8895013332366943, D Loss: 1.3930981159210205, alpha: 0.9911810989803573\n",
      "epoch 214 iteration0, G Loss: 0.7848618030548096, D Loss: 1.3963487148284912, alpha: 0.9911284973485716\n",
      "epoch 214 iteration100, G Loss: 0.9780020713806152, D Loss: 1.3886997699737549, alpha: 0.9911284973485716\n",
      "epoch 215 iteration0, G Loss: 0.9302152395248413, D Loss: 1.384568214416504, alpha: 0.9910755847915687\n",
      "epoch 215 iteration100, G Loss: 0.9741278290748596, D Loss: 1.3917016983032227, alpha: 0.9910755847915687\n",
      "epoch 216 iteration0, G Loss: 0.9063460826873779, D Loss: 1.3716790676116943, alpha: 0.9910223595052832\n",
      "epoch 216 iteration100, G Loss: 0.866265058517456, D Loss: 1.3767311573028564, alpha: 0.9910223595052832\n",
      "epoch 217 iteration0, G Loss: 0.9544329643249512, D Loss: 1.3771207332611084, alpha: 0.9909688196755864\n",
      "epoch 217 iteration100, G Loss: 0.8861501812934875, D Loss: 1.3746193647384644, alpha: 0.9909688196755864\n",
      "epoch 218 iteration0, G Loss: 0.9898754954338074, D Loss: 1.3678333759307861, alpha: 0.9909149634782348\n",
      "epoch 218 iteration100, G Loss: 0.9279053807258606, D Loss: 1.379199504852295, alpha: 0.9909149634782348\n",
      "epoch 219 iteration0, G Loss: 1.0068567991256714, D Loss: 1.3741055727005005, alpha: 0.990860789078819\n",
      "epoch 219 iteration100, G Loss: 0.8772663474082947, D Loss: 1.3746669292449951, alpha: 0.990860789078819\n",
      "epoch 220 iteration0, G Loss: 0.9095862507820129, D Loss: 1.3823809623718262, alpha: 0.9908062946327119\n",
      "epoch 220 iteration100, G Loss: 0.9257515668869019, D Loss: 1.375628113746643, alpha: 0.9908062946327119\n",
      "epoch 221 iteration0, G Loss: 0.8478323221206665, D Loss: 1.3701858520507812, alpha: 0.9907514782850164\n",
      "epoch 221 iteration100, G Loss: 0.9085121750831604, D Loss: 1.4120004177093506, alpha: 0.9907514782850164\n",
      "epoch 222 iteration0, G Loss: 0.7817699313163757, D Loss: 1.3857078552246094, alpha: 0.9906963381705141\n",
      "epoch 222 iteration100, G Loss: 0.8193052411079407, D Loss: 1.372990608215332, alpha: 0.9906963381705141\n",
      "epoch 223 iteration0, G Loss: 0.9067589044570923, D Loss: 1.3827366828918457, alpha: 0.9906408724136121\n",
      "epoch 223 iteration100, G Loss: 0.744976818561554, D Loss: 1.3947999477386475, alpha: 0.9906408724136121\n",
      "epoch 224 iteration0, G Loss: 1.0296920537948608, D Loss: 1.4293092489242554, alpha: 0.9905850791282914\n",
      "epoch 224 iteration100, G Loss: 0.895235538482666, D Loss: 1.372471809387207, alpha: 0.9905850791282914\n",
      "epoch 225 iteration0, G Loss: 0.815051794052124, D Loss: 1.401121973991394, alpha: 0.9905289564180539\n",
      "epoch 225 iteration100, G Loss: 0.8046573400497437, D Loss: 1.3933448791503906, alpha: 0.9905289564180539\n",
      "epoch 226 iteration0, G Loss: 0.9046668410301208, D Loss: 1.3444218635559082, alpha: 0.990472502375869\n",
      "epoch 226 iteration100, G Loss: 0.9837007522583008, D Loss: 1.3715009689331055, alpha: 0.990472502375869\n",
      "epoch 227 iteration0, G Loss: 1.0701850652694702, D Loss: 1.3658260107040405, alpha: 0.9904157150841214\n",
      "epoch 227 iteration100, G Loss: 0.9509269595146179, D Loss: 1.3644613027572632, alpha: 0.9904157150841214\n",
      "epoch 228 iteration0, G Loss: 0.9224778413772583, D Loss: 1.404377818107605, alpha: 0.9903585926145569\n",
      "epoch 228 iteration100, G Loss: 1.1034289598464966, D Loss: 1.4081270694732666, alpha: 0.9903585926145569\n",
      "epoch 229 iteration0, G Loss: 0.8912424445152283, D Loss: 1.3716256618499756, alpha: 0.9903011330282299\n",
      "epoch 229 iteration100, G Loss: 1.0824171304702759, D Loss: 1.4001835584640503, alpha: 0.9903011330282299\n",
      "epoch 230 iteration0, G Loss: 0.9078292846679688, D Loss: 1.4047554731369019, alpha: 0.9902433343754486\n",
      "epoch 230 iteration100, G Loss: 0.9151896834373474, D Loss: 1.3687342405319214, alpha: 0.9902433343754486\n",
      "epoch 231 iteration0, G Loss: 0.909201443195343, D Loss: 1.3831195831298828, alpha: 0.9901851946957222\n",
      "epoch 231 iteration100, G Loss: 0.902772068977356, D Loss: 1.3822107315063477, alpha: 0.9901851946957222\n",
      "epoch 232 iteration0, G Loss: 0.9256988167762756, D Loss: 1.3688771724700928, alpha: 0.990126712017706\n",
      "epoch 232 iteration100, G Loss: 0.9880946278572083, D Loss: 1.380098819732666, alpha: 0.990126712017706\n",
      "epoch 233 iteration0, G Loss: 0.8815214037895203, D Loss: 1.379105806350708, alpha: 0.9900678843591474\n",
      "epoch 233 iteration100, G Loss: 0.8348116874694824, D Loss: 1.3831313848495483, alpha: 0.9900678843591474\n",
      "epoch 234 iteration0, G Loss: 0.9527860283851624, D Loss: 1.3307139873504639, alpha: 0.9900087097268315\n",
      "epoch 234 iteration100, G Loss: 0.9067296385765076, D Loss: 1.369534969329834, alpha: 0.9900087097268315\n",
      "epoch 235 iteration0, G Loss: 0.8716732263565063, D Loss: 1.368303656578064, alpha: 0.9899491861165263\n",
      "epoch 235 iteration100, G Loss: 0.884119987487793, D Loss: 1.382660984992981, alpha: 0.9899491861165263\n",
      "epoch 236 iteration0, G Loss: 0.876635730266571, D Loss: 1.347931981086731, alpha: 0.9898893115129276\n",
      "epoch 236 iteration100, G Loss: 0.8600072860717773, D Loss: 1.3755552768707275, alpha: 0.9898893115129276\n",
      "epoch 237 iteration0, G Loss: 0.8932421207427979, D Loss: 1.3631343841552734, alpha: 0.9898290838896044\n",
      "epoch 237 iteration100, G Loss: 0.9914032816886902, D Loss: 1.3458267450332642, alpha: 0.9898290838896044\n",
      "epoch 238 iteration0, G Loss: 0.9496191143989563, D Loss: 1.390599012374878, alpha: 0.9897685012089434\n",
      "epoch 238 iteration100, G Loss: 0.8630542159080505, D Loss: 1.3816215991973877, alpha: 0.9897685012089434\n",
      "epoch 239 iteration0, G Loss: 0.8703594207763672, D Loss: 1.3769416809082031, alpha: 0.9897075614220929\n",
      "epoch 239 iteration100, G Loss: 0.8671261668205261, D Loss: 1.3664404153823853, alpha: 0.9897075614220929\n",
      "epoch 240 iteration0, G Loss: 0.9183393716812134, D Loss: 1.3740241527557373, alpha: 0.9896462624689083\n",
      "epoch 240 iteration100, G Loss: 0.9433660507202148, D Loss: 1.4021726846694946, alpha: 0.9896462624689083\n",
      "epoch 241 iteration0, G Loss: 0.927525520324707, D Loss: 1.3879222869873047, alpha: 0.9895846022778949\n",
      "epoch 241 iteration100, G Loss: 0.9335746765136719, D Loss: 1.395216703414917, alpha: 0.9895846022778949\n",
      "epoch 242 iteration0, G Loss: 0.9483511447906494, D Loss: 1.3877744674682617, alpha: 0.989522578766153\n",
      "epoch 242 iteration100, G Loss: 0.925979495048523, D Loss: 1.3876821994781494, alpha: 0.989522578766153\n",
      "epoch 243 iteration0, G Loss: 0.8993934988975525, D Loss: 1.3764948844909668, alpha: 0.9894601898393207\n",
      "epoch 243 iteration100, G Loss: 0.8597829937934875, D Loss: 1.367192268371582, alpha: 0.9894601898393207\n",
      "epoch 244 iteration0, G Loss: 0.8810839653015137, D Loss: 1.386979579925537, alpha: 0.9893974333915181\n",
      "epoch 244 iteration100, G Loss: 0.8873761892318726, D Loss: 1.3610299825668335, alpha: 0.9893974333915181\n",
      "epoch 245 iteration0, G Loss: 0.8325038552284241, D Loss: 1.3903381824493408, alpha: 0.98933430730529\n",
      "epoch 245 iteration100, G Loss: 0.9143622517585754, D Loss: 1.3435559272766113, alpha: 0.98933430730529\n",
      "epoch 246 iteration0, G Loss: 0.8981292247772217, D Loss: 1.3887073993682861, alpha: 0.9892708094515494\n",
      "epoch 246 iteration100, G Loss: 0.9492890238761902, D Loss: 1.3490369319915771, alpha: 0.9892708094515494\n",
      "epoch 247 iteration0, G Loss: 0.9566372632980347, D Loss: 1.3698188066482544, alpha: 0.9892069376895206\n",
      "epoch 247 iteration100, G Loss: 0.9008311033248901, D Loss: 1.370326280593872, alpha: 0.9892069376895206\n",
      "epoch 248 iteration0, G Loss: 0.9284757375717163, D Loss: 1.3794872760772705, alpha: 0.9891426898666814\n",
      "epoch 248 iteration100, G Loss: 0.8951094150543213, D Loss: 1.314096450805664, alpha: 0.9891426898666814\n",
      "epoch 249 iteration0, G Loss: 0.8819129467010498, D Loss: 1.3677736520767212, alpha: 0.9890780638187058\n",
      "epoch 249 iteration100, G Loss: 0.9160705804824829, D Loss: 1.360721230506897, alpha: 0.9890780638187058\n",
      "epoch 250 iteration0, G Loss: 0.9151988625526428, D Loss: 1.379734992980957, alpha: 0.9890130573694068\n",
      "epoch 250 iteration100, G Loss: 0.9523987770080566, D Loss: 1.4092028141021729, alpha: 0.9890130573694068\n",
      "Saving content.\n",
      "epoch 251 iteration0, G Loss: 0.9579542279243469, D Loss: 1.3970706462860107, alpha: 0.9889476683306779\n",
      "epoch 251 iteration100, G Loss: 0.9697183966636658, D Loss: 1.393472671508789, alpha: 0.9889476683306779\n",
      "epoch 252 iteration0, G Loss: 0.8971258997917175, D Loss: 1.3789455890655518, alpha: 0.9888818945024357\n",
      "epoch 252 iteration100, G Loss: 0.9499428272247314, D Loss: 1.3630315065383911, alpha: 0.9888818945024357\n",
      "epoch 253 iteration0, G Loss: 0.9438914060592651, D Loss: 1.3796643018722534, alpha: 0.9888157336725607\n",
      "epoch 253 iteration100, G Loss: 0.9126641750335693, D Loss: 1.3433079719543457, alpha: 0.9888157336725607\n",
      "epoch 254 iteration0, G Loss: 0.9045481085777283, D Loss: 1.3685437440872192, alpha: 0.9887491836168399\n",
      "epoch 254 iteration100, G Loss: 0.9740697145462036, D Loss: 1.3798935413360596, alpha: 0.9887491836168399\n",
      "epoch 255 iteration0, G Loss: 0.976865291595459, D Loss: 1.3172929286956787, alpha: 0.9886822420989076\n",
      "epoch 255 iteration100, G Loss: 0.8105961084365845, D Loss: 1.365581750869751, alpha: 0.9886822420989076\n",
      "epoch 256 iteration0, G Loss: 0.8971711993217468, D Loss: 1.3796333074569702, alpha: 0.9886149068701868\n",
      "epoch 256 iteration100, G Loss: 1.0360441207885742, D Loss: 1.356887698173523, alpha: 0.9886149068701868\n",
      "epoch 257 iteration0, G Loss: 0.8809348344802856, D Loss: 1.3854451179504395, alpha: 0.98854717566983\n",
      "epoch 257 iteration100, G Loss: 0.9584619998931885, D Loss: 1.393545150756836, alpha: 0.98854717566983\n",
      "epoch 258 iteration0, G Loss: 0.8825845718383789, D Loss: 1.37734055519104, alpha: 0.9884790462246599\n",
      "epoch 258 iteration100, G Loss: 0.845071017742157, D Loss: 1.3647615909576416, alpha: 0.9884790462246599\n",
      "epoch 259 iteration0, G Loss: 0.9310380220413208, D Loss: 1.368289589881897, alpha: 0.9884105162491105\n",
      "epoch 259 iteration100, G Loss: 0.9270336627960205, D Loss: 1.3477437496185303, alpha: 0.9884105162491105\n",
      "epoch 260 iteration0, G Loss: 0.9288842678070068, D Loss: 1.377551794052124, alpha: 0.9883415834451669\n",
      "epoch 260 iteration100, G Loss: 0.9165423512458801, D Loss: 1.3692761659622192, alpha: 0.9883415834451669\n",
      "epoch 261 iteration0, G Loss: 0.8038169145584106, D Loss: 1.306894302368164, alpha: 0.9882722455023062\n",
      "epoch 261 iteration100, G Loss: 0.924082338809967, D Loss: 1.398507833480835, alpha: 0.9882722455023062\n",
      "epoch 262 iteration0, G Loss: 0.9192397594451904, D Loss: 1.4160614013671875, alpha: 0.9882025000974367\n",
      "epoch 262 iteration100, G Loss: 0.9561903476715088, D Loss: 1.3456783294677734, alpha: 0.9882025000974367\n",
      "epoch 263 iteration0, G Loss: 0.9601590633392334, D Loss: 1.3862080574035645, alpha: 0.9881323448948387\n",
      "epoch 263 iteration100, G Loss: 0.8826819658279419, D Loss: 1.3897876739501953, alpha: 0.9881323448948387\n",
      "epoch 264 iteration0, G Loss: 0.8525700569152832, D Loss: 1.3856489658355713, alpha: 0.9880617775461034\n",
      "epoch 264 iteration100, G Loss: 0.9465140104293823, D Loss: 1.3806569576263428, alpha: 0.9880617775461034\n",
      "epoch 265 iteration0, G Loss: 0.9606935977935791, D Loss: 1.362243413925171, alpha: 0.9879907956900726\n",
      "epoch 265 iteration100, G Loss: 0.8480085134506226, D Loss: 1.3700625896453857, alpha: 0.9879907956900726\n",
      "epoch 266 iteration0, G Loss: 0.8440918922424316, D Loss: 1.3813599348068237, alpha: 0.9879193969527783\n",
      "epoch 266 iteration100, G Loss: 0.9462175369262695, D Loss: 1.389833688735962, alpha: 0.9879193969527783\n",
      "epoch 267 iteration0, G Loss: 0.9654408097267151, D Loss: 1.3658517599105835, alpha: 0.9878475789473815\n",
      "epoch 267 iteration100, G Loss: 0.9740258455276489, D Loss: 1.3734140396118164, alpha: 0.9878475789473815\n",
      "epoch 268 iteration0, G Loss: 0.9319193959236145, D Loss: 1.3563568592071533, alpha: 0.9877753392741111\n",
      "epoch 268 iteration100, G Loss: 0.8522328734397888, D Loss: 1.3635151386260986, alpha: 0.9877753392741111\n",
      "epoch 269 iteration0, G Loss: 0.9038551449775696, D Loss: 1.3536596298217773, alpha: 0.9877026755202027\n",
      "epoch 269 iteration100, G Loss: 0.9437845945358276, D Loss: 1.3771991729736328, alpha: 0.9877026755202027\n",
      "epoch 270 iteration0, G Loss: 0.9526807069778442, D Loss: 1.3571903705596924, alpha: 0.9876295852598376\n",
      "epoch 270 iteration100, G Loss: 0.8842576742172241, D Loss: 1.3484926223754883, alpha: 0.9876295852598376\n",
      "epoch 271 iteration0, G Loss: 0.8605691194534302, D Loss: 1.3634613752365112, alpha: 0.9875560660540803\n",
      "epoch 271 iteration100, G Loss: 1.0103195905685425, D Loss: 1.4093934297561646, alpha: 0.9875560660540803\n",
      "epoch 272 iteration0, G Loss: 0.9194086194038391, D Loss: 1.371558666229248, alpha: 0.9874821154508174\n",
      "epoch 272 iteration100, G Loss: 0.9237042665481567, D Loss: 1.3653504848480225, alpha: 0.9874821154508174\n",
      "epoch 273 iteration0, G Loss: 0.9318444132804871, D Loss: 1.3866792917251587, alpha: 0.9874077309846958\n",
      "epoch 273 iteration100, G Loss: 0.8778998851776123, D Loss: 1.3841373920440674, alpha: 0.9874077309846958\n",
      "epoch 274 iteration0, G Loss: 0.8744131922721863, D Loss: 1.3659121990203857, alpha: 0.9873329101770595\n",
      "epoch 274 iteration100, G Loss: 0.9519117474555969, D Loss: 1.3710393905639648, alpha: 0.9873329101770595\n",
      "epoch 275 iteration0, G Loss: 0.9486055374145508, D Loss: 1.4429057836532593, alpha: 0.9872576505358884\n",
      "epoch 275 iteration100, G Loss: 0.8715177774429321, D Loss: 1.366199254989624, alpha: 0.9872576505358884\n",
      "epoch 276 iteration0, G Loss: 0.8406612277030945, D Loss: 1.3713955879211426, alpha: 0.9871819495557353\n",
      "epoch 276 iteration100, G Loss: 0.890518069267273, D Loss: 1.374954104423523, alpha: 0.9871819495557353\n",
      "epoch 277 iteration0, G Loss: 0.95924973487854, D Loss: 1.408050537109375, alpha: 0.9871058047176633\n",
      "epoch 277 iteration100, G Loss: 0.8496562838554382, D Loss: 1.370445966720581, alpha: 0.9871058047176633\n",
      "epoch 278 iteration0, G Loss: 0.9292445182800293, D Loss: 1.3648043870925903, alpha: 0.9870292134891828\n",
      "epoch 278 iteration100, G Loss: 0.9540082216262817, D Loss: 1.378999948501587, alpha: 0.9870292134891828\n",
      "epoch 279 iteration0, G Loss: 0.9444434642791748, D Loss: 1.3661224842071533, alpha: 0.9869521733241887\n",
      "epoch 279 iteration100, G Loss: 0.9497329592704773, D Loss: 1.3779258728027344, alpha: 0.9869521733241887\n",
      "epoch 280 iteration0, G Loss: 0.9694018959999084, D Loss: 1.4043349027633667, alpha: 0.9868746816628972\n",
      "epoch 280 iteration100, G Loss: 0.8753706812858582, D Loss: 1.3398020267486572, alpha: 0.9868746816628972\n",
      "epoch 281 iteration0, G Loss: 0.8930488228797913, D Loss: 1.3737457990646362, alpha: 0.9867967359317822\n",
      "epoch 281 iteration100, G Loss: 0.8794505000114441, D Loss: 1.3652288913726807, alpha: 0.9867967359317822\n",
      "epoch 282 iteration0, G Loss: 0.935235321521759, D Loss: 1.3863078355789185, alpha: 0.986718333543512\n",
      "epoch 282 iteration100, G Loss: 1.0193802118301392, D Loss: 1.3723748922348022, alpha: 0.986718333543512\n",
      "epoch 283 iteration0, G Loss: 0.8987497687339783, D Loss: 1.3566184043884277, alpha: 0.9866394718968857\n",
      "epoch 283 iteration100, G Loss: 0.8955432176589966, D Loss: 1.3715568780899048, alpha: 0.9866394718968857\n",
      "epoch 284 iteration0, G Loss: 0.8493037223815918, D Loss: 1.3571295738220215, alpha: 0.986560148376769\n",
      "epoch 284 iteration100, G Loss: 0.9691707491874695, D Loss: 1.377698302268982, alpha: 0.986560148376769\n",
      "epoch 285 iteration0, G Loss: 0.8628432750701904, D Loss: 1.3507094383239746, alpha: 0.9864803603540304\n",
      "epoch 285 iteration100, G Loss: 0.9134466052055359, D Loss: 1.365057110786438, alpha: 0.9864803603540304\n",
      "epoch 286 iteration0, G Loss: 0.887317955493927, D Loss: 1.392926573753357, alpha: 0.9864001051854769\n",
      "epoch 286 iteration100, G Loss: 0.9367242455482483, D Loss: 1.3864076137542725, alpha: 0.9864001051854769\n",
      "epoch 287 iteration0, G Loss: 0.9205164909362793, D Loss: 1.3426029682159424, alpha: 0.9863193802137901\n",
      "epoch 287 iteration100, G Loss: 0.9153175950050354, D Loss: 1.3436977863311768, alpha: 0.9863193802137901\n",
      "epoch 288 iteration0, G Loss: 0.8059207797050476, D Loss: 1.416540265083313, alpha: 0.9862381827674608\n",
      "epoch 288 iteration100, G Loss: 0.9638047814369202, D Loss: 1.379346489906311, alpha: 0.9862381827674608\n",
      "epoch 289 iteration0, G Loss: 0.909267246723175, D Loss: 1.379830241203308, alpha: 0.9861565101607251\n",
      "epoch 289 iteration100, G Loss: 0.9362943768501282, D Loss: 1.3434669971466064, alpha: 0.9861565101607251\n",
      "epoch 290 iteration0, G Loss: 0.9030029773712158, D Loss: 1.3541003465652466, alpha: 0.9860743596934997\n",
      "epoch 290 iteration100, G Loss: 0.8677259087562561, D Loss: 1.360330581665039, alpha: 0.9860743596934997\n",
      "epoch 291 iteration0, G Loss: 0.8887382745742798, D Loss: 1.3631856441497803, alpha: 0.9859917286513157\n",
      "epoch 291 iteration100, G Loss: 0.8871753811836243, D Loss: 1.379582405090332, alpha: 0.9859917286513157\n",
      "epoch 292 iteration0, G Loss: 0.8952111005783081, D Loss: 1.3660770654678345, alpha: 0.9859086143052553\n",
      "epoch 292 iteration100, G Loss: 0.852426290512085, D Loss: 1.3728786706924438, alpha: 0.9859086143052553\n",
      "epoch 293 iteration0, G Loss: 0.9634177088737488, D Loss: 1.353106141090393, alpha: 0.9858250139118848\n",
      "epoch 293 iteration100, G Loss: 0.9620583653450012, D Loss: 1.3920265436172485, alpha: 0.9858250139118848\n",
      "epoch 294 iteration0, G Loss: 0.9052221775054932, D Loss: 1.3765389919281006, alpha: 0.9857409247131904\n",
      "epoch 294 iteration100, G Loss: 0.8990303874015808, D Loss: 1.4135574102401733, alpha: 0.9857409247131904\n",
      "epoch 295 iteration0, G Loss: 0.9400736093521118, D Loss: 1.3619812726974487, alpha: 0.9856563439365119\n",
      "epoch 295 iteration100, G Loss: 0.8547884821891785, D Loss: 1.3726165294647217, alpha: 0.9856563439365119\n",
      "epoch 296 iteration0, G Loss: 0.9005181789398193, D Loss: 1.361341953277588, alpha: 0.9855712687944772\n",
      "epoch 296 iteration100, G Loss: 0.9082948565483093, D Loss: 1.3862332105636597, alpha: 0.9855712687944772\n",
      "epoch 297 iteration0, G Loss: 1.0504494905471802, D Loss: 1.4087028503417969, alpha: 0.9854856964849366\n",
      "epoch 297 iteration100, G Loss: 0.961443305015564, D Loss: 1.3558510541915894, alpha: 0.9854856964849366\n",
      "epoch 298 iteration0, G Loss: 0.8887830972671509, D Loss: 1.3696961402893066, alpha: 0.9853996241908963\n",
      "epoch 298 iteration100, G Loss: 0.8827042579650879, D Loss: 1.387087106704712, alpha: 0.9853996241908963\n",
      "epoch 299 iteration0, G Loss: 0.9308143258094788, D Loss: 1.349929928779602, alpha: 0.985313049080453\n",
      "epoch 299 iteration100, G Loss: 0.9090790748596191, D Loss: 1.3597841262817383, alpha: 0.985313049080453\n",
      "epoch 300 iteration0, G Loss: 1.086443305015564, D Loss: 1.384685754776001, alpha: 0.9852259683067269\n",
      "epoch 300 iteration100, G Loss: 0.9742946624755859, D Loss: 1.3447595834732056, alpha: 0.9852259683067269\n",
      "Saving content.\n",
      "epoch 301 iteration0, G Loss: 0.8452402353286743, D Loss: 1.3672459125518799, alpha: 0.9851383790077956\n",
      "epoch 301 iteration100, G Loss: 0.8884066343307495, D Loss: 1.3297009468078613, alpha: 0.9851383790077956\n",
      "epoch 302 iteration0, G Loss: 1.0548717975616455, D Loss: 1.372887372970581, alpha: 0.9850502783066273\n",
      "epoch 302 iteration100, G Loss: 0.9372674226760864, D Loss: 1.3530547618865967, alpha: 0.9850502783066273\n",
      "epoch 303 iteration0, G Loss: 0.8692572116851807, D Loss: 1.3646929264068604, alpha: 0.9849616633110144\n",
      "epoch 303 iteration100, G Loss: 0.936497688293457, D Loss: 1.3911371231079102, alpha: 0.9849616633110144\n",
      "epoch 304 iteration0, G Loss: 0.9199866056442261, D Loss: 1.3772644996643066, alpha: 0.9848725311135066\n",
      "epoch 304 iteration100, G Loss: 1.0322291851043701, D Loss: 1.4075591564178467, alpha: 0.9848725311135066\n",
      "epoch 305 iteration0, G Loss: 0.9325875043869019, D Loss: 1.3818211555480957, alpha: 0.9847828787913437\n",
      "epoch 305 iteration100, G Loss: 0.9100867509841919, D Loss: 1.3606425523757935, alpha: 0.9847828787913437\n",
      "epoch 306 iteration0, G Loss: 0.9823065400123596, D Loss: 1.3805029392242432, alpha: 0.9846927034063887\n",
      "epoch 306 iteration100, G Loss: 0.9005783796310425, D Loss: 1.4023683071136475, alpha: 0.9846927034063887\n",
      "epoch 307 iteration0, G Loss: 0.9297576546669006, D Loss: 1.3380521535873413, alpha: 0.9846020020050607\n",
      "epoch 307 iteration100, G Loss: 0.9097309708595276, D Loss: 1.3375864028930664, alpha: 0.9846020020050607\n",
      "epoch 308 iteration0, G Loss: 0.9221588969230652, D Loss: 1.38889479637146, alpha: 0.984510771618267\n",
      "epoch 308 iteration100, G Loss: 0.8835659027099609, D Loss: 1.3731160163879395, alpha: 0.984510771618267\n",
      "epoch 309 iteration0, G Loss: 0.9207644462585449, D Loss: 1.3927273750305176, alpha: 0.9844190092613365\n",
      "epoch 309 iteration100, G Loss: 0.9604894518852234, D Loss: 1.3465955257415771, alpha: 0.9844190092613365\n",
      "epoch 310 iteration0, G Loss: 0.9041953682899475, D Loss: 1.3398597240447998, alpha: 0.9843267119339514\n",
      "epoch 310 iteration100, G Loss: 0.9342139959335327, D Loss: 1.3558969497680664, alpha: 0.9843267119339514\n",
      "epoch 311 iteration0, G Loss: 0.9649258255958557, D Loss: 1.3485536575317383, alpha: 0.9842338766200798\n",
      "epoch 311 iteration100, G Loss: 0.8947180509567261, D Loss: 1.3711128234863281, alpha: 0.9842338766200798\n",
      "epoch 312 iteration0, G Loss: 0.9295795559883118, D Loss: 1.3616801500320435, alpha: 0.9841405002879078\n",
      "epoch 312 iteration100, G Loss: 0.9441094994544983, D Loss: 1.3734679222106934, alpha: 0.9841405002879078\n",
      "epoch 313 iteration0, G Loss: 0.8808887004852295, D Loss: 1.3973971605300903, alpha: 0.9840465798897717\n",
      "epoch 313 iteration100, G Loss: 0.8991559147834778, D Loss: 1.385216236114502, alpha: 0.9840465798897717\n",
      "epoch 314 iteration0, G Loss: 0.903976321220398, D Loss: 1.3810497522354126, alpha: 0.98395211236209\n",
      "epoch 314 iteration100, G Loss: 0.9395813941955566, D Loss: 1.3395881652832031, alpha: 0.98395211236209\n",
      "epoch 315 iteration0, G Loss: 0.8678485155105591, D Loss: 1.4029096364974976, alpha: 0.9838570946252948\n",
      "epoch 315 iteration100, G Loss: 0.9574015140533447, D Loss: 1.3380892276763916, alpha: 0.9838570946252948\n",
      "epoch 316 iteration0, G Loss: 0.8985663056373596, D Loss: 1.3531936407089233, alpha: 0.9837615235837642\n",
      "epoch 316 iteration100, G Loss: 1.0606822967529297, D Loss: 1.3495304584503174, alpha: 0.9837615235837642\n",
      "epoch 317 iteration0, G Loss: 0.9577227830886841, D Loss: 1.3461625576019287, alpha: 0.9836653961257537\n",
      "epoch 317 iteration100, G Loss: 0.9911142587661743, D Loss: 1.3221046924591064, alpha: 0.9836653961257537\n",
      "epoch 318 iteration0, G Loss: 0.8962438702583313, D Loss: 1.349287748336792, alpha: 0.9835687091233274\n",
      "epoch 318 iteration100, G Loss: 0.9274101257324219, D Loss: 1.3556630611419678, alpha: 0.9835687091233274\n",
      "epoch 319 iteration0, G Loss: 0.8627294898033142, D Loss: 1.3631060123443604, alpha: 0.9834714594322902\n",
      "epoch 319 iteration100, G Loss: 0.9456416964530945, D Loss: 1.3749475479125977, alpha: 0.9834714594322902\n",
      "epoch 320 iteration0, G Loss: 0.8248187899589539, D Loss: 1.366699457168579, alpha: 0.9833736438921183\n",
      "epoch 320 iteration100, G Loss: 0.9612556099891663, D Loss: 1.3664380311965942, alpha: 0.9833736438921183\n",
      "epoch 321 iteration0, G Loss: 0.9373442530632019, D Loss: 1.3560330867767334, alpha: 0.9832752593258914\n",
      "epoch 321 iteration100, G Loss: 0.9220194816589355, D Loss: 1.3901925086975098, alpha: 0.9832752593258914\n",
      "epoch 322 iteration0, G Loss: 0.926516056060791, D Loss: 1.3517308235168457, alpha: 0.9831763025402231\n",
      "epoch 322 iteration100, G Loss: 0.8865422010421753, D Loss: 1.3471322059631348, alpha: 0.9831763025402231\n",
      "epoch 323 iteration0, G Loss: 0.9436105489730835, D Loss: 1.3906149864196777, alpha: 0.9830767703251925\n",
      "epoch 323 iteration100, G Loss: 0.9868268370628357, D Loss: 1.3485848903656006, alpha: 0.9830767703251925\n",
      "epoch 324 iteration0, G Loss: 0.9661366939544678, D Loss: 1.421494960784912, alpha: 0.9829766594542746\n",
      "epoch 324 iteration100, G Loss: 0.8600822687149048, D Loss: 1.447420597076416, alpha: 0.9829766594542746\n",
      "epoch 325 iteration0, G Loss: 0.7902180552482605, D Loss: 1.3900988101959229, alpha: 0.9828759666842722\n",
      "epoch 325 iteration100, G Loss: 0.9959667921066284, D Loss: 1.3931026458740234, alpha: 0.9828759666842722\n",
      "epoch 326 iteration0, G Loss: 0.9120201468467712, D Loss: 1.3590930700302124, alpha: 0.9827746887552462\n",
      "epoch 326 iteration100, G Loss: 0.9029844999313354, D Loss: 1.384358286857605, alpha: 0.9827746887552462\n",
      "epoch 327 iteration0, G Loss: 0.9753626585006714, D Loss: 1.3951876163482666, alpha: 0.9826728223904461\n",
      "epoch 327 iteration100, G Loss: 0.9553758502006531, D Loss: 1.3526690006256104, alpha: 0.9826728223904461\n",
      "epoch 328 iteration0, G Loss: 0.876335859298706, D Loss: 1.4036047458648682, alpha: 0.9825703642962413\n",
      "epoch 328 iteration100, G Loss: 0.8646220564842224, D Loss: 1.3598804473876953, alpha: 0.9825703642962413\n",
      "epoch 329 iteration0, G Loss: 0.9411457777023315, D Loss: 1.360440969467163, alpha: 0.9824673111620515\n",
      "epoch 329 iteration100, G Loss: 0.9212791919708252, D Loss: 1.362051248550415, alpha: 0.9824673111620515\n",
      "epoch 330 iteration0, G Loss: 0.9122806787490845, D Loss: 1.3711552619934082, alpha: 0.9823636596602773\n",
      "epoch 330 iteration100, G Loss: 0.9799014329910278, D Loss: 1.3698203563690186, alpha: 0.9823636596602773\n",
      "epoch 331 iteration0, G Loss: 0.8637208342552185, D Loss: 1.3721070289611816, alpha: 0.9822594064462308\n",
      "epoch 331 iteration100, G Loss: 0.8927304744720459, D Loss: 1.393000602722168, alpha: 0.9822594064462308\n",
      "epoch 332 iteration0, G Loss: 0.9868212342262268, D Loss: 1.3712913990020752, alpha: 0.9821545481580658\n",
      "epoch 332 iteration100, G Loss: 1.0524587631225586, D Loss: 1.3199158906936646, alpha: 0.9821545481580658\n",
      "epoch 333 iteration0, G Loss: 1.011690616607666, D Loss: 1.3554246425628662, alpha: 0.9820490814167088\n",
      "epoch 333 iteration100, G Loss: 0.8149507641792297, D Loss: 1.3551957607269287, alpha: 0.9820490814167088\n",
      "epoch 334 iteration0, G Loss: 0.851127028465271, D Loss: 1.3635890483856201, alpha: 0.9819430028257886\n",
      "epoch 334 iteration100, G Loss: 0.8092138171195984, D Loss: 1.3464363813400269, alpha: 0.9819430028257886\n",
      "epoch 335 iteration0, G Loss: 0.8691482543945312, D Loss: 1.3574875593185425, alpha: 0.9818363089715675\n",
      "epoch 335 iteration100, G Loss: 1.0139856338500977, D Loss: 1.3456192016601562, alpha: 0.9818363089715675\n",
      "epoch 336 iteration0, G Loss: 0.964728057384491, D Loss: 1.3566631078720093, alpha: 0.9817289964228708\n",
      "epoch 336 iteration100, G Loss: 0.8939241170883179, D Loss: 1.3611352443695068, alpha: 0.9817289964228708\n",
      "epoch 337 iteration0, G Loss: 0.893409252166748, D Loss: 1.3448776006698608, alpha: 0.9816210617310175\n",
      "epoch 337 iteration100, G Loss: 0.8537853956222534, D Loss: 1.3650403022766113, alpha: 0.9816210617310175\n",
      "epoch 338 iteration0, G Loss: 0.8881415724754333, D Loss: 1.3581808805465698, alpha: 0.9815125014297503\n",
      "epoch 338 iteration100, G Loss: 1.0170981884002686, D Loss: 1.3559668064117432, alpha: 0.9815125014297503\n",
      "epoch 339 iteration0, G Loss: 0.8670375943183899, D Loss: 1.3520236015319824, alpha: 0.981403312035166\n",
      "epoch 339 iteration100, G Loss: 0.9336070418357849, D Loss: 1.3615261316299438, alpha: 0.981403312035166\n",
      "epoch 340 iteration0, G Loss: 0.944840669631958, D Loss: 1.381333351135254, alpha: 0.9812934900456454\n",
      "epoch 340 iteration100, G Loss: 0.9412901401519775, D Loss: 1.349087119102478, alpha: 0.9812934900456454\n",
      "epoch 341 iteration0, G Loss: 1.0359883308410645, D Loss: 1.3596291542053223, alpha: 0.9811830319417836\n",
      "epoch 341 iteration100, G Loss: 0.9004613757133484, D Loss: 1.4257452487945557, alpha: 0.9811830319417836\n",
      "epoch 342 iteration0, G Loss: 0.9093976020812988, D Loss: 1.2961739301681519, alpha: 0.9810719341863199\n",
      "epoch 342 iteration100, G Loss: 0.887994110584259, D Loss: 1.3221313953399658, alpha: 0.9810719341863199\n",
      "epoch 343 iteration0, G Loss: 0.8241920471191406, D Loss: 1.3807041645050049, alpha: 0.9809601932240681\n",
      "epoch 343 iteration100, G Loss: 0.9708104133605957, D Loss: 1.3463244438171387, alpha: 0.9809601932240681\n",
      "epoch 344 iteration0, G Loss: 0.9521548748016357, D Loss: 1.3502097129821777, alpha: 0.9808478054818466\n",
      "epoch 344 iteration100, G Loss: 1.0291030406951904, D Loss: 1.319637656211853, alpha: 0.9808478054818466\n",
      "epoch 345 iteration0, G Loss: 0.9921649694442749, D Loss: 1.398547649383545, alpha: 0.9807347673684084\n",
      "epoch 345 iteration100, G Loss: 1.077536702156067, D Loss: 1.3349628448486328, alpha: 0.9807347673684084\n",
      "epoch 346 iteration0, G Loss: 0.9132235646247864, D Loss: 1.3443927764892578, alpha: 0.9806210752743707\n",
      "epoch 346 iteration100, G Loss: 0.9061927795410156, D Loss: 1.3008426427841187, alpha: 0.9806210752743707\n",
      "epoch 347 iteration0, G Loss: 0.8073629140853882, D Loss: 1.4000805616378784, alpha: 0.9805067255721459\n",
      "epoch 347 iteration100, G Loss: 0.9087566137313843, D Loss: 1.3442506790161133, alpha: 0.9805067255721459\n",
      "epoch 348 iteration0, G Loss: 0.9772616624832153, D Loss: 1.40391206741333, alpha: 0.9803917146158709\n",
      "epoch 348 iteration100, G Loss: 0.9135634899139404, D Loss: 1.325119972229004, alpha: 0.9803917146158709\n",
      "epoch 349 iteration0, G Loss: 0.9836716651916504, D Loss: 1.3500399589538574, alpha: 0.9802760387413375\n",
      "epoch 349 iteration100, G Loss: 0.9614880681037903, D Loss: 1.3473602533340454, alpha: 0.9802760387413375\n",
      "epoch 350 iteration0, G Loss: 0.978359043598175, D Loss: 1.3450181484222412, alpha: 0.9801596942659225\n",
      "epoch 350 iteration100, G Loss: 0.9168311953544617, D Loss: 1.3715271949768066, alpha: 0.9801596942659225\n",
      "Saving content.\n",
      "epoch 351 iteration0, G Loss: 0.9696193933486938, D Loss: 1.3459954261779785, alpha: 0.9800426774885175\n",
      "epoch 351 iteration100, G Loss: 0.7922707200050354, D Loss: 1.463761568069458, alpha: 0.9800426774885175\n",
      "epoch 352 iteration0, G Loss: 0.9050159454345703, D Loss: 1.3569138050079346, alpha: 0.9799249846894594\n",
      "epoch 352 iteration100, G Loss: 1.055575966835022, D Loss: 1.3629908561706543, alpha: 0.9799249846894594\n",
      "epoch 353 iteration0, G Loss: 0.9396823644638062, D Loss: 1.3391695022583008, alpha: 0.9798066121304606\n",
      "epoch 353 iteration100, G Loss: 1.0281102657318115, D Loss: 1.3940244913101196, alpha: 0.9798066121304606\n",
      "epoch 354 iteration0, G Loss: 0.9317454695701599, D Loss: 1.363351583480835, alpha: 0.9796875560545386\n",
      "epoch 354 iteration100, G Loss: 0.9416882395744324, D Loss: 1.369139552116394, alpha: 0.9796875560545386\n",
      "epoch 355 iteration0, G Loss: 0.995334267616272, D Loss: 1.360933780670166, alpha: 0.979567812685947\n",
      "epoch 355 iteration100, G Loss: 0.7820556163787842, D Loss: 1.3543777465820312, alpha: 0.979567812685947\n",
      "epoch 356 iteration0, G Loss: 0.8589438199996948, D Loss: 1.3577309846878052, alpha: 0.9794473782301051\n",
      "epoch 356 iteration100, G Loss: 0.9854452610015869, D Loss: 1.3490442037582397, alpha: 0.9794473782301051\n",
      "epoch 357 iteration0, G Loss: 1.017927646636963, D Loss: 1.3712722063064575, alpha: 0.9793262488735286\n",
      "epoch 357 iteration100, G Loss: 0.9112600684165955, D Loss: 1.3188871145248413, alpha: 0.9793262488735286\n",
      "epoch 358 iteration0, G Loss: 0.9038491249084473, D Loss: 1.3543545007705688, alpha: 0.97920442078376\n",
      "epoch 358 iteration100, G Loss: 0.8852181434631348, D Loss: 1.3191332817077637, alpha: 0.97920442078376\n",
      "epoch 359 iteration0, G Loss: 0.998147189617157, D Loss: 1.3550429344177246, alpha: 0.9790818901092987\n",
      "epoch 359 iteration100, G Loss: 0.9103497862815857, D Loss: 1.4172794818878174, alpha: 0.9790818901092987\n",
      "epoch 360 iteration0, G Loss: 0.9063132405281067, D Loss: 1.367706298828125, alpha: 0.9789586529795318\n",
      "epoch 360 iteration100, G Loss: 1.0111619234085083, D Loss: 1.3710989952087402, alpha: 0.9789586529795318\n",
      "epoch 361 iteration0, G Loss: 1.0556000471115112, D Loss: 1.3713154792785645, alpha: 0.9788347055046641\n",
      "epoch 361 iteration100, G Loss: 0.9602387547492981, D Loss: 1.360666036605835, alpha: 0.9788347055046641\n",
      "epoch 362 iteration0, G Loss: 0.8502631783485413, D Loss: 1.3956758975982666, alpha: 0.9787100437756497\n",
      "epoch 362 iteration100, G Loss: 0.9874811172485352, D Loss: 1.381788969039917, alpha: 0.9787100437756497\n",
      "epoch 363 iteration0, G Loss: 0.9495798349380493, D Loss: 1.3088109493255615, alpha: 0.9785846638641217\n",
      "epoch 363 iteration100, G Loss: 0.8902347683906555, D Loss: 1.4206762313842773, alpha: 0.9785846638641217\n",
      "epoch 364 iteration0, G Loss: 0.8404120206832886, D Loss: 1.4005088806152344, alpha: 0.9784585618223235\n",
      "epoch 364 iteration100, G Loss: 0.8901362419128418, D Loss: 1.360991358757019, alpha: 0.9784585618223235\n",
      "epoch 365 iteration0, G Loss: 0.9379503726959229, D Loss: 1.3537373542785645, alpha: 0.9783317336830395\n",
      "epoch 365 iteration100, G Loss: 1.0122666358947754, D Loss: 1.34587824344635, alpha: 0.9783317336830395\n",
      "epoch 366 iteration0, G Loss: 0.9685102701187134, D Loss: 1.3932077884674072, alpha: 0.9782041754595261\n",
      "epoch 366 iteration100, G Loss: 0.9710069298744202, D Loss: 1.336699366569519, alpha: 0.9782041754595261\n",
      "epoch 367 iteration0, G Loss: 1.031617283821106, D Loss: 1.352792739868164, alpha: 0.9780758831454427\n",
      "epoch 367 iteration100, G Loss: 1.045982837677002, D Loss: 1.3377678394317627, alpha: 0.9780758831454427\n",
      "epoch 368 iteration0, G Loss: 1.0031605958938599, D Loss: 1.3730859756469727, alpha: 0.977946852714783\n",
      "epoch 368 iteration100, G Loss: 0.9105815291404724, D Loss: 1.3578072786331177, alpha: 0.977946852714783\n",
      "epoch 369 iteration0, G Loss: 0.9653433561325073, D Loss: 1.3874409198760986, alpha: 0.977817080121806\n",
      "epoch 369 iteration100, G Loss: 1.1107275485992432, D Loss: 1.3313713073730469, alpha: 0.977817080121806\n",
      "epoch 370 iteration0, G Loss: 0.9536160230636597, D Loss: 1.3566335439682007, alpha: 0.9776865613009678\n",
      "epoch 370 iteration100, G Loss: 0.9906550645828247, D Loss: 1.3621845245361328, alpha: 0.9776865613009678\n",
      "epoch 371 iteration0, G Loss: 0.8748841285705566, D Loss: 1.3072164058685303, alpha: 0.9775552921668526\n",
      "epoch 371 iteration100, G Loss: 0.8971232175827026, D Loss: 1.340172529220581, alpha: 0.9775552921668526\n",
      "epoch 372 iteration0, G Loss: 0.936223030090332, D Loss: 1.3282815217971802, alpha: 0.9774232686141044\n",
      "epoch 372 iteration100, G Loss: 0.9768708348274231, D Loss: 1.3357977867126465, alpha: 0.9774232686141044\n",
      "epoch 373 iteration0, G Loss: 0.803137481212616, D Loss: 1.3629146814346313, alpha: 0.9772904865173597\n",
      "epoch 373 iteration100, G Loss: 0.9215665459632874, D Loss: 1.315479040145874, alpha: 0.9772904865173597\n",
      "epoch 374 iteration0, G Loss: 0.9765485525131226, D Loss: 1.295040488243103, alpha: 0.977156941731178\n",
      "epoch 374 iteration100, G Loss: 0.9378350973129272, D Loss: 1.2838428020477295, alpha: 0.977156941731178\n",
      "epoch 375 iteration0, G Loss: 0.9503545761108398, D Loss: 1.3281025886535645, alpha: 0.9770226300899744\n",
      "epoch 375 iteration100, G Loss: 0.9096841812133789, D Loss: 1.4184714555740356, alpha: 0.9770226300899744\n",
      "epoch 376 iteration0, G Loss: 0.8878182172775269, D Loss: 1.332099199295044, alpha: 0.9768875474079524\n",
      "epoch 376 iteration100, G Loss: 0.915141761302948, D Loss: 1.3423504829406738, alpha: 0.9768875474079524\n",
      "epoch 377 iteration0, G Loss: 0.9151173830032349, D Loss: 1.3432927131652832, alpha: 0.9767516894790355\n",
      "epoch 377 iteration100, G Loss: 0.9778997898101807, D Loss: 1.315029263496399, alpha: 0.9767516894790355\n",
      "epoch 378 iteration0, G Loss: 0.9980950355529785, D Loss: 1.3158495426177979, alpha: 0.9766150520767999\n",
      "epoch 378 iteration100, G Loss: 0.948347806930542, D Loss: 1.3837084770202637, alpha: 0.9766150520767999\n",
      "epoch 379 iteration0, G Loss: 1.051174283027649, D Loss: 1.343408226966858, alpha: 0.9764776309544076\n",
      "epoch 379 iteration100, G Loss: 0.9285801649093628, D Loss: 1.360355257987976, alpha: 0.9764776309544076\n",
      "epoch 380 iteration0, G Loss: 0.8221867084503174, D Loss: 1.3620439767837524, alpha: 0.9763394218445388\n",
      "epoch 380 iteration100, G Loss: 0.897254467010498, D Loss: 1.3721699714660645, alpha: 0.9763394218445388\n",
      "epoch 381 iteration0, G Loss: 0.9775080680847168, D Loss: 1.3654282093048096, alpha: 0.976200420459325\n",
      "epoch 381 iteration100, G Loss: 0.8778908252716064, D Loss: 1.3477108478546143, alpha: 0.976200420459325\n",
      "epoch 382 iteration0, G Loss: 0.9115986824035645, D Loss: 1.3606115579605103, alpha: 0.9760606224902827\n",
      "epoch 382 iteration100, G Loss: 1.0059515237808228, D Loss: 1.3430864810943604, alpha: 0.9760606224902827\n",
      "epoch 383 iteration0, G Loss: 0.9494234919548035, D Loss: 1.3751709461212158, alpha: 0.9759200236082463\n",
      "epoch 383 iteration100, G Loss: 0.9269881844520569, D Loss: 1.3893487453460693, alpha: 0.9759200236082463\n",
      "epoch 384 iteration0, G Loss: 0.8428031206130981, D Loss: 1.3531548976898193, alpha: 0.9757786194633021\n",
      "epoch 384 iteration100, G Loss: 0.9734055995941162, D Loss: 1.3345081806182861, alpha: 0.9757786194633021\n",
      "epoch 385 iteration0, G Loss: 0.8606312274932861, D Loss: 1.3585245609283447, alpha: 0.9756364056847221\n",
      "epoch 385 iteration100, G Loss: 0.9710416197776794, D Loss: 1.3346912860870361, alpha: 0.9756364056847221\n",
      "epoch 386 iteration0, G Loss: 1.0167911052703857, D Loss: 1.3044015169143677, alpha: 0.9754933778808983\n",
      "epoch 386 iteration100, G Loss: 0.9362916350364685, D Loss: 1.334140419960022, alpha: 0.9754933778808983\n",
      "epoch 387 iteration0, G Loss: 0.972859799861908, D Loss: 1.355997085571289, alpha: 0.9753495316392763\n",
      "epoch 387 iteration100, G Loss: 0.9791918396949768, D Loss: 1.3363125324249268, alpha: 0.9753495316392763\n",
      "epoch 388 iteration0, G Loss: 0.9500228762626648, D Loss: 1.35679292678833, alpha: 0.9752048625262908\n",
      "epoch 388 iteration100, G Loss: 1.0090998411178589, D Loss: 1.309946060180664, alpha: 0.9752048625262908\n",
      "epoch 389 iteration0, G Loss: 1.0005215406417847, D Loss: 1.3148049116134644, alpha: 0.9750593660872999\n",
      "epoch 389 iteration100, G Loss: 0.8966295719146729, D Loss: 1.4032407999038696, alpha: 0.9750593660872999\n",
      "epoch 390 iteration0, G Loss: 0.9608117938041687, D Loss: 1.3531193733215332, alpha: 0.9749130378465202\n",
      "epoch 390 iteration100, G Loss: 0.9961380958557129, D Loss: 1.3134620189666748, alpha: 0.9749130378465202\n",
      "epoch 391 iteration0, G Loss: 1.0057322978973389, D Loss: 1.3023738861083984, alpha: 0.974765873306962\n",
      "epoch 391 iteration100, G Loss: 0.849435031414032, D Loss: 1.3825936317443848, alpha: 0.974765873306962\n",
      "epoch 392 iteration0, G Loss: 1.0321133136749268, D Loss: 1.3435280323028564, alpha: 0.974617867950365\n",
      "epoch 392 iteration100, G Loss: 0.9564012289047241, D Loss: 1.3618533611297607, alpha: 0.974617867950365\n",
      "epoch 393 iteration0, G Loss: 0.9828447103500366, D Loss: 1.3318406343460083, alpha: 0.9744690172371344\n",
      "epoch 393 iteration100, G Loss: 1.0378636121749878, D Loss: 1.2819937467575073, alpha: 0.9744690172371344\n",
      "epoch 394 iteration0, G Loss: 0.9025276899337769, D Loss: 1.409078598022461, alpha: 0.9743193166062767\n",
      "epoch 394 iteration100, G Loss: 0.9591660499572754, D Loss: 1.3391603231430054, alpha: 0.9743193166062767\n",
      "epoch 395 iteration0, G Loss: 0.9696555733680725, D Loss: 1.2979629039764404, alpha: 0.9741687614753359\n",
      "epoch 395 iteration100, G Loss: 1.0876508951187134, D Loss: 1.3678631782531738, alpha: 0.9741687614753359\n",
      "epoch 396 iteration0, G Loss: 0.9260240793228149, D Loss: 1.3700535297393799, alpha: 0.9740173472403311\n",
      "epoch 396 iteration100, G Loss: 1.0069330930709839, D Loss: 1.3650768995285034, alpha: 0.9740173472403311\n",
      "epoch 397 iteration0, G Loss: 0.8859015703201294, D Loss: 1.3500380516052246, alpha: 0.9738650692756922\n",
      "epoch 397 iteration100, G Loss: 0.9889802932739258, D Loss: 1.3158726692199707, alpha: 0.9738650692756922\n",
      "epoch 398 iteration0, G Loss: 0.9151333570480347, D Loss: 1.4006843566894531, alpha: 0.9737119229341985\n",
      "epoch 398 iteration100, G Loss: 0.9150797724723816, D Loss: 1.3309111595153809, alpha: 0.9737119229341985\n",
      "epoch 399 iteration0, G Loss: 0.9936802983283997, D Loss: 1.3451167345046997, alpha: 0.9735579035469157\n",
      "epoch 399 iteration100, G Loss: 1.0745131969451904, D Loss: 1.3167879581451416, alpha: 0.9735579035469157\n",
      "epoch 400 iteration0, G Loss: 1.02424156665802, D Loss: 1.3371829986572266, alpha: 0.9734030064231342\n",
      "epoch 400 iteration100, G Loss: 0.9527463912963867, D Loss: 1.3424983024597168, alpha: 0.9734030064231342\n",
      "Saving content.\n",
      "epoch 401 iteration0, G Loss: 0.8763477802276611, D Loss: 1.3519545793533325, alpha: 0.9732472268503066\n",
      "epoch 401 iteration100, G Loss: 0.9269540905952454, D Loss: 1.346950888633728, alpha: 0.9732472268503066\n",
      "epoch 402 iteration0, G Loss: 0.9767985939979553, D Loss: 1.300110936164856, alpha: 0.9730905600939879\n",
      "epoch 402 iteration100, G Loss: 0.958842396736145, D Loss: 1.3965532779693604, alpha: 0.9730905600939879\n",
      "epoch 403 iteration0, G Loss: 0.917129635810852, D Loss: 1.3451954126358032, alpha: 0.972933001397773\n",
      "epoch 403 iteration100, G Loss: 1.0634808540344238, D Loss: 1.3311688899993896, alpha: 0.972933001397773\n",
      "epoch 404 iteration0, G Loss: 0.9292988777160645, D Loss: 1.3635255098342896, alpha: 0.9727745459832368\n",
      "epoch 404 iteration100, G Loss: 0.9325806498527527, D Loss: 1.3868227005004883, alpha: 0.9727745459832368\n",
      "epoch 405 iteration0, G Loss: 0.9857592582702637, D Loss: 1.3692508935928345, alpha: 0.9726151890498743\n",
      "epoch 405 iteration100, G Loss: 0.9527115821838379, D Loss: 1.3341929912567139, alpha: 0.9726151890498743\n",
      "epoch 406 iteration0, G Loss: 0.838988184928894, D Loss: 1.3428795337677002, alpha: 0.9724549257750401\n",
      "epoch 406 iteration100, G Loss: 0.9059083461761475, D Loss: 1.351620078086853, alpha: 0.9724549257750401\n",
      "epoch 407 iteration0, G Loss: 1.0707602500915527, D Loss: 1.360306978225708, alpha: 0.9722937513138894\n",
      "epoch 407 iteration100, G Loss: 1.1980899572372437, D Loss: 1.340885877609253, alpha: 0.9722937513138894\n",
      "epoch 408 iteration0, G Loss: 0.9145723581314087, D Loss: 1.3476142883300781, alpha: 0.9721316607993185\n",
      "epoch 408 iteration100, G Loss: 0.91527259349823, D Loss: 1.3332635164260864, alpha: 0.9721316607993185\n",
      "epoch 409 iteration0, G Loss: 0.9805300235748291, D Loss: 1.351287841796875, alpha: 0.9719686493419065\n",
      "epoch 409 iteration100, G Loss: 0.9355448484420776, D Loss: 1.3653860092163086, alpha: 0.9719686493419065\n",
      "epoch 410 iteration0, G Loss: 0.9372561573982239, D Loss: 1.370966911315918, alpha: 0.9718047120298574\n",
      "epoch 410 iteration100, G Loss: 0.9881971478462219, D Loss: 1.3359181880950928, alpha: 0.9718047120298574\n",
      "epoch 411 iteration0, G Loss: 0.8541632890701294, D Loss: 1.3381030559539795, alpha: 0.9716398439289416\n",
      "epoch 411 iteration100, G Loss: 1.0518767833709717, D Loss: 1.3778913021087646, alpha: 0.9716398439289416\n",
      "epoch 412 iteration0, G Loss: 0.9239641427993774, D Loss: 1.3296294212341309, alpha: 0.9714740400824391\n",
      "epoch 412 iteration100, G Loss: 0.9331629276275635, D Loss: 1.338901162147522, alpha: 0.9714740400824391\n",
      "epoch 413 iteration0, G Loss: 0.9024696350097656, D Loss: 1.3795400857925415, alpha: 0.9713072955110821\n",
      "epoch 413 iteration100, G Loss: 0.9313614964485168, D Loss: 1.3335843086242676, alpha: 0.9713072955110821\n",
      "epoch 414 iteration0, G Loss: 0.95821613073349, D Loss: 1.3931775093078613, alpha: 0.9711396052129992\n",
      "epoch 414 iteration100, G Loss: 1.0500613451004028, D Loss: 1.3668913841247559, alpha: 0.9711396052129992\n",
      "epoch 415 iteration0, G Loss: 0.9989141821861267, D Loss: 1.389496088027954, alpha: 0.9709709641636592\n",
      "epoch 415 iteration100, G Loss: 1.009671688079834, D Loss: 1.3856221437454224, alpha: 0.9709709641636592\n",
      "epoch 416 iteration0, G Loss: 0.8356886506080627, D Loss: 1.3431575298309326, alpha: 0.9708013673158152\n",
      "epoch 416 iteration100, G Loss: 0.886940062046051, D Loss: 1.3439955711364746, alpha: 0.9708013673158152\n",
      "epoch 417 iteration0, G Loss: 0.8992193937301636, D Loss: 1.3209928274154663, alpha: 0.9706308095994504\n",
      "epoch 417 iteration100, G Loss: 0.8563145399093628, D Loss: 1.3919739723205566, alpha: 0.9706308095994504\n",
      "epoch 418 iteration0, G Loss: 0.8702667951583862, D Loss: 1.327046275138855, alpha: 0.9704592859217226\n",
      "epoch 418 iteration100, G Loss: 0.9713919162750244, D Loss: 1.3779973983764648, alpha: 0.9704592859217226\n",
      "epoch 419 iteration0, G Loss: 1.0154764652252197, D Loss: 1.3417587280273438, alpha: 0.9702867911669113\n",
      "epoch 419 iteration100, G Loss: 1.0927811861038208, D Loss: 1.313333511352539, alpha: 0.9702867911669113\n",
      "epoch 420 iteration0, G Loss: 1.0904347896575928, D Loss: 1.3746085166931152, alpha: 0.9701133201963638\n",
      "epoch 420 iteration100, G Loss: 0.9542585611343384, D Loss: 1.3430144786834717, alpha: 0.9701133201963638\n",
      "epoch 421 iteration0, G Loss: 0.9658486843109131, D Loss: 1.3216149806976318, alpha: 0.9699388678484417\n",
      "epoch 421 iteration100, G Loss: 0.8345683217048645, D Loss: 1.3609470129013062, alpha: 0.9699388678484417\n",
      "epoch 422 iteration0, G Loss: 0.9750866293907166, D Loss: 1.3290464878082275, alpha: 0.9697634289384699\n",
      "epoch 422 iteration100, G Loss: 0.8874395489692688, D Loss: 1.4160099029541016, alpha: 0.9697634289384699\n",
      "epoch 423 iteration0, G Loss: 1.0273383855819702, D Loss: 1.316161036491394, alpha: 0.9695869982586831\n",
      "epoch 423 iteration100, G Loss: 1.0210281610488892, D Loss: 1.3418021202087402, alpha: 0.9695869982586831\n",
      "epoch 424 iteration0, G Loss: 0.9355047941207886, D Loss: 1.2878644466400146, alpha: 0.9694095705781761\n",
      "epoch 424 iteration100, G Loss: 0.8884459733963013, D Loss: 1.3803304433822632, alpha: 0.9694095705781761\n",
      "epoch 425 iteration0, G Loss: 1.06973397731781, D Loss: 1.3134404420852661, alpha: 0.969231140642852\n",
      "epoch 425 iteration100, G Loss: 0.9894877672195435, D Loss: 1.4380989074707031, alpha: 0.969231140642852\n",
      "epoch 426 iteration0, G Loss: 0.8489789962768555, D Loss: 1.316037654876709, alpha: 0.9690517031753728\n",
      "epoch 426 iteration100, G Loss: 1.160111904144287, D Loss: 1.3713257312774658, alpha: 0.9690517031753728\n",
      "epoch 427 iteration0, G Loss: 0.8503922820091248, D Loss: 1.3365013599395752, alpha: 0.9688712528751097\n",
      "epoch 427 iteration100, G Loss: 0.9700900316238403, D Loss: 1.334518313407898, alpha: 0.9688712528751097\n",
      "epoch 428 iteration0, G Loss: 1.0031450986862183, D Loss: 1.33114755153656, alpha: 0.968689784418094\n",
      "epoch 428 iteration100, G Loss: 0.9354057312011719, D Loss: 1.3345654010772705, alpha: 0.968689784418094\n",
      "epoch 429 iteration0, G Loss: 1.0327728986740112, D Loss: 1.4484808444976807, alpha: 0.9685072924569692\n",
      "epoch 429 iteration100, G Loss: 0.890060305595398, D Loss: 1.3432400226593018, alpha: 0.9685072924569692\n",
      "epoch 430 iteration0, G Loss: 0.9070001840591431, D Loss: 1.3619834184646606, alpha: 0.9683237716209436\n",
      "epoch 430 iteration100, G Loss: 1.1252797842025757, D Loss: 1.3355870246887207, alpha: 0.9683237716209436\n",
      "epoch 431 iteration0, G Loss: 0.9879208207130432, D Loss: 1.3096344470977783, alpha: 0.9681392165157425\n",
      "epoch 431 iteration100, G Loss: 0.9389824867248535, D Loss: 1.3444185256958008, alpha: 0.9681392165157425\n",
      "epoch 432 iteration0, G Loss: 1.0161582231521606, D Loss: 1.352502703666687, alpha: 0.9679536217235628\n",
      "epoch 432 iteration100, G Loss: 0.9957289695739746, D Loss: 1.2618842124938965, alpha: 0.9679536217235628\n",
      "epoch 433 iteration0, G Loss: 0.983136773109436, D Loss: 1.3345741033554077, alpha: 0.9677669818030268\n",
      "epoch 433 iteration100, G Loss: 1.0105607509613037, D Loss: 1.3684276342391968, alpha: 0.9677669818030268\n",
      "epoch 434 iteration0, G Loss: 0.9707896709442139, D Loss: 1.3397104740142822, alpha: 0.9675792912891376\n",
      "epoch 434 iteration100, G Loss: 1.05267333984375, D Loss: 1.3200733661651611, alpha: 0.9675792912891376\n",
      "epoch 435 iteration0, G Loss: 1.050283432006836, D Loss: 1.3536765575408936, alpha: 0.9673905446932344\n",
      "epoch 435 iteration100, G Loss: 0.9047077894210815, D Loss: 1.364802360534668, alpha: 0.9673905446932344\n",
      "epoch 436 iteration0, G Loss: 1.0090327262878418, D Loss: 1.3667137622833252, alpha: 0.9672007365029498\n",
      "epoch 436 iteration100, G Loss: 0.9329994916915894, D Loss: 1.333632469177246, alpha: 0.9672007365029498\n",
      "epoch 437 iteration0, G Loss: 0.9151350259780884, D Loss: 1.3395946025848389, alpha: 0.9670098611821661\n",
      "epoch 437 iteration100, G Loss: 1.1070446968078613, D Loss: 1.3624011278152466, alpha: 0.9670098611821661\n",
      "epoch 438 iteration0, G Loss: 0.9934105277061462, D Loss: 1.326879858970642, alpha: 0.9668179131709738\n",
      "epoch 438 iteration100, G Loss: 0.8673070073127747, D Loss: 1.351973295211792, alpha: 0.9668179131709738\n",
      "epoch 439 iteration0, G Loss: 1.0096023082733154, D Loss: 1.3794140815734863, alpha: 0.9666248868856298\n",
      "epoch 439 iteration100, G Loss: 0.836148738861084, D Loss: 1.3105778694152832, alpha: 0.9666248868856298\n",
      "epoch 440 iteration0, G Loss: 1.0023245811462402, D Loss: 1.3116018772125244, alpha: 0.9664307767185175\n",
      "epoch 440 iteration100, G Loss: 0.9380416870117188, D Loss: 1.3615046739578247, alpha: 0.9664307767185175\n",
      "epoch 441 iteration0, G Loss: 0.9456831216812134, D Loss: 1.3613159656524658, alpha: 0.9662355770381064\n",
      "epoch 441 iteration100, G Loss: 1.140124797821045, D Loss: 1.3620636463165283, alpha: 0.9662355770381064\n",
      "epoch 442 iteration0, G Loss: 1.2937606573104858, D Loss: 1.3280775547027588, alpha: 0.9660392821889131\n",
      "epoch 442 iteration100, G Loss: 0.9111097455024719, D Loss: 1.3509526252746582, alpha: 0.9660392821889131\n",
      "epoch 443 iteration0, G Loss: 0.890722930431366, D Loss: 1.3139262199401855, alpha: 0.965841886491464\n",
      "epoch 443 iteration100, G Loss: 1.003146767616272, D Loss: 1.3438944816589355, alpha: 0.965841886491464\n",
      "epoch 444 iteration0, G Loss: 0.9278523921966553, D Loss: 1.3868224620819092, alpha: 0.9656433842422564\n",
      "epoch 444 iteration100, G Loss: 1.0005948543548584, D Loss: 1.3259379863739014, alpha: 0.9656433842422564\n",
      "epoch 445 iteration0, G Loss: 1.0129610300064087, D Loss: 1.3415253162384033, alpha: 0.9654437697137235\n",
      "epoch 445 iteration100, G Loss: 0.8758771419525146, D Loss: 1.3732728958129883, alpha: 0.9654437697137235\n",
      "epoch 446 iteration0, G Loss: 0.9116865992546082, D Loss: 1.3643884658813477, alpha: 0.9652430371541975\n",
      "epoch 446 iteration100, G Loss: 0.948134183883667, D Loss: 1.3227341175079346, alpha: 0.9652430371541975\n",
      "epoch 447 iteration0, G Loss: 0.9249624013900757, D Loss: 1.3791656494140625, alpha: 0.9650411807878754\n",
      "epoch 447 iteration100, G Loss: 1.1392592191696167, D Loss: 1.36723792552948, alpha: 0.9650411807878754\n",
      "epoch 448 iteration0, G Loss: 0.9423633813858032, D Loss: 1.3041391372680664, alpha: 0.9648381948147847\n",
      "epoch 448 iteration100, G Loss: 0.9313468933105469, D Loss: 1.3535258769989014, alpha: 0.9648381948147847\n",
      "epoch 449 iteration0, G Loss: 0.9038442373275757, D Loss: 1.289284586906433, alpha: 0.9646340734107508\n",
      "epoch 449 iteration100, G Loss: 1.0657322406768799, D Loss: 1.3594021797180176, alpha: 0.9646340734107508\n",
      "epoch 450 iteration0, G Loss: 0.9337666034698486, D Loss: 1.345976710319519, alpha: 0.9644288107273639\n",
      "epoch 450 iteration100, G Loss: 1.0252342224121094, D Loss: 1.3133577108383179, alpha: 0.9644288107273639\n",
      "Saving content.\n",
      "epoch 451 iteration0, G Loss: 1.0756053924560547, D Loss: 1.3524878025054932, alpha: 0.9642224008919484\n",
      "epoch 451 iteration100, G Loss: 0.8383755087852478, D Loss: 1.3390388488769531, alpha: 0.9642224008919484\n",
      "epoch 452 iteration0, G Loss: 0.9409880638122559, D Loss: 1.3497146368026733, alpha: 0.9640148380075328\n",
      "epoch 452 iteration100, G Loss: 1.067400336265564, D Loss: 1.3718961477279663, alpha: 0.9640148380075328\n",
      "epoch 453 iteration0, G Loss: 0.9650887846946716, D Loss: 1.3653817176818848, alpha: 0.9638061161528193\n",
      "epoch 453 iteration100, G Loss: 1.1393711566925049, D Loss: 1.3745746612548828, alpha: 0.9638061161528193\n",
      "epoch 454 iteration0, G Loss: 0.8956443071365356, D Loss: 1.3333854675292969, alpha: 0.9635962293821563\n",
      "epoch 454 iteration100, G Loss: 1.2849769592285156, D Loss: 1.3210041522979736, alpha: 0.9635962293821563\n",
      "epoch 455 iteration0, G Loss: 0.9507105946540833, D Loss: 1.3606619834899902, alpha: 0.9633851717255101\n",
      "epoch 455 iteration100, G Loss: 0.9956690073013306, D Loss: 1.3739426136016846, alpha: 0.9633851717255101\n",
      "epoch 456 iteration0, G Loss: 1.0094581842422485, D Loss: 1.3315465450286865, alpha: 0.9631729371884394\n",
      "epoch 456 iteration100, G Loss: 0.8962535858154297, D Loss: 1.3374501466751099, alpha: 0.9631729371884394\n",
      "epoch 457 iteration0, G Loss: 0.9842394590377808, D Loss: 1.3174837827682495, alpha: 0.9629595197520688\n",
      "epoch 457 iteration100, G Loss: 0.9372290372848511, D Loss: 1.36086905002594, alpha: 0.9629595197520688\n",
      "epoch 458 iteration0, G Loss: 1.0537550449371338, D Loss: 1.3309274911880493, alpha: 0.962744913373065\n",
      "epoch 458 iteration100, G Loss: 1.023881196975708, D Loss: 1.3000962734222412, alpha: 0.962744913373065\n",
      "epoch 459 iteration0, G Loss: 1.0316381454467773, D Loss: 1.3370774984359741, alpha: 0.962529111983613\n",
      "epoch 459 iteration100, G Loss: 1.0513055324554443, D Loss: 1.3646996021270752, alpha: 0.962529111983613\n",
      "epoch 460 iteration0, G Loss: 1.078896164894104, D Loss: 1.3332163095474243, alpha: 0.9623121094913941\n",
      "epoch 460 iteration100, G Loss: 0.9851504564285278, D Loss: 1.3324470520019531, alpha: 0.9623121094913941\n",
      "epoch 461 iteration0, G Loss: 1.0693538188934326, D Loss: 1.3574886322021484, alpha: 0.9620938997795639\n",
      "epoch 461 iteration100, G Loss: 0.955249547958374, D Loss: 1.2720283269882202, alpha: 0.9620938997795639\n",
      "epoch 462 iteration0, G Loss: 0.8797190189361572, D Loss: 1.3392752408981323, alpha: 0.9618744767067332\n",
      "epoch 462 iteration100, G Loss: 0.9611515998840332, D Loss: 1.330756664276123, alpha: 0.9618744767067332\n",
      "epoch 463 iteration0, G Loss: 0.9326762557029724, D Loss: 1.3297226428985596, alpha: 0.9616538341069474\n",
      "epoch 463 iteration100, G Loss: 0.9169772267341614, D Loss: 1.3300814628601074, alpha: 0.9616538341069474\n",
      "epoch 464 iteration0, G Loss: 0.9995267391204834, D Loss: 1.366010069847107, alpha: 0.9614319657896698\n",
      "epoch 464 iteration100, G Loss: 0.9510548114776611, D Loss: 1.3511221408843994, alpha: 0.9614319657896698\n",
      "epoch 465 iteration0, G Loss: 0.9728803634643555, D Loss: 1.3556468486785889, alpha: 0.9612088655397639\n",
      "epoch 465 iteration100, G Loss: 0.9291982650756836, D Loss: 1.3653886318206787, alpha: 0.9612088655397639\n",
      "epoch 466 iteration0, G Loss: 1.1276841163635254, D Loss: 1.3417547941207886, alpha: 0.9609845271174783\n",
      "epoch 466 iteration100, G Loss: 1.2566132545471191, D Loss: 1.3152635097503662, alpha: 0.9609845271174783\n",
      "epoch 467 iteration0, G Loss: 1.0814934968948364, D Loss: 1.3775256872177124, alpha: 0.9607589442584311\n",
      "epoch 467 iteration100, G Loss: 0.9133139252662659, D Loss: 1.300565242767334, alpha: 0.9607589442584311\n",
      "epoch 468 iteration0, G Loss: 0.9770886898040771, D Loss: 1.315982699394226, alpha: 0.9605321106735979\n",
      "epoch 468 iteration100, G Loss: 1.0837515592575073, D Loss: 1.337320327758789, alpha: 0.9605321106735979\n",
      "epoch 469 iteration0, G Loss: 0.8386019468307495, D Loss: 1.3816275596618652, alpha: 0.9603040200492985\n",
      "epoch 469 iteration100, G Loss: 0.9616966247558594, D Loss: 1.3638532161712646, alpha: 0.9603040200492985\n",
      "epoch 470 iteration0, G Loss: 0.9943749904632568, D Loss: 1.3159446716308594, alpha: 0.9600746660471862\n",
      "epoch 470 iteration100, G Loss: 1.0734351873397827, D Loss: 1.2624156475067139, alpha: 0.9600746660471862\n",
      "epoch 471 iteration0, G Loss: 0.9067533016204834, D Loss: 1.3041048049926758, alpha: 0.9598440423042385\n",
      "epoch 471 iteration100, G Loss: 1.0803951025009155, D Loss: 1.3458507061004639, alpha: 0.9598440423042385\n",
      "epoch 472 iteration0, G Loss: 0.9982213973999023, D Loss: 1.3288849592208862, alpha: 0.959612142432748\n",
      "epoch 472 iteration100, G Loss: 0.9480912685394287, D Loss: 1.377923607826233, alpha: 0.959612142432748\n",
      "epoch 473 iteration0, G Loss: 0.9738137722015381, D Loss: 1.4180036783218384, alpha: 0.9593789600203156\n",
      "epoch 473 iteration100, G Loss: 1.0288492441177368, D Loss: 1.3271050453186035, alpha: 0.9593789600203156\n",
      "epoch 474 iteration0, G Loss: 0.9898049831390381, D Loss: 1.3562122583389282, alpha: 0.9591444886298444\n",
      "epoch 474 iteration100, G Loss: 1.0171923637390137, D Loss: 1.301889419555664, alpha: 0.9591444886298444\n",
      "epoch 475 iteration0, G Loss: 0.9510970115661621, D Loss: 1.3529680967330933, alpha: 0.958908721799535\n",
      "epoch 475 iteration100, G Loss: 0.9929560422897339, D Loss: 1.3276760578155518, alpha: 0.958908721799535\n",
      "epoch 476 iteration0, G Loss: 0.939387857913971, D Loss: 1.3068182468414307, alpha: 0.9586716530428824\n",
      "epoch 476 iteration100, G Loss: 0.9142563939094543, D Loss: 1.2966043949127197, alpha: 0.9586716530428824\n",
      "epoch 477 iteration0, G Loss: 1.0013699531555176, D Loss: 1.3215723037719727, alpha: 0.9584332758486738\n",
      "epoch 477 iteration100, G Loss: 0.9490320682525635, D Loss: 1.3062946796417236, alpha: 0.9584332758486738\n",
      "epoch 478 iteration0, G Loss: 0.9655536413192749, D Loss: 1.2887558937072754, alpha: 0.9581935836809882\n",
      "epoch 478 iteration100, G Loss: 0.9224821329116821, D Loss: 1.340250015258789, alpha: 0.9581935836809882\n",
      "epoch 479 iteration0, G Loss: 0.8669756650924683, D Loss: 1.3367154598236084, alpha: 0.957952569979197\n",
      "epoch 479 iteration100, G Loss: 0.9181967973709106, D Loss: 1.3399291038513184, alpha: 0.957952569979197\n",
      "epoch 480 iteration0, G Loss: 0.8810943961143494, D Loss: 1.4102085828781128, alpha: 0.9577102281579662\n",
      "epoch 480 iteration100, G Loss: 0.9771348834037781, D Loss: 1.3296756744384766, alpha: 0.9577102281579662\n",
      "epoch 481 iteration0, G Loss: 1.0096994638442993, D Loss: 1.3472673892974854, alpha: 0.9574665516072602\n",
      "epoch 481 iteration100, G Loss: 1.0009825229644775, D Loss: 1.3324779272079468, alpha: 0.9574665516072602\n",
      "epoch 482 iteration0, G Loss: 0.9150152206420898, D Loss: 1.3493707180023193, alpha: 0.9572215336923464\n",
      "epoch 482 iteration100, G Loss: 0.9169490337371826, D Loss: 1.3145661354064941, alpha: 0.9572215336923464\n",
      "epoch 483 iteration0, G Loss: 1.0919808149337769, D Loss: 1.372664213180542, alpha: 0.9569751677538021\n",
      "epoch 483 iteration100, G Loss: 1.1213659048080444, D Loss: 1.3521907329559326, alpha: 0.9569751677538021\n",
      "epoch 484 iteration0, G Loss: 1.0361042022705078, D Loss: 1.444045066833496, alpha: 0.9567274471075219\n",
      "epoch 484 iteration100, G Loss: 0.9007631540298462, D Loss: 1.3645777702331543, alpha: 0.9567274471075219\n",
      "epoch 485 iteration0, G Loss: 0.845205545425415, D Loss: 1.3502333164215088, alpha: 0.9564783650447278\n",
      "epoch 485 iteration100, G Loss: 0.9070965051651001, D Loss: 1.3527673482894897, alpha: 0.9564783650447278\n",
      "epoch 486 iteration0, G Loss: 0.9733308553695679, D Loss: 1.3864538669586182, alpha: 0.9562279148319796\n",
      "epoch 486 iteration100, G Loss: 1.0119917392730713, D Loss: 1.3761155605316162, alpha: 0.9562279148319796\n",
      "epoch 487 iteration0, G Loss: 1.085526943206787, D Loss: 1.2866681814193726, alpha: 0.9559760897111875\n",
      "epoch 487 iteration100, G Loss: 0.9831962585449219, D Loss: 1.3251054286956787, alpha: 0.9559760897111875\n",
      "epoch 488 iteration0, G Loss: 0.8419632911682129, D Loss: 1.3490160703659058, alpha: 0.9557228828996265\n",
      "epoch 488 iteration100, G Loss: 1.0405534505844116, D Loss: 1.3099391460418701, alpha: 0.9557228828996265\n",
      "epoch 489 iteration0, G Loss: 0.9854865670204163, D Loss: 1.3382893800735474, alpha: 0.955468287589951\n",
      "epoch 489 iteration100, G Loss: 0.9763803482055664, D Loss: 1.3422877788543701, alpha: 0.955468287589951\n",
      "epoch 490 iteration0, G Loss: 1.0366154909133911, D Loss: 1.3111891746520996, alpha: 0.9552122969502133\n",
      "epoch 490 iteration100, G Loss: 0.9416638612747192, D Loss: 1.258751392364502, alpha: 0.9552122969502133\n",
      "epoch 491 iteration0, G Loss: 0.9700905680656433, D Loss: 1.3559229373931885, alpha: 0.9549549041238813\n",
      "epoch 491 iteration100, G Loss: 1.0063780546188354, D Loss: 1.3289594650268555, alpha: 0.9549549041238813\n",
      "epoch 492 iteration0, G Loss: 1.0389351844787598, D Loss: 1.3362417221069336, alpha: 0.9546961022298595\n",
      "epoch 492 iteration100, G Loss: 1.0098743438720703, D Loss: 1.3812241554260254, alpha: 0.9546961022298595\n",
      "epoch 493 iteration0, G Loss: 0.999012291431427, D Loss: 1.3330810070037842, alpha: 0.9544358843625106\n",
      "epoch 493 iteration100, G Loss: 0.9896044731140137, D Loss: 1.304749608039856, alpha: 0.9544358843625106\n",
      "epoch 494 iteration0, G Loss: 1.0092182159423828, D Loss: 1.3218152523040771, alpha: 0.95417424359168\n",
      "epoch 494 iteration100, G Loss: 1.0455087423324585, D Loss: 1.3353517055511475, alpha: 0.95417424359168\n",
      "epoch 495 iteration0, G Loss: 1.0323117971420288, D Loss: 1.3810827732086182, alpha: 0.9539111729627203\n",
      "epoch 495 iteration100, G Loss: 1.1193771362304688, D Loss: 1.37114679813385, alpha: 0.9539111729627203\n",
      "epoch 496 iteration0, G Loss: 1.0026884078979492, D Loss: 1.2815369367599487, alpha: 0.9536466654965192\n",
      "epoch 496 iteration100, G Loss: 1.069541335105896, D Loss: 1.2939066886901855, alpha: 0.9536466654965192\n",
      "epoch 497 iteration0, G Loss: 0.942452609539032, D Loss: 1.3690773248672485, alpha: 0.9533807141895276\n",
      "epoch 497 iteration100, G Loss: 0.9580026865005493, D Loss: 1.3445357084274292, alpha: 0.9533807141895276\n",
      "epoch 498 iteration0, G Loss: 0.9319517612457275, D Loss: 1.3531237840652466, alpha: 0.9531133120137913\n",
      "epoch 498 iteration100, G Loss: 0.9826453924179077, D Loss: 1.3054273128509521, alpha: 0.9531133120137913\n",
      "epoch 499 iteration0, G Loss: 0.9462171792984009, D Loss: 1.3217432498931885, alpha: 0.9528444519169822\n",
      "epoch 499 iteration100, G Loss: 0.9556707143783569, D Loss: 1.301513433456421, alpha: 0.9528444519169822\n",
      "epoch 500 iteration0, G Loss: 0.9358897805213928, D Loss: 1.3038389682769775, alpha: 0.9525741268224333\n",
      "epoch 500 iteration100, G Loss: 0.9066917896270752, D Loss: 1.4050800800323486, alpha: 0.9525741268224333\n",
      "Saving content.\n",
      "epoch 501 iteration0, G Loss: 0.9878899455070496, D Loss: 1.326695442199707, alpha: 0.9523023296291744\n",
      "epoch 501 iteration100, G Loss: 1.0522549152374268, D Loss: 1.2979364395141602, alpha: 0.9523023296291744\n",
      "epoch 502 iteration0, G Loss: 0.8409854769706726, D Loss: 1.316736102104187, alpha: 0.9520290532119702\n",
      "epoch 502 iteration100, G Loss: 0.8561415076255798, D Loss: 1.3686528205871582, alpha: 0.9520290532119702\n",
      "epoch 503 iteration0, G Loss: 0.9822187423706055, D Loss: 1.389800786972046, alpha: 0.9517542904213597\n",
      "epoch 503 iteration100, G Loss: 0.9887503385543823, D Loss: 1.3686950206756592, alpha: 0.9517542904213597\n",
      "epoch 504 iteration0, G Loss: 1.0822443962097168, D Loss: 1.3586933612823486, alpha: 0.9514780340836981\n",
      "epoch 504 iteration100, G Loss: 1.11243736743927, D Loss: 1.3692086935043335, alpha: 0.9514780340836981\n",
      "epoch 505 iteration0, G Loss: 1.0351707935333252, D Loss: 1.3595075607299805, alpha: 0.9512002770012\n",
      "epoch 505 iteration100, G Loss: 0.971802294254303, D Loss: 1.3656563758850098, alpha: 0.9512002770012\n",
      "epoch 506 iteration0, G Loss: 1.0228846073150635, D Loss: 1.3801438808441162, alpha: 0.9509210119519851\n",
      "epoch 506 iteration100, G Loss: 0.7615719437599182, D Loss: 1.3201104402542114, alpha: 0.9509210119519851\n",
      "epoch 507 iteration0, G Loss: 1.108878493309021, D Loss: 1.3256125450134277, alpha: 0.9506402316901252\n",
      "epoch 507 iteration100, G Loss: 0.988580584526062, D Loss: 1.327275037765503, alpha: 0.9506402316901252\n",
      "epoch 508 iteration0, G Loss: 1.0478394031524658, D Loss: 1.350338339805603, alpha: 0.9503579289456944\n",
      "epoch 508 iteration100, G Loss: 1.124475121498108, D Loss: 1.3446261882781982, alpha: 0.9503579289456944\n",
      "epoch 509 iteration0, G Loss: 0.9732163548469543, D Loss: 1.364202618598938, alpha: 0.9500740964248193\n",
      "epoch 509 iteration100, G Loss: 0.9220926761627197, D Loss: 1.3641313314437866, alpha: 0.9500740964248193\n",
      "epoch 510 iteration0, G Loss: 0.9764304161071777, D Loss: 1.368539810180664, alpha: 0.9497887268097335\n",
      "epoch 510 iteration100, G Loss: 0.9053616523742676, D Loss: 1.3972423076629639, alpha: 0.9497887268097335\n",
      "epoch 511 iteration0, G Loss: 1.1190037727355957, D Loss: 1.326059341430664, alpha: 0.9495018127588318\n",
      "epoch 511 iteration100, G Loss: 0.9736469388008118, D Loss: 1.4264354705810547, alpha: 0.9495018127588318\n",
      "epoch 512 iteration0, G Loss: 0.9634549617767334, D Loss: 1.3673598766326904, alpha: 0.9492133469067291\n",
      "epoch 512 iteration100, G Loss: 1.0103625059127808, D Loss: 1.3097407817840576, alpha: 0.9492133469067291\n",
      "epoch 513 iteration0, G Loss: 0.9213378429412842, D Loss: 1.3247294425964355, alpha: 0.9489233218643187\n",
      "epoch 513 iteration100, G Loss: 0.9562461376190186, D Loss: 1.302333116531372, alpha: 0.9489233218643187\n",
      "epoch 514 iteration0, G Loss: 0.9415661096572876, D Loss: 1.3289355039596558, alpha: 0.9486317302188345\n",
      "epoch 514 iteration100, G Loss: 0.8908913135528564, D Loss: 1.3773791790008545, alpha: 0.9486317302188345\n",
      "epoch 515 iteration0, G Loss: 0.9767268896102905, D Loss: 1.33217453956604, alpha: 0.9483385645339152\n",
      "epoch 515 iteration100, G Loss: 1.2855793237686157, D Loss: 1.2378522157669067, alpha: 0.9483385645339152\n",
      "epoch 516 iteration0, G Loss: 1.075121521949768, D Loss: 1.28759765625, alpha: 0.9480438173496692\n",
      "epoch 516 iteration100, G Loss: 0.9595070481300354, D Loss: 1.339869737625122, alpha: 0.9480438173496692\n",
      "epoch 517 iteration0, G Loss: 1.0277172327041626, D Loss: 1.3409521579742432, alpha: 0.9477474811827441\n",
      "epoch 517 iteration100, G Loss: 1.049498438835144, D Loss: 1.3421226739883423, alpha: 0.9477474811827441\n",
      "epoch 518 iteration0, G Loss: 0.8815438747406006, D Loss: 1.340074062347412, alpha: 0.9474495485263958\n",
      "epoch 518 iteration100, G Loss: 0.883396327495575, D Loss: 1.3374664783477783, alpha: 0.9474495485263958\n",
      "epoch 519 iteration0, G Loss: 1.0810377597808838, D Loss: 1.3398215770721436, alpha: 0.947150011850562\n",
      "epoch 519 iteration100, G Loss: 1.000821590423584, D Loss: 1.340135097503662, alpha: 0.947150011850562\n",
      "epoch 520 iteration0, G Loss: 0.918822169303894, D Loss: 1.3133647441864014, alpha: 0.9468488636019363\n",
      "epoch 520 iteration100, G Loss: 0.9997822046279907, D Loss: 1.2966690063476562, alpha: 0.9468488636019363\n",
      "epoch 521 iteration0, G Loss: 0.8537259101867676, D Loss: 1.3404277563095093, alpha: 0.9465460962040458\n",
      "epoch 521 iteration100, G Loss: 0.8750834465026855, D Loss: 1.3513481616973877, alpha: 0.9465460962040458\n",
      "epoch 522 iteration0, G Loss: 0.9406634569168091, D Loss: 1.3537766933441162, alpha: 0.9462417020573307\n",
      "epoch 522 iteration100, G Loss: 1.0298534631729126, D Loss: 1.3389267921447754, alpha: 0.9462417020573307\n",
      "epoch 523 iteration0, G Loss: 1.1331080198287964, D Loss: 1.3787918090820312, alpha: 0.945935673539225\n",
      "epoch 523 iteration100, G Loss: 0.9897810816764832, D Loss: 1.2813425064086914, alpha: 0.945935673539225\n",
      "epoch 524 iteration0, G Loss: 0.9809768795967102, D Loss: 1.3259291648864746, alpha: 0.9456280030042419\n",
      "epoch 524 iteration100, G Loss: 1.1843841075897217, D Loss: 1.3089874982833862, alpha: 0.9456280030042419\n",
      "epoch 525 iteration0, G Loss: 0.988906741142273, D Loss: 1.2991962432861328, alpha: 0.9453186827840593\n",
      "epoch 525 iteration100, G Loss: 0.9744043946266174, D Loss: 1.3614528179168701, alpha: 0.9453186827840593\n",
      "epoch 526 iteration0, G Loss: 1.0788160562515259, D Loss: 1.3055866956710815, alpha: 0.9450077051876089\n",
      "epoch 526 iteration100, G Loss: 1.0319342613220215, D Loss: 1.357654333114624, alpha: 0.9450077051876089\n",
      "epoch 527 iteration0, G Loss: 0.9663424491882324, D Loss: 1.320420265197754, alpha: 0.9446950625011679\n",
      "epoch 527 iteration100, G Loss: 0.9887580275535583, D Loss: 1.329948902130127, alpha: 0.9446950625011679\n",
      "epoch 528 iteration0, G Loss: 0.9771187901496887, D Loss: 1.3114680051803589, alpha: 0.9443807469884519\n",
      "epoch 528 iteration100, G Loss: 0.935734748840332, D Loss: 1.3156883716583252, alpha: 0.9443807469884519\n",
      "epoch 529 iteration0, G Loss: 1.0551661252975464, D Loss: 1.3048300743103027, alpha: 0.944064750890712\n",
      "epoch 529 iteration100, G Loss: 0.9634541869163513, D Loss: 1.3007011413574219, alpha: 0.944064750890712\n",
      "epoch 530 iteration0, G Loss: 1.0230331420898438, D Loss: 1.2950557470321655, alpha: 0.9437470664268326\n",
      "epoch 530 iteration100, G Loss: 0.9934471249580383, D Loss: 1.3315768241882324, alpha: 0.9437470664268326\n",
      "epoch 531 iteration0, G Loss: 1.0719358921051025, D Loss: 1.3133517503738403, alpha: 0.9434276857934336\n",
      "epoch 531 iteration100, G Loss: 1.0725069046020508, D Loss: 1.292830228805542, alpha: 0.9434276857934336\n",
      "epoch 532 iteration0, G Loss: 0.9876134991645813, D Loss: 1.3124158382415771, alpha: 0.9431066011649731\n",
      "epoch 532 iteration100, G Loss: 1.061505913734436, D Loss: 1.384095549583435, alpha: 0.9431066011649731\n",
      "epoch 533 iteration0, G Loss: 1.0291234254837036, D Loss: 1.3302706480026245, alpha: 0.9427838046938548\n",
      "epoch 533 iteration100, G Loss: 0.9502210021018982, D Loss: 1.2777643203735352, alpha: 0.9427838046938548\n",
      "epoch 534 iteration0, G Loss: 0.9735568761825562, D Loss: 1.359241008758545, alpha: 0.9424592885105357\n",
      "epoch 534 iteration100, G Loss: 1.0444111824035645, D Loss: 1.3504061698913574, alpha: 0.9424592885105357\n",
      "epoch 535 iteration0, G Loss: 0.985721230506897, D Loss: 1.2507232427597046, alpha: 0.942133044723639\n",
      "epoch 535 iteration100, G Loss: 0.9638906121253967, D Loss: 1.2840865850448608, alpha: 0.942133044723639\n",
      "epoch 536 iteration0, G Loss: 1.0211982727050781, D Loss: 1.286399245262146, alpha: 0.9418050654200673\n",
      "epoch 536 iteration100, G Loss: 0.8098714351654053, D Loss: 1.3889129161834717, alpha: 0.9418050654200673\n",
      "epoch 537 iteration0, G Loss: 0.9942873120307922, D Loss: 1.40297532081604, alpha: 0.94147534266512\n",
      "epoch 537 iteration100, G Loss: 0.8741140961647034, D Loss: 1.368601679801941, alpha: 0.94147534266512\n",
      "epoch 538 iteration0, G Loss: 1.001804232597351, D Loss: 1.3546257019042969, alpha: 0.9411438685026128\n",
      "epoch 538 iteration100, G Loss: 1.006202220916748, D Loss: 1.2986485958099365, alpha: 0.9411438685026128\n",
      "epoch 539 iteration0, G Loss: 1.0540436506271362, D Loss: 1.2905161380767822, alpha: 0.9408106349549997\n",
      "epoch 539 iteration100, G Loss: 0.9486673474311829, D Loss: 1.345604658126831, alpha: 0.9408106349549997\n",
      "epoch 540 iteration0, G Loss: 0.9920740127563477, D Loss: 1.3560705184936523, alpha: 0.9404756340234984\n",
      "epoch 540 iteration100, G Loss: 1.104382872581482, D Loss: 1.3460124731063843, alpha: 0.9404756340234984\n",
      "epoch 541 iteration0, G Loss: 0.9956258535385132, D Loss: 1.35109281539917, alpha: 0.9401388576882185\n",
      "epoch 541 iteration100, G Loss: 1.1426230669021606, D Loss: 1.3270282745361328, alpha: 0.9401388576882185\n",
      "epoch 542 iteration0, G Loss: 0.9155235886573792, D Loss: 1.4226961135864258, alpha: 0.9398002979082909\n",
      "epoch 542 iteration100, G Loss: 1.0456335544586182, D Loss: 1.3487396240234375, alpha: 0.9398002979082909\n",
      "epoch 543 iteration0, G Loss: 1.0938270092010498, D Loss: 1.318090796470642, alpha: 0.9394599466220029\n",
      "epoch 543 iteration100, G Loss: 1.027305245399475, D Loss: 1.252487063407898, alpha: 0.9394599466220029\n",
      "epoch 544 iteration0, G Loss: 0.984028697013855, D Loss: 1.263305902481079, alpha: 0.9391177957469332\n",
      "epoch 544 iteration100, G Loss: 1.0301593542099, D Loss: 1.3091681003570557, alpha: 0.9391177957469332\n",
      "epoch 545 iteration0, G Loss: 0.9468352198600769, D Loss: 1.2398580312728882, alpha: 0.938773837180092\n",
      "epoch 545 iteration100, G Loss: 0.9913409948348999, D Loss: 1.3107788562774658, alpha: 0.938773837180092\n",
      "epoch 546 iteration0, G Loss: 0.8382766842842102, D Loss: 1.3605421781539917, alpha: 0.9384280627980626\n",
      "epoch 546 iteration100, G Loss: 1.0568163394927979, D Loss: 1.2947847843170166, alpha: 0.9384280627980626\n",
      "epoch 547 iteration0, G Loss: 0.9373741745948792, D Loss: 1.2958701848983765, alpha: 0.9380804644571467\n",
      "epoch 547 iteration100, G Loss: 0.9909896850585938, D Loss: 1.3165934085845947, alpha: 0.9380804644571467\n",
      "epoch 548 iteration0, G Loss: 0.9866383671760559, D Loss: 1.3047561645507812, alpha: 0.9377310339935125\n",
      "epoch 548 iteration100, G Loss: 1.1142359972000122, D Loss: 1.2926428318023682, alpha: 0.9377310339935125\n",
      "epoch 549 iteration0, G Loss: 1.2553722858428955, D Loss: 1.416022539138794, alpha: 0.9373797632233458\n",
      "epoch 549 iteration100, G Loss: 1.0660583972930908, D Loss: 1.3127071857452393, alpha: 0.9373797632233458\n",
      "epoch 550 iteration0, G Loss: 1.059904932975769, D Loss: 1.326897144317627, alpha: 0.9370266439430035\n",
      "epoch 550 iteration100, G Loss: 1.0643258094787598, D Loss: 1.3400993347167969, alpha: 0.9370266439430035\n",
      "Saving content.\n",
      "epoch 551 iteration0, G Loss: 0.9348382949829102, D Loss: 1.3593659400939941, alpha: 0.9366716679291713\n",
      "epoch 551 iteration100, G Loss: 0.9297147393226624, D Loss: 1.304654598236084, alpha: 0.9366716679291713\n",
      "epoch 552 iteration0, G Loss: 1.0526862144470215, D Loss: 1.3801114559173584, alpha: 0.9363148269390238\n",
      "epoch 552 iteration100, G Loss: 1.0442924499511719, D Loss: 1.3107025623321533, alpha: 0.9363148269390238\n",
      "epoch 553 iteration0, G Loss: 0.9840704798698425, D Loss: 1.3427358865737915, alpha: 0.9359561127103874\n",
      "epoch 553 iteration100, G Loss: 0.9696686863899231, D Loss: 1.3605834245681763, alpha: 0.9359561127103874\n",
      "epoch 554 iteration0, G Loss: 1.017507791519165, D Loss: 1.3133376836776733, alpha: 0.9355955169619067\n",
      "epoch 554 iteration100, G Loss: 1.1655060052871704, D Loss: 1.37284255027771, alpha: 0.9355955169619067\n",
      "epoch 555 iteration0, G Loss: 0.9711005687713623, D Loss: 1.2589266300201416, alpha: 0.9352330313932145\n",
      "epoch 555 iteration100, G Loss: 1.141737699508667, D Loss: 1.345018982887268, alpha: 0.9352330313932145\n",
      "epoch 556 iteration0, G Loss: 0.875951886177063, D Loss: 1.3431365489959717, alpha: 0.934868647685104\n",
      "epoch 556 iteration100, G Loss: 0.9969846606254578, D Loss: 1.319690465927124, alpha: 0.934868647685104\n",
      "epoch 557 iteration0, G Loss: 0.9711844325065613, D Loss: 1.2580095529556274, alpha: 0.9345023574997053\n",
      "epoch 557 iteration100, G Loss: 1.2263332605361938, D Loss: 1.3020858764648438, alpha: 0.9345023574997053\n",
      "epoch 558 iteration0, G Loss: 0.8569460511207581, D Loss: 1.3500277996063232, alpha: 0.9341341524806636\n",
      "epoch 558 iteration100, G Loss: 0.9109744429588318, D Loss: 1.340341567993164, alpha: 0.9341341524806636\n",
      "epoch 559 iteration0, G Loss: 0.9545885920524597, D Loss: 1.3151038885116577, alpha: 0.9337640242533225\n",
      "epoch 559 iteration100, G Loss: 0.9869642853736877, D Loss: 1.3259214162826538, alpha: 0.9337640242533225\n",
      "epoch 560 iteration0, G Loss: 1.0629774332046509, D Loss: 1.3038558959960938, alpha: 0.9333919644249093\n",
      "epoch 560 iteration100, G Loss: 1.103277325630188, D Loss: 1.384434700012207, alpha: 0.9333919644249093\n",
      "epoch 561 iteration0, G Loss: 1.0240837335586548, D Loss: 1.2866415977478027, alpha: 0.9330179645847241\n",
      "epoch 561 iteration100, G Loss: 1.0012816190719604, D Loss: 1.35868501663208, alpha: 0.9330179645847241\n",
      "epoch 562 iteration0, G Loss: 1.0588021278381348, D Loss: 1.288896083831787, alpha: 0.9326420163043319\n",
      "epoch 562 iteration100, G Loss: 1.1679248809814453, D Loss: 1.302011251449585, alpha: 0.9326420163043319\n",
      "epoch 563 iteration0, G Loss: 0.9919602870941162, D Loss: 1.3211621046066284, alpha: 0.9322641111377585\n",
      "epoch 563 iteration100, G Loss: 1.0858652591705322, D Loss: 1.288525104522705, alpha: 0.9322641111377585\n",
      "epoch 564 iteration0, G Loss: 1.0010755062103271, D Loss: 1.3234469890594482, alpha: 0.9318842406216898\n",
      "epoch 564 iteration100, G Loss: 1.0371739864349365, D Loss: 1.332310676574707, alpha: 0.9318842406216898\n",
      "epoch 565 iteration0, G Loss: 0.9899560213088989, D Loss: 1.351820468902588, alpha: 0.9315023962756739\n",
      "epoch 565 iteration100, G Loss: 1.0022177696228027, D Loss: 1.3235132694244385, alpha: 0.9315023962756739\n",
      "epoch 566 iteration0, G Loss: 1.0606999397277832, D Loss: 1.3194329738616943, alpha: 0.9311185696023273\n",
      "epoch 566 iteration100, G Loss: 0.9101499319076538, D Loss: 1.2717688083648682, alpha: 0.9311185696023273\n",
      "epoch 567 iteration0, G Loss: 1.140307068824768, D Loss: 1.2905235290527344, alpha: 0.9307327520875442\n",
      "epoch 567 iteration100, G Loss: 0.9077288508415222, D Loss: 1.3374075889587402, alpha: 0.9307327520875442\n",
      "epoch 568 iteration0, G Loss: 1.0977118015289307, D Loss: 1.3259209394454956, alpha: 0.9303449352007099\n",
      "epoch 568 iteration100, G Loss: 0.8949189186096191, D Loss: 1.3009517192840576, alpha: 0.9303449352007099\n",
      "epoch 569 iteration0, G Loss: 1.0809272527694702, D Loss: 1.3758940696716309, alpha: 0.9299551103949163\n",
      "epoch 569 iteration100, G Loss: 0.9567936658859253, D Loss: 1.3461494445800781, alpha: 0.9299551103949163\n",
      "epoch 570 iteration0, G Loss: 1.1200475692749023, D Loss: 1.3353286981582642, alpha: 0.9295632691071829\n",
      "epoch 570 iteration100, G Loss: 1.1879205703735352, D Loss: 1.3679568767547607, alpha: 0.9295632691071829\n",
      "epoch 571 iteration0, G Loss: 0.9975557327270508, D Loss: 1.3269178867340088, alpha: 0.92916940275868\n",
      "epoch 571 iteration100, G Loss: 1.0241425037384033, D Loss: 1.3529856204986572, alpha: 0.92916940275868\n",
      "epoch 572 iteration0, G Loss: 1.1450045108795166, D Loss: 1.3853614330291748, alpha: 0.9287735027549558\n",
      "epoch 572 iteration100, G Loss: 1.0106415748596191, D Loss: 1.3258605003356934, alpha: 0.9287735027549558\n",
      "epoch 573 iteration0, G Loss: 1.05962073802948, D Loss: 1.2738301753997803, alpha: 0.9283755604861677\n",
      "epoch 573 iteration100, G Loss: 1.0688892602920532, D Loss: 1.3413169384002686, alpha: 0.9283755604861677\n",
      "epoch 574 iteration0, G Loss: 1.045753002166748, D Loss: 1.3188965320587158, alpha: 0.9279755673273157\n",
      "epoch 574 iteration100, G Loss: 1.1536874771118164, D Loss: 1.305634617805481, alpha: 0.9279755673273157\n",
      "epoch 575 iteration0, G Loss: 1.0468944311141968, D Loss: 1.3512859344482422, alpha: 0.9275735146384823\n",
      "epoch 575 iteration100, G Loss: 1.1843841075897217, D Loss: 1.3128547668457031, alpha: 0.9275735146384823\n",
      "epoch 576 iteration0, G Loss: 0.9337223172187805, D Loss: 1.3562486171722412, alpha: 0.9271693937650729\n",
      "epoch 576 iteration100, G Loss: 0.9941340088844299, D Loss: 1.3166000843048096, alpha: 0.9271693937650729\n",
      "epoch 577 iteration0, G Loss: 0.9944857954978943, D Loss: 1.340444803237915, alpha: 0.9267631960380622\n",
      "epoch 577 iteration100, G Loss: 1.17997145652771, D Loss: 1.2997612953186035, alpha: 0.9267631960380622\n",
      "epoch 578 iteration0, G Loss: 0.989424467086792, D Loss: 1.34349524974823, alpha: 0.9263549127742438\n",
      "epoch 578 iteration100, G Loss: 1.0848268270492554, D Loss: 1.3147006034851074, alpha: 0.9263549127742438\n",
      "epoch 579 iteration0, G Loss: 1.0044173002243042, D Loss: 1.326794981956482, alpha: 0.9259445352764824\n",
      "epoch 579 iteration100, G Loss: 1.0800243616104126, D Loss: 1.29877507686615, alpha: 0.9259445352764824\n",
      "epoch 580 iteration0, G Loss: 0.9631770849227905, D Loss: 1.3186490535736084, alpha: 0.9255320548339719\n",
      "epoch 580 iteration100, G Loss: 1.04011070728302, D Loss: 1.3016042709350586, alpha: 0.9255320548339719\n",
      "epoch 581 iteration0, G Loss: 1.000463604927063, D Loss: 1.3638460636138916, alpha: 0.9251174627224962\n",
      "epoch 581 iteration100, G Loss: 0.9627093076705933, D Loss: 1.3730075359344482, alpha: 0.9251174627224962\n",
      "epoch 582 iteration0, G Loss: 0.9976863861083984, D Loss: 1.3574719429016113, alpha: 0.9247007502046931\n",
      "epoch 582 iteration100, G Loss: 1.0190563201904297, D Loss: 1.3303604125976562, alpha: 0.9247007502046931\n",
      "epoch 583 iteration0, G Loss: 0.9537267684936523, D Loss: 1.3379877805709839, alpha: 0.924281908530324\n",
      "epoch 583 iteration100, G Loss: 1.0589910745620728, D Loss: 1.3141040802001953, alpha: 0.924281908530324\n",
      "epoch 584 iteration0, G Loss: 1.048654317855835, D Loss: 1.286841630935669, alpha: 0.9238609289365459\n",
      "epoch 584 iteration100, G Loss: 0.9109585285186768, D Loss: 1.2797282934188843, alpha: 0.9238609289365459\n",
      "epoch 585 iteration0, G Loss: 0.9343404173851013, D Loss: 1.3152188062667847, alpha: 0.9234378026481879\n",
      "epoch 585 iteration100, G Loss: 1.4173321723937988, D Loss: 1.3208210468292236, alpha: 0.9234378026481879\n",
      "epoch 586 iteration0, G Loss: 1.0096826553344727, D Loss: 1.3557441234588623, alpha: 0.923012520878032\n",
      "epoch 586 iteration100, G Loss: 0.8956707715988159, D Loss: 1.3115260601043701, alpha: 0.923012520878032\n",
      "epoch 587 iteration0, G Loss: 0.9355952143669128, D Loss: 1.3996646404266357, alpha: 0.9225850748270976\n",
      "epoch 587 iteration100, G Loss: 1.1624666452407837, D Loss: 1.2758861780166626, alpha: 0.9225850748270976\n",
      "epoch 588 iteration0, G Loss: 1.0100929737091064, D Loss: 1.3359851837158203, alpha: 0.92215545568493\n",
      "epoch 588 iteration100, G Loss: 0.9664998054504395, D Loss: 1.3071062564849854, alpha: 0.92215545568493\n",
      "epoch 589 iteration0, G Loss: 1.0117919445037842, D Loss: 1.3367584943771362, alpha: 0.9217236546298927\n",
      "epoch 589 iteration100, G Loss: 0.9783565998077393, D Loss: 1.3163671493530273, alpha: 0.9217236546298927\n",
      "epoch 590 iteration0, G Loss: 1.038211703300476, D Loss: 1.2895987033843994, alpha: 0.9212896628294648\n",
      "epoch 590 iteration100, G Loss: 1.0025523900985718, D Loss: 1.3062529563903809, alpha: 0.9212896628294648\n",
      "epoch 591 iteration0, G Loss: 1.0646917819976807, D Loss: 1.3434953689575195, alpha: 0.9208534714405409\n",
      "epoch 591 iteration100, G Loss: 1.2394132614135742, D Loss: 1.333130955696106, alpha: 0.9208534714405409\n",
      "epoch 592 iteration0, G Loss: 1.0126246213912964, D Loss: 1.3242048025131226, alpha: 0.9204150716097369\n",
      "epoch 592 iteration100, G Loss: 1.0496594905853271, D Loss: 1.3136438131332397, alpha: 0.9204150716097369\n",
      "epoch 593 iteration0, G Loss: 1.0435376167297363, D Loss: 1.3221080303192139, alpha: 0.9199744544736984\n",
      "epoch 593 iteration100, G Loss: 1.0721049308776855, D Loss: 1.3049120903015137, alpha: 0.9199744544736984\n",
      "epoch 594 iteration0, G Loss: 0.949125349521637, D Loss: 1.3241163492202759, alpha: 0.9195316111594145\n",
      "epoch 594 iteration100, G Loss: 0.9021099805831909, D Loss: 1.331092357635498, alpha: 0.9195316111594145\n",
      "epoch 595 iteration0, G Loss: 1.001877784729004, D Loss: 1.2965015172958374, alpha: 0.9190865327845347\n",
      "epoch 595 iteration100, G Loss: 1.08653724193573, D Loss: 1.2864017486572266, alpha: 0.9190865327845347\n",
      "epoch 596 iteration0, G Loss: 1.108510136604309, D Loss: 1.3247733116149902, alpha: 0.918639210457691\n",
      "epoch 596 iteration100, G Loss: 0.9693451523780823, D Loss: 1.316794991493225, alpha: 0.918639210457691\n",
      "epoch 597 iteration0, G Loss: 0.9346133470535278, D Loss: 1.3173490762710571, alpha: 0.918189635278824\n",
      "epoch 597 iteration100, G Loss: 0.9938290119171143, D Loss: 1.4042413234710693, alpha: 0.918189635278824\n",
      "epoch 598 iteration0, G Loss: 1.070568561553955, D Loss: 1.3304497003555298, alpha: 0.9177377983395127\n",
      "epoch 598 iteration100, G Loss: 1.1119276285171509, D Loss: 1.28513765335083, alpha: 0.9177377983395127\n",
      "epoch 599 iteration0, G Loss: 1.1569024324417114, D Loss: 1.3178033828735352, alpha: 0.9172836907233093\n",
      "epoch 599 iteration100, G Loss: 1.0157320499420166, D Loss: 1.2082988023757935, alpha: 0.9172836907233093\n",
      "epoch 600 iteration0, G Loss: 1.1355547904968262, D Loss: 1.2960138320922852, alpha: 0.9168273035060777\n",
      "epoch 600 iteration100, G Loss: 1.1685504913330078, D Loss: 1.300991177558899, alpha: 0.9168273035060777\n",
      "Saving content.\n",
      "epoch 601 iteration0, G Loss: 1.0276155471801758, D Loss: 1.4078288078308105, alpha: 0.9163686277563372\n",
      "epoch 601 iteration100, G Loss: 0.8560145497322083, D Loss: 1.3381237983703613, alpha: 0.9163686277563372\n",
      "epoch 602 iteration0, G Loss: 1.034769058227539, D Loss: 1.2744991779327393, alpha: 0.9159076545356102\n",
      "epoch 602 iteration100, G Loss: 1.20626962184906, D Loss: 1.3392395973205566, alpha: 0.9159076545356102\n",
      "epoch 603 iteration0, G Loss: 0.9896426200866699, D Loss: 1.3393269777297974, alpha: 0.9154443748987733\n",
      "epoch 603 iteration100, G Loss: 0.9230226278305054, D Loss: 1.2933863401412964, alpha: 0.9154443748987733\n",
      "epoch 604 iteration0, G Loss: 1.1265019178390503, D Loss: 1.3132121562957764, alpha: 0.9149787798944143\n",
      "epoch 604 iteration100, G Loss: 1.00261390209198, D Loss: 1.3070136308670044, alpha: 0.9149787798944143\n",
      "epoch 605 iteration0, G Loss: 1.0728669166564941, D Loss: 1.2541128396987915, alpha: 0.9145108605651935\n",
      "epoch 605 iteration100, G Loss: 1.0152616500854492, D Loss: 1.2991538047790527, alpha: 0.9145108605651935\n",
      "epoch 606 iteration0, G Loss: 0.9695420265197754, D Loss: 1.27269446849823, alpha: 0.9140406079482077\n",
      "epoch 606 iteration100, G Loss: 0.9717082381248474, D Loss: 1.3046854734420776, alpha: 0.9140406079482077\n",
      "epoch 607 iteration0, G Loss: 1.0618702173233032, D Loss: 1.3253201246261597, alpha: 0.9135680130753614\n",
      "epoch 607 iteration100, G Loss: 1.1171585321426392, D Loss: 1.3263012170791626, alpha: 0.9135680130753614\n",
      "epoch 608 iteration0, G Loss: 1.0983792543411255, D Loss: 1.3378006219863892, alpha: 0.91309306697374\n",
      "epoch 608 iteration100, G Loss: 1.0608042478561401, D Loss: 1.3076040744781494, alpha: 0.91309306697374\n",
      "epoch 609 iteration0, G Loss: 1.224894404411316, D Loss: 1.3397597074508667, alpha: 0.9126157606659895\n",
      "epoch 609 iteration100, G Loss: 1.15780770778656, D Loss: 1.3031160831451416, alpha: 0.9126157606659895\n",
      "epoch 610 iteration0, G Loss: 1.0390539169311523, D Loss: 1.3291370868682861, alpha: 0.9121360851706988\n",
      "epoch 610 iteration100, G Loss: 0.9161354303359985, D Loss: 1.3522915840148926, alpha: 0.9121360851706988\n",
      "epoch 611 iteration0, G Loss: 1.0295867919921875, D Loss: 1.2790539264678955, alpha: 0.9116540315027887\n",
      "epoch 611 iteration100, G Loss: 1.04521906375885, D Loss: 1.3586515188217163, alpha: 0.9116540315027887\n",
      "epoch 612 iteration0, G Loss: 0.8870832920074463, D Loss: 1.3093702793121338, alpha: 0.9111695906739038\n",
      "epoch 612 iteration100, G Loss: 1.2748081684112549, D Loss: 1.2876304388046265, alpha: 0.9111695906739038\n",
      "epoch 613 iteration0, G Loss: 0.9233819842338562, D Loss: 1.3645026683807373, alpha: 0.9106827536928102\n",
      "epoch 613 iteration100, G Loss: 1.0278582572937012, D Loss: 1.2966368198394775, alpha: 0.9106827536928102\n",
      "epoch 614 iteration0, G Loss: 0.9528586864471436, D Loss: 1.30794358253479, alpha: 0.9101935115657962\n",
      "epoch 614 iteration100, G Loss: 1.0939103364944458, D Loss: 1.277345895767212, alpha: 0.9101935115657962\n",
      "epoch 615 iteration0, G Loss: 1.0672297477722168, D Loss: 1.3414685726165771, alpha: 0.9097018552970801\n",
      "epoch 615 iteration100, G Loss: 1.028152585029602, D Loss: 1.3217010498046875, alpha: 0.9097018552970801\n",
      "epoch 616 iteration0, G Loss: 1.0920897722244263, D Loss: 1.3253108263015747, alpha: 0.9092077758892203\n",
      "epoch 616 iteration100, G Loss: 1.1927515268325806, D Loss: 1.3146311044692993, alpha: 0.9092077758892203\n",
      "epoch 617 iteration0, G Loss: 1.0314240455627441, D Loss: 1.310023307800293, alpha: 0.9087112643435313\n",
      "epoch 617 iteration100, G Loss: 0.9767899513244629, D Loss: 1.3049323558807373, alpha: 0.9087112643435313\n",
      "epoch 618 iteration0, G Loss: 1.0741121768951416, D Loss: 1.3842887878417969, alpha: 0.9082123116605046\n",
      "epoch 618 iteration100, G Loss: 1.0174627304077148, D Loss: 1.315618634223938, alpha: 0.9082123116605046\n",
      "epoch 619 iteration0, G Loss: 1.1207351684570312, D Loss: 1.2992405891418457, alpha: 0.9077109088402335\n",
      "epoch 619 iteration100, G Loss: 0.9925081133842468, D Loss: 1.3580832481384277, alpha: 0.9077109088402335\n",
      "epoch 620 iteration0, G Loss: 1.1717033386230469, D Loss: 1.2552976608276367, alpha: 0.9072070468828429\n",
      "epoch 620 iteration100, G Loss: 1.119826078414917, D Loss: 1.3277510404586792, alpha: 0.9072070468828429\n",
      "epoch 621 iteration0, G Loss: 1.0086114406585693, D Loss: 1.2658636569976807, alpha: 0.9067007167889249\n",
      "epoch 621 iteration100, G Loss: 1.0005979537963867, D Loss: 1.275606393814087, alpha: 0.9067007167889249\n",
      "epoch 622 iteration0, G Loss: 1.059844732284546, D Loss: 1.311419129371643, alpha: 0.9061919095599771\n",
      "epoch 622 iteration100, G Loss: 1.038615345954895, D Loss: 1.3252243995666504, alpha: 0.9061919095599771\n",
      "epoch 623 iteration0, G Loss: 1.0299813747406006, D Loss: 1.3828293085098267, alpha: 0.9056806161988479\n",
      "epoch 623 iteration100, G Loss: 1.012861728668213, D Loss: 1.2918944358825684, alpha: 0.9056806161988479\n",
      "epoch 624 iteration0, G Loss: 1.0482935905456543, D Loss: 1.3558003902435303, alpha: 0.9051668277101852\n",
      "epoch 624 iteration100, G Loss: 1.062883973121643, D Loss: 1.3532475233078003, alpha: 0.9051668277101852\n",
      "epoch 625 iteration0, G Loss: 1.1832594871520996, D Loss: 1.3623273372650146, alpha: 0.9046505351008906\n",
      "epoch 625 iteration100, G Loss: 1.2505592107772827, D Loss: 1.2087619304656982, alpha: 0.9046505351008906\n",
      "epoch 626 iteration0, G Loss: 0.9875838756561279, D Loss: 1.2913309335708618, alpha: 0.9041317293805773\n",
      "epoch 626 iteration100, G Loss: 1.09592604637146, D Loss: 1.2960327863693237, alpha: 0.9041317293805773\n",
      "epoch 627 iteration0, G Loss: 1.0129761695861816, D Loss: 1.3200855255126953, alpha: 0.9036104015620353\n",
      "epoch 627 iteration100, G Loss: 1.1125301122665405, D Loss: 1.3253902196884155, alpha: 0.9036104015620353\n",
      "epoch 628 iteration0, G Loss: 1.0608049631118774, D Loss: 1.2977666854858398, alpha: 0.9030865426616987\n",
      "epoch 628 iteration100, G Loss: 0.9792942404747009, D Loss: 1.370673656463623, alpha: 0.9030865426616987\n",
      "epoch 629 iteration0, G Loss: 1.1152445077896118, D Loss: 1.3042552471160889, alpha: 0.9025601437001196\n",
      "epoch 629 iteration100, G Loss: 1.1397258043289185, D Loss: 1.3598960638046265, alpha: 0.9025601437001196\n",
      "epoch 630 iteration0, G Loss: 1.0511194467544556, D Loss: 1.2862515449523926, alpha: 0.902031195702446\n",
      "epoch 630 iteration100, G Loss: 1.1462914943695068, D Loss: 1.3873841762542725, alpha: 0.902031195702446\n",
      "epoch 631 iteration0, G Loss: 1.1409176588058472, D Loss: 1.349003791809082, alpha: 0.901499689698906\n",
      "epoch 631 iteration100, G Loss: 1.1359981298446655, D Loss: 1.3520228862762451, alpha: 0.901499689698906\n",
      "epoch 632 iteration0, G Loss: 1.116707682609558, D Loss: 1.26077401638031, alpha: 0.9009656167252947\n",
      "epoch 632 iteration100, G Loss: 0.996880054473877, D Loss: 1.3209666013717651, alpha: 0.9009656167252947\n",
      "epoch 633 iteration0, G Loss: 1.0172227621078491, D Loss: 1.317887783050537, alpha: 0.9004289678234686\n",
      "epoch 633 iteration100, G Loss: 1.0745317935943604, D Loss: 1.3158702850341797, alpha: 0.9004289678234686\n",
      "epoch 634 iteration0, G Loss: 1.0810292959213257, D Loss: 1.371329426765442, alpha: 0.8998897340418424\n",
      "epoch 634 iteration100, G Loss: 0.9964622259140015, D Loss: 1.2843875885009766, alpha: 0.8998897340418424\n",
      "epoch 635 iteration0, G Loss: 1.0085668563842773, D Loss: 1.310652732849121, alpha: 0.8993479064358931\n",
      "epoch 635 iteration100, G Loss: 0.927802324295044, D Loss: 1.3047738075256348, alpha: 0.8993479064358931\n",
      "epoch 636 iteration0, G Loss: 0.9687674641609192, D Loss: 1.2941968441009521, alpha: 0.8988034760686675\n",
      "epoch 636 iteration100, G Loss: 0.9892550706863403, D Loss: 1.322399377822876, alpha: 0.8988034760686675\n",
      "epoch 637 iteration0, G Loss: 0.9385477304458618, D Loss: 1.3417694568634033, alpha: 0.8982564340112953\n",
      "epoch 637 iteration100, G Loss: 1.0686768293380737, D Loss: 1.214294672012329, alpha: 0.8982564340112953\n",
      "epoch 638 iteration0, G Loss: 1.0016003847122192, D Loss: 1.307769775390625, alpha: 0.8977067713435066\n",
      "epoch 638 iteration100, G Loss: 1.1341785192489624, D Loss: 1.27924382686615, alpha: 0.8977067713435066\n",
      "epoch 639 iteration0, G Loss: 1.024608850479126, D Loss: 1.277653694152832, alpha: 0.8971544791541564\n",
      "epoch 639 iteration100, G Loss: 1.0990172624588013, D Loss: 1.3585000038146973, alpha: 0.8971544791541564\n",
      "epoch 640 iteration0, G Loss: 0.9980334043502808, D Loss: 1.267019510269165, alpha: 0.8965995485417504\n",
      "epoch 640 iteration100, G Loss: 1.1296615600585938, D Loss: 1.2978867292404175, alpha: 0.8965995485417504\n",
      "epoch 641 iteration0, G Loss: 1.0878828763961792, D Loss: 1.3341352939605713, alpha: 0.8960419706149801\n",
      "epoch 641 iteration100, G Loss: 0.9417541027069092, D Loss: 1.3363513946533203, alpha: 0.8960419706149801\n",
      "epoch 642 iteration0, G Loss: 1.1458258628845215, D Loss: 1.3150924444198608, alpha: 0.8954817364932596\n",
      "epoch 642 iteration100, G Loss: 1.0097198486328125, D Loss: 1.2825380563735962, alpha: 0.8954817364932596\n",
      "epoch 643 iteration0, G Loss: 1.0940306186676025, D Loss: 1.289878249168396, alpha: 0.8949188373072692\n",
      "epoch 643 iteration100, G Loss: 1.096929907798767, D Loss: 1.2525537014007568, alpha: 0.8949188373072692\n",
      "epoch 644 iteration0, G Loss: 1.1293472051620483, D Loss: 1.2680718898773193, alpha: 0.8943532641995036\n",
      "epoch 644 iteration100, G Loss: 0.876286506652832, D Loss: 1.2919343709945679, alpha: 0.8943532641995036\n",
      "epoch 645 iteration0, G Loss: 1.0424082279205322, D Loss: 1.2680721282958984, alpha: 0.8937850083248244\n",
      "epoch 645 iteration100, G Loss: 1.018561601638794, D Loss: 1.3103854656219482, alpha: 0.8937850083248244\n",
      "epoch 646 iteration0, G Loss: 1.13875150680542, D Loss: 1.2860487699508667, alpha: 0.8932140608510197\n",
      "epoch 646 iteration100, G Loss: 0.9481396079063416, D Loss: 1.3524680137634277, alpha: 0.8932140608510197\n",
      "epoch 647 iteration0, G Loss: 0.9357187151908875, D Loss: 1.3079466819763184, alpha: 0.8926404129593662\n",
      "epoch 647 iteration100, G Loss: 1.15365469455719, D Loss: 1.2389566898345947, alpha: 0.8926404129593662\n",
      "epoch 648 iteration0, G Loss: 1.0082330703735352, D Loss: 1.326828956604004, alpha: 0.8920640558451981\n",
      "epoch 648 iteration100, G Loss: 0.9632722735404968, D Loss: 1.3625825643539429, alpha: 0.8920640558451981\n",
      "epoch 649 iteration0, G Loss: 0.9980331659317017, D Loss: 1.3440377712249756, alpha: 0.8914849807184801\n",
      "epoch 649 iteration100, G Loss: 0.8906272053718567, D Loss: 1.2393231391906738, alpha: 0.8914849807184801\n",
      "epoch 650 iteration0, G Loss: 0.8905274868011475, D Loss: 1.3138737678527832, alpha: 0.8909031788043871\n",
      "epoch 650 iteration100, G Loss: 0.8634600639343262, D Loss: 1.3695695400238037, alpha: 0.8909031788043871\n",
      "Saving content.\n",
      "epoch 651 iteration0, G Loss: 1.0408779382705688, D Loss: 1.2960573434829712, alpha: 0.8903186413438859\n",
      "epoch 651 iteration100, G Loss: 0.9666692018508911, D Loss: 1.316080093383789, alpha: 0.8903186413438859\n",
      "epoch 652 iteration0, G Loss: 0.9859060049057007, D Loss: 1.3612486124038696, alpha: 0.8897313595943259\n",
      "epoch 652 iteration100, G Loss: 1.0366345643997192, D Loss: 1.3127646446228027, alpha: 0.8897313595943259\n",
      "epoch 653 iteration0, G Loss: 1.066908359527588, D Loss: 1.3365169763565063, alpha: 0.8891413248300313\n",
      "epoch 653 iteration100, G Loss: 1.1099073886871338, D Loss: 1.269805669784546, alpha: 0.8891413248300313\n",
      "epoch 654 iteration0, G Loss: 0.9813817739486694, D Loss: 1.2934069633483887, alpha: 0.8885485283429004\n",
      "epoch 654 iteration100, G Loss: 1.3166565895080566, D Loss: 1.3070837259292603, alpha: 0.8885485283429004\n",
      "epoch 655 iteration0, G Loss: 1.000494360923767, D Loss: 1.2861497402191162, alpha: 0.8879529614430097\n",
      "epoch 655 iteration100, G Loss: 1.112717628479004, D Loss: 1.333702564239502, alpha: 0.8879529614430097\n",
      "epoch 656 iteration0, G Loss: 0.9340061545372009, D Loss: 1.3040122985839844, alpha: 0.8873546154592227\n",
      "epoch 656 iteration100, G Loss: 1.048486351966858, D Loss: 1.2882673740386963, alpha: 0.8873546154592227\n",
      "epoch 657 iteration0, G Loss: 1.032395362854004, D Loss: 1.2933136224746704, alpha: 0.8867534817398037\n",
      "epoch 657 iteration100, G Loss: 1.0184227228164673, D Loss: 1.197493314743042, alpha: 0.8867534817398037\n",
      "epoch 658 iteration0, G Loss: 1.0511958599090576, D Loss: 1.3102154731750488, alpha: 0.8861495516530374\n",
      "epoch 658 iteration100, G Loss: 1.0845977067947388, D Loss: 1.288810133934021, alpha: 0.8861495516530374\n",
      "epoch 659 iteration0, G Loss: 0.9749064445495605, D Loss: 1.3060187101364136, alpha: 0.8855428165878523\n",
      "epoch 659 iteration100, G Loss: 1.1234521865844727, D Loss: 1.3174036741256714, alpha: 0.8855428165878523\n",
      "epoch 660 iteration0, G Loss: 1.0873628854751587, D Loss: 1.3639593124389648, alpha: 0.8849332679544502\n",
      "epoch 660 iteration100, G Loss: 1.0337995290756226, D Loss: 1.3318545818328857, alpha: 0.8849332679544502\n",
      "epoch 661 iteration0, G Loss: 0.956337571144104, D Loss: 1.4076354503631592, alpha: 0.8843208971849409\n",
      "epoch 661 iteration100, G Loss: 1.1514521837234497, D Loss: 1.3999940156936646, alpha: 0.8843208971849409\n",
      "epoch 662 iteration0, G Loss: 0.8937143683433533, D Loss: 1.4360246658325195, alpha: 0.883705695733981\n",
      "epoch 662 iteration100, G Loss: 0.9750592708587646, D Loss: 1.3271379470825195, alpha: 0.883705695733981\n",
      "epoch 663 iteration0, G Loss: 1.1618574857711792, D Loss: 1.3564051389694214, alpha: 0.8830876550794178\n",
      "epoch 663 iteration100, G Loss: 1.0447890758514404, D Loss: 1.324818730354309, alpha: 0.8830876550794178\n",
      "epoch 664 iteration0, G Loss: 1.075855016708374, D Loss: 1.3811049461364746, alpha: 0.88246676672294\n",
      "epoch 664 iteration100, G Loss: 0.9577575325965881, D Loss: 1.2871404886245728, alpha: 0.88246676672294\n",
      "epoch 665 iteration0, G Loss: 0.9466339349746704, D Loss: 1.2962039709091187, alpha: 0.8818430221907304\n",
      "epoch 665 iteration100, G Loss: 0.9582564830780029, D Loss: 1.263084888458252, alpha: 0.8818430221907304\n",
      "epoch 666 iteration0, G Loss: 0.9541943669319153, D Loss: 1.3338278532028198, alpha: 0.8812164130341268\n",
      "epoch 666 iteration100, G Loss: 0.8973575830459595, D Loss: 1.3266074657440186, alpha: 0.8812164130341268\n",
      "epoch 667 iteration0, G Loss: 0.9967960119247437, D Loss: 1.3044954538345337, alpha: 0.8805869308302849\n",
      "epoch 667 iteration100, G Loss: 0.9679262638092041, D Loss: 1.4124255180358887, alpha: 0.8805869308302849\n",
      "epoch 668 iteration0, G Loss: 0.9984438419342041, D Loss: 1.2319670915603638, alpha: 0.8799545671828493\n",
      "epoch 668 iteration100, G Loss: 0.9575766324996948, D Loss: 1.3028175830841064, alpha: 0.8799545671828493\n",
      "epoch 669 iteration0, G Loss: 1.1002205610275269, D Loss: 1.251418113708496, alpha: 0.8793193137226258\n",
      "epoch 669 iteration100, G Loss: 1.1390372514724731, D Loss: 1.2362141609191895, alpha: 0.8793193137226258\n",
      "epoch 670 iteration0, G Loss: 1.0602563619613647, D Loss: 1.274315357208252, alpha: 0.8786811621082631\n",
      "epoch 670 iteration100, G Loss: 0.7738147377967834, D Loss: 1.2741320133209229, alpha: 0.8786811621082631\n",
      "epoch 671 iteration0, G Loss: 0.9828363060951233, D Loss: 1.3331706523895264, alpha: 0.8780401040269349\n",
      "epoch 671 iteration100, G Loss: 1.0706119537353516, D Loss: 1.243887186050415, alpha: 0.8780401040269349\n",
      "epoch 672 iteration0, G Loss: 0.9556388854980469, D Loss: 1.2287925481796265, alpha: 0.8773961311950302\n",
      "epoch 672 iteration100, G Loss: 1.1474579572677612, D Loss: 1.3608261346817017, alpha: 0.8773961311950302\n",
      "epoch 673 iteration0, G Loss: 1.011411190032959, D Loss: 1.3392574787139893, alpha: 0.8767492353588473\n",
      "epoch 673 iteration100, G Loss: 1.054891586303711, D Loss: 1.3270092010498047, alpha: 0.8767492353588473\n",
      "epoch 674 iteration0, G Loss: 1.0572057962417603, D Loss: 1.2405312061309814, alpha: 0.8760994082952922\n",
      "epoch 674 iteration100, G Loss: 1.0291415452957153, D Loss: 1.3937246799468994, alpha: 0.8760994082952922\n",
      "epoch 675 iteration0, G Loss: 1.0428434610366821, D Loss: 1.2437129020690918, alpha: 0.8754466418125836\n",
      "epoch 675 iteration100, G Loss: 0.9543268084526062, D Loss: 1.211660385131836, alpha: 0.8754466418125836\n",
      "epoch 676 iteration0, G Loss: 0.942338764667511, D Loss: 1.297976016998291, alpha: 0.8747909277509601\n",
      "epoch 676 iteration100, G Loss: 1.1914362907409668, D Loss: 1.2563910484313965, alpha: 0.8747909277509601\n",
      "epoch 677 iteration0, G Loss: 1.1142863035202026, D Loss: 1.2678390741348267, alpha: 0.8741322579833951\n",
      "epoch 677 iteration100, G Loss: 0.9483582377433777, D Loss: 1.2705312967300415, alpha: 0.8741322579833951\n",
      "epoch 678 iteration0, G Loss: 1.1448819637298584, D Loss: 1.3294181823730469, alpha: 0.8734706244163147\n",
      "epoch 678 iteration100, G Loss: 1.0492854118347168, D Loss: 1.2834596633911133, alpha: 0.8734706244163147\n",
      "epoch 679 iteration0, G Loss: 1.0960410833358765, D Loss: 1.3441851139068604, alpha: 0.8728060189903207\n",
      "epoch 679 iteration100, G Loss: 1.1865695714950562, D Loss: 1.2712994813919067, alpha: 0.8728060189903207\n",
      "epoch 680 iteration0, G Loss: 1.1837363243103027, D Loss: 1.29301118850708, alpha: 0.8721384336809187\n",
      "epoch 680 iteration100, G Loss: 1.0921212434768677, D Loss: 1.3494553565979004, alpha: 0.8721384336809187\n",
      "epoch 681 iteration0, G Loss: 1.0924549102783203, D Loss: 1.254292368888855, alpha: 0.871467860499251\n",
      "epoch 681 iteration100, G Loss: 0.9804655313491821, D Loss: 1.3201018571853638, alpha: 0.871467860499251\n",
      "epoch 682 iteration0, G Loss: 0.9402077794075012, D Loss: 1.3232431411743164, alpha: 0.8707942914928337\n",
      "epoch 682 iteration100, G Loss: 1.038590431213379, D Loss: 1.2992758750915527, alpha: 0.8707942914928337\n",
      "epoch 683 iteration0, G Loss: 0.9776235818862915, D Loss: 1.2516810894012451, alpha: 0.8701177187462997\n",
      "epoch 683 iteration100, G Loss: 1.0141944885253906, D Loss: 1.2547276020050049, alpha: 0.8701177187462997\n",
      "epoch 684 iteration0, G Loss: 1.0830682516098022, D Loss: 1.2804758548736572, alpha: 0.869438134382144\n",
      "epoch 684 iteration100, G Loss: 1.035272479057312, D Loss: 1.332111120223999, alpha: 0.869438134382144\n",
      "epoch 685 iteration0, G Loss: 1.0112504959106445, D Loss: 1.2634236812591553, alpha: 0.8687555305614766\n",
      "epoch 685 iteration100, G Loss: 0.9951765537261963, D Loss: 1.2633733749389648, alpha: 0.8687555305614766\n",
      "epoch 686 iteration0, G Loss: 1.1470701694488525, D Loss: 1.3027504682540894, alpha: 0.868069899484778\n",
      "epoch 686 iteration100, G Loss: 1.153996467590332, D Loss: 1.2705872058868408, alpha: 0.868069899484778\n",
      "epoch 687 iteration0, G Loss: 1.0206983089447021, D Loss: 1.33180832862854, alpha: 0.8673812333926596\n",
      "epoch 687 iteration100, G Loss: 1.0708621740341187, D Loss: 1.244796633720398, alpha: 0.8673812333926596\n",
      "epoch 688 iteration0, G Loss: 1.138702392578125, D Loss: 1.2752970457077026, alpha: 0.8666895245666295\n",
      "epoch 688 iteration100, G Loss: 1.2443498373031616, D Loss: 1.273375153541565, alpha: 0.8666895245666295\n",
      "epoch 689 iteration0, G Loss: 0.9492117166519165, D Loss: 1.3169081211090088, alpha: 0.8659947653298621\n",
      "epoch 689 iteration100, G Loss: 1.100311517715454, D Loss: 1.2636189460754395, alpha: 0.8659947653298621\n",
      "epoch 690 iteration0, G Loss: 0.9918622374534607, D Loss: 1.2528254985809326, alpha: 0.865296948047972\n",
      "epoch 690 iteration100, G Loss: 0.8766108155250549, D Loss: 1.344879388809204, alpha: 0.865296948047972\n",
      "epoch 691 iteration0, G Loss: 1.0198800563812256, D Loss: 1.2556966543197632, alpha: 0.8645960651297927\n",
      "epoch 691 iteration100, G Loss: 0.9016115665435791, D Loss: 1.3032639026641846, alpha: 0.8645960651297927\n",
      "epoch 692 iteration0, G Loss: 1.0040892362594604, D Loss: 1.2783336639404297, alpha: 0.8638921090281604\n",
      "epoch 692 iteration100, G Loss: 1.1923930644989014, D Loss: 1.372154951095581, alpha: 0.8638921090281604\n",
      "epoch 693 iteration0, G Loss: 0.9528646469116211, D Loss: 1.2780241966247559, alpha: 0.8631850722407007\n",
      "epoch 693 iteration100, G Loss: 1.1382416486740112, D Loss: 1.2747138738632202, alpha: 0.8631850722407007\n",
      "epoch 694 iteration0, G Loss: 0.9163784980773926, D Loss: 1.2590563297271729, alpha: 0.862474947310621\n",
      "epoch 694 iteration100, G Loss: 1.1176199913024902, D Loss: 1.2934975624084473, alpha: 0.862474947310621\n",
      "epoch 695 iteration0, G Loss: 1.069064974784851, D Loss: 1.2917897701263428, alpha: 0.861761726827506\n",
      "epoch 695 iteration100, G Loss: 0.8810390830039978, D Loss: 1.311463713645935, alpha: 0.861761726827506\n",
      "epoch 696 iteration0, G Loss: 1.082212209701538, D Loss: 1.314264178276062, alpha: 0.8610454034281185\n",
      "epoch 696 iteration100, G Loss: 0.9234201908111572, D Loss: 1.2614331245422363, alpha: 0.8610454034281185\n",
      "epoch 697 iteration0, G Loss: 1.0684515237808228, D Loss: 1.2684153318405151, alpha: 0.8603259697972045\n",
      "epoch 697 iteration100, G Loss: 1.4357829093933105, D Loss: 1.3020702600479126, alpha: 0.8603259697972045\n",
      "epoch 698 iteration0, G Loss: 0.9368157982826233, D Loss: 1.3084243535995483, alpha: 0.8596034186683009\n",
      "epoch 698 iteration100, G Loss: 1.0208866596221924, D Loss: 1.2676055431365967, alpha: 0.8596034186683009\n",
      "epoch 699 iteration0, G Loss: 1.0562890768051147, D Loss: 1.2700235843658447, alpha: 0.8588777428245492\n",
      "epoch 699 iteration100, G Loss: 1.1128331422805786, D Loss: 1.3209508657455444, alpha: 0.8588777428245492\n",
      "epoch 700 iteration0, G Loss: 1.1010700464248657, D Loss: 1.2958309650421143, alpha: 0.8581489350995122\n",
      "epoch 700 iteration100, G Loss: 1.0917413234710693, D Loss: 1.2478983402252197, alpha: 0.8581489350995122\n",
      "Saving content.\n",
      "epoch 701 iteration0, G Loss: 1.092362880706787, D Loss: 1.250942349433899, alpha: 0.8574169883779953\n",
      "epoch 701 iteration100, G Loss: 0.9875229597091675, D Loss: 1.2848607301712036, alpha: 0.8574169883779953\n",
      "epoch 702 iteration0, G Loss: 0.9896050691604614, D Loss: 1.302762508392334, alpha: 0.8566818955968716\n",
      "epoch 702 iteration100, G Loss: 1.2281625270843506, D Loss: 1.2588173151016235, alpha: 0.8566818955968716\n",
      "epoch 703 iteration0, G Loss: 1.0286176204681396, D Loss: 1.33522367477417, alpha: 0.85594364974591\n",
      "epoch 703 iteration100, G Loss: 1.0345494747161865, D Loss: 1.2748585939407349, alpha: 0.85594364974591\n",
      "epoch 704 iteration0, G Loss: 1.0211819410324097, D Loss: 1.2624622583389282, alpha: 0.8552022438686094\n",
      "epoch 704 iteration100, G Loss: 1.1446659564971924, D Loss: 1.2575258016586304, alpha: 0.8552022438686094\n",
      "epoch 705 iteration0, G Loss: 1.1340885162353516, D Loss: 1.2617287635803223, alpha: 0.8544576710630347\n",
      "epoch 705 iteration100, G Loss: 1.183149814605713, D Loss: 1.3239814043045044, alpha: 0.8544576710630347\n",
      "epoch 706 iteration0, G Loss: 1.1061919927597046, D Loss: 1.2428535223007202, alpha: 0.8537099244826571\n",
      "epoch 706 iteration100, G Loss: 1.078601360321045, D Loss: 1.3032513856887817, alpha: 0.8537099244826571\n",
      "epoch 707 iteration0, G Loss: 0.9214571714401245, D Loss: 1.2891299724578857, alpha: 0.8529589973371989\n",
      "epoch 707 iteration100, G Loss: 1.3321442604064941, D Loss: 1.2493219375610352, alpha: 0.8529589973371989\n",
      "epoch 708 iteration0, G Loss: 0.9243752360343933, D Loss: 1.2322046756744385, alpha: 0.852204882893481\n",
      "epoch 708 iteration100, G Loss: 0.9787594676017761, D Loss: 1.2918972969055176, alpha: 0.852204882893481\n",
      "epoch 709 iteration0, G Loss: 0.8695415258407593, D Loss: 1.3509799242019653, alpha: 0.8514475744762745\n",
      "epoch 709 iteration100, G Loss: 1.271074652671814, D Loss: 1.2505491971969604, alpha: 0.8514475744762745\n",
      "epoch 710 iteration0, G Loss: 0.9625280499458313, D Loss: 1.2604951858520508, alpha: 0.8506870654691563\n",
      "epoch 710 iteration100, G Loss: 1.1328579187393188, D Loss: 1.3028194904327393, alpha: 0.8506870654691563\n",
      "epoch 711 iteration0, G Loss: 1.132106065750122, D Loss: 1.507197380065918, alpha: 0.8499233493153666\n",
      "epoch 711 iteration100, G Loss: 1.2574353218078613, D Loss: 1.2812001705169678, alpha: 0.8499233493153666\n",
      "epoch 712 iteration0, G Loss: 0.9559624195098877, D Loss: 1.3126252889633179, alpha: 0.8491564195186722\n",
      "epoch 712 iteration100, G Loss: 1.0636792182922363, D Loss: 1.2350188493728638, alpha: 0.8491564195186722\n",
      "epoch 713 iteration0, G Loss: 0.8937837481498718, D Loss: 1.296043872833252, alpha: 0.848386269644231\n",
      "epoch 713 iteration100, G Loss: 0.8701937794685364, D Loss: 1.3108184337615967, alpha: 0.848386269644231\n",
      "epoch 714 iteration0, G Loss: 1.153136968612671, D Loss: 1.32685124874115, alpha: 0.8476128933194615\n",
      "epoch 714 iteration100, G Loss: 1.1915363073349, D Loss: 1.1910990476608276, alpha: 0.8476128933194615\n",
      "epoch 715 iteration0, G Loss: 0.9538122415542603, D Loss: 1.278551459312439, alpha: 0.8468362842349137\n",
      "epoch 715 iteration100, G Loss: 1.027071475982666, D Loss: 1.267493486404419, alpha: 0.8468362842349137\n",
      "epoch 716 iteration0, G Loss: 1.052192211151123, D Loss: 1.2684228420257568, alpha: 0.8460564361451456\n",
      "epoch 716 iteration100, G Loss: 1.0665173530578613, D Loss: 1.2545647621154785, alpha: 0.8460564361451456\n",
      "epoch 717 iteration0, G Loss: 0.9960421919822693, D Loss: 1.3481433391571045, alpha: 0.8452733428696002\n",
      "epoch 717 iteration100, G Loss: 1.0337222814559937, D Loss: 1.3567867279052734, alpha: 0.8452733428696002\n",
      "epoch 718 iteration0, G Loss: 1.003235101699829, D Loss: 1.1632139682769775, alpha: 0.8444869982934881\n",
      "epoch 718 iteration100, G Loss: 1.192097783088684, D Loss: 1.3464488983154297, alpha: 0.8444869982934881\n",
      "epoch 719 iteration0, G Loss: 1.1562221050262451, D Loss: 1.2766339778900146, alpha: 0.8436973963686705\n",
      "epoch 719 iteration100, G Loss: 1.1683038473129272, D Loss: 1.2587673664093018, alpha: 0.8436973963686705\n",
      "epoch 720 iteration0, G Loss: 1.2491934299468994, D Loss: 1.2582296133041382, alpha: 0.8429045311145472\n",
      "epoch 720 iteration100, G Loss: 1.2288373708724976, D Loss: 1.3560285568237305, alpha: 0.8429045311145472\n",
      "epoch 721 iteration0, G Loss: 1.0620146989822388, D Loss: 1.2816803455352783, alpha: 0.8421083966189471\n",
      "epoch 721 iteration100, G Loss: 1.376756191253662, D Loss: 1.2734426259994507, alpha: 0.8421083966189471\n",
      "epoch 722 iteration0, G Loss: 1.2157551050186157, D Loss: 1.3083897829055786, alpha: 0.8413089870390198\n",
      "epoch 722 iteration100, G Loss: 1.4460786581039429, D Loss: 1.3226197957992554, alpha: 0.8413089870390198\n",
      "epoch 723 iteration0, G Loss: 1.2144237756729126, D Loss: 1.258805513381958, alpha: 0.8405062966021317\n",
      "epoch 723 iteration100, G Loss: 1.0796458721160889, D Loss: 1.2895479202270508, alpha: 0.8405062966021317\n",
      "epoch 724 iteration0, G Loss: 1.0459213256835938, D Loss: 1.2743942737579346, alpha: 0.8397003196067644\n",
      "epoch 724 iteration100, G Loss: 1.2823784351348877, D Loss: 1.3480606079101562, alpha: 0.8397003196067644\n",
      "epoch 725 iteration0, G Loss: 1.0941137075424194, D Loss: 1.2172257900238037, alpha: 0.8388910504234147\n",
      "epoch 725 iteration100, G Loss: 1.1090120077133179, D Loss: 1.2414326667785645, alpha: 0.8388910504234147\n",
      "epoch 726 iteration0, G Loss: 0.9736910462379456, D Loss: 1.3688182830810547, alpha: 0.8380784834954982\n",
      "epoch 726 iteration100, G Loss: 1.095440149307251, D Loss: 1.389343500137329, alpha: 0.8380784834954982\n",
      "epoch 727 iteration0, G Loss: 1.0423671007156372, D Loss: 1.216776967048645, alpha: 0.8372626133402539\n",
      "epoch 727 iteration100, G Loss: 1.2782455682754517, D Loss: 1.2950133085250854, alpha: 0.8372626133402539\n",
      "epoch 728 iteration0, G Loss: 1.0438964366912842, D Loss: 1.346380352973938, alpha: 0.8364434345496531\n",
      "epoch 728 iteration100, G Loss: 1.22499680519104, D Loss: 1.2132582664489746, alpha: 0.8364434345496531\n",
      "epoch 729 iteration0, G Loss: 1.1462292671203613, D Loss: 1.2353681325912476, alpha: 0.8356209417913083\n",
      "epoch 729 iteration100, G Loss: 1.2556172609329224, D Loss: 1.2862567901611328, alpha: 0.8356209417913083\n",
      "epoch 730 iteration0, G Loss: 1.0098381042480469, D Loss: 1.0524847507476807, alpha: 0.8347951298093854\n",
      "epoch 730 iteration100, G Loss: 1.1749053001403809, D Loss: 1.2124302387237549, alpha: 0.8347951298093854\n",
      "epoch 731 iteration0, G Loss: 1.0202100276947021, D Loss: 1.1928805112838745, alpha: 0.8339659934255179\n",
      "epoch 731 iteration100, G Loss: 0.9281365871429443, D Loss: 1.358187198638916, alpha: 0.8339659934255179\n",
      "epoch 732 iteration0, G Loss: 1.135279655456543, D Loss: 1.3057156801223755, alpha: 0.8331335275397229\n",
      "epoch 732 iteration100, G Loss: 1.2668540477752686, D Loss: 1.2619292736053467, alpha: 0.8331335275397229\n",
      "epoch 733 iteration0, G Loss: 1.1038448810577393, D Loss: 1.2412258386611938, alpha: 0.8322977271313189\n",
      "epoch 733 iteration100, G Loss: 1.3088696002960205, D Loss: 1.350339651107788, alpha: 0.8322977271313189\n",
      "epoch 734 iteration0, G Loss: 1.2285670042037964, D Loss: 1.2617768049240112, alpha: 0.8314585872598446\n",
      "epoch 734 iteration100, G Loss: 0.94770348072052, D Loss: 1.2734458446502686, alpha: 0.8314585872598446\n",
      "epoch 735 iteration0, G Loss: 1.0665652751922607, D Loss: 1.3010188341140747, alpha: 0.8306161030659813\n",
      "epoch 735 iteration100, G Loss: 1.0464198589324951, D Loss: 1.3734701871871948, alpha: 0.8306161030659813\n",
      "epoch 736 iteration0, G Loss: 1.1903973817825317, D Loss: 1.2918230295181274, alpha: 0.8297702697724747\n",
      "epoch 736 iteration100, G Loss: 1.2117788791656494, D Loss: 1.242506504058838, alpha: 0.8297702697724747\n",
      "epoch 737 iteration0, G Loss: 1.0425480604171753, D Loss: 1.2428803443908691, alpha: 0.82892108268506\n",
      "epoch 737 iteration100, G Loss: 1.1602805852890015, D Loss: 1.340368390083313, alpha: 0.82892108268506\n",
      "epoch 738 iteration0, G Loss: 1.1107149124145508, D Loss: 1.2694947719573975, alpha: 0.8280685371933862\n",
      "epoch 738 iteration100, G Loss: 0.8876842856407166, D Loss: 1.3080840110778809, alpha: 0.8280685371933862\n",
      "epoch 739 iteration0, G Loss: 1.1517441272735596, D Loss: 1.3158369064331055, alpha: 0.8272126287719443\n",
      "epoch 739 iteration100, G Loss: 1.0583827495574951, D Loss: 1.302168369293213, alpha: 0.8272126287719443\n",
      "epoch 740 iteration0, G Loss: 1.1011008024215698, D Loss: 1.2346415519714355, alpha: 0.8263533529809949\n",
      "epoch 740 iteration100, G Loss: 1.1945632696151733, D Loss: 1.2655386924743652, alpha: 0.8263533529809949\n",
      "epoch 741 iteration0, G Loss: 0.9742372632026672, D Loss: 1.2950336933135986, alpha: 0.8254907054674968\n",
      "epoch 741 iteration100, G Loss: 1.1613810062408447, D Loss: 1.253526210784912, alpha: 0.8254907054674968\n",
      "epoch 742 iteration0, G Loss: 0.9146278500556946, D Loss: 1.295835256576538, alpha: 0.8246246819660374\n",
      "epoch 742 iteration100, G Loss: 0.9691531658172607, D Loss: 1.2623724937438965, alpha: 0.8246246819660374\n",
      "epoch 743 iteration0, G Loss: 0.9765856266021729, D Loss: 1.2984199523925781, alpha: 0.8237552782997641\n",
      "epoch 743 iteration100, G Loss: 1.2197991609573364, D Loss: 1.2758350372314453, alpha: 0.8237552782997641\n",
      "epoch 744 iteration0, G Loss: 1.042344331741333, D Loss: 1.2529520988464355, alpha: 0.8228824903813154\n",
      "epoch 744 iteration100, G Loss: 1.3947762250900269, D Loss: 1.1806426048278809, alpha: 0.8228824903813154\n",
      "epoch 745 iteration0, G Loss: 1.152915120124817, D Loss: 1.2839395999908447, alpha: 0.8220063142137535\n",
      "epoch 745 iteration100, G Loss: 1.043206810951233, D Loss: 1.271693229675293, alpha: 0.8220063142137535\n",
      "epoch 746 iteration0, G Loss: 0.9925442337989807, D Loss: 1.2804698944091797, alpha: 0.8211267458914967\n",
      "epoch 746 iteration100, G Loss: 1.357239842414856, D Loss: 1.1808347702026367, alpha: 0.8211267458914967\n",
      "epoch 747 iteration0, G Loss: 0.9248950481414795, D Loss: 1.2923482656478882, alpha: 0.8202437816012536\n",
      "epoch 747 iteration100, G Loss: 1.2090179920196533, D Loss: 1.3539083003997803, alpha: 0.8202437816012536\n",
      "epoch 748 iteration0, G Loss: 1.1220827102661133, D Loss: 1.2135536670684814, alpha: 0.8193574176229559\n",
      "epoch 748 iteration100, G Loss: 1.0467015504837036, D Loss: 1.245505690574646, alpha: 0.8193574176229559\n",
      "epoch 749 iteration0, G Loss: 1.2072007656097412, D Loss: 1.310686707496643, alpha: 0.8184676503306926\n",
      "epoch 749 iteration100, G Loss: 1.0268973112106323, D Loss: 1.2650604248046875, alpha: 0.8184676503306926\n",
      "epoch 750 iteration0, G Loss: 1.1764439344406128, D Loss: 1.3278982639312744, alpha: 0.8175744761936437\n",
      "epoch 750 iteration100, G Loss: 1.290838360786438, D Loss: 1.3372809886932373, alpha: 0.8175744761936437\n",
      "Saving content.\n",
      "epoch 751 iteration0, G Loss: 1.0434541702270508, D Loss: 1.2912684679031372, alpha: 0.8166778917770144\n",
      "epoch 751 iteration100, G Loss: 1.0578103065490723, D Loss: 1.2317801713943481, alpha: 0.8166778917770144\n",
      "epoch 752 iteration0, G Loss: 1.0504271984100342, D Loss: 1.279665470123291, alpha: 0.8157778937429687\n",
      "epoch 752 iteration100, G Loss: 0.9398468732833862, D Loss: 1.2983427047729492, alpha: 0.8157778937429687\n",
      "epoch 753 iteration0, G Loss: 1.0351147651672363, D Loss: 1.3724124431610107, alpha: 0.8148744788515628\n",
      "epoch 753 iteration100, G Loss: 1.0371315479278564, D Loss: 1.2690579891204834, alpha: 0.8148744788515628\n",
      "epoch 754 iteration0, G Loss: 1.0534214973449707, D Loss: 1.2614610195159912, alpha: 0.813967643961678\n",
      "epoch 754 iteration100, G Loss: 1.1048461198806763, D Loss: 1.2933502197265625, alpha: 0.813967643961678\n",
      "epoch 755 iteration0, G Loss: 1.1093339920043945, D Loss: 1.243713617324829, alpha: 0.8130573860319537\n",
      "epoch 755 iteration100, G Loss: 1.3456225395202637, D Loss: 1.396256446838379, alpha: 0.8130573860319537\n",
      "epoch 756 iteration0, G Loss: 1.1357108354568481, D Loss: 1.276652455329895, alpha: 0.812143702121719\n",
      "epoch 756 iteration100, G Loss: 1.0338152647018433, D Loss: 1.3170852661132812, alpha: 0.812143702121719\n",
      "epoch 757 iteration0, G Loss: 1.155937671661377, D Loss: 1.2632091045379639, alpha: 0.8112265893919247\n",
      "epoch 757 iteration100, G Loss: 1.3564395904541016, D Loss: 1.1641862392425537, alpha: 0.8112265893919247\n",
      "epoch 758 iteration0, G Loss: 1.1648228168487549, D Loss: 1.3138363361358643, alpha: 0.8103060451060722\n",
      "epoch 758 iteration100, G Loss: 1.0509268045425415, D Loss: 1.2655069828033447, alpha: 0.8103060451060722\n",
      "epoch 759 iteration0, G Loss: 1.2033896446228027, D Loss: 1.2254325151443481, alpha: 0.8093820666311443\n",
      "epoch 759 iteration100, G Loss: 0.9312854409217834, D Loss: 1.2271201610565186, alpha: 0.8093820666311443\n",
      "epoch 760 iteration0, G Loss: 0.892934262752533, D Loss: 1.3945257663726807, alpha: 0.8084546514385325\n",
      "epoch 760 iteration100, G Loss: 0.968102216720581, D Loss: 1.2654969692230225, alpha: 0.8084546514385325\n",
      "epoch 761 iteration0, G Loss: 1.012022614479065, D Loss: 1.2066148519515991, alpha: 0.8075237971049642\n",
      "epoch 761 iteration100, G Loss: 1.3532936573028564, D Loss: 1.283578634262085, alpha: 0.8075237971049642\n",
      "epoch 762 iteration0, G Loss: 0.9469487071037292, D Loss: 1.235391616821289, alpha: 0.8065895013134284\n",
      "epoch 762 iteration100, G Loss: 1.6564674377441406, D Loss: 1.195467233657837, alpha: 0.8065895013134284\n",
      "epoch 763 iteration0, G Loss: 1.3097981214523315, D Loss: 1.2098562717437744, alpha: 0.8056517618540996\n",
      "epoch 763 iteration100, G Loss: 0.9095819592475891, D Loss: 1.3054701089859009, alpha: 0.8056517618540996\n",
      "epoch 764 iteration0, G Loss: 0.9296299815177917, D Loss: 1.327070713043213, alpha: 0.8047105766252601\n",
      "epoch 764 iteration100, G Loss: 1.1922146081924438, D Loss: 1.2917563915252686, alpha: 0.8047105766252601\n",
      "epoch 765 iteration0, G Loss: 0.9946773052215576, D Loss: 1.2846589088439941, alpha: 0.8037659436342209\n",
      "epoch 765 iteration100, G Loss: 1.1679660081863403, D Loss: 1.2980756759643555, alpha: 0.8037659436342209\n",
      "epoch 766 iteration0, G Loss: 1.1635335683822632, D Loss: 1.2839542627334595, alpha: 0.8028178609982396\n",
      "epoch 766 iteration100, G Loss: 1.1723639965057373, D Loss: 1.3175716400146484, alpha: 0.8028178609982396\n",
      "epoch 767 iteration0, G Loss: 1.0563385486602783, D Loss: 1.2555159330368042, alpha: 0.8018663269454381\n",
      "epoch 767 iteration100, G Loss: 1.0277433395385742, D Loss: 1.3127679824829102, alpha: 0.8018663269454381\n",
      "epoch 768 iteration0, G Loss: 0.9869834780693054, D Loss: 1.2018938064575195, alpha: 0.8009113398157162\n",
      "epoch 768 iteration100, G Loss: 1.1314773559570312, D Loss: 1.3314164876937866, alpha: 0.8009113398157162\n",
      "epoch 769 iteration0, G Loss: 1.1767877340316772, D Loss: 1.3054566383361816, alpha: 0.7999528980616638\n",
      "epoch 769 iteration100, G Loss: 0.9683401584625244, D Loss: 1.290320634841919, alpha: 0.7999528980616638\n",
      "epoch 770 iteration0, G Loss: 0.9608402252197266, D Loss: 1.2438995838165283, alpha: 0.7989910002494707\n",
      "epoch 770 iteration100, G Loss: 1.0497101545333862, D Loss: 1.2272825241088867, alpha: 0.7989910002494707\n",
      "epoch 771 iteration0, G Loss: 1.1415172815322876, D Loss: 1.2867674827575684, alpha: 0.798025645059833\n",
      "epoch 771 iteration100, G Loss: 0.8728170990943909, D Loss: 1.2886264324188232, alpha: 0.798025645059833\n",
      "epoch 772 iteration0, G Loss: 1.0027936697006226, D Loss: 1.2470418214797974, alpha: 0.7970568312888584\n",
      "epoch 772 iteration100, G Loss: 1.061288833618164, D Loss: 1.3489222526550293, alpha: 0.7970568312888584\n",
      "epoch 773 iteration0, G Loss: 1.1149065494537354, D Loss: 1.2114523649215698, alpha: 0.796084557848966\n",
      "epoch 773 iteration100, G Loss: 1.2623294591903687, D Loss: 1.271141529083252, alpha: 0.796084557848966\n",
      "epoch 774 iteration0, G Loss: 1.0448139905929565, D Loss: 1.3465920686721802, alpha: 0.7951088237697856\n",
      "epoch 774 iteration100, G Loss: 1.187362551689148, D Loss: 1.2765092849731445, alpha: 0.7951088237697856\n",
      "epoch 775 iteration0, G Loss: 1.299892544746399, D Loss: 1.347554326057434, alpha: 0.7941296281990526\n",
      "epoch 775 iteration100, G Loss: 1.149389624595642, D Loss: 1.2377842664718628, alpha: 0.7941296281990526\n",
      "epoch 776 iteration0, G Loss: 1.0591446161270142, D Loss: 1.2902247905731201, alpha: 0.7931469704034991\n",
      "epoch 776 iteration100, G Loss: 1.385049819946289, D Loss: 1.2542893886566162, alpha: 0.7931469704034991\n",
      "epoch 777 iteration0, G Loss: 1.2495899200439453, D Loss: 1.3646621704101562, alpha: 0.7921608497697423\n",
      "epoch 777 iteration100, G Loss: 1.1981955766677856, D Loss: 1.296072006225586, alpha: 0.7921608497697423\n",
      "epoch 778 iteration0, G Loss: 1.1319111585617065, D Loss: 1.305532693862915, alpha: 0.7911712658051694\n",
      "epoch 778 iteration100, G Loss: 1.2051197290420532, D Loss: 1.2362730503082275, alpha: 0.7911712658051694\n",
      "epoch 779 iteration0, G Loss: 1.054370641708374, D Loss: 1.2628066539764404, alpha: 0.790178218138818\n",
      "epoch 779 iteration100, G Loss: 0.9473005533218384, D Loss: 1.2487584352493286, alpha: 0.790178218138818\n",
      "epoch 780 iteration0, G Loss: 1.0742413997650146, D Loss: 1.2789006233215332, alpha: 0.789181706522253\n",
      "epoch 780 iteration100, G Loss: 1.098484754562378, D Loss: 1.2491211891174316, alpha: 0.789181706522253\n",
      "epoch 781 iteration0, G Loss: 1.2977601289749146, D Loss: 1.397388219833374, alpha: 0.7881817308304386\n",
      "epoch 781 iteration100, G Loss: 1.1108309030532837, D Loss: 1.194193720817566, alpha: 0.7881817308304386\n",
      "epoch 782 iteration0, G Loss: 0.9468435645103455, D Loss: 1.2630784511566162, alpha: 0.7871782910626082\n",
      "epoch 782 iteration100, G Loss: 1.075644850730896, D Loss: 1.2679029703140259, alpha: 0.7871782910626082\n",
      "epoch 783 iteration0, G Loss: 1.0395312309265137, D Loss: 1.284913182258606, alpha: 0.7861713873431267\n",
      "epoch 783 iteration100, G Loss: 1.078255295753479, D Loss: 1.272347092628479, alpha: 0.7861713873431267\n",
      "epoch 784 iteration0, G Loss: 0.8056932091712952, D Loss: 1.195958137512207, alpha: 0.7851610199223515\n",
      "epoch 784 iteration100, G Loss: 1.183207631111145, D Loss: 1.2161428928375244, alpha: 0.7851610199223515\n",
      "epoch 785 iteration0, G Loss: 0.9952896237373352, D Loss: 1.2396551370620728, alpha: 0.7841471891774854\n",
      "epoch 785 iteration100, G Loss: 1.2119110822677612, D Loss: 1.2216218709945679, alpha: 0.7841471891774854\n",
      "epoch 786 iteration0, G Loss: 1.0727518796920776, D Loss: 1.2085089683532715, alpha: 0.7831298956134283\n",
      "epoch 786 iteration100, G Loss: 1.1726380586624146, D Loss: 1.2526532411575317, alpha: 0.7831298956134283\n",
      "epoch 787 iteration0, G Loss: 1.0599950551986694, D Loss: 1.3191269636154175, alpha: 0.7821091398636207\n",
      "epoch 787 iteration100, G Loss: 1.531673789024353, D Loss: 1.2197999954223633, alpha: 0.7821091398636207\n",
      "epoch 788 iteration0, G Loss: 1.1040316820144653, D Loss: 1.2953184843063354, alpha: 0.7810849226908843\n",
      "epoch 788 iteration100, G Loss: 1.0758925676345825, D Loss: 1.3067376613616943, alpha: 0.7810849226908843\n",
      "epoch 789 iteration0, G Loss: 1.1128292083740234, D Loss: 1.2320237159729004, alpha: 0.7800572449882548\n",
      "epoch 789 iteration100, G Loss: 1.169538974761963, D Loss: 1.2456319332122803, alpha: 0.7800572449882548\n",
      "epoch 790 iteration0, G Loss: 1.0838656425476074, D Loss: 1.286238193511963, alpha: 0.7790261077798122\n",
      "epoch 790 iteration100, G Loss: 1.1246788501739502, D Loss: 1.3182975053787231, alpha: 0.7790261077798122\n",
      "epoch 791 iteration0, G Loss: 0.9840914607048035, D Loss: 1.225020170211792, alpha: 0.7779915122215029\n",
      "epoch 791 iteration100, G Loss: 1.0040676593780518, D Loss: 1.2344210147857666, alpha: 0.7779915122215029\n",
      "epoch 792 iteration0, G Loss: 0.9273650646209717, D Loss: 1.2430425882339478, alpha: 0.7769534596019573\n",
      "epoch 792 iteration100, G Loss: 1.1802372932434082, D Loss: 1.3236007690429688, alpha: 0.7769534596019573\n",
      "epoch 793 iteration0, G Loss: 1.0828702449798584, D Loss: 1.2570382356643677, alpha: 0.7759119513433005\n",
      "epoch 793 iteration100, G Loss: 1.0535181760787964, D Loss: 1.1889994144439697, alpha: 0.7759119513433005\n",
      "epoch 794 iteration0, G Loss: 1.2525345087051392, D Loss: 1.2763688564300537, alpha: 0.7748669890019579\n",
      "epoch 794 iteration100, G Loss: 0.956328809261322, D Loss: 1.227239966392517, alpha: 0.7748669890019579\n",
      "epoch 795 iteration0, G Loss: 1.1465260982513428, D Loss: 1.2586982250213623, alpha: 0.7738185742694538\n",
      "epoch 795 iteration100, G Loss: 1.1746079921722412, D Loss: 1.3458842039108276, alpha: 0.7738185742694538\n",
      "epoch 796 iteration0, G Loss: 1.0710651874542236, D Loss: 1.2545816898345947, alpha: 0.7727667089732031\n",
      "epoch 796 iteration100, G Loss: 1.1525236368179321, D Loss: 1.3500783443450928, alpha: 0.7727667089732031\n",
      "epoch 797 iteration0, G Loss: 0.9332931041717529, D Loss: 1.260324239730835, alpha: 0.7717113950772974\n",
      "epoch 797 iteration100, G Loss: 1.0544323921203613, D Loss: 1.2067209482192993, alpha: 0.7717113950772974\n",
      "epoch 798 iteration0, G Loss: 1.0922605991363525, D Loss: 1.3236362934112549, alpha: 0.7706526346832835\n",
      "epoch 798 iteration100, G Loss: 1.1302274465560913, D Loss: 1.2498033046722412, alpha: 0.7706526346832835\n",
      "epoch 799 iteration0, G Loss: 1.084624171257019, D Loss: 1.3662590980529785, alpha: 0.7695904300309351\n",
      "epoch 799 iteration100, G Loss: 1.2591593265533447, D Loss: 1.2526905536651611, alpha: 0.7695904300309351\n",
      "epoch 800 iteration0, G Loss: 0.9705270528793335, D Loss: 1.2586928606033325, alpha: 0.7685247834990176\n",
      "epoch 800 iteration100, G Loss: 1.2795844078063965, D Loss: 1.2389146089553833, alpha: 0.7685247834990176\n",
      "Saving content.\n",
      "epoch 801 iteration0, G Loss: 1.1016452312469482, D Loss: 1.2560038566589355, alpha: 0.7674556976060448\n",
      "epoch 801 iteration100, G Loss: 1.1608284711837769, D Loss: 1.245029091835022, alpha: 0.7674556976060448\n",
      "epoch 802 iteration0, G Loss: 1.0067545175552368, D Loss: 1.233981966972351, alpha: 0.7663831750110291\n",
      "epoch 802 iteration100, G Loss: 1.1239230632781982, D Loss: 1.282581090927124, alpha: 0.7663831750110291\n",
      "epoch 803 iteration0, G Loss: 1.2071661949157715, D Loss: 1.2161505222320557, alpha: 0.7653072185142237\n",
      "epoch 803 iteration100, G Loss: 1.2535258531570435, D Loss: 1.3314144611358643, alpha: 0.7653072185142237\n",
      "epoch 804 iteration0, G Loss: 1.1668847799301147, D Loss: 1.3199963569641113, alpha: 0.7642278310578563\n",
      "epoch 804 iteration100, G Loss: 1.0111103057861328, D Loss: 1.2797412872314453, alpha: 0.7642278310578563\n",
      "epoch 805 iteration0, G Loss: 1.2380571365356445, D Loss: 1.3348970413208008, alpha: 0.7631450157268554\n",
      "epoch 805 iteration100, G Loss: 1.3582749366760254, D Loss: 1.2424826622009277, alpha: 0.7631450157268554\n",
      "epoch 806 iteration0, G Loss: 1.1437511444091797, D Loss: 1.253444790840149, alpha: 0.7620587757495692\n",
      "epoch 806 iteration100, G Loss: 0.9551123380661011, D Loss: 1.286221981048584, alpha: 0.7620587757495692\n",
      "epoch 807 iteration0, G Loss: 1.117156744003296, D Loss: 1.2954914569854736, alpha: 0.7609691144984745\n",
      "epoch 807 iteration100, G Loss: 1.1477084159851074, D Loss: 1.215336799621582, alpha: 0.7609691144984745\n",
      "epoch 808 iteration0, G Loss: 1.1847251653671265, D Loss: 1.22464919090271, alpha: 0.7598760354908782\n",
      "epoch 808 iteration100, G Loss: 1.1016948223114014, D Loss: 1.3783576488494873, alpha: 0.7598760354908782\n",
      "epoch 809 iteration0, G Loss: 1.1248586177825928, D Loss: 1.144728183746338, alpha: 0.7587795423896097\n",
      "epoch 809 iteration100, G Loss: 1.4002505540847778, D Loss: 1.3276374340057373, alpha: 0.7587795423896097\n",
      "epoch 810 iteration0, G Loss: 1.063621163368225, D Loss: 1.2604130506515503, alpha: 0.7576796390037048\n",
      "epoch 810 iteration100, G Loss: 1.2411236763000488, D Loss: 1.2427695989608765, alpha: 0.7576796390037048\n",
      "epoch 811 iteration0, G Loss: 1.0965509414672852, D Loss: 1.2010444402694702, alpha: 0.7565763292890808\n",
      "epoch 811 iteration100, G Loss: 0.9401681423187256, D Loss: 1.2428359985351562, alpha: 0.7565763292890808\n",
      "epoch 812 iteration0, G Loss: 0.9691412448883057, D Loss: 1.337111234664917, alpha: 0.7554696173492006\n",
      "epoch 812 iteration100, G Loss: 0.9682167768478394, D Loss: 1.2556153535842896, alpha: 0.7554696173492006\n",
      "epoch 813 iteration0, G Loss: 1.126277208328247, D Loss: 1.2539646625518799, alpha: 0.7543595074357307\n",
      "epoch 813 iteration100, G Loss: 0.9304121136665344, D Loss: 1.3045573234558105, alpha: 0.7543595074357307\n",
      "epoch 814 iteration0, G Loss: 1.1771100759506226, D Loss: 1.2279795408248901, alpha: 0.7532460039491866\n",
      "epoch 814 iteration100, G Loss: 1.0542502403259277, D Loss: 1.179766058921814, alpha: 0.7532460039491866\n",
      "epoch 815 iteration0, G Loss: 1.0856969356536865, D Loss: 1.253641128540039, alpha: 0.7521291114395702\n",
      "epoch 815 iteration100, G Loss: 1.0081124305725098, D Loss: 1.2717630863189697, alpha: 0.7521291114395702\n",
      "epoch 816 iteration0, G Loss: 1.0699670314788818, D Loss: 1.2519464492797852, alpha: 0.7510088346069963\n",
      "epoch 816 iteration100, G Loss: 1.0222704410552979, D Loss: 1.2781734466552734, alpha: 0.7510088346069963\n",
      "epoch 817 iteration0, G Loss: 1.0410823822021484, D Loss: 1.3129502534866333, alpha: 0.7498851783023105\n",
      "epoch 817 iteration100, G Loss: 1.17435622215271, D Loss: 1.260447382926941, alpha: 0.7498851783023105\n",
      "epoch 818 iteration0, G Loss: 1.11485755443573, D Loss: 1.2996046543121338, alpha: 0.7487581475276954\n",
      "epoch 818 iteration100, G Loss: 1.114517092704773, D Loss: 1.2343616485595703, alpha: 0.7487581475276954\n",
      "epoch 819 iteration0, G Loss: 1.1408145427703857, D Loss: 1.28975248336792, alpha: 0.7476277474372675\n",
      "epoch 819 iteration100, G Loss: 1.3029438257217407, D Loss: 1.429353952407837, alpha: 0.7476277474372675\n",
      "epoch 820 iteration0, G Loss: 0.9831791520118713, D Loss: 1.3063673973083496, alpha: 0.7464939833376623\n",
      "epoch 820 iteration100, G Loss: 1.039797067642212, D Loss: 1.2138340473175049, alpha: 0.7464939833376623\n",
      "epoch 821 iteration0, G Loss: 1.1801466941833496, D Loss: 1.3040151596069336, alpha: 0.7453568606886103\n",
      "epoch 821 iteration100, G Loss: 1.2133663892745972, D Loss: 1.3089038133621216, alpha: 0.7453568606886103\n",
      "epoch 822 iteration0, G Loss: 0.9930955171585083, D Loss: 1.3095780611038208, alpha: 0.7442163851035011\n",
      "epoch 822 iteration100, G Loss: 0.9063600301742554, D Loss: 1.2978442907333374, alpha: 0.7442163851035011\n",
      "epoch 823 iteration0, G Loss: 1.1107169389724731, D Loss: 1.1502633094787598, alpha: 0.7430725623499372\n",
      "epoch 823 iteration100, G Loss: 1.1172000169754028, D Loss: 1.2460765838623047, alpha: 0.7430725623499372\n",
      "epoch 824 iteration0, G Loss: 0.9283658266067505, D Loss: 1.295358419418335, alpha: 0.7419253983502743\n",
      "epoch 824 iteration100, G Loss: 2.1236796379089355, D Loss: 1.2553414106369019, alpha: 0.7419253983502743\n",
      "epoch 825 iteration0, G Loss: 1.0669217109680176, D Loss: 1.1982930898666382, alpha: 0.7407748991821539\n",
      "epoch 825 iteration100, G Loss: 1.4038385152816772, D Loss: 1.2863843441009521, alpha: 0.7407748991821539\n",
      "epoch 826 iteration0, G Loss: 1.0825765132904053, D Loss: 1.2521237134933472, alpha: 0.739621071079022\n",
      "epoch 826 iteration100, G Loss: 0.7272861003875732, D Loss: 1.4493145942687988, alpha: 0.739621071079022\n",
      "epoch 827 iteration0, G Loss: 0.8583352565765381, D Loss: 1.2773802280426025, alpha: 0.7384639204306358\n",
      "epoch 827 iteration100, G Loss: 1.0591541528701782, D Loss: 1.2345881462097168, alpha: 0.7384639204306358\n",
      "epoch 828 iteration0, G Loss: 0.9527193903923035, D Loss: 1.2508516311645508, alpha: 0.7373034537835592\n",
      "epoch 828 iteration100, G Loss: 1.0436757802963257, D Loss: 1.167376160621643, alpha: 0.7373034537835592\n",
      "epoch 829 iteration0, G Loss: 1.0017638206481934, D Loss: 1.2715039253234863, alpha: 0.7361396778416479\n",
      "epoch 829 iteration100, G Loss: 0.9644750356674194, D Loss: 1.3137123584747314, alpha: 0.7361396778416479\n",
      "epoch 830 iteration0, G Loss: 1.1424845457077026, D Loss: 1.3069884777069092, alpha: 0.7349725994665187\n",
      "epoch 830 iteration100, G Loss: 1.5617786645889282, D Loss: 1.2699055671691895, alpha: 0.7349725994665187\n",
      "epoch 831 iteration0, G Loss: 0.9650018811225891, D Loss: 1.2563095092773438, alpha: 0.7338022256780099\n",
      "epoch 831 iteration100, G Loss: 1.3011378049850464, D Loss: 1.1940590143203735, alpha: 0.7338022256780099\n",
      "epoch 832 iteration0, G Loss: 1.032804012298584, D Loss: 1.2454780340194702, alpha: 0.7326285636546261\n",
      "epoch 832 iteration100, G Loss: 1.2661393880844116, D Loss: 1.297976016998291, alpha: 0.7326285636546261\n",
      "epoch 833 iteration0, G Loss: 1.0326141119003296, D Loss: 1.297999382019043, alpha: 0.7314516207339741\n",
      "epoch 833 iteration100, G Loss: 1.1298253536224365, D Loss: 1.1691365242004395, alpha: 0.7314516207339741\n",
      "epoch 834 iteration0, G Loss: 0.9333212375640869, D Loss: 1.1841776371002197, alpha: 0.7302714044131815\n",
      "epoch 834 iteration100, G Loss: 1.2981141805648804, D Loss: 1.2334518432617188, alpha: 0.7302714044131815\n",
      "epoch 835 iteration0, G Loss: 1.1889350414276123, D Loss: 1.1884939670562744, alpha: 0.7290879223493065\n",
      "epoch 835 iteration100, G Loss: 1.289941430091858, D Loss: 1.2894458770751953, alpha: 0.7290879223493065\n",
      "epoch 836 iteration0, G Loss: 1.1562530994415283, D Loss: 1.3211326599121094, alpha: 0.7279011823597308\n",
      "epoch 836 iteration100, G Loss: 1.4477102756500244, D Loss: 1.1909286975860596, alpha: 0.7279011823597308\n",
      "epoch 837 iteration0, G Loss: 1.0319571495056152, D Loss: 1.2424135208129883, alpha: 0.7267111924225421\n",
      "epoch 837 iteration100, G Loss: 1.1910072565078735, D Loss: 1.320087194442749, alpha: 0.7267111924225421\n",
      "epoch 838 iteration0, G Loss: 0.943434476852417, D Loss: 1.2482044696807861, alpha: 0.7255179606769017\n",
      "epoch 838 iteration100, G Loss: 1.1322821378707886, D Loss: 1.2443299293518066, alpha: 0.7255179606769017\n",
      "epoch 839 iteration0, G Loss: 1.041350245475769, D Loss: 1.2192344665527344, alpha: 0.7243214954233987\n",
      "epoch 839 iteration100, G Loss: 1.3397222757339478, D Loss: 1.2117469310760498, alpha: 0.7243214954233987\n",
      "epoch 840 iteration0, G Loss: 1.1897333860397339, D Loss: 1.2463865280151367, alpha: 0.7231218051243897\n",
      "epoch 840 iteration100, G Loss: 1.1005682945251465, D Loss: 1.1486177444458008, alpha: 0.7231218051243897\n",
      "epoch 841 iteration0, G Loss: 1.0358645915985107, D Loss: 1.234886884689331, alpha: 0.721918898404327\n",
      "epoch 841 iteration100, G Loss: 1.1009206771850586, D Loss: 1.2861326932907104, alpha: 0.721918898404327\n",
      "epoch 842 iteration0, G Loss: 1.1192235946655273, D Loss: 1.2207282781600952, alpha: 0.7207127840500687\n",
      "epoch 842 iteration100, G Loss: 1.092254638671875, D Loss: 1.2203187942504883, alpha: 0.7207127840500687\n",
      "epoch 843 iteration0, G Loss: 1.0097877979278564, D Loss: 1.2748767137527466, alpha: 0.7195034710111788\n",
      "epoch 843 iteration100, G Loss: 1.2865662574768066, D Loss: 1.2292413711547852, alpha: 0.7195034710111788\n",
      "epoch 844 iteration0, G Loss: 1.0195269584655762, D Loss: 1.2554699182510376, alpha: 0.7182909684002099\n",
      "epoch 844 iteration100, G Loss: 0.9408460855484009, D Loss: 1.2489638328552246, alpha: 0.7182909684002099\n",
      "epoch 845 iteration0, G Loss: 0.8791537880897522, D Loss: 1.258251667022705, alpha: 0.7170752854929725\n",
      "epoch 845 iteration100, G Loss: 1.2152656316757202, D Loss: 1.2609975337982178, alpha: 0.7170752854929725\n",
      "epoch 846 iteration0, G Loss: 1.1645063161849976, D Loss: 1.3274739980697632, alpha: 0.7158564317287897\n",
      "epoch 846 iteration100, G Loss: 1.2372775077819824, D Loss: 1.2683489322662354, alpha: 0.7158564317287897\n",
      "epoch 847 iteration0, G Loss: 0.9669047594070435, D Loss: 1.2248992919921875, alpha: 0.7146344167107368\n",
      "epoch 847 iteration100, G Loss: 1.26541268825531, D Loss: 1.1746790409088135, alpha: 0.7146344167107368\n",
      "epoch 848 iteration0, G Loss: 1.0418099164962769, D Loss: 1.2757729291915894, alpha: 0.7134092502058658\n",
      "epoch 848 iteration100, G Loss: 1.0892480611801147, D Loss: 1.3003343343734741, alpha: 0.7134092502058658\n",
      "epoch 849 iteration0, G Loss: 1.0019716024398804, D Loss: 1.2667367458343506, alpha: 0.712180942145415\n",
      "epoch 849 iteration100, G Loss: 1.1821187734603882, D Loss: 1.340193748474121, alpha: 0.712180942145415\n",
      "epoch 850 iteration0, G Loss: 1.1078424453735352, D Loss: 1.105553388595581, alpha: 0.7109495026250039\n",
      "epoch 850 iteration100, G Loss: 1.0131672620773315, D Loss: 1.3286393880844116, alpha: 0.7109495026250039\n",
      "Saving content.\n",
      "epoch 851 iteration0, G Loss: 1.082213044166565, D Loss: 1.248495101928711, alpha: 0.709714941904811\n",
      "epoch 851 iteration100, G Loss: 1.0123796463012695, D Loss: 1.2942790985107422, alpha: 0.709714941904811\n",
      "epoch 852 iteration0, G Loss: 1.1093201637268066, D Loss: 1.241795301437378, alpha: 0.708477270409738\n",
      "epoch 852 iteration100, G Loss: 1.4563887119293213, D Loss: 1.1481355428695679, alpha: 0.708477270409738\n",
      "epoch 853 iteration0, G Loss: 0.9071866273880005, D Loss: 1.2598305940628052, alpha: 0.7072364987295572\n",
      "epoch 853 iteration100, G Loss: 1.0152260065078735, D Loss: 1.2639868259429932, alpha: 0.7072364987295572\n",
      "epoch 854 iteration0, G Loss: 0.9902773499488831, D Loss: 1.1998170614242554, alpha: 0.7059926376190437\n",
      "epoch 854 iteration100, G Loss: 1.4603718519210815, D Loss: 1.160921335220337, alpha: 0.7059926376190437\n",
      "epoch 855 iteration0, G Loss: 1.0687713623046875, D Loss: 1.2108049392700195, alpha: 0.7047456979980911\n",
      "epoch 855 iteration100, G Loss: 1.2757164239883423, D Loss: 1.2448382377624512, alpha: 0.7047456979980911\n",
      "epoch 856 iteration0, G Loss: 1.117489218711853, D Loss: 1.2243757247924805, alpha: 0.7034956909518111\n",
      "epoch 856 iteration100, G Loss: 1.2248032093048096, D Loss: 1.30137038230896, alpha: 0.7034956909518111\n",
      "epoch 857 iteration0, G Loss: 1.0170265436172485, D Loss: 1.2789175510406494, alpha: 0.7022426277306182\n",
      "epoch 857 iteration100, G Loss: 1.131241798400879, D Loss: 1.2657697200775146, alpha: 0.7022426277306182\n",
      "epoch 858 iteration0, G Loss: 1.014020562171936, D Loss: 1.2053850889205933, alpha: 0.7009865197502964\n",
      "epoch 858 iteration100, G Loss: 1.0230035781860352, D Loss: 1.193556785583496, alpha: 0.7009865197502964\n",
      "epoch 859 iteration0, G Loss: 1.1570043563842773, D Loss: 1.309131145477295, alpha: 0.6997273785920499\n",
      "epoch 859 iteration100, G Loss: 1.115610122680664, D Loss: 1.331542730331421, alpha: 0.6997273785920499\n",
      "epoch 860 iteration0, G Loss: 0.995153546333313, D Loss: 1.3351895809173584, alpha: 0.6984652160025386\n",
      "epoch 860 iteration100, G Loss: 0.966181755065918, D Loss: 1.3103854656219482, alpha: 0.6984652160025386\n",
      "epoch 861 iteration0, G Loss: 1.0935943126678467, D Loss: 1.2568483352661133, alpha: 0.6972000438938954\n",
      "epoch 861 iteration100, G Loss: 1.4475212097167969, D Loss: 1.2281205654144287, alpha: 0.6972000438938954\n",
      "epoch 862 iteration0, G Loss: 0.9932423233985901, D Loss: 1.1610835790634155, alpha: 0.6959318743437266\n",
      "epoch 862 iteration100, G Loss: 1.2922754287719727, D Loss: 1.1953036785125732, alpha: 0.6959318743437266\n",
      "epoch 863 iteration0, G Loss: 1.0517784357070923, D Loss: 1.2268283367156982, alpha: 0.6946607195950969\n",
      "epoch 863 iteration100, G Loss: 1.34755277633667, D Loss: 1.2172683477401733, alpha: 0.6946607195950969\n",
      "epoch 864 iteration0, G Loss: 0.942858099937439, D Loss: 1.2683594226837158, alpha: 0.6933865920564957\n",
      "epoch 864 iteration100, G Loss: 1.1818515062332153, D Loss: 1.2696985006332397, alpha: 0.6933865920564957\n",
      "epoch 865 iteration0, G Loss: 0.9638437032699585, D Loss: 1.2687232494354248, alpha: 0.6921095043017881\n",
      "epoch 865 iteration100, G Loss: 1.1138956546783447, D Loss: 1.2720260620117188, alpha: 0.6921095043017881\n",
      "epoch 866 iteration0, G Loss: 0.9499050378799438, D Loss: 1.2776997089385986, alpha: 0.6908294690701471\n",
      "epoch 866 iteration100, G Loss: 1.0038225650787354, D Loss: 1.2365937232971191, alpha: 0.6908294690701471\n",
      "epoch 867 iteration0, G Loss: 0.9886340498924255, D Loss: 1.2855310440063477, alpha: 0.6895464992659683\n",
      "epoch 867 iteration100, G Loss: 1.3097918033599854, D Loss: 1.2138653993606567, alpha: 0.6895464992659683\n",
      "epoch 868 iteration0, G Loss: 1.2144050598144531, D Loss: 1.2026269435882568, alpha: 0.6882606079587694\n",
      "epoch 868 iteration100, G Loss: 0.9388547539710999, D Loss: 1.3541302680969238, alpha: 0.6882606079587694\n",
      "epoch 869 iteration0, G Loss: 1.003853440284729, D Loss: 1.2951894998550415, alpha: 0.6869718083830699\n",
      "epoch 869 iteration100, G Loss: 1.3713123798370361, D Loss: 1.2799105644226074, alpha: 0.6869718083830699\n",
      "epoch 870 iteration0, G Loss: 1.0446702241897583, D Loss: 1.2718545198440552, alpha: 0.6856801139382539\n",
      "epoch 870 iteration100, G Loss: 0.8816981911659241, D Loss: 1.2171024084091187, alpha: 0.6856801139382539\n",
      "epoch 871 iteration0, G Loss: 1.024653673171997, D Loss: 1.2784616947174072, alpha: 0.6843855381884151\n",
      "epoch 871 iteration100, G Loss: 0.9999792575836182, D Loss: 1.2599601745605469, alpha: 0.6843855381884151\n",
      "epoch 872 iteration0, G Loss: 0.9963648915290833, D Loss: 1.2629508972167969, alpha: 0.683088094862185\n",
      "epoch 872 iteration100, G Loss: 1.2060976028442383, D Loss: 1.2396880388259888, alpha: 0.683088094862185\n",
      "epoch 873 iteration0, G Loss: 1.1202315092086792, D Loss: 1.243560552597046, alpha: 0.6817877978525417\n",
      "epoch 873 iteration100, G Loss: 1.0422203540802002, D Loss: 1.1453568935394287, alpha: 0.6817877978525417\n",
      "epoch 874 iteration0, G Loss: 1.108406901359558, D Loss: 1.3406342267990112, alpha: 0.6804846612166018\n",
      "epoch 874 iteration100, G Loss: 1.0379079580307007, D Loss: 1.343762755393982, alpha: 0.6804846612166018\n",
      "epoch 875 iteration0, G Loss: 1.1258611679077148, D Loss: 1.2100542783737183, alpha: 0.679178699175393\n",
      "epoch 875 iteration100, G Loss: 1.140685796737671, D Loss: 1.3025894165039062, alpha: 0.679178699175393\n",
      "epoch 876 iteration0, G Loss: 1.1787806749343872, D Loss: 1.2887954711914062, alpha: 0.6778699261136105\n",
      "epoch 876 iteration100, G Loss: 1.038902997970581, D Loss: 1.3328115940093994, alpha: 0.6778699261136105\n",
      "epoch 877 iteration0, G Loss: 1.117600917816162, D Loss: 1.2617247104644775, alpha: 0.6765583565793538\n",
      "epoch 877 iteration100, G Loss: 1.200426697731018, D Loss: 1.1744592189788818, alpha: 0.6765583565793538\n",
      "epoch 878 iteration0, G Loss: 1.0621612071990967, D Loss: 1.1979551315307617, alpha: 0.6752440052838453\n",
      "epoch 878 iteration100, G Loss: 1.1577017307281494, D Loss: 1.2206758260726929, alpha: 0.6752440052838453\n",
      "epoch 879 iteration0, G Loss: 1.1758042573928833, D Loss: 1.2506392002105713, alpha: 0.6739268871011302\n",
      "epoch 879 iteration100, G Loss: 1.1110652685165405, D Loss: 1.1876319646835327, alpha: 0.6739268871011302\n",
      "epoch 880 iteration0, G Loss: 1.0222480297088623, D Loss: 1.31410551071167, alpha: 0.6726070170677604\n",
      "epoch 880 iteration100, G Loss: 1.107802391052246, D Loss: 1.2507842779159546, alpha: 0.6726070170677604\n",
      "epoch 881 iteration0, G Loss: 1.0132391452789307, D Loss: 1.3073153495788574, alpha: 0.671284410382456\n",
      "epoch 881 iteration100, G Loss: 1.07334566116333, D Loss: 1.1949020624160767, alpha: 0.671284410382456\n",
      "epoch 882 iteration0, G Loss: 1.4024531841278076, D Loss: 1.3450534343719482, alpha: 0.6699590824057517\n",
      "epoch 882 iteration100, G Loss: 1.0234391689300537, D Loss: 1.319630742073059, alpha: 0.6699590824057517\n",
      "epoch 883 iteration0, G Loss: 1.1194028854370117, D Loss: 1.2291351556777954, alpha: 0.6686310486596224\n",
      "epoch 883 iteration100, G Loss: 0.911973774433136, D Loss: 1.257749319076538, alpha: 0.6686310486596224\n",
      "epoch 884 iteration0, G Loss: 0.947081983089447, D Loss: 1.2942651510238647, alpha: 0.6673003248270916\n",
      "epoch 884 iteration100, G Loss: 1.0217589139938354, D Loss: 1.3565878868103027, alpha: 0.6673003248270916\n",
      "epoch 885 iteration0, G Loss: 1.234876036643982, D Loss: 1.2208675146102905, alpha: 0.6659669267518202\n",
      "epoch 885 iteration100, G Loss: 1.2594685554504395, D Loss: 1.2856464385986328, alpha: 0.6659669267518202\n",
      "epoch 886 iteration0, G Loss: 0.9977494478225708, D Loss: 1.1809556484222412, alpha: 0.6646308704376769\n",
      "epoch 886 iteration100, G Loss: 1.1528414487838745, D Loss: 1.2279908657073975, alpha: 0.6646308704376769\n",
      "epoch 887 iteration0, G Loss: 1.240883231163025, D Loss: 1.2803590297698975, alpha: 0.6632921720482895\n",
      "epoch 887 iteration100, G Loss: 1.2370198965072632, D Loss: 1.1993348598480225, alpha: 0.6632921720482895\n",
      "epoch 888 iteration0, G Loss: 1.051102638244629, D Loss: 1.3250946998596191, alpha: 0.6619508479065779\n",
      "epoch 888 iteration100, G Loss: 0.8024567365646362, D Loss: 1.3849146366119385, alpha: 0.6619508479065779\n",
      "epoch 889 iteration0, G Loss: 0.9087411165237427, D Loss: 1.2530097961425781, alpha: 0.6606069144942676\n",
      "epoch 889 iteration100, G Loss: 0.9926315546035767, D Loss: 1.251645803451538, alpha: 0.6606069144942676\n",
      "epoch 890 iteration0, G Loss: 0.8817389011383057, D Loss: 1.2409565448760986, alpha: 0.6592603884513855\n",
      "epoch 890 iteration100, G Loss: 0.9827849268913269, D Loss: 1.250564455986023, alpha: 0.6592603884513855\n",
      "epoch 891 iteration0, G Loss: 1.043318271636963, D Loss: 1.1989976167678833, alpha: 0.6579112865757341\n",
      "epoch 891 iteration100, G Loss: 1.0619724988937378, D Loss: 1.2679065465927124, alpha: 0.6579112865757341\n",
      "epoch 892 iteration0, G Loss: 0.849885106086731, D Loss: 1.3316527605056763, alpha: 0.6565596258223503\n",
      "epoch 892 iteration100, G Loss: 1.1434094905853271, D Loss: 1.209611177444458, alpha: 0.6565596258223503\n",
      "epoch 893 iteration0, G Loss: 1.0192277431488037, D Loss: 1.2614206075668335, alpha: 0.6552054233029428\n",
      "epoch 893 iteration100, G Loss: 0.8514314889907837, D Loss: 1.2298990488052368, alpha: 0.6552054233029428\n",
      "epoch 894 iteration0, G Loss: 1.0603463649749756, D Loss: 1.2940068244934082, alpha: 0.6538486962853111\n",
      "epoch 894 iteration100, G Loss: 1.335916519165039, D Loss: 1.2361363172531128, alpha: 0.6538486962853111\n",
      "epoch 895 iteration0, G Loss: 1.1190624237060547, D Loss: 1.2279605865478516, alpha: 0.6524894621927444\n",
      "epoch 895 iteration100, G Loss: 1.007838487625122, D Loss: 1.2167669534683228, alpha: 0.6524894621927444\n",
      "epoch 896 iteration0, G Loss: 0.993757963180542, D Loss: 1.2126669883728027, alpha: 0.6511277386034049\n",
      "epoch 896 iteration100, G Loss: 1.2462717294692993, D Loss: 1.2169911861419678, alpha: 0.6511277386034049\n",
      "epoch 897 iteration0, G Loss: 0.7942047715187073, D Loss: 1.3554266691207886, alpha: 0.649763543249688\n",
      "epoch 897 iteration100, G Loss: 1.0219602584838867, D Loss: 1.2782979011535645, alpha: 0.649763543249688\n",
      "epoch 898 iteration0, G Loss: 0.8489126563072205, D Loss: 1.3057289123535156, alpha: 0.6483968940175651\n",
      "epoch 898 iteration100, G Loss: 1.2768869400024414, D Loss: 1.3261218070983887, alpha: 0.6483968940175651\n",
      "epoch 899 iteration0, G Loss: 1.0049189329147339, D Loss: 1.2630364894866943, alpha: 0.6470278089459085\n",
      "epoch 899 iteration100, G Loss: 1.0565615892410278, D Loss: 1.2427772283554077, alpha: 0.6470278089459085\n",
      "epoch 900 iteration0, G Loss: 1.0305736064910889, D Loss: 1.2908763885498047, alpha: 0.6456563062257954\n",
      "epoch 900 iteration100, G Loss: 1.0972484350204468, D Loss: 1.321533441543579, alpha: 0.6456563062257954\n",
      "Saving content.\n",
      "epoch 901 iteration0, G Loss: 1.0604255199432373, D Loss: 1.2472137212753296, alpha: 0.6442824041997939\n",
      "epoch 901 iteration100, G Loss: 1.033830165863037, D Loss: 1.2281595468521118, alpha: 0.6442824041997939\n",
      "epoch 902 iteration0, G Loss: 1.0367274284362793, D Loss: 1.1927435398101807, alpha: 0.642906121361229\n",
      "epoch 902 iteration100, G Loss: 0.990043044090271, D Loss: 1.267257571220398, alpha: 0.642906121361229\n",
      "epoch 903 iteration0, G Loss: 0.9742192625999451, D Loss: 1.2369006872177124, alpha: 0.6415274763534318\n",
      "epoch 903 iteration100, G Loss: 0.8847728371620178, D Loss: 1.2948572635650635, alpha: 0.6415274763534318\n",
      "epoch 904 iteration0, G Loss: 0.8680469989776611, D Loss: 1.2415812015533447, alpha: 0.6401464879689667\n",
      "epoch 904 iteration100, G Loss: 1.2387570142745972, D Loss: 1.2691521644592285, alpha: 0.6401464879689667\n",
      "epoch 905 iteration0, G Loss: 1.1943272352218628, D Loss: 1.1898880004882812, alpha: 0.638763175148842\n",
      "epoch 905 iteration100, G Loss: 1.2814611196517944, D Loss: 1.2864348888397217, alpha: 0.638763175148842\n",
      "epoch 906 iteration0, G Loss: 0.9771629571914673, D Loss: 1.2979798316955566, alpha: 0.6373775569816997\n",
      "epoch 906 iteration100, G Loss: 1.2178702354431152, D Loss: 1.27914297580719, alpha: 0.6373775569816997\n",
      "epoch 907 iteration0, G Loss: 1.1638942956924438, D Loss: 1.2534215450286865, alpha: 0.6359896527029888\n",
      "epoch 907 iteration100, G Loss: 0.8478243350982666, D Loss: 1.2909986972808838, alpha: 0.6359896527029888\n",
      "epoch 908 iteration0, G Loss: 1.2334425449371338, D Loss: 1.2355155944824219, alpha: 0.6345994816941167\n",
      "epoch 908 iteration100, G Loss: 1.3131048679351807, D Loss: 1.14132821559906, alpha: 0.6345994816941167\n",
      "epoch 909 iteration0, G Loss: 1.0331424474716187, D Loss: 1.2730932235717773, alpha: 0.6332070634815847\n",
      "epoch 909 iteration100, G Loss: 1.2487417459487915, D Loss: 1.2694709300994873, alpha: 0.6332070634815847\n",
      "epoch 910 iteration0, G Loss: 1.0566538572311401, D Loss: 1.2207322120666504, alpha: 0.6318124177361018\n",
      "epoch 910 iteration100, G Loss: 0.9830504059791565, D Loss: 1.1689279079437256, alpha: 0.6318124177361018\n",
      "epoch 911 iteration0, G Loss: 1.0428532361984253, D Loss: 1.213221549987793, alpha: 0.630415564271682\n",
      "epoch 911 iteration100, G Loss: 1.225157618522644, D Loss: 1.2648676633834839, alpha: 0.630415564271682\n",
      "epoch 912 iteration0, G Loss: 1.1035913228988647, D Loss: 1.1588822603225708, alpha: 0.6290165230447224\n",
      "epoch 912 iteration100, G Loss: 1.2764745950698853, D Loss: 1.2515134811401367, alpha: 0.6290165230447224\n",
      "epoch 913 iteration0, G Loss: 1.0479607582092285, D Loss: 1.2458751201629639, alpha: 0.6276153141530625\n",
      "epoch 913 iteration100, G Loss: 1.0864313840866089, D Loss: 1.24203622341156, alpha: 0.6276153141530625\n",
      "epoch 914 iteration0, G Loss: 1.0749127864837646, D Loss: 1.3283941745758057, alpha: 0.6262119578350229\n",
      "epoch 914 iteration100, G Loss: 0.9648764729499817, D Loss: 1.2476298809051514, alpha: 0.6262119578350229\n",
      "epoch 915 iteration0, G Loss: 1.201158881187439, D Loss: 1.2379928827285767, alpha: 0.6248064744684292\n",
      "epoch 915 iteration100, G Loss: 1.0920249223709106, D Loss: 1.267220377922058, alpha: 0.6248064744684292\n",
      "epoch 916 iteration0, G Loss: 1.1078126430511475, D Loss: 1.272626280784607, alpha: 0.6233988845696152\n",
      "epoch 916 iteration100, G Loss: 1.087525725364685, D Loss: 1.213759422302246, alpha: 0.6233988845696152\n",
      "epoch 917 iteration0, G Loss: 1.1457022428512573, D Loss: 1.3064541816711426, alpha: 0.6219892087924073\n",
      "epoch 917 iteration100, G Loss: 1.2939540147781372, D Loss: 1.29170823097229, alpha: 0.6219892087924073\n",
      "epoch 918 iteration0, G Loss: 1.0233877897262573, D Loss: 1.2830771207809448, alpha: 0.620577467927091\n",
      "epoch 918 iteration100, G Loss: 1.206426978111267, D Loss: 1.1538991928100586, alpha: 0.620577467927091\n",
      "epoch 919 iteration0, G Loss: 0.8862975835800171, D Loss: 1.157503366470337, alpha: 0.6191636828993606\n",
      "epoch 919 iteration100, G Loss: 1.0280646085739136, D Loss: 1.2105082273483276, alpha: 0.6191636828993606\n",
      "epoch 920 iteration0, G Loss: 0.9618790745735168, D Loss: 1.1951814889907837, alpha: 0.6177478747692489\n",
      "epoch 920 iteration100, G Loss: 1.0403343439102173, D Loss: 1.1980173587799072, alpha: 0.6177478747692489\n",
      "epoch 921 iteration0, G Loss: 1.003682255744934, D Loss: 1.2191691398620605, alpha: 0.6163300647300389\n",
      "epoch 921 iteration100, G Loss: 1.0724916458129883, D Loss: 1.2778271436691284, alpha: 0.6163300647300389\n",
      "epoch 922 iteration0, G Loss: 0.8774896264076233, D Loss: 1.3190782070159912, alpha: 0.6149102741071584\n",
      "epoch 922 iteration100, G Loss: 1.328087568283081, D Loss: 1.2168426513671875, alpha: 0.6149102741071584\n",
      "epoch 923 iteration0, G Loss: 1.0158157348632812, D Loss: 1.2740198373794556, alpha: 0.6134885243570563\n",
      "epoch 923 iteration100, G Loss: 1.0923861265182495, D Loss: 1.2544138431549072, alpha: 0.6134885243570563\n",
      "epoch 924 iteration0, G Loss: 1.0542962551116943, D Loss: 1.2441370487213135, alpha: 0.6120648370660613\n",
      "epoch 924 iteration100, G Loss: 1.0869966745376587, D Loss: 1.2930012941360474, alpha: 0.6120648370660613\n",
      "epoch 925 iteration0, G Loss: 1.1378084421157837, D Loss: 1.2421505451202393, alpha: 0.6106392339492219\n",
      "epoch 925 iteration100, G Loss: 1.0847750902175903, D Loss: 1.2477607727050781, alpha: 0.6106392339492219\n",
      "epoch 926 iteration0, G Loss: 0.9980577826499939, D Loss: 1.2672102451324463, alpha: 0.6092117368491302\n",
      "epoch 926 iteration100, G Loss: 1.3865838050842285, D Loss: 1.119046688079834, alpha: 0.6092117368491302\n",
      "epoch 927 iteration0, G Loss: 1.0037076473236084, D Loss: 1.2089715003967285, alpha: 0.607782367734727\n",
      "epoch 927 iteration100, G Loss: 1.0688402652740479, D Loss: 1.2227866649627686, alpha: 0.607782367734727\n",
      "epoch 928 iteration0, G Loss: 1.0907306671142578, D Loss: 1.2907354831695557, alpha: 0.6063511487000908\n",
      "epoch 928 iteration100, G Loss: 1.0213289260864258, D Loss: 1.2341665029525757, alpha: 0.6063511487000908\n",
      "epoch 929 iteration0, G Loss: 1.1449006795883179, D Loss: 1.1546295881271362, alpha: 0.6049181019632079\n",
      "epoch 929 iteration100, G Loss: 1.2559115886688232, D Loss: 1.2343411445617676, alpha: 0.6049181019632079\n",
      "epoch 930 iteration0, G Loss: 1.0543746948242188, D Loss: 1.2065019607543945, alpha: 0.6034832498647262\n",
      "epoch 930 iteration100, G Loss: 0.9698997139930725, D Loss: 1.2989987134933472, alpha: 0.6034832498647262\n",
      "epoch 931 iteration0, G Loss: 1.0731229782104492, D Loss: 1.2443149089813232, alpha: 0.6020466148666932\n",
      "epoch 931 iteration100, G Loss: 1.3212242126464844, D Loss: 1.2200500965118408, alpha: 0.6020466148666932\n",
      "epoch 932 iteration0, G Loss: 1.0719935894012451, D Loss: 1.2512931823730469, alpha: 0.6006082195512743\n",
      "epoch 932 iteration100, G Loss: 0.7549581527709961, D Loss: 1.295091152191162, alpha: 0.6006082195512743\n",
      "epoch 933 iteration0, G Loss: 0.9888888597488403, D Loss: 1.262542486190796, alpha: 0.5991680866194572\n",
      "epoch 933 iteration100, G Loss: 1.112597942352295, D Loss: 1.2237735986709595, alpha: 0.5991680866194572\n",
      "epoch 934 iteration0, G Loss: 1.2586508989334106, D Loss: 1.201375126838684, alpha: 0.5977262388897371\n",
      "epoch 934 iteration100, G Loss: 1.176418662071228, D Loss: 1.214357852935791, alpha: 0.5977262388897371\n",
      "epoch 935 iteration0, G Loss: 1.0442956686019897, D Loss: 1.2445958852767944, alpha: 0.5962826992967878\n",
      "epoch 935 iteration100, G Loss: 0.9517926573753357, D Loss: 1.3048821687698364, alpha: 0.5962826992967878\n",
      "epoch 936 iteration0, G Loss: 0.9808626174926758, D Loss: 1.199711561203003, alpha: 0.594837490890115\n",
      "epoch 936 iteration100, G Loss: 0.9429696202278137, D Loss: 1.217832088470459, alpha: 0.594837490890115\n",
      "epoch 937 iteration0, G Loss: 0.9822339415550232, D Loss: 1.2842249870300293, alpha: 0.5933906368326937\n",
      "epoch 937 iteration100, G Loss: 1.2963944673538208, D Loss: 1.2487459182739258, alpha: 0.5933906368326937\n",
      "epoch 938 iteration0, G Loss: 0.9477629661560059, D Loss: 1.185511589050293, alpha: 0.5919421603995894\n",
      "epoch 938 iteration100, G Loss: 1.0541168451309204, D Loss: 1.2328053712844849, alpha: 0.5919421603995894\n",
      "epoch 939 iteration0, G Loss: 1.0553048849105835, D Loss: 1.3041781187057495, alpha: 0.5904920849765638\n",
      "epoch 939 iteration100, G Loss: 1.0667753219604492, D Loss: 1.3169550895690918, alpha: 0.5904920849765638\n",
      "epoch 940 iteration0, G Loss: 0.9644047617912292, D Loss: 1.2526003122329712, alpha: 0.5890404340586652\n",
      "epoch 940 iteration100, G Loss: 1.4399195909500122, D Loss: 1.2121920585632324, alpha: 0.5890404340586652\n",
      "epoch 941 iteration0, G Loss: 0.8270034193992615, D Loss: 1.2473760843276978, alpha: 0.5875872312488013\n",
      "epoch 941 iteration100, G Loss: 1.1073371171951294, D Loss: 1.2461905479431152, alpha: 0.5875872312488013\n",
      "epoch 942 iteration0, G Loss: 1.1482298374176025, D Loss: 1.2377114295959473, alpha: 0.5861325002562995\n",
      "epoch 942 iteration100, G Loss: 1.1677621603012085, D Loss: 1.2608389854431152, alpha: 0.5861325002562995\n",
      "epoch 943 iteration0, G Loss: 1.253474235534668, D Loss: 1.1998928785324097, alpha: 0.5846762648954498\n",
      "epoch 943 iteration100, G Loss: 1.1047402620315552, D Loss: 1.1857563257217407, alpha: 0.5846762648954498\n",
      "epoch 944 iteration0, G Loss: 1.0550967454910278, D Loss: 1.2035069465637207, alpha: 0.5832185490840334\n",
      "epoch 944 iteration100, G Loss: 1.178553819656372, D Loss: 1.158048391342163, alpha: 0.5832185490840334\n",
      "epoch 945 iteration0, G Loss: 1.0145002603530884, D Loss: 1.1917102336883545, alpha: 0.5817593768418362\n",
      "epoch 945 iteration100, G Loss: 1.289511799812317, D Loss: 1.2435564994812012, alpha: 0.5817593768418362\n",
      "epoch 946 iteration0, G Loss: 1.0645031929016113, D Loss: 1.3433501720428467, alpha: 0.5802987722891484\n",
      "epoch 946 iteration100, G Loss: 0.9754819869995117, D Loss: 1.2790954113006592, alpha: 0.5802987722891484\n",
      "epoch 947 iteration0, G Loss: 1.1507306098937988, D Loss: 1.311262607574463, alpha: 0.5788367596452482\n",
      "epoch 947 iteration100, G Loss: 1.1422780752182007, D Loss: 1.2758572101593018, alpha: 0.5788367596452482\n",
      "epoch 948 iteration0, G Loss: 0.8320209383964539, D Loss: 1.147623062133789, alpha: 0.5773733632268729\n",
      "epoch 948 iteration100, G Loss: 1.0468554496765137, D Loss: 1.2530370950698853, alpha: 0.5773733632268729\n",
      "epoch 949 iteration0, G Loss: 1.0519752502441406, D Loss: 1.2753369808197021, alpha: 0.5759086074466737\n",
      "epoch 949 iteration100, G Loss: 1.2288583517074585, D Loss: 1.3014967441558838, alpha: 0.5759086074466737\n",
      "epoch 950 iteration0, G Loss: 1.1322180032730103, D Loss: 1.2246317863464355, alpha: 0.5744425168116589\n",
      "epoch 950 iteration100, G Loss: 1.6704578399658203, D Loss: 1.203598976135254, alpha: 0.5744425168116589\n",
      "Saving content.\n",
      "epoch 951 iteration0, G Loss: 1.0741642713546753, D Loss: 1.307910680770874, alpha: 0.5729751159216219\n",
      "epoch 951 iteration100, G Loss: 0.8599358201026917, D Loss: 1.33477783203125, alpha: 0.5729751159216219\n",
      "epoch 952 iteration0, G Loss: 0.9086159467697144, D Loss: 1.2418893575668335, alpha: 0.5715064294675559\n",
      "epoch 952 iteration100, G Loss: 1.0084917545318604, D Loss: 1.254728078842163, alpha: 0.5715064294675559\n",
      "epoch 953 iteration0, G Loss: 1.01104736328125, D Loss: 1.297584056854248, alpha: 0.5700364822300554\n",
      "epoch 953 iteration100, G Loss: 0.9828860759735107, D Loss: 1.3425618410110474, alpha: 0.5700364822300554\n",
      "epoch 954 iteration0, G Loss: 1.2809444665908813, D Loss: 1.3451135158538818, alpha: 0.5685652990777049\n",
      "epoch 954 iteration100, G Loss: 1.0338120460510254, D Loss: 1.200939655303955, alpha: 0.5685652990777049\n",
      "epoch 955 iteration0, G Loss: 0.8972383141517639, D Loss: 1.2124255895614624, alpha: 0.5670929049654543\n",
      "epoch 955 iteration100, G Loss: 0.87871253490448, D Loss: 1.2130004167556763, alpha: 0.5670929049654543\n",
      "epoch 956 iteration0, G Loss: 1.085684895515442, D Loss: 1.1890016794204712, alpha: 0.5656193249329815\n",
      "epoch 956 iteration100, G Loss: 0.8846546411514282, D Loss: 1.2083618640899658, alpha: 0.5656193249329815\n",
      "epoch 957 iteration0, G Loss: 0.9041790962219238, D Loss: 1.293166160583496, alpha: 0.564144584103043\n",
      "epoch 957 iteration100, G Loss: 1.0019917488098145, D Loss: 1.293553352355957, alpha: 0.564144584103043\n",
      "epoch 958 iteration0, G Loss: 0.9305536150932312, D Loss: 1.187300205230713, alpha: 0.562668707679812\n",
      "epoch 958 iteration100, G Loss: 1.0764878988265991, D Loss: 1.2792421579360962, alpha: 0.562668707679812\n",
      "epoch 959 iteration0, G Loss: 0.939997673034668, D Loss: 1.1924817562103271, alpha: 0.5611917209472043\n",
      "epoch 959 iteration100, G Loss: 1.1065502166748047, D Loss: 1.240379810333252, alpha: 0.5611917209472043\n",
      "epoch 960 iteration0, G Loss: 0.950019359588623, D Loss: 1.2762720584869385, alpha: 0.559713649267193\n",
      "epoch 960 iteration100, G Loss: 1.5091817378997803, D Loss: 1.2478420734405518, alpha: 0.559713649267193\n",
      "epoch 961 iteration0, G Loss: 1.0166069269180298, D Loss: 1.2794640064239502, alpha: 0.5582345180781104\n",
      "epoch 961 iteration100, G Loss: 1.2304267883300781, D Loss: 1.2401058673858643, alpha: 0.5582345180781104\n",
      "epoch 962 iteration0, G Loss: 1.2277368307113647, D Loss: 1.2651642560958862, alpha: 0.5567543528929406\n",
      "epoch 962 iteration100, G Loss: 1.4453004598617554, D Loss: 1.285996675491333, alpha: 0.5567543528929406\n",
      "epoch 963 iteration0, G Loss: 1.0069763660430908, D Loss: 1.3797764778137207, alpha: 0.5552731792975989\n",
      "epoch 963 iteration100, G Loss: 1.1351211071014404, D Loss: 1.175606608390808, alpha: 0.5552731792975989\n",
      "epoch 964 iteration0, G Loss: 1.1191401481628418, D Loss: 1.286042332649231, alpha: 0.5537910229492018\n",
      "epoch 964 iteration100, G Loss: 1.2114490270614624, D Loss: 1.2896747589111328, alpha: 0.5537910229492018\n",
      "epoch 965 iteration0, G Loss: 0.9697298407554626, D Loss: 1.2454261779785156, alpha: 0.5523079095743252\n",
      "epoch 965 iteration100, G Loss: 1.15920889377594, D Loss: 1.2595247030258179, alpha: 0.5523079095743252\n",
      "epoch 966 iteration0, G Loss: 0.941996693611145, D Loss: 1.3609962463378906, alpha: 0.5508238649672539\n",
      "epoch 966 iteration100, G Loss: 1.2015966176986694, D Loss: 1.178597092628479, alpha: 0.5508238649672539\n",
      "epoch 967 iteration0, G Loss: 0.9396567940711975, D Loss: 1.168383002281189, alpha: 0.5493389149882191\n",
      "epoch 967 iteration100, G Loss: 1.2436386346817017, D Loss: 1.1206625699996948, alpha: 0.5493389149882191\n",
      "epoch 968 iteration0, G Loss: 1.038413643836975, D Loss: 1.2195723056793213, alpha: 0.5478530855616275\n",
      "epoch 968 iteration100, G Loss: 1.1764503717422485, D Loss: 1.2012602090835571, alpha: 0.5478530855616275\n",
      "epoch 969 iteration0, G Loss: 1.0821702480316162, D Loss: 1.2018051147460938, alpha: 0.5463664026742796\n",
      "epoch 969 iteration100, G Loss: 1.053344488143921, D Loss: 1.2563115358352661, alpha: 0.5463664026742796\n",
      "epoch 970 iteration0, G Loss: 1.1132423877716064, D Loss: 1.1844942569732666, alpha: 0.5448788923735799\n",
      "epoch 970 iteration100, G Loss: 1.049535870552063, D Loss: 1.262841820716858, alpha: 0.5448788923735799\n",
      "epoch 971 iteration0, G Loss: 1.0642884969711304, D Loss: 1.1821198463439941, alpha: 0.5433905807657373\n",
      "epoch 971 iteration100, G Loss: 1.134191632270813, D Loss: 1.272454023361206, alpha: 0.5433905807657373\n",
      "epoch 972 iteration0, G Loss: 1.046367883682251, D Loss: 1.219401478767395, alpha: 0.5419014940139564\n",
      "epoch 972 iteration100, G Loss: 1.1515320539474487, D Loss: 1.2469210624694824, alpha: 0.5419014940139564\n",
      "epoch 973 iteration0, G Loss: 0.8350663781166077, D Loss: 1.2893681526184082, alpha: 0.5404116583366201\n",
      "epoch 973 iteration100, G Loss: 1.1233636140823364, D Loss: 1.2249120473861694, alpha: 0.5404116583366201\n",
      "epoch 974 iteration0, G Loss: 1.037815809249878, D Loss: 1.1934716701507568, alpha: 0.5389211000054652\n",
      "epoch 974 iteration100, G Loss: 1.237783432006836, D Loss: 1.261930227279663, alpha: 0.5389211000054652\n",
      "epoch 975 iteration0, G Loss: 1.0074583292007446, D Loss: 1.274085521697998, alpha: 0.5374298453437494\n",
      "epoch 975 iteration100, G Loss: 0.8955113887786865, D Loss: 1.2644600868225098, alpha: 0.5374298453437494\n",
      "epoch 976 iteration0, G Loss: 1.123593807220459, D Loss: 1.2170281410217285, alpha: 0.5359379207244088\n",
      "epoch 976 iteration100, G Loss: 1.1501710414886475, D Loss: 1.3459552526474, alpha: 0.5359379207244088\n",
      "epoch 977 iteration0, G Loss: 1.0287580490112305, D Loss: 1.2723493576049805, alpha: 0.5344453525682101\n",
      "epoch 977 iteration100, G Loss: 1.274810791015625, D Loss: 1.1990292072296143, alpha: 0.5344453525682101\n",
      "epoch 978 iteration0, G Loss: 0.9979052543640137, D Loss: 1.2576110363006592, alpha: 0.532952167341895\n",
      "epoch 978 iteration100, G Loss: 0.9894893169403076, D Loss: 1.2231340408325195, alpha: 0.532952167341895\n",
      "epoch 979 iteration0, G Loss: 0.9600703716278076, D Loss: 1.201951026916504, alpha: 0.5314583915563169\n",
      "epoch 979 iteration100, G Loss: 1.1304634809494019, D Loss: 1.3115723133087158, alpha: 0.5314583915563169\n",
      "epoch 980 iteration0, G Loss: 1.0447200536727905, D Loss: 1.1612982749938965, alpha: 0.5299640517645718\n",
      "epoch 980 iteration100, G Loss: 1.1241304874420166, D Loss: 1.2439500093460083, alpha: 0.5299640517645718\n",
      "epoch 981 iteration0, G Loss: 0.9941239356994629, D Loss: 1.2342954874038696, alpha: 0.528469174560122\n",
      "epoch 981 iteration100, G Loss: 0.9720230102539062, D Loss: 1.3329014778137207, alpha: 0.528469174560122\n",
      "epoch 982 iteration0, G Loss: 1.014227271080017, D Loss: 1.1427571773529053, alpha: 0.5269737865749144\n",
      "epoch 982 iteration100, G Loss: 1.1063019037246704, D Loss: 1.1993200778961182, alpha: 0.5269737865749144\n",
      "epoch 983 iteration0, G Loss: 1.022092580795288, D Loss: 1.2000153064727783, alpha: 0.525477914477493\n",
      "epoch 983 iteration100, G Loss: 1.0833351612091064, D Loss: 1.1943532228469849, alpha: 0.525477914477493\n",
      "epoch 984 iteration0, G Loss: 1.1350553035736084, D Loss: 1.1845619678497314, alpha: 0.5239815849711045\n",
      "epoch 984 iteration100, G Loss: 1.3807289600372314, D Loss: 1.2489631175994873, alpha: 0.5239815849711045\n",
      "epoch 985 iteration0, G Loss: 0.9091020822525024, D Loss: 1.2567579746246338, alpha: 0.5224848247918001\n",
      "epoch 985 iteration100, G Loss: 1.2408621311187744, D Loss: 1.2105402946472168, alpha: 0.5224848247918001\n",
      "epoch 986 iteration0, G Loss: 0.9501575827598572, D Loss: 1.146641492843628, alpha: 0.5209876607065322\n",
      "epoch 986 iteration100, G Loss: 1.194998860359192, D Loss: 1.1251275539398193, alpha: 0.5209876607065322\n",
      "epoch 987 iteration0, G Loss: 0.9777680039405823, D Loss: 1.1783390045166016, alpha: 0.5194901195112459\n",
      "epoch 987 iteration100, G Loss: 1.3730548620224, D Loss: 1.3092701435089111, alpha: 0.5194901195112459\n",
      "epoch 988 iteration0, G Loss: 1.239107608795166, D Loss: 1.1879205703735352, alpha: 0.5179922280289649\n",
      "epoch 988 iteration100, G Loss: 1.0846350193023682, D Loss: 1.2326278686523438, alpha: 0.5179922280289649\n",
      "epoch 989 iteration0, G Loss: 1.1582497358322144, D Loss: 1.2393964529037476, alpha: 0.5164940131078767\n",
      "epoch 989 iteration100, G Loss: 1.1451363563537598, D Loss: 1.223270058631897, alpha: 0.5164940131078767\n",
      "epoch 990 iteration0, G Loss: 1.0863300561904907, D Loss: 1.2015351057052612, alpha: 0.51499550161941\n",
      "epoch 990 iteration100, G Loss: 0.7055919766426086, D Loss: 1.3786710500717163, alpha: 0.51499550161941\n",
      "epoch 991 iteration0, G Loss: 1.003000259399414, D Loss: 1.2135779857635498, alpha: 0.5134967204563117\n",
      "epoch 991 iteration100, G Loss: 0.8931700587272644, D Loss: 1.3699030876159668, alpha: 0.5134967204563117\n",
      "epoch 992 iteration0, G Loss: 0.9870752096176147, D Loss: 1.2344874143600464, alpha: 0.5119976965307178\n",
      "epoch 992 iteration100, G Loss: 1.1070556640625, D Loss: 1.2419695854187012, alpha: 0.5119976965307178\n",
      "epoch 993 iteration0, G Loss: 1.019774079322815, D Loss: 1.1985753774642944, alpha: 0.5104984567722248\n",
      "epoch 993 iteration100, G Loss: 1.2568854093551636, D Loss: 1.3324816226959229, alpha: 0.5104984567722248\n",
      "epoch 994 iteration0, G Loss: 1.1204752922058105, D Loss: 1.159814715385437, alpha: 0.5089990281259545\n",
      "epoch 994 iteration100, G Loss: 0.9251309633255005, D Loss: 1.2614692449569702, alpha: 0.5089990281259545\n",
      "epoch 995 iteration0, G Loss: 1.1904771327972412, D Loss: 1.1991899013519287, alpha: 0.5074994375506205\n",
      "epoch 995 iteration100, G Loss: 0.9374294877052307, D Loss: 1.2644026279449463, alpha: 0.5074994375506205\n",
      "epoch 996 iteration0, G Loss: 1.0589619874954224, D Loss: 1.1601303815841675, alpha: 0.5059997120165878\n",
      "epoch 996 iteration100, G Loss: 0.8199009299278259, D Loss: 1.2593088150024414, alpha: 0.5059997120165878\n",
      "epoch 997 iteration0, G Loss: 0.8472316861152649, D Loss: 1.2857718467712402, alpha: 0.5044998785039363\n",
      "epoch 997 iteration100, G Loss: 1.1018010377883911, D Loss: 1.1805115938186646, alpha: 0.5044998785039363\n",
      "epoch 998 iteration0, G Loss: 1.023481011390686, D Loss: 1.3089001178741455, alpha: 0.5029999640005183\n",
      "epoch 998 iteration100, G Loss: 1.2765753269195557, D Loss: 1.2713799476623535, alpha: 0.5029999640005183\n",
      "epoch 999 iteration0, G Loss: 0.9673486948013306, D Loss: 1.1538348197937012, alpha: 0.5014999955000163\n",
      "epoch 999 iteration100, G Loss: 1.13852858543396, D Loss: 1.1938083171844482, alpha: 0.5014999955000163\n",
      "epoch 1000 iteration0, G Loss: 1.0377590656280518, D Loss: 1.3291488885879517, alpha: 0.5\n",
      "epoch 1000 iteration100, G Loss: 1.1771316528320312, D Loss: 1.1629374027252197, alpha: 0.5\n",
      "Saving content.\n",
      "epoch 1001 iteration0, G Loss: 1.0034900903701782, D Loss: 1.2124443054199219, alpha: 0.4985000044999838\n",
      "epoch 1001 iteration100, G Loss: 1.0102198123931885, D Loss: 1.246219277381897, alpha: 0.4985000044999838\n",
      "epoch 1002 iteration0, G Loss: 0.9228422045707703, D Loss: 1.2946560382843018, alpha: 0.4970000359994815\n",
      "epoch 1002 iteration100, G Loss: 1.1422592401504517, D Loss: 1.195454478263855, alpha: 0.4970000359994815\n",
      "epoch 1003 iteration0, G Loss: 0.9256319999694824, D Loss: 1.2933623790740967, alpha: 0.4955001214960636\n",
      "epoch 1003 iteration100, G Loss: 1.1261787414550781, D Loss: 1.191947340965271, alpha: 0.4955001214960636\n",
      "epoch 1004 iteration0, G Loss: 1.175012230873108, D Loss: 1.2571688890457153, alpha: 0.4940002879834122\n",
      "epoch 1004 iteration100, G Loss: 1.020573616027832, D Loss: 1.2617073059082031, alpha: 0.4940002879834122\n",
      "epoch 1005 iteration0, G Loss: 0.9756450057029724, D Loss: 1.2695786952972412, alpha: 0.49250056244937956\n",
      "epoch 1005 iteration100, G Loss: 1.1498310565948486, D Loss: 1.3097965717315674, alpha: 0.49250056244937956\n",
      "epoch 1006 iteration0, G Loss: 1.1340035200119019, D Loss: 1.2166162729263306, alpha: 0.49100097187404523\n",
      "epoch 1006 iteration100, G Loss: 1.0479933023452759, D Loss: 1.2927873134613037, alpha: 0.49100097187404523\n",
      "epoch 1007 iteration0, G Loss: 1.2146189212799072, D Loss: 1.2400240898132324, alpha: 0.4895015432277753\n",
      "epoch 1007 iteration100, G Loss: 1.165817141532898, D Loss: 1.25627863407135, alpha: 0.4895015432277753\n",
      "epoch 1008 iteration0, G Loss: 1.040926456451416, D Loss: 1.194619059562683, alpha: 0.4880023034692821\n",
      "epoch 1008 iteration100, G Loss: 1.4113603830337524, D Loss: 1.288313388824463, alpha: 0.4880023034692821\n",
      "epoch 1009 iteration0, G Loss: 0.9123562574386597, D Loss: 1.2735424041748047, alpha: 0.4865032795436883\n",
      "epoch 1009 iteration100, G Loss: 1.2821340560913086, D Loss: 1.2372410297393799, alpha: 0.4865032795436883\n",
      "epoch 1010 iteration0, G Loss: 0.8429760336875916, D Loss: 1.2716059684753418, alpha: 0.4850044983805898\n",
      "epoch 1010 iteration100, G Loss: 0.9627541303634644, D Loss: 1.2564798593521118, alpha: 0.4850044983805898\n",
      "epoch 1011 iteration0, G Loss: 1.0911527872085571, D Loss: 1.264394760131836, alpha: 0.48350598689212343\n",
      "epoch 1011 iteration100, G Loss: 0.9308127164840698, D Loss: 1.237675428390503, alpha: 0.48350598689212343\n",
      "epoch 1012 iteration0, G Loss: 0.9198824167251587, D Loss: 1.2592374086380005, alpha: 0.48200777197103506\n",
      "epoch 1012 iteration100, G Loss: 1.026581048965454, D Loss: 1.296156644821167, alpha: 0.48200777197103506\n",
      "epoch 1013 iteration0, G Loss: 1.0072894096374512, D Loss: 1.194848656654358, alpha: 0.4805098804887541\n",
      "epoch 1013 iteration100, G Loss: 1.564739465713501, D Loss: 1.1459158658981323, alpha: 0.4805098804887541\n",
      "epoch 1014 iteration0, G Loss: 0.9029098153114319, D Loss: 1.196866512298584, alpha: 0.47901233929346754\n",
      "epoch 1014 iteration100, G Loss: 0.9916113615036011, D Loss: 1.2463433742523193, alpha: 0.47901233929346754\n",
      "epoch 1015 iteration0, G Loss: 1.1455204486846924, D Loss: 1.225652813911438, alpha: 0.47751517520819997\n",
      "epoch 1015 iteration100, G Loss: 1.0140022039413452, D Loss: 1.190195083618164, alpha: 0.47751517520819997\n",
      "epoch 1016 iteration0, G Loss: 0.8653734922409058, D Loss: 1.3097336292266846, alpha: 0.4760184150288955\n",
      "epoch 1016 iteration100, G Loss: 0.9301949739456177, D Loss: 1.186340093612671, alpha: 0.4760184150288955\n",
      "epoch 1017 iteration0, G Loss: 1.0069612264633179, D Loss: 1.286737084388733, alpha: 0.47452208552250685\n",
      "epoch 1017 iteration100, G Loss: 1.025117039680481, D Loss: 1.231810212135315, alpha: 0.47452208552250685\n",
      "epoch 1018 iteration0, G Loss: 1.1380484104156494, D Loss: 1.255232810974121, alpha: 0.47302621342508533\n",
      "epoch 1018 iteration100, G Loss: 1.1706032752990723, D Loss: 1.2064297199249268, alpha: 0.47302621342508533\n",
      "epoch 1019 iteration0, G Loss: 0.9450107216835022, D Loss: 1.2095026969909668, alpha: 0.4715308254398781\n",
      "epoch 1019 iteration100, G Loss: 1.126452922821045, D Loss: 1.1597853899002075, alpha: 0.4715308254398781\n",
      "epoch 1020 iteration0, G Loss: 1.2255901098251343, D Loss: 1.2680288553237915, alpha: 0.47003594823542827\n",
      "epoch 1020 iteration100, G Loss: 1.1684589385986328, D Loss: 1.1996023654937744, alpha: 0.47003594823542827\n",
      "epoch 1021 iteration0, G Loss: 1.240644097328186, D Loss: 1.2289170026779175, alpha: 0.468541608443683\n",
      "epoch 1021 iteration100, G Loss: 1.0997600555419922, D Loss: 1.2486112117767334, alpha: 0.468541608443683\n",
      "epoch 1022 iteration0, G Loss: 0.9958745241165161, D Loss: 1.2917965650558472, alpha: 0.4670478326581048\n",
      "epoch 1022 iteration100, G Loss: 1.1637685298919678, D Loss: 1.3211941719055176, alpha: 0.4670478326581048\n",
      "epoch 1023 iteration0, G Loss: 1.035220980644226, D Loss: 1.2889271974563599, alpha: 0.46555464743178987\n",
      "epoch 1023 iteration100, G Loss: 0.977601170539856, D Loss: 1.4064151048660278, alpha: 0.46555464743178987\n",
      "epoch 1024 iteration0, G Loss: 1.1175179481506348, D Loss: 1.1960623264312744, alpha: 0.46406207927559107\n",
      "epoch 1024 iteration100, G Loss: 1.3055839538574219, D Loss: 1.1977660655975342, alpha: 0.46406207927559107\n",
      "epoch 1025 iteration0, G Loss: 0.9550713896751404, D Loss: 1.2304160594940186, alpha: 0.4625701546562503\n",
      "epoch 1025 iteration100, G Loss: 0.9625982046127319, D Loss: 1.2160193920135498, alpha: 0.4625701546562503\n",
      "epoch 1026 iteration0, G Loss: 0.9798166155815125, D Loss: 1.3697577714920044, alpha: 0.46107889999453466\n",
      "epoch 1026 iteration100, G Loss: 0.9293659925460815, D Loss: 1.1932865381240845, alpha: 0.46107889999453466\n",
      "epoch 1027 iteration0, G Loss: 1.0496464967727661, D Loss: 1.246378779411316, alpha: 0.4595883416633799\n",
      "epoch 1027 iteration100, G Loss: 1.1500897407531738, D Loss: 1.1953306198120117, alpha: 0.4595883416633799\n",
      "epoch 1028 iteration0, G Loss: 1.0009244680404663, D Loss: 1.2630186080932617, alpha: 0.4580985059860436\n",
      "epoch 1028 iteration100, G Loss: 1.1688312292099, D Loss: 1.1882281303405762, alpha: 0.4580985059860436\n",
      "epoch 1029 iteration0, G Loss: 0.8368172645568848, D Loss: 1.2803245782852173, alpha: 0.45660941923426246\n",
      "epoch 1029 iteration100, G Loss: 1.1457754373550415, D Loss: 1.2729730606079102, alpha: 0.45660941923426246\n",
      "epoch 1030 iteration0, G Loss: 1.133105993270874, D Loss: 1.2036116123199463, alpha: 0.45512110762642\n",
      "epoch 1030 iteration100, G Loss: 0.9736874103546143, D Loss: 1.2968114614486694, alpha: 0.45512110762642\n",
      "epoch 1031 iteration0, G Loss: 0.9181643724441528, D Loss: 1.1615300178527832, alpha: 0.4536335973257204\n",
      "epoch 1031 iteration100, G Loss: 1.0184260606765747, D Loss: 1.1803213357925415, alpha: 0.4536335973257204\n",
      "epoch 1032 iteration0, G Loss: 1.0834072828292847, D Loss: 1.3033421039581299, alpha: 0.4521469144383725\n",
      "epoch 1032 iteration100, G Loss: 1.042060375213623, D Loss: 1.2888073921203613, alpha: 0.4521469144383725\n",
      "epoch 1033 iteration0, G Loss: 1.1296648979187012, D Loss: 1.1610991954803467, alpha: 0.4506610850117807\n",
      "epoch 1033 iteration100, G Loss: 1.1887943744659424, D Loss: 1.278092861175537, alpha: 0.4506610850117807\n",
      "epoch 1034 iteration0, G Loss: 1.073349118232727, D Loss: 1.2029229402542114, alpha: 0.4491761350327461\n",
      "epoch 1034 iteration100, G Loss: 1.2247843742370605, D Loss: 1.2643249034881592, alpha: 0.4491761350327461\n",
      "epoch 1035 iteration0, G Loss: 1.1016499996185303, D Loss: 1.3440160751342773, alpha: 0.4476920904256747\n",
      "epoch 1035 iteration100, G Loss: 1.0895212888717651, D Loss: 1.2628214359283447, alpha: 0.4476920904256747\n",
      "epoch 1036 iteration0, G Loss: 1.0901597738265991, D Loss: 1.3059170246124268, alpha: 0.4462089770507981\n",
      "epoch 1036 iteration100, G Loss: 1.3495522737503052, D Loss: 1.2415945529937744, alpha: 0.4462089770507981\n",
      "epoch 1037 iteration0, G Loss: 0.9404396414756775, D Loss: 1.2076959609985352, alpha: 0.4447268207024009\n",
      "epoch 1037 iteration100, G Loss: 0.932312548160553, D Loss: 1.252321720123291, alpha: 0.4447268207024009\n",
      "epoch 1038 iteration0, G Loss: 0.9403980374336243, D Loss: 1.0931973457336426, alpha: 0.4432456471070594\n",
      "epoch 1038 iteration100, G Loss: 0.8783408999443054, D Loss: 1.3233271837234497, alpha: 0.4432456471070594\n",
      "epoch 1039 iteration0, G Loss: 1.1012444496154785, D Loss: 1.2050005197525024, alpha: 0.4417654819218896\n",
      "epoch 1039 iteration100, G Loss: 1.5350987911224365, D Loss: 1.0736771821975708, alpha: 0.4417654819218896\n",
      "epoch 1040 iteration0, G Loss: 1.0925003290176392, D Loss: 1.1788573265075684, alpha: 0.4402863507328071\n",
      "epoch 1040 iteration100, G Loss: 1.2847833633422852, D Loss: 1.206040620803833, alpha: 0.4402863507328071\n",
      "epoch 1041 iteration0, G Loss: 1.2111878395080566, D Loss: 1.2311197519302368, alpha: 0.4388082790527955\n",
      "epoch 1041 iteration100, G Loss: 1.4057636260986328, D Loss: 1.1704685688018799, alpha: 0.4388082790527955\n",
      "epoch 1042 iteration0, G Loss: 1.1706254482269287, D Loss: 1.1489412784576416, alpha: 0.43733129232018797\n",
      "epoch 1042 iteration100, G Loss: 0.9362376928329468, D Loss: 1.3159443140029907, alpha: 0.43733129232018797\n",
      "epoch 1043 iteration0, G Loss: 1.1629385948181152, D Loss: 1.092034935951233, alpha: 0.435855415896957\n",
      "epoch 1043 iteration100, G Loss: 0.9160335063934326, D Loss: 1.206141710281372, alpha: 0.435855415896957\n",
      "epoch 1044 iteration0, G Loss: 0.9983589053153992, D Loss: 1.1726977825164795, alpha: 0.4343806750670184\n",
      "epoch 1044 iteration100, G Loss: 1.012621521949768, D Loss: 1.233743667602539, alpha: 0.4343806750670184\n",
      "epoch 1045 iteration0, G Loss: 1.123366117477417, D Loss: 1.2024855613708496, alpha: 0.4329070950345455\n",
      "epoch 1045 iteration100, G Loss: 1.3237595558166504, D Loss: 1.3103431463241577, alpha: 0.4329070950345455\n",
      "epoch 1046 iteration0, G Loss: 0.9999861121177673, D Loss: 1.1983250379562378, alpha: 0.4314347009222951\n",
      "epoch 1046 iteration100, G Loss: 1.0706557035446167, D Loss: 1.3084267377853394, alpha: 0.4314347009222951\n",
      "epoch 1047 iteration0, G Loss: 0.9445719718933105, D Loss: 1.2269890308380127, alpha: 0.42996351776994457\n",
      "epoch 1047 iteration100, G Loss: 0.9970444440841675, D Loss: 1.2299177646636963, alpha: 0.42996351776994457\n",
      "epoch 1048 iteration0, G Loss: 0.9677097797393799, D Loss: 1.146917700767517, alpha: 0.4284935705324441\n",
      "epoch 1048 iteration100, G Loss: 1.0837427377700806, D Loss: 1.1599397659301758, alpha: 0.4284935705324441\n",
      "epoch 1049 iteration0, G Loss: 1.152624487876892, D Loss: 1.2854275703430176, alpha: 0.4270248840783779\n",
      "epoch 1049 iteration100, G Loss: 1.0526354312896729, D Loss: 1.2688676118850708, alpha: 0.4270248840783779\n",
      "epoch 1050 iteration0, G Loss: 1.3001878261566162, D Loss: 1.1887826919555664, alpha: 0.4255574831883411\n",
      "epoch 1050 iteration100, G Loss: 1.0878148078918457, D Loss: 1.2663911581039429, alpha: 0.4255574831883411\n",
      "Saving content.\n",
      "epoch 1051 iteration0, G Loss: 1.1534720659255981, D Loss: 1.2421910762786865, alpha: 0.4240913925533263\n",
      "epoch 1051 iteration100, G Loss: 1.1670068502426147, D Loss: 1.2120552062988281, alpha: 0.4240913925533263\n",
      "epoch 1052 iteration0, G Loss: 0.8764123916625977, D Loss: 1.2238715887069702, alpha: 0.42262663677312706\n",
      "epoch 1052 iteration100, G Loss: 1.1712597608566284, D Loss: 1.1787351369857788, alpha: 0.42262663677312706\n",
      "epoch 1053 iteration0, G Loss: 1.0277246236801147, D Loss: 1.1156209707260132, alpha: 0.4211632403547515\n",
      "epoch 1053 iteration100, G Loss: 1.1862365007400513, D Loss: 1.2239577770233154, alpha: 0.4211632403547515\n",
      "epoch 1054 iteration0, G Loss: 1.123692512512207, D Loss: 1.2361717224121094, alpha: 0.4197012277108516\n",
      "epoch 1054 iteration100, G Loss: 1.2370531558990479, D Loss: 1.2308944463729858, alpha: 0.4197012277108516\n",
      "epoch 1055 iteration0, G Loss: 0.9899439811706543, D Loss: 1.209795355796814, alpha: 0.4182406231581637\n",
      "epoch 1055 iteration100, G Loss: 1.36707603931427, D Loss: 1.2432615756988525, alpha: 0.4182406231581637\n",
      "epoch 1056 iteration0, G Loss: 0.9556273221969604, D Loss: 1.2178605794906616, alpha: 0.41678145091596663\n",
      "epoch 1056 iteration100, G Loss: 0.9615839719772339, D Loss: 1.2437918186187744, alpha: 0.41678145091596663\n",
      "epoch 1057 iteration0, G Loss: 1.0738353729248047, D Loss: 1.2372773885726929, alpha: 0.41532373510455\n",
      "epoch 1057 iteration100, G Loss: 1.2346858978271484, D Loss: 1.179081916809082, alpha: 0.41532373510455\n",
      "epoch 1058 iteration0, G Loss: 0.9703311920166016, D Loss: 1.268798828125, alpha: 0.4138674997437005\n",
      "epoch 1058 iteration100, G Loss: 1.0905991792678833, D Loss: 1.2356374263763428, alpha: 0.4138674997437005\n",
      "epoch 1059 iteration0, G Loss: 1.0956225395202637, D Loss: 1.211844801902771, alpha: 0.4124127687511987\n",
      "epoch 1059 iteration100, G Loss: 1.28627610206604, D Loss: 1.2064666748046875, alpha: 0.4124127687511987\n",
      "epoch 1060 iteration0, G Loss: 1.0329855680465698, D Loss: 1.2533092498779297, alpha: 0.41095956594133476\n",
      "epoch 1060 iteration100, G Loss: 1.1527386903762817, D Loss: 1.073521614074707, alpha: 0.41095956594133476\n",
      "epoch 1061 iteration0, G Loss: 1.0352303981781006, D Loss: 1.1684494018554688, alpha: 0.4095079150234361\n",
      "epoch 1061 iteration100, G Loss: 1.1352012157440186, D Loss: 1.2096954584121704, alpha: 0.4095079150234361\n",
      "epoch 1062 iteration0, G Loss: 1.0585929155349731, D Loss: 1.2337491512298584, alpha: 0.40805783960041075\n",
      "epoch 1062 iteration100, G Loss: 1.0079008340835571, D Loss: 1.2949938774108887, alpha: 0.40805783960041075\n",
      "epoch 1063 iteration0, G Loss: 0.9615278244018555, D Loss: 1.3204882144927979, alpha: 0.40660936316730634\n",
      "epoch 1063 iteration100, G Loss: 1.075379729270935, D Loss: 1.2595767974853516, alpha: 0.40660936316730634\n",
      "epoch 1064 iteration0, G Loss: 0.871399998664856, D Loss: 1.199822187423706, alpha: 0.40516250910988494\n",
      "epoch 1064 iteration100, G Loss: 0.9816514849662781, D Loss: 1.2552943229675293, alpha: 0.40516250910988494\n",
      "epoch 1065 iteration0, G Loss: 0.8725357055664062, D Loss: 1.183547019958496, alpha: 0.4037173007032121\n",
      "epoch 1065 iteration100, G Loss: 0.8774743676185608, D Loss: 1.2112579345703125, alpha: 0.4037173007032121\n",
      "epoch 1066 iteration0, G Loss: 1.0723819732666016, D Loss: 1.1749461889266968, alpha: 0.4022737611102629\n",
      "epoch 1066 iteration100, G Loss: 1.3532723188400269, D Loss: 1.269679069519043, alpha: 0.4022737611102629\n",
      "epoch 1067 iteration0, G Loss: 0.8936394453048706, D Loss: 1.224983811378479, alpha: 0.4008319133805428\n",
      "epoch 1067 iteration100, G Loss: 0.9874203205108643, D Loss: 1.2812185287475586, alpha: 0.4008319133805428\n",
      "epoch 1068 iteration0, G Loss: 0.9582313895225525, D Loss: 1.2062342166900635, alpha: 0.39939178044872536\n",
      "epoch 1068 iteration100, G Loss: 1.3086172342300415, D Loss: 1.2728271484375, alpha: 0.39939178044872536\n",
      "epoch 1069 iteration0, G Loss: 1.1320090293884277, D Loss: 1.2190959453582764, alpha: 0.3979533851333068\n",
      "epoch 1069 iteration100, G Loss: 1.105001449584961, D Loss: 1.2280975580215454, alpha: 0.3979533851333068\n",
      "epoch 1070 iteration0, G Loss: 0.8317502737045288, D Loss: 1.2203035354614258, alpha: 0.39651675013527377\n",
      "epoch 1070 iteration100, G Loss: 1.0467827320098877, D Loss: 1.2650032043457031, alpha: 0.39651675013527377\n",
      "epoch 1071 iteration0, G Loss: 0.8457075357437134, D Loss: 1.2778210639953613, alpha: 0.39508189803679217\n",
      "epoch 1071 iteration100, G Loss: 1.1184748411178589, D Loss: 1.2508964538574219, alpha: 0.39508189803679217\n",
      "epoch 1072 iteration0, G Loss: 1.0816285610198975, D Loss: 1.266594409942627, alpha: 0.393648851299909\n",
      "epoch 1072 iteration100, G Loss: 1.1088354587554932, D Loss: 1.2043174505233765, alpha: 0.393648851299909\n",
      "epoch 1073 iteration0, G Loss: 1.0360643863677979, D Loss: 1.3109502792358398, alpha: 0.39221763226527295\n",
      "epoch 1073 iteration100, G Loss: 1.0653538703918457, D Loss: 1.2219243049621582, alpha: 0.39221763226527295\n",
      "epoch 1074 iteration0, G Loss: 0.9269241690635681, D Loss: 1.2193005084991455, alpha: 0.3907882631508698\n",
      "epoch 1074 iteration100, G Loss: 0.8347033858299255, D Loss: 1.188868522644043, alpha: 0.3907882631508698\n",
      "epoch 1075 iteration0, G Loss: 1.1039608716964722, D Loss: 1.190375566482544, alpha: 0.38936076605077796\n",
      "epoch 1075 iteration100, G Loss: 0.7555177807807922, D Loss: 1.1914582252502441, alpha: 0.38936076605077796\n",
      "epoch 1076 iteration0, G Loss: 0.9794536232948303, D Loss: 1.2102205753326416, alpha: 0.3879351629339385\n",
      "epoch 1076 iteration100, G Loss: 1.7187509536743164, D Loss: 1.275500774383545, alpha: 0.3879351629339385\n",
      "epoch 1077 iteration0, G Loss: 0.9037957787513733, D Loss: 1.2265208959579468, alpha: 0.38651147564294364\n",
      "epoch 1077 iteration100, G Loss: 1.1008635759353638, D Loss: 1.2917594909667969, alpha: 0.38651147564294364\n",
      "epoch 1078 iteration0, G Loss: 0.8287105560302734, D Loss: 1.220531940460205, alpha: 0.3850897258928415\n",
      "epoch 1078 iteration100, G Loss: 1.0091345310211182, D Loss: 1.1364467144012451, alpha: 0.3850897258928415\n",
      "epoch 1079 iteration0, G Loss: 1.129503846168518, D Loss: 1.2061899900436401, alpha: 0.38366993526996096\n",
      "epoch 1079 iteration100, G Loss: 0.8470908999443054, D Loss: 1.2132716178894043, alpha: 0.38366993526996096\n",
      "epoch 1080 iteration0, G Loss: 1.2119218111038208, D Loss: 1.222328782081604, alpha: 0.3822521252307509\n",
      "epoch 1080 iteration100, G Loss: 1.2966973781585693, D Loss: 1.2750084400177002, alpha: 0.3822521252307509\n",
      "epoch 1081 iteration0, G Loss: 0.7969818711280823, D Loss: 1.3467532396316528, alpha: 0.38083631710063937\n",
      "epoch 1081 iteration100, G Loss: 0.8297364711761475, D Loss: 1.235235333442688, alpha: 0.38083631710063937\n",
      "epoch 1082 iteration0, G Loss: 0.9479371309280396, D Loss: 1.177625298500061, alpha: 0.3794225320729091\n",
      "epoch 1082 iteration100, G Loss: 0.8730335831642151, D Loss: 1.2688533067703247, alpha: 0.3794225320729091\n",
      "epoch 1083 iteration0, G Loss: 0.8577733635902405, D Loss: 1.1898908615112305, alpha: 0.37801079120759273\n",
      "epoch 1083 iteration100, G Loss: 0.9587365984916687, D Loss: 1.337705373764038, alpha: 0.37801079120759273\n",
      "epoch 1084 iteration0, G Loss: 0.88880455493927, D Loss: 1.1827160120010376, alpha: 0.37660111543038466\n",
      "epoch 1084 iteration100, G Loss: 1.0565035343170166, D Loss: 1.2142804861068726, alpha: 0.37660111543038466\n",
      "epoch 1085 iteration0, G Loss: 1.2708486318588257, D Loss: 1.2285852432250977, alpha: 0.3751935255315708\n",
      "epoch 1085 iteration100, G Loss: 0.9957704544067383, D Loss: 1.1726064682006836, alpha: 0.3751935255315708\n",
      "epoch 1086 iteration0, G Loss: 1.0658377408981323, D Loss: 1.2719480991363525, alpha: 0.3737880421649772\n",
      "epoch 1086 iteration100, G Loss: 1.1818442344665527, D Loss: 1.256761074066162, alpha: 0.3737880421649772\n",
      "epoch 1087 iteration0, G Loss: 1.0159406661987305, D Loss: 1.2136043310165405, alpha: 0.3723846858469374\n",
      "epoch 1087 iteration100, G Loss: 1.135457992553711, D Loss: 1.2197290658950806, alpha: 0.3723846858469374\n",
      "epoch 1088 iteration0, G Loss: 1.0244557857513428, D Loss: 1.3190484046936035, alpha: 0.37098347695527734\n",
      "epoch 1088 iteration100, G Loss: 0.8220322132110596, D Loss: 1.3096892833709717, alpha: 0.37098347695527734\n",
      "epoch 1089 iteration0, G Loss: 0.9042105674743652, D Loss: 1.2327580451965332, alpha: 0.369584435728318\n",
      "epoch 1089 iteration100, G Loss: 1.042298674583435, D Loss: 1.1968311071395874, alpha: 0.369584435728318\n",
      "epoch 1090 iteration0, G Loss: 0.8273824453353882, D Loss: 1.2091078758239746, alpha: 0.36818758226389836\n",
      "epoch 1090 iteration100, G Loss: 1.2634377479553223, D Loss: 1.2636401653289795, alpha: 0.36818758226389836\n",
      "epoch 1091 iteration0, G Loss: 0.9980089068412781, D Loss: 1.2123961448669434, alpha: 0.36679293651841516\n",
      "epoch 1091 iteration100, G Loss: 1.3441263437271118, D Loss: 1.3121328353881836, alpha: 0.36679293651841516\n",
      "epoch 1092 iteration0, G Loss: 0.7967943549156189, D Loss: 1.2272720336914062, alpha: 0.36540051830588294\n",
      "epoch 1092 iteration100, G Loss: 1.4050912857055664, D Loss: 1.1306958198547363, alpha: 0.36540051830588294\n",
      "epoch 1093 iteration0, G Loss: 1.042444109916687, D Loss: 1.302104115486145, alpha: 0.3640103472970112\n",
      "epoch 1093 iteration100, G Loss: 0.9520552158355713, D Loss: 1.2453758716583252, alpha: 0.3640103472970112\n",
      "epoch 1094 iteration0, G Loss: 0.9006535410881042, D Loss: 1.2115594148635864, alpha: 0.36262244301830027\n",
      "epoch 1094 iteration100, G Loss: 1.2857186794281006, D Loss: 1.2210865020751953, alpha: 0.36262244301830027\n",
      "epoch 1095 iteration0, G Loss: 1.1033231019973755, D Loss: 1.2039129734039307, alpha: 0.36123682485115804\n",
      "epoch 1095 iteration100, G Loss: 1.152514100074768, D Loss: 1.2083897590637207, alpha: 0.36123682485115804\n",
      "epoch 1096 iteration0, G Loss: 0.8629310131072998, D Loss: 1.2169708013534546, alpha: 0.3598535120310331\n",
      "epoch 1096 iteration100, G Loss: 1.064671516418457, D Loss: 1.1861746311187744, alpha: 0.3598535120310331\n",
      "epoch 1097 iteration0, G Loss: 1.1278386116027832, D Loss: 1.2515687942504883, alpha: 0.35847252364656823\n",
      "epoch 1097 iteration100, G Loss: 1.198751449584961, D Loss: 1.2836650609970093, alpha: 0.35847252364656823\n",
      "epoch 1098 iteration0, G Loss: 0.8776905536651611, D Loss: 1.308887004852295, alpha: 0.35709387863877096\n",
      "epoch 1098 iteration100, G Loss: 1.129138708114624, D Loss: 1.22006356716156, alpha: 0.35709387863877096\n",
      "epoch 1099 iteration0, G Loss: 1.0756964683532715, D Loss: 1.2789440155029297, alpha: 0.35571759580020623\n",
      "epoch 1099 iteration100, G Loss: 1.077785849571228, D Loss: 1.2771117687225342, alpha: 0.35571759580020623\n",
      "epoch 1100 iteration0, G Loss: 0.8867028951644897, D Loss: 1.1726433038711548, alpha: 0.3543436937742044\n",
      "epoch 1100 iteration100, G Loss: 1.1189208030700684, D Loss: 1.2305268049240112, alpha: 0.3543436937742044\n",
      "Saving content.\n",
      "epoch 1101 iteration0, G Loss: 0.9915876388549805, D Loss: 1.2125980854034424, alpha: 0.3529721910540915\n",
      "epoch 1101 iteration100, G Loss: 1.2095537185668945, D Loss: 1.1505666971206665, alpha: 0.3529721910540915\n",
      "epoch 1102 iteration0, G Loss: 1.1577469110488892, D Loss: 1.2542378902435303, alpha: 0.3516031059824348\n",
      "epoch 1102 iteration100, G Loss: 0.9795660972595215, D Loss: 1.3135476112365723, alpha: 0.3516031059824348\n",
      "epoch 1103 iteration0, G Loss: 1.0367377996444702, D Loss: 1.2158470153808594, alpha: 0.3502364567503119\n",
      "epoch 1103 iteration100, G Loss: 1.2894166707992554, D Loss: 1.2467641830444336, alpha: 0.3502364567503119\n",
      "epoch 1104 iteration0, G Loss: 0.9867286086082458, D Loss: 1.2167387008666992, alpha: 0.3488722613965949\n",
      "epoch 1104 iteration100, G Loss: 1.0791065692901611, D Loss: 1.3191146850585938, alpha: 0.3488722613965949\n",
      "epoch 1105 iteration0, G Loss: 0.9057610034942627, D Loss: 1.3398958444595337, alpha: 0.3475105378072556\n",
      "epoch 1105 iteration100, G Loss: 1.0865741968154907, D Loss: 1.1509804725646973, alpha: 0.3475105378072556\n",
      "epoch 1106 iteration0, G Loss: 0.956767737865448, D Loss: 1.1995892524719238, alpha: 0.34615130371468894\n",
      "epoch 1106 iteration100, G Loss: 1.2613582611083984, D Loss: 1.2123465538024902, alpha: 0.34615130371468894\n",
      "epoch 1107 iteration0, G Loss: 0.9615500569343567, D Loss: 1.1688549518585205, alpha: 0.34479457669705693\n",
      "epoch 1107 iteration100, G Loss: 0.8280546069145203, D Loss: 1.1950116157531738, alpha: 0.34479457669705693\n",
      "epoch 1108 iteration0, G Loss: 1.0325138568878174, D Loss: 1.198662281036377, alpha: 0.3434403741776495\n",
      "epoch 1108 iteration100, G Loss: 1.4170637130737305, D Loss: 1.211175799369812, alpha: 0.3434403741776495\n",
      "epoch 1109 iteration0, G Loss: 0.929474949836731, D Loss: 1.3011844158172607, alpha: 0.34208871342426594\n",
      "epoch 1109 iteration100, G Loss: 1.157786250114441, D Loss: 1.2318956851959229, alpha: 0.34208871342426594\n",
      "epoch 1110 iteration0, G Loss: 1.0034794807434082, D Loss: 1.197547435760498, alpha: 0.34073961154861454\n",
      "epoch 1110 iteration100, G Loss: 1.364154577255249, D Loss: 1.3066506385803223, alpha: 0.34073961154861454\n",
      "epoch 1111 iteration0, G Loss: 0.8525816202163696, D Loss: 1.3332083225250244, alpha: 0.3393930855057322\n",
      "epoch 1111 iteration100, G Loss: 1.0250184535980225, D Loss: 1.2696282863616943, alpha: 0.3393930855057322\n",
      "epoch 1112 iteration0, G Loss: 1.0855945348739624, D Loss: 1.1736699342727661, alpha: 0.33804915209342223\n",
      "epoch 1112 iteration100, G Loss: 1.0609866380691528, D Loss: 1.2965435981750488, alpha: 0.33804915209342223\n",
      "epoch 1113 iteration0, G Loss: 1.076631784439087, D Loss: 1.1578432321548462, alpha: 0.3367078279517105\n",
      "epoch 1113 iteration100, G Loss: 0.9917449355125427, D Loss: 1.2216894626617432, alpha: 0.3367078279517105\n",
      "epoch 1114 iteration0, G Loss: 1.0214797258377075, D Loss: 1.217829942703247, alpha: 0.3353691295623231\n",
      "epoch 1114 iteration100, G Loss: 1.155237078666687, D Loss: 1.1983652114868164, alpha: 0.3353691295623231\n",
      "epoch 1115 iteration0, G Loss: 1.1395936012268066, D Loss: 1.2035188674926758, alpha: 0.33403307324817966\n",
      "epoch 1115 iteration100, G Loss: 1.1161959171295166, D Loss: 1.2479968070983887, alpha: 0.33403307324817966\n",
      "epoch 1116 iteration0, G Loss: 0.9472361207008362, D Loss: 1.2255616188049316, alpha: 0.33269967517290844\n",
      "epoch 1116 iteration100, G Loss: 0.9867889285087585, D Loss: 1.3390926122665405, alpha: 0.33269967517290844\n",
      "epoch 1117 iteration0, G Loss: 0.9745253324508667, D Loss: 1.267359733581543, alpha: 0.3313689513403777\n",
      "epoch 1117 iteration100, G Loss: 0.998620331287384, D Loss: 1.2016773223876953, alpha: 0.3313689513403777\n",
      "epoch 1118 iteration0, G Loss: 1.261792778968811, D Loss: 1.3001536130905151, alpha: 0.33004091759424825\n",
      "epoch 1118 iteration100, G Loss: 1.1452044248580933, D Loss: 1.2202509641647339, alpha: 0.33004091759424825\n",
      "epoch 1119 iteration0, G Loss: 0.9420925378799438, D Loss: 1.1052972078323364, alpha: 0.3287155896175439\n",
      "epoch 1119 iteration100, G Loss: 1.4946948289871216, D Loss: 1.1394968032836914, alpha: 0.3287155896175439\n",
      "epoch 1120 iteration0, G Loss: 0.904890775680542, D Loss: 1.1499288082122803, alpha: 0.3273929829322396\n",
      "epoch 1120 iteration100, G Loss: 1.0212973356246948, D Loss: 1.2509615421295166, alpha: 0.3273929829322396\n",
      "epoch 1121 iteration0, G Loss: 0.8625127077102661, D Loss: 1.163855791091919, alpha: 0.32607311289886975\n",
      "epoch 1121 iteration100, G Loss: 1.0821888446807861, D Loss: 1.1556543111801147, alpha: 0.32607311289886975\n",
      "epoch 1122 iteration0, G Loss: 0.923780620098114, D Loss: 1.1955547332763672, alpha: 0.3247559947161548\n",
      "epoch 1122 iteration100, G Loss: 0.896813690662384, D Loss: 1.2545291185379028, alpha: 0.3247559947161548\n",
      "epoch 1123 iteration0, G Loss: 0.9849264025688171, D Loss: 1.3090312480926514, alpha: 0.32344164342064596\n",
      "epoch 1123 iteration100, G Loss: 1.2516916990280151, D Loss: 1.165255069732666, alpha: 0.32344164342064596\n",
      "epoch 1124 iteration0, G Loss: 1.0053316354751587, D Loss: 1.2503833770751953, alpha: 0.3221300738863896\n",
      "epoch 1124 iteration100, G Loss: 1.2181298732757568, D Loss: 1.2395453453063965, alpha: 0.3221300738863896\n",
      "epoch 1125 iteration0, G Loss: 1.2015467882156372, D Loss: 1.3164951801300049, alpha: 0.320821300824607\n",
      "epoch 1125 iteration100, G Loss: 1.166826605796814, D Loss: 1.1161937713623047, alpha: 0.320821300824607\n",
      "epoch 1126 iteration0, G Loss: 0.833010196685791, D Loss: 1.2005949020385742, alpha: 0.3195153387833981\n",
      "epoch 1126 iteration100, G Loss: 0.8709330558776855, D Loss: 1.2045177221298218, alpha: 0.3195153387833981\n",
      "epoch 1127 iteration0, G Loss: 1.2220953702926636, D Loss: 1.2958946228027344, alpha: 0.31821220214745805\n",
      "epoch 1127 iteration100, G Loss: 1.1827877759933472, D Loss: 1.254401683807373, alpha: 0.31821220214745805\n",
      "epoch 1128 iteration0, G Loss: 0.8867579698562622, D Loss: 1.3241965770721436, alpha: 0.31691190513781486\n",
      "epoch 1128 iteration100, G Loss: 1.0757349729537964, D Loss: 1.1800296306610107, alpha: 0.31691190513781486\n",
      "epoch 1129 iteration0, G Loss: 0.9680806994438171, D Loss: 1.270561695098877, alpha: 0.3156144618115849\n",
      "epoch 1129 iteration100, G Loss: 0.9079269766807556, D Loss: 1.2460567951202393, alpha: 0.3156144618115849\n",
      "epoch 1130 iteration0, G Loss: 0.8545224070549011, D Loss: 1.2676078081130981, alpha: 0.3143198860617461\n",
      "epoch 1130 iteration100, G Loss: 1.018545389175415, D Loss: 1.2111881971359253, alpha: 0.3143198860617461\n",
      "epoch 1131 iteration0, G Loss: 0.8761502504348755, D Loss: 1.1907203197479248, alpha: 0.31302819161692996\n",
      "epoch 1131 iteration100, G Loss: 1.0584543943405151, D Loss: 1.1459646224975586, alpha: 0.31302819161692996\n",
      "epoch 1132 iteration0, G Loss: 0.8416278958320618, D Loss: 1.2649586200714111, alpha: 0.3117393920412306\n",
      "epoch 1132 iteration100, G Loss: 1.2913836240768433, D Loss: 1.2802445888519287, alpha: 0.3117393920412306\n",
      "epoch 1133 iteration0, G Loss: 0.9105092883110046, D Loss: 1.3012830018997192, alpha: 0.3104535007340318\n",
      "epoch 1133 iteration100, G Loss: 0.9877114295959473, D Loss: 1.223691463470459, alpha: 0.3104535007340318\n",
      "epoch 1134 iteration0, G Loss: 0.8779931664466858, D Loss: 1.1673569679260254, alpha: 0.3091705309298529\n",
      "epoch 1134 iteration100, G Loss: 0.8543711304664612, D Loss: 1.2488759756088257, alpha: 0.3091705309298529\n",
      "epoch 1135 iteration0, G Loss: 1.2360607385635376, D Loss: 1.1899988651275635, alpha: 0.3078904956982117\n",
      "epoch 1135 iteration100, G Loss: 1.0081093311309814, D Loss: 1.298067569732666, alpha: 0.3078904956982117\n",
      "epoch 1136 iteration0, G Loss: 0.9716236591339111, D Loss: 1.3104722499847412, alpha: 0.30661340794350433\n",
      "epoch 1136 iteration100, G Loss: 0.9737630486488342, D Loss: 1.1296796798706055, alpha: 0.30661340794350433\n",
      "epoch 1137 iteration0, G Loss: 0.8071290254592896, D Loss: 1.282920479774475, alpha: 0.3053392804049032\n",
      "epoch 1137 iteration100, G Loss: 1.276585340499878, D Loss: 1.2155998945236206, alpha: 0.3053392804049032\n",
      "epoch 1138 iteration0, G Loss: 0.9954645037651062, D Loss: 1.2292454242706299, alpha: 0.3040681256562733\n",
      "epoch 1138 iteration100, G Loss: 1.018068552017212, D Loss: 1.1730308532714844, alpha: 0.3040681256562733\n",
      "epoch 1139 iteration0, G Loss: 0.881723940372467, D Loss: 1.2015376091003418, alpha: 0.30279995610610433\n",
      "epoch 1139 iteration100, G Loss: 1.444380521774292, D Loss: 1.2419153451919556, alpha: 0.30279995610610433\n",
      "epoch 1140 iteration0, G Loss: 1.1353760957717896, D Loss: 1.1936463117599487, alpha: 0.30153478399746125\n",
      "epoch 1140 iteration100, G Loss: 1.0672743320465088, D Loss: 1.1963980197906494, alpha: 0.30153478399746125\n",
      "epoch 1141 iteration0, G Loss: 1.070159673690796, D Loss: 1.1818885803222656, alpha: 0.3002726214079501\n",
      "epoch 1141 iteration100, G Loss: 1.4139153957366943, D Loss: 1.2962603569030762, alpha: 0.3002726214079501\n",
      "epoch 1142 iteration0, G Loss: 1.1984633207321167, D Loss: 1.2006642818450928, alpha: 0.29901348024970353\n",
      "epoch 1142 iteration100, G Loss: 1.1608972549438477, D Loss: 1.2171602249145508, alpha: 0.29901348024970353\n",
      "epoch 1143 iteration0, G Loss: 1.0817333459854126, D Loss: 1.2791773080825806, alpha: 0.2977573722693817\n",
      "epoch 1143 iteration100, G Loss: 0.9097225069999695, D Loss: 1.4043748378753662, alpha: 0.2977573722693817\n",
      "epoch 1144 iteration0, G Loss: 0.8465167880058289, D Loss: 1.1955177783966064, alpha: 0.2965043090481889\n",
      "epoch 1144 iteration100, G Loss: 1.0044128894805908, D Loss: 1.311853289604187, alpha: 0.2965043090481889\n",
      "epoch 1145 iteration0, G Loss: 0.9052436947822571, D Loss: 1.2775471210479736, alpha: 0.29525430200190894\n",
      "epoch 1145 iteration100, G Loss: 0.9600440859794617, D Loss: 1.2404636144638062, alpha: 0.29525430200190894\n",
      "epoch 1146 iteration0, G Loss: 0.9032272696495056, D Loss: 1.1437712907791138, alpha: 0.29400736238095615\n",
      "epoch 1146 iteration100, G Loss: 1.0749757289886475, D Loss: 1.108596682548523, alpha: 0.29400736238095615\n",
      "epoch 1147 iteration0, G Loss: 0.932290256023407, D Loss: 1.2042790651321411, alpha: 0.2927635012704426\n",
      "epoch 1147 iteration100, G Loss: 1.3880962133407593, D Loss: 1.1559010744094849, alpha: 0.2927635012704426\n",
      "epoch 1148 iteration0, G Loss: 0.9304639101028442, D Loss: 1.2341032028198242, alpha: 0.29152272959026204\n",
      "epoch 1148 iteration100, G Loss: 1.1441311836242676, D Loss: 1.2603535652160645, alpha: 0.29152272959026204\n",
      "epoch 1149 iteration0, G Loss: 1.017687201499939, D Loss: 1.2354533672332764, alpha: 0.290285058095189\n",
      "epoch 1149 iteration100, G Loss: 1.049631953239441, D Loss: 1.2336549758911133, alpha: 0.290285058095189\n",
      "epoch 1150 iteration0, G Loss: 0.9632821083068848, D Loss: 1.2384705543518066, alpha: 0.289050497374996\n",
      "epoch 1150 iteration100, G Loss: 1.059768795967102, D Loss: 1.2822725772857666, alpha: 0.289050497374996\n",
      "Saving content.\n",
      "epoch 1151 iteration0, G Loss: 0.9714888334274292, D Loss: 1.1141562461853027, alpha: 0.2878190578545847\n",
      "epoch 1151 iteration100, G Loss: 0.9449083209037781, D Loss: 1.3153090476989746, alpha: 0.2878190578545847\n",
      "epoch 1152 iteration0, G Loss: 0.8679466843605042, D Loss: 1.2192816734313965, alpha: 0.28659074979413424\n",
      "epoch 1152 iteration100, G Loss: 1.2370953559875488, D Loss: 1.2665330171585083, alpha: 0.28659074979413424\n",
      "epoch 1153 iteration0, G Loss: 1.22352135181427, D Loss: 1.2219444513320923, alpha: 0.2853655832892632\n",
      "epoch 1153 iteration100, G Loss: 1.0209838151931763, D Loss: 1.2700365781784058, alpha: 0.2853655832892632\n",
      "epoch 1154 iteration0, G Loss: 1.029732346534729, D Loss: 1.3171710968017578, alpha: 0.2841435682712101\n",
      "epoch 1154 iteration100, G Loss: 0.8496579527854919, D Loss: 1.3220839500427246, alpha: 0.2841435682712101\n",
      "epoch 1155 iteration0, G Loss: 0.9916307330131531, D Loss: 1.1943848133087158, alpha: 0.2829247145070275\n",
      "epoch 1155 iteration100, G Loss: 1.1753675937652588, D Loss: 1.2429804801940918, alpha: 0.2829247145070275\n",
      "epoch 1156 iteration0, G Loss: 0.7747642993927002, D Loss: 1.174175500869751, alpha: 0.2817090315997901\n",
      "epoch 1156 iteration100, G Loss: 1.125949501991272, D Loss: 1.1522622108459473, alpha: 0.2817090315997901\n",
      "epoch 1157 iteration0, G Loss: 0.9401816129684448, D Loss: 1.175171136856079, alpha: 0.28049652898882105\n",
      "epoch 1157 iteration100, G Loss: 1.1028504371643066, D Loss: 1.2360336780548096, alpha: 0.28049652898882105\n",
      "epoch 1158 iteration0, G Loss: 1.1158140897750854, D Loss: 1.2579911947250366, alpha: 0.2792872159499311\n",
      "epoch 1158 iteration100, G Loss: 1.0249079465866089, D Loss: 1.3252499103546143, alpha: 0.2792872159499311\n",
      "epoch 1159 iteration0, G Loss: 0.8903865814208984, D Loss: 1.2364718914031982, alpha: 0.2780811015956731\n",
      "epoch 1159 iteration100, G Loss: 1.044672966003418, D Loss: 1.3052887916564941, alpha: 0.2780811015956731\n",
      "epoch 1160 iteration0, G Loss: 0.9891404509544373, D Loss: 1.226783037185669, alpha: 0.27687819487561016\n",
      "epoch 1160 iteration100, G Loss: 0.8807584047317505, D Loss: 1.2009317874908447, alpha: 0.27687819487561016\n",
      "epoch 1161 iteration0, G Loss: 1.1017481088638306, D Loss: 1.1649779081344604, alpha: 0.27567850457660126\n",
      "epoch 1161 iteration100, G Loss: 1.0977686643600464, D Loss: 1.1769616603851318, alpha: 0.27567850457660126\n",
      "epoch 1162 iteration0, G Loss: 1.0026841163635254, D Loss: 1.1597347259521484, alpha: 0.2744820393230981\n",
      "epoch 1162 iteration100, G Loss: 1.1993436813354492, D Loss: 1.270578145980835, alpha: 0.2744820393230981\n",
      "epoch 1163 iteration0, G Loss: 0.859919011592865, D Loss: 1.2203905582427979, alpha: 0.2732888075774579\n",
      "epoch 1163 iteration100, G Loss: 0.8818163871765137, D Loss: 1.2088239192962646, alpha: 0.2732888075774579\n",
      "epoch 1164 iteration0, G Loss: 1.0238232612609863, D Loss: 1.1907243728637695, alpha: 0.2720988176402692\n",
      "epoch 1164 iteration100, G Loss: 1.1478689908981323, D Loss: 1.227736234664917, alpha: 0.2720988176402692\n",
      "epoch 1165 iteration0, G Loss: 0.772395670413971, D Loss: 1.2267200946807861, alpha: 0.27091207765069336\n",
      "epoch 1165 iteration100, G Loss: 1.331617832183838, D Loss: 1.2455470561981201, alpha: 0.27091207765069336\n",
      "epoch 1166 iteration0, G Loss: 1.0260987281799316, D Loss: 1.1937696933746338, alpha: 0.2697285955868183\n",
      "epoch 1166 iteration100, G Loss: 1.0021957159042358, D Loss: 1.2618358135223389, alpha: 0.2697285955868183\n",
      "epoch 1167 iteration0, G Loss: 1.1025346517562866, D Loss: 1.2673403024673462, alpha: 0.26854837926602604\n",
      "epoch 1167 iteration100, G Loss: 0.9403493404388428, D Loss: 1.1982284784317017, alpha: 0.26854837926602604\n",
      "epoch 1168 iteration0, G Loss: 0.8089774250984192, D Loss: 1.206420660018921, alpha: 0.26737143634537386\n",
      "epoch 1168 iteration100, G Loss: 0.8762294054031372, D Loss: 1.2443467378616333, alpha: 0.26737143634537386\n",
      "epoch 1169 iteration0, G Loss: 0.9653047323226929, D Loss: 1.2786750793457031, alpha: 0.2661977743219901\n",
      "epoch 1169 iteration100, G Loss: 1.2798222303390503, D Loss: 1.2757453918457031, alpha: 0.2661977743219901\n",
      "epoch 1170 iteration0, G Loss: 0.8640612959861755, D Loss: 1.4149610996246338, alpha: 0.26502740053348106\n",
      "epoch 1170 iteration100, G Loss: 1.3947032690048218, D Loss: 1.2961660623550415, alpha: 0.26502740053348106\n",
      "epoch 1171 iteration0, G Loss: 0.8953878283500671, D Loss: 1.3137381076812744, alpha: 0.2638603221583521\n",
      "epoch 1171 iteration100, G Loss: 0.9869287014007568, D Loss: 1.197077751159668, alpha: 0.2638603221583521\n",
      "epoch 1172 iteration0, G Loss: 0.8358736634254456, D Loss: 1.2461471557617188, alpha: 0.2626965462164407\n",
      "epoch 1172 iteration100, G Loss: 0.8326316475868225, D Loss: 1.1916747093200684, alpha: 0.2626965462164407\n",
      "epoch 1173 iteration0, G Loss: 0.9907347559928894, D Loss: 1.167394995689392, alpha: 0.2615360795693643\n",
      "epoch 1173 iteration100, G Loss: 1.025933027267456, D Loss: 1.3235666751861572, alpha: 0.2615360795693643\n",
      "epoch 1174 iteration0, G Loss: 0.9814862012863159, D Loss: 1.2797894477844238, alpha: 0.2603789289209778\n",
      "epoch 1174 iteration100, G Loss: 1.0664036273956299, D Loss: 1.2462096214294434, alpha: 0.2603789289209778\n",
      "epoch 1175 iteration0, G Loss: 0.8098117113113403, D Loss: 1.1089813709259033, alpha: 0.2592251008178461\n",
      "epoch 1175 iteration100, G Loss: 0.954075038433075, D Loss: 1.1805031299591064, alpha: 0.2592251008178461\n",
      "epoch 1176 iteration0, G Loss: 0.8237826824188232, D Loss: 1.2265691757202148, alpha: 0.25807460164972573\n",
      "epoch 1176 iteration100, G Loss: 1.1584804058074951, D Loss: 1.2856597900390625, alpha: 0.25807460164972573\n",
      "epoch 1177 iteration0, G Loss: 0.9960674047470093, D Loss: 1.1769239902496338, alpha: 0.25692743765006276\n",
      "epoch 1177 iteration100, G Loss: 1.1166409254074097, D Loss: 1.1783068180084229, alpha: 0.25692743765006276\n",
      "epoch 1178 iteration0, G Loss: 0.9711639285087585, D Loss: 1.1725952625274658, alpha: 0.2557836148964986\n",
      "epoch 1178 iteration100, G Loss: 1.393757700920105, D Loss: 1.2461391687393188, alpha: 0.2557836148964986\n",
      "epoch 1179 iteration0, G Loss: 0.9991068243980408, D Loss: 1.1728914976119995, alpha: 0.2546431393113898\n",
      "epoch 1179 iteration100, G Loss: 1.1884206533432007, D Loss: 1.1768234968185425, alpha: 0.2546431393113898\n",
      "epoch 1180 iteration0, G Loss: 1.0242053270339966, D Loss: 1.2517348527908325, alpha: 0.25350601666233785\n",
      "epoch 1180 iteration100, G Loss: 1.4508287906646729, D Loss: 1.134377360343933, alpha: 0.25350601666233785\n",
      "epoch 1181 iteration0, G Loss: 1.0801702737808228, D Loss: 1.2581734657287598, alpha: 0.25237225256273255\n",
      "epoch 1181 iteration100, G Loss: 1.4141829013824463, D Loss: 1.1801055669784546, alpha: 0.25237225256273255\n",
      "epoch 1182 iteration0, G Loss: 0.96896892786026, D Loss: 1.2202818393707275, alpha: 0.25124185247230435\n",
      "epoch 1182 iteration100, G Loss: 0.9940335154533386, D Loss: 1.258925199508667, alpha: 0.25124185247230435\n",
      "epoch 1183 iteration0, G Loss: 0.9652438759803772, D Loss: 1.0910686254501343, alpha: 0.2501148216976895\n",
      "epoch 1183 iteration100, G Loss: 0.8454100489616394, D Loss: 1.3097617626190186, alpha: 0.2501148216976895\n",
      "epoch 1184 iteration0, G Loss: 0.9628103971481323, D Loss: 1.1787168979644775, alpha: 0.2489911653930037\n",
      "epoch 1184 iteration100, G Loss: 1.2829045057296753, D Loss: 1.3264466524124146, alpha: 0.2489911653930037\n",
      "epoch 1185 iteration0, G Loss: 0.9655611515045166, D Loss: 1.2395981550216675, alpha: 0.24787088856042983\n",
      "epoch 1185 iteration100, G Loss: 1.2008893489837646, D Loss: 1.2979910373687744, alpha: 0.24787088856042983\n",
      "epoch 1186 iteration0, G Loss: 1.0861388444900513, D Loss: 1.1453535556793213, alpha: 0.24675399605081327\n",
      "epoch 1186 iteration100, G Loss: 1.0544617176055908, D Loss: 1.2073187828063965, alpha: 0.24675399605081327\n",
      "epoch 1187 iteration0, G Loss: 1.0533745288848877, D Loss: 1.1920127868652344, alpha: 0.24564049256426923\n",
      "epoch 1187 iteration100, G Loss: 0.8214499950408936, D Loss: 1.2268145084381104, alpha: 0.24564049256426923\n",
      "epoch 1188 iteration0, G Loss: 0.9188433885574341, D Loss: 1.1569018363952637, alpha: 0.2445303826507994\n",
      "epoch 1188 iteration100, G Loss: 1.3352614641189575, D Loss: 1.1913236379623413, alpha: 0.2445303826507994\n",
      "epoch 1189 iteration0, G Loss: 0.9259287714958191, D Loss: 1.2133489847183228, alpha: 0.2434236707109193\n",
      "epoch 1189 iteration100, G Loss: 1.0413426160812378, D Loss: 1.1764696836471558, alpha: 0.2434236707109193\n",
      "epoch 1190 iteration0, G Loss: 0.9299643635749817, D Loss: 1.2165205478668213, alpha: 0.24232036099629506\n",
      "epoch 1190 iteration100, G Loss: 1.1258158683776855, D Loss: 1.2658263444900513, alpha: 0.24232036099629506\n",
      "epoch 1191 iteration0, G Loss: 1.0719318389892578, D Loss: 1.277123212814331, alpha: 0.24122045761039035\n",
      "epoch 1191 iteration100, G Loss: 0.9227684736251831, D Loss: 1.267866611480713, alpha: 0.24122045761039035\n",
      "epoch 1192 iteration0, G Loss: 0.8395238518714905, D Loss: 1.2227165699005127, alpha: 0.24012396450912177\n",
      "epoch 1192 iteration100, G Loss: 1.3233586549758911, D Loss: 1.2177342176437378, alpha: 0.24012396450912177\n",
      "epoch 1193 iteration0, G Loss: 0.9705480933189392, D Loss: 1.2339328527450562, alpha: 0.2390308855015253\n",
      "epoch 1193 iteration100, G Loss: 1.231622576713562, D Loss: 1.2694815397262573, alpha: 0.2390308855015253\n",
      "epoch 1194 iteration0, G Loss: 0.9267611503601074, D Loss: 1.1496665477752686, alpha: 0.23794122425043063\n",
      "epoch 1194 iteration100, G Loss: 1.2889118194580078, D Loss: 1.2859095335006714, alpha: 0.23794122425043063\n",
      "epoch 1195 iteration0, G Loss: 0.8966219425201416, D Loss: 1.2439148426055908, alpha: 0.23685498427314455\n",
      "epoch 1195 iteration100, G Loss: 1.1856565475463867, D Loss: 1.2042694091796875, alpha: 0.23685498427314455\n",
      "epoch 1196 iteration0, G Loss: 1.136777400970459, D Loss: 1.2646286487579346, alpha: 0.2357721689421437\n",
      "epoch 1196 iteration100, G Loss: 1.169092059135437, D Loss: 1.2935326099395752, alpha: 0.2357721689421437\n",
      "epoch 1197 iteration0, G Loss: 0.8720074892044067, D Loss: 1.2884719371795654, alpha: 0.2346927814857761\n",
      "epoch 1197 iteration100, G Loss: 1.1793968677520752, D Loss: 1.204065203666687, alpha: 0.2346927814857761\n",
      "epoch 1198 iteration0, G Loss: 0.9423892498016357, D Loss: 1.1581329107284546, alpha: 0.23361682498897074\n",
      "epoch 1198 iteration100, G Loss: 1.1714118719100952, D Loss: 1.1907567977905273, alpha: 0.23361682498897074\n",
      "epoch 1199 iteration0, G Loss: 0.9116836190223694, D Loss: 1.1567156314849854, alpha: 0.23254430239395518\n",
      "epoch 1199 iteration100, G Loss: 0.9629958868026733, D Loss: 1.248846411705017, alpha: 0.23254430239395518\n",
      "epoch 1200 iteration0, G Loss: 1.1178686618804932, D Loss: 0.9965351819992065, alpha: 0.23147521650098224\n",
      "epoch 1200 iteration100, G Loss: 1.2289851903915405, D Loss: 1.2086842060089111, alpha: 0.23147521650098224\n",
      "Saving content.\n",
      "epoch 1201 iteration0, G Loss: 0.9331566095352173, D Loss: 1.2047250270843506, alpha: 0.2304095699690648\n",
      "epoch 1201 iteration100, G Loss: 1.0231530666351318, D Loss: 1.3355886936187744, alpha: 0.2304095699690648\n",
      "epoch 1202 iteration0, G Loss: 0.9543555974960327, D Loss: 1.2241930961608887, alpha: 0.2293473653167165\n",
      "epoch 1202 iteration100, G Loss: 1.4253844022750854, D Loss: 1.2207595109939575, alpha: 0.2293473653167165\n",
      "epoch 1203 iteration0, G Loss: 0.956081211566925, D Loss: 1.265467643737793, alpha: 0.22828860492270264\n",
      "epoch 1203 iteration100, G Loss: 1.1663316488265991, D Loss: 1.2233598232269287, alpha: 0.22828860492270264\n",
      "epoch 1204 iteration0, G Loss: 1.0069869756698608, D Loss: 1.1753768920898438, alpha: 0.2272332910267969\n",
      "epoch 1204 iteration100, G Loss: 1.3285874128341675, D Loss: 1.1460728645324707, alpha: 0.2272332910267969\n",
      "epoch 1205 iteration0, G Loss: 0.9082920551300049, D Loss: 1.2158604860305786, alpha: 0.22618142573054623\n",
      "epoch 1205 iteration100, G Loss: 1.3065543174743652, D Loss: 1.1030268669128418, alpha: 0.22618142573054623\n",
      "epoch 1206 iteration0, G Loss: 1.006908655166626, D Loss: 1.2217711210250854, alpha: 0.22513301099804206\n",
      "epoch 1206 iteration100, G Loss: 1.3874610662460327, D Loss: 1.195474624633789, alpha: 0.22513301099804206\n",
      "epoch 1207 iteration0, G Loss: 0.8696163296699524, D Loss: 1.2241814136505127, alpha: 0.2240880486566995\n",
      "epoch 1207 iteration100, G Loss: 0.932055652141571, D Loss: 1.2529889345169067, alpha: 0.2240880486566995\n",
      "epoch 1208 iteration0, G Loss: 0.9678741097450256, D Loss: 1.3165768384933472, alpha: 0.22304654039804273\n",
      "epoch 1208 iteration100, G Loss: 1.1013256311416626, D Loss: 1.1876113414764404, alpha: 0.22304654039804273\n",
      "epoch 1209 iteration0, G Loss: 1.168555498123169, D Loss: 1.187965989112854, alpha: 0.22200848777849702\n",
      "epoch 1209 iteration100, G Loss: 1.10684335231781, D Loss: 1.185835599899292, alpha: 0.22200848777849702\n",
      "epoch 1210 iteration0, G Loss: 0.8573576211929321, D Loss: 1.2037169933319092, alpha: 0.22097389222018782\n",
      "epoch 1210 iteration100, G Loss: 1.0622477531433105, D Loss: 1.158632516860962, alpha: 0.22097389222018782\n",
      "epoch 1211 iteration0, G Loss: 1.0771502256393433, D Loss: 1.2260966300964355, alpha: 0.21994275501174532\n",
      "epoch 1211 iteration100, G Loss: 1.1863887310028076, D Loss: 1.2425920963287354, alpha: 0.21994275501174532\n",
      "epoch 1212 iteration0, G Loss: 0.9662498831748962, D Loss: 1.2635998725891113, alpha: 0.21891507730911575\n",
      "epoch 1212 iteration100, G Loss: 1.1900663375854492, D Loss: 1.3366061449050903, alpha: 0.21891507730911575\n",
      "epoch 1213 iteration0, G Loss: 0.9869633316993713, D Loss: 1.1722960472106934, alpha: 0.21789086013637915\n",
      "epoch 1213 iteration100, G Loss: 1.1457828283309937, D Loss: 1.1756579875946045, alpha: 0.21789086013637915\n",
      "epoch 1214 iteration0, G Loss: 1.0150355100631714, D Loss: 1.1648911237716675, alpha: 0.21687010438657173\n",
      "epoch 1214 iteration100, G Loss: 1.6511893272399902, D Loss: 1.240342617034912, alpha: 0.21687010438657173\n",
      "epoch 1215 iteration0, G Loss: 1.104663610458374, D Loss: 1.149289608001709, alpha: 0.2158528108225145\n",
      "epoch 1215 iteration100, G Loss: 1.164792537689209, D Loss: 1.0538711547851562, alpha: 0.2158528108225145\n",
      "epoch 1216 iteration0, G Loss: 0.9115472435951233, D Loss: 1.1334939002990723, alpha: 0.21483898007764857\n",
      "epoch 1216 iteration100, G Loss: 0.947830855846405, D Loss: 1.1324470043182373, alpha: 0.21483898007764857\n",
      "epoch 1217 iteration0, G Loss: 0.9745535850524902, D Loss: 1.246299386024475, alpha: 0.21382861265687303\n",
      "epoch 1217 iteration100, G Loss: 0.9734897017478943, D Loss: 1.189166784286499, alpha: 0.21382861265687303\n",
      "epoch 1218 iteration0, G Loss: 0.9080060720443726, D Loss: 1.1784603595733643, alpha: 0.21282170893739183\n",
      "epoch 1218 iteration100, G Loss: 1.3821604251861572, D Loss: 1.2420076131820679, alpha: 0.21282170893739183\n",
      "epoch 1219 iteration0, G Loss: 1.047648310661316, D Loss: 1.2853885889053345, alpha: 0.21181826916956137\n",
      "epoch 1219 iteration100, G Loss: 1.342836618423462, D Loss: 1.2227413654327393, alpha: 0.21181826916956137\n",
      "epoch 1220 iteration0, G Loss: 0.8566038608551025, D Loss: 1.260685682296753, alpha: 0.21081829347774705\n",
      "epoch 1220 iteration100, G Loss: 0.7281125783920288, D Loss: 1.252971887588501, alpha: 0.21081829347774705\n",
      "epoch 1221 iteration0, G Loss: 1.0380749702453613, D Loss: 1.135145902633667, alpha: 0.20982178186118194\n",
      "epoch 1221 iteration100, G Loss: 0.9005589485168457, D Loss: 1.2206480503082275, alpha: 0.20982178186118194\n",
      "epoch 1222 iteration0, G Loss: 0.8606963157653809, D Loss: 1.3125581741333008, alpha: 0.2088287341948305\n",
      "epoch 1222 iteration100, G Loss: 1.3968043327331543, D Loss: 1.2665067911148071, alpha: 0.2088287341948305\n",
      "epoch 1223 iteration0, G Loss: 1.0890089273452759, D Loss: 1.1688131093978882, alpha: 0.20783915023025767\n",
      "epoch 1223 iteration100, G Loss: 0.8889675140380859, D Loss: 1.2551066875457764, alpha: 0.20783915023025767\n",
      "epoch 1224 iteration0, G Loss: 0.7914485335350037, D Loss: 1.228192925453186, alpha: 0.20685302959650098\n",
      "epoch 1224 iteration100, G Loss: 0.8899196982383728, D Loss: 1.2071776390075684, alpha: 0.20685302959650098\n",
      "epoch 1225 iteration0, G Loss: 1.0721802711486816, D Loss: 1.1203588247299194, alpha: 0.20587037180094725\n",
      "epoch 1225 iteration100, G Loss: 0.8280496597290039, D Loss: 1.2355430126190186, alpha: 0.20587037180094725\n",
      "epoch 1226 iteration0, G Loss: 0.921710729598999, D Loss: 1.302213191986084, alpha: 0.20489117623021424\n",
      "epoch 1226 iteration100, G Loss: 1.2612946033477783, D Loss: 1.2277945280075073, alpha: 0.20489117623021424\n",
      "epoch 1227 iteration0, G Loss: 1.0519071817398071, D Loss: 1.189694881439209, alpha: 0.20391544215103408\n",
      "epoch 1227 iteration100, G Loss: 1.1435418128967285, D Loss: 1.180983066558838, alpha: 0.20391544215103408\n",
      "epoch 1228 iteration0, G Loss: 1.030320405960083, D Loss: 1.1826932430267334, alpha: 0.2029431687111415\n",
      "epoch 1228 iteration100, G Loss: 1.1715812683105469, D Loss: 1.231100082397461, alpha: 0.2029431687111415\n",
      "epoch 1229 iteration0, G Loss: 1.1218087673187256, D Loss: 1.152589201927185, alpha: 0.2019743549401669\n",
      "epoch 1229 iteration100, G Loss: 1.0619242191314697, D Loss: 1.2983770370483398, alpha: 0.2019743549401669\n",
      "epoch 1230 iteration0, G Loss: 0.9226678609848022, D Loss: 1.1860549449920654, alpha: 0.20100899975052933\n",
      "epoch 1230 iteration100, G Loss: 0.847726047039032, D Loss: 1.1396657228469849, alpha: 0.20100899975052933\n",
      "epoch 1231 iteration0, G Loss: 0.9827133417129517, D Loss: 1.161220908164978, alpha: 0.2000471019383362\n",
      "epoch 1231 iteration100, G Loss: 1.2839081287384033, D Loss: 1.2328848838806152, alpha: 0.2000471019383362\n",
      "epoch 1232 iteration0, G Loss: 1.0052266120910645, D Loss: 1.2407313585281372, alpha: 0.19908866018428373\n",
      "epoch 1232 iteration100, G Loss: 1.2746398448944092, D Loss: 1.3234723806381226, alpha: 0.19908866018428373\n",
      "epoch 1233 iteration0, G Loss: 0.7378803491592407, D Loss: 1.207944631576538, alpha: 0.19813367305456175\n",
      "epoch 1233 iteration100, G Loss: 1.317159652709961, D Loss: 1.1494969129562378, alpha: 0.19813367305456175\n",
      "epoch 1234 iteration0, G Loss: 0.8909585475921631, D Loss: 1.1809003353118896, alpha: 0.1971821390017604\n",
      "epoch 1234 iteration100, G Loss: 1.1104682683944702, D Loss: 1.2195442914962769, alpha: 0.1971821390017604\n",
      "epoch 1235 iteration0, G Loss: 1.0229765176773071, D Loss: 1.1947873830795288, alpha: 0.19623405636577917\n",
      "epoch 1235 iteration100, G Loss: 0.8523001670837402, D Loss: 1.3391122817993164, alpha: 0.19623405636577917\n",
      "epoch 1236 iteration0, G Loss: 0.9226288199424744, D Loss: 1.277686595916748, alpha: 0.19528942337473987\n",
      "epoch 1236 iteration100, G Loss: 1.0422295331954956, D Loss: 1.2120540142059326, alpha: 0.19528942337473987\n",
      "epoch 1237 iteration0, G Loss: 0.9252580404281616, D Loss: 1.164926290512085, alpha: 0.1943482381459002\n",
      "epoch 1237 iteration100, G Loss: 1.195992112159729, D Loss: 1.1537859439849854, alpha: 0.1943482381459002\n",
      "epoch 1238 iteration0, G Loss: 0.9144633412361145, D Loss: 1.1224771738052368, alpha: 0.19341049868657156\n",
      "epoch 1238 iteration100, G Loss: 1.1454623937606812, D Loss: 1.24613618850708, alpha: 0.19341049868657156\n",
      "epoch 1239 iteration0, G Loss: 1.0787410736083984, D Loss: 1.2143398523330688, alpha: 0.19247620289503564\n",
      "epoch 1239 iteration100, G Loss: 0.9993952512741089, D Loss: 1.1739697456359863, alpha: 0.19247620289503564\n",
      "epoch 1240 iteration0, G Loss: 0.9837968349456787, D Loss: 1.2627129554748535, alpha: 0.19154534856146743\n",
      "epoch 1240 iteration100, G Loss: 0.9931796193122864, D Loss: 1.213979959487915, alpha: 0.19154534856146743\n",
      "epoch 1241 iteration0, G Loss: 1.001908779144287, D Loss: 1.2002774477005005, alpha: 0.19061793336885569\n",
      "epoch 1241 iteration100, G Loss: 1.3036595582962036, D Loss: 1.0661673545837402, alpha: 0.19061793336885569\n",
      "epoch 1242 iteration0, G Loss: 1.049766182899475, D Loss: 1.1359546184539795, alpha: 0.18969395489392782\n",
      "epoch 1242 iteration100, G Loss: 0.9153726100921631, D Loss: 1.3493645191192627, alpha: 0.18969395489392782\n",
      "epoch 1243 iteration0, G Loss: 0.7965728640556335, D Loss: 1.278437614440918, alpha: 0.1887734106080753\n",
      "epoch 1243 iteration100, G Loss: 1.006588101387024, D Loss: 1.2749651670455933, alpha: 0.1887734106080753\n",
      "epoch 1244 iteration0, G Loss: 0.9462428092956543, D Loss: 1.1276581287384033, alpha: 0.18785629787828084\n",
      "epoch 1244 iteration100, G Loss: 1.129989504814148, D Loss: 1.2279025316238403, alpha: 0.18785629787828084\n",
      "epoch 1245 iteration0, G Loss: 0.8948792815208435, D Loss: 1.1747386455535889, alpha: 0.18694261396804635\n",
      "epoch 1245 iteration100, G Loss: 1.0912755727767944, D Loss: 1.1975064277648926, alpha: 0.18694261396804635\n",
      "epoch 1246 iteration0, G Loss: 0.9608289003372192, D Loss: 1.1602485179901123, alpha: 0.18603235603832213\n",
      "epoch 1246 iteration100, G Loss: 1.1404129266738892, D Loss: 1.3014724254608154, alpha: 0.18603235603832213\n",
      "epoch 1247 iteration0, G Loss: 1.0352109670639038, D Loss: 1.1765929460525513, alpha: 0.18512552114843717\n",
      "epoch 1247 iteration100, G Loss: 1.0914644002914429, D Loss: 1.2096707820892334, alpha: 0.18512552114843717\n",
      "epoch 1248 iteration0, G Loss: 1.1228946447372437, D Loss: 1.174994945526123, alpha: 0.18422210625703106\n",
      "epoch 1248 iteration100, G Loss: 1.1395221948623657, D Loss: 1.2181720733642578, alpha: 0.18422210625703106\n",
      "epoch 1249 iteration0, G Loss: 0.9339821338653564, D Loss: 1.1707472801208496, alpha: 0.18332210822298556\n",
      "epoch 1249 iteration100, G Loss: 1.0673359632492065, D Loss: 1.1640809774398804, alpha: 0.18332210822298556\n",
      "epoch 1250 iteration0, G Loss: 1.0147446393966675, D Loss: 1.2572697401046753, alpha: 0.18242552380635635\n",
      "epoch 1250 iteration100, G Loss: 1.1002373695373535, D Loss: 1.0894172191619873, alpha: 0.18242552380635635\n",
      "Saving content.\n",
      "epoch 1251 iteration0, G Loss: 0.9680564403533936, D Loss: 1.2141358852386475, alpha: 0.18153234966930742\n",
      "epoch 1251 iteration100, G Loss: 1.138885259628296, D Loss: 1.2120717763900757, alpha: 0.18153234966930742\n",
      "epoch 1252 iteration0, G Loss: 1.0425159931182861, D Loss: 1.281830072402954, alpha: 0.18064258237704411\n",
      "epoch 1252 iteration100, G Loss: 1.6396363973617554, D Loss: 1.1672381162643433, alpha: 0.18064258237704411\n",
      "epoch 1253 iteration0, G Loss: 0.8073675036430359, D Loss: 1.2737150192260742, alpha: 0.17975621839874645\n",
      "epoch 1253 iteration100, G Loss: 1.5021620988845825, D Loss: 1.1917701959609985, alpha: 0.17975621839874645\n",
      "epoch 1254 iteration0, G Loss: 0.9865926504135132, D Loss: 1.138327956199646, alpha: 0.1788732541085032\n",
      "epoch 1254 iteration100, G Loss: 1.3046714067459106, D Loss: 1.1436363458633423, alpha: 0.1788732541085032\n",
      "epoch 1255 iteration0, G Loss: 0.9335399866104126, D Loss: 1.2258247137069702, alpha: 0.17799368578624652\n",
      "epoch 1255 iteration100, G Loss: 0.8564697504043579, D Loss: 1.2158377170562744, alpha: 0.17799368578624652\n",
      "epoch 1256 iteration0, G Loss: 0.913153350353241, D Loss: 1.1830544471740723, alpha: 0.17711750961868433\n",
      "epoch 1256 iteration100, G Loss: 1.4954222440719604, D Loss: 1.1533583402633667, alpha: 0.17711750961868433\n",
      "epoch 1257 iteration0, G Loss: 1.1043940782546997, D Loss: 1.2099089622497559, alpha: 0.17624472170023586\n",
      "epoch 1257 iteration100, G Loss: 1.29690420627594, D Loss: 1.1123671531677246, alpha: 0.17624472170023586\n",
      "epoch 1258 iteration0, G Loss: 1.0412436723709106, D Loss: 1.2207753658294678, alpha: 0.17537531803396256\n",
      "epoch 1258 iteration100, G Loss: 1.033228874206543, D Loss: 1.1438604593276978, alpha: 0.17537531803396256\n",
      "epoch 1259 iteration0, G Loss: 0.7263587117195129, D Loss: 1.251136302947998, alpha: 0.1745092945325032\n",
      "epoch 1259 iteration100, G Loss: 0.9369677901268005, D Loss: 1.3177917003631592, alpha: 0.1745092945325032\n",
      "epoch 1260 iteration0, G Loss: 0.8851693868637085, D Loss: 1.2289457321166992, alpha: 0.173646647019005\n",
      "epoch 1260 iteration100, G Loss: 1.0327739715576172, D Loss: 1.2420556545257568, alpha: 0.173646647019005\n",
      "epoch 1261 iteration0, G Loss: 1.1686420440673828, D Loss: 1.2483057975769043, alpha: 0.17278737122805565\n",
      "epoch 1261 iteration100, G Loss: 1.2817845344543457, D Loss: 1.1615504026412964, alpha: 0.17278737122805565\n",
      "epoch 1262 iteration0, G Loss: 1.0432374477386475, D Loss: 1.22388756275177, alpha: 0.17193146280661376\n",
      "epoch 1262 iteration100, G Loss: 0.9987047910690308, D Loss: 1.1805496215820312, alpha: 0.17193146280661376\n",
      "epoch 1263 iteration0, G Loss: 1.2260160446166992, D Loss: 1.2379610538482666, alpha: 0.17107891731493996\n",
      "epoch 1263 iteration100, G Loss: 0.931398868560791, D Loss: 1.1703895330429077, alpha: 0.17107891731493996\n",
      "epoch 1264 iteration0, G Loss: 0.7476694583892822, D Loss: 1.2630611658096313, alpha: 0.17022973022752508\n",
      "epoch 1264 iteration100, G Loss: 1.2279586791992188, D Loss: 1.2059707641601562, alpha: 0.17022973022752508\n",
      "epoch 1265 iteration0, G Loss: 0.8712829351425171, D Loss: 1.2178882360458374, alpha: 0.16938389693401867\n",
      "epoch 1265 iteration100, G Loss: 0.9775829911231995, D Loss: 1.2254995107650757, alpha: 0.16938389693401867\n",
      "epoch 1266 iteration0, G Loss: 1.056328535079956, D Loss: 1.2280088663101196, alpha: 0.16854141274015533\n",
      "epoch 1266 iteration100, G Loss: 1.3240007162094116, D Loss: 1.1903395652770996, alpha: 0.16854141274015533\n",
      "epoch 1267 iteration0, G Loss: 0.7552207708358765, D Loss: 1.1993745565414429, alpha: 0.167702272868681\n",
      "epoch 1267 iteration100, G Loss: 0.9544470310211182, D Loss: 1.268991231918335, alpha: 0.167702272868681\n",
      "epoch 1268 iteration0, G Loss: 1.0646097660064697, D Loss: 1.3085535764694214, alpha: 0.16686647246027686\n",
      "epoch 1268 iteration100, G Loss: 1.0521950721740723, D Loss: 1.3013598918914795, alpha: 0.16686647246027686\n",
      "epoch 1269 iteration0, G Loss: 0.9465442299842834, D Loss: 1.1865918636322021, alpha: 0.16603400657448208\n",
      "epoch 1269 iteration100, G Loss: 0.7385956645011902, D Loss: 1.308313012123108, alpha: 0.16603400657448208\n",
      "epoch 1270 iteration0, G Loss: 0.9612381458282471, D Loss: 1.255234718322754, alpha: 0.16520487019061458\n",
      "epoch 1270 iteration100, G Loss: 1.2036879062652588, D Loss: 1.2346060276031494, alpha: 0.16520487019061458\n",
      "epoch 1271 iteration0, G Loss: 0.9397018551826477, D Loss: 1.1040031909942627, alpha: 0.1643790582086916\n",
      "epoch 1271 iteration100, G Loss: 0.9589773416519165, D Loss: 1.2054054737091064, alpha: 0.1643790582086916\n",
      "epoch 1272 iteration0, G Loss: 1.0818824768066406, D Loss: 1.2423778772354126, alpha: 0.1635565654503467\n",
      "epoch 1272 iteration100, G Loss: 0.8946623802185059, D Loss: 1.2003777027130127, alpha: 0.1635565654503467\n",
      "epoch 1273 iteration0, G Loss: 1.0337278842926025, D Loss: 1.2103207111358643, alpha: 0.16273738665974602\n",
      "epoch 1273 iteration100, G Loss: 1.0285027027130127, D Loss: 1.2016162872314453, alpha: 0.16273738665974602\n",
      "epoch 1274 iteration0, G Loss: 0.920398473739624, D Loss: 1.2617075443267822, alpha: 0.16192151650450182\n",
      "epoch 1274 iteration100, G Loss: 1.3241240978240967, D Loss: 1.1622061729431152, alpha: 0.16192151650450182\n",
      "epoch 1275 iteration0, G Loss: 0.923586368560791, D Loss: 1.2045775651931763, alpha: 0.16110894957658528\n",
      "epoch 1275 iteration100, G Loss: 1.0941272974014282, D Loss: 1.367272973060608, alpha: 0.16110894957658528\n",
      "epoch 1276 iteration0, G Loss: 0.9218786358833313, D Loss: 1.1275842189788818, alpha: 0.1602996803932355\n",
      "epoch 1276 iteration100, G Loss: 1.0408751964569092, D Loss: 1.305790662765503, alpha: 0.1602996803932355\n",
      "epoch 1277 iteration0, G Loss: 0.9089754819869995, D Loss: 1.240497350692749, alpha: 0.15949370339786817\n",
      "epoch 1277 iteration100, G Loss: 1.6644638776779175, D Loss: 1.3321399688720703, alpha: 0.15949370339786817\n",
      "epoch 1278 iteration0, G Loss: 0.8825480341911316, D Loss: 1.2630149126052856, alpha: 0.1586910129609802\n",
      "epoch 1278 iteration100, G Loss: 1.197967767715454, D Loss: 1.2012149095535278, alpha: 0.1586910129609802\n",
      "epoch 1279 iteration0, G Loss: 0.8315020799636841, D Loss: 1.2492116689682007, alpha: 0.1578916033810528\n",
      "epoch 1279 iteration100, G Loss: 1.1425979137420654, D Loss: 1.1981544494628906, alpha: 0.1578916033810528\n",
      "epoch 1280 iteration0, G Loss: 0.8819073438644409, D Loss: 1.104388952255249, alpha: 0.15709546888545278\n",
      "epoch 1280 iteration100, G Loss: 0.8664387464523315, D Loss: 1.2164517641067505, alpha: 0.15709546888545278\n",
      "epoch 1281 iteration0, G Loss: 0.8178568482398987, D Loss: 1.2926204204559326, alpha: 0.15630260363132953\n",
      "epoch 1281 iteration100, G Loss: 1.3202718496322632, D Loss: 1.3544600009918213, alpha: 0.15630260363132953\n",
      "epoch 1282 iteration0, G Loss: 0.9227048754692078, D Loss: 1.2209053039550781, alpha: 0.15551300170651194\n",
      "epoch 1282 iteration100, G Loss: 1.0593682527542114, D Loss: 1.2187113761901855, alpha: 0.15551300170651194\n",
      "epoch 1283 iteration0, G Loss: 0.907682478427887, D Loss: 1.1332697868347168, alpha: 0.15472665713039957\n",
      "epoch 1283 iteration100, G Loss: 1.296175479888916, D Loss: 1.3011571168899536, alpha: 0.15472665713039957\n",
      "epoch 1284 iteration0, G Loss: 0.929040253162384, D Loss: 1.1799927949905396, alpha: 0.15394356385485441\n",
      "epoch 1284 iteration100, G Loss: 1.274926781654358, D Loss: 1.1735196113586426, alpha: 0.15394356385485441\n",
      "epoch 1285 iteration0, G Loss: 0.8536069393157959, D Loss: 1.2207565307617188, alpha: 0.15316371576508614\n",
      "epoch 1285 iteration100, G Loss: 1.2623533010482788, D Loss: 1.1692198514938354, alpha: 0.15316371576508614\n",
      "epoch 1286 iteration0, G Loss: 0.9523807764053345, D Loss: 1.2046334743499756, alpha: 0.15238710668053845\n",
      "epoch 1286 iteration100, G Loss: 1.1172733306884766, D Loss: 1.2941193580627441, alpha: 0.15238710668053845\n",
      "epoch 1287 iteration0, G Loss: 0.8035471439361572, D Loss: 1.1820135116577148, alpha: 0.15161373035576875\n",
      "epoch 1287 iteration100, G Loss: 1.1824917793273926, D Loss: 1.2095544338226318, alpha: 0.15161373035576875\n",
      "epoch 1288 iteration0, G Loss: 1.020627498626709, D Loss: 1.1499054431915283, alpha: 0.15084358048132773\n",
      "epoch 1288 iteration100, G Loss: 0.9996755123138428, D Loss: 1.2809443473815918, alpha: 0.15084358048132773\n",
      "epoch 1289 iteration0, G Loss: 0.8785191774368286, D Loss: 1.1487622261047363, alpha: 0.15007665068463327\n",
      "epoch 1289 iteration100, G Loss: 1.3318289518356323, D Loss: 1.1870367527008057, alpha: 0.15007665068463327\n",
      "epoch 1290 iteration0, G Loss: 0.9121578335762024, D Loss: 1.218216061592102, alpha: 0.1493129345308437\n",
      "epoch 1290 iteration100, G Loss: 0.8080112934112549, D Loss: 1.3198704719543457, alpha: 0.1493129345308437\n",
      "epoch 1291 iteration0, G Loss: 0.94803786277771, D Loss: 1.2101376056671143, alpha: 0.14855242552372538\n",
      "epoch 1291 iteration100, G Loss: 1.315072774887085, D Loss: 1.2119821310043335, alpha: 0.14855242552372538\n",
      "epoch 1292 iteration0, G Loss: 0.8631866574287415, D Loss: 1.1572558879852295, alpha: 0.14779511710651905\n",
      "epoch 1292 iteration100, G Loss: 0.782907247543335, D Loss: 1.3034093379974365, alpha: 0.14779511710651905\n",
      "epoch 1293 iteration0, G Loss: 0.9782005548477173, D Loss: 1.243822455406189, alpha: 0.14704100266280107\n",
      "epoch 1293 iteration100, G Loss: 1.176852822303772, D Loss: 1.1362587213516235, alpha: 0.14704100266280107\n",
      "epoch 1294 iteration0, G Loss: 0.8375436067581177, D Loss: 1.2269976139068604, alpha: 0.14629007551734285\n",
      "epoch 1294 iteration100, G Loss: 1.2712382078170776, D Loss: 1.1429662704467773, alpha: 0.14629007551734285\n",
      "epoch 1295 iteration0, G Loss: 0.8342958092689514, D Loss: 1.2139911651611328, alpha: 0.14554232893696517\n",
      "epoch 1295 iteration100, G Loss: 1.1417502164840698, D Loss: 1.2040420770645142, alpha: 0.14554232893696517\n",
      "epoch 1296 iteration0, G Loss: 0.9270591735839844, D Loss: 1.1800761222839355, alpha: 0.14479775613139056\n",
      "epoch 1296 iteration100, G Loss: 1.376773476600647, D Loss: 1.1023292541503906, alpha: 0.14479775613139056\n",
      "epoch 1297 iteration0, G Loss: 0.9734087586402893, D Loss: 1.1924293041229248, alpha: 0.14405635025408992\n",
      "epoch 1297 iteration100, G Loss: 1.11384117603302, D Loss: 1.2641583681106567, alpha: 0.14405635025408992\n",
      "epoch 1298 iteration0, G Loss: 1.1328809261322021, D Loss: 1.218106746673584, alpha: 0.14331810440312842\n",
      "epoch 1298 iteration100, G Loss: 0.9710994958877563, D Loss: 1.2026220560073853, alpha: 0.14331810440312842\n",
      "epoch 1299 iteration0, G Loss: 0.8853396773338318, D Loss: 1.1682615280151367, alpha: 0.1425830116220046\n",
      "epoch 1299 iteration100, G Loss: 0.8650977611541748, D Loss: 1.2165484428405762, alpha: 0.1425830116220046\n",
      "epoch 1300 iteration0, G Loss: 0.8582941293716431, D Loss: 1.224616289138794, alpha: 0.1418510649004877\n",
      "epoch 1300 iteration100, G Loss: 1.313256025314331, D Loss: 1.2038049697875977, alpha: 0.1418510649004877\n",
      "Saving content.\n",
      "epoch 1301 iteration0, G Loss: 0.793156087398529, D Loss: 1.1892374753952026, alpha: 0.1411222571754509\n",
      "epoch 1301 iteration100, G Loss: 0.8351375460624695, D Loss: 1.2038414478302002, alpha: 0.1411222571754509\n",
      "epoch 1302 iteration0, G Loss: 1.069802165031433, D Loss: 1.1258182525634766, alpha: 0.14039658133169897\n",
      "epoch 1302 iteration100, G Loss: 1.0662858486175537, D Loss: 1.210559606552124, alpha: 0.14039658133169897\n",
      "epoch 1303 iteration0, G Loss: 0.9059982895851135, D Loss: 1.1736711263656616, alpha: 0.13967403020279534\n",
      "epoch 1303 iteration100, G Loss: 0.9980247616767883, D Loss: 1.333896517753601, alpha: 0.13967403020279534\n",
      "epoch 1304 iteration0, G Loss: 0.9906606078147888, D Loss: 1.1706531047821045, alpha: 0.13895459657188147\n",
      "epoch 1304 iteration100, G Loss: 0.8566068410873413, D Loss: 1.2682747840881348, alpha: 0.13895459657188147\n",
      "epoch 1305 iteration0, G Loss: 0.8180770874023438, D Loss: 1.2311716079711914, alpha: 0.13823827317249404\n",
      "epoch 1305 iteration100, G Loss: 1.0159670114517212, D Loss: 1.1237365007400513, alpha: 0.13823827317249404\n",
      "epoch 1306 iteration0, G Loss: 0.7505610585212708, D Loss: 1.3035681247711182, alpha: 0.1375250526893791\n",
      "epoch 1306 iteration100, G Loss: 0.9943316578865051, D Loss: 1.1447973251342773, alpha: 0.1375250526893791\n",
      "epoch 1307 iteration0, G Loss: 1.1913864612579346, D Loss: 1.174983263015747, alpha: 0.13681492775929927\n",
      "epoch 1307 iteration100, G Loss: 0.9937716126441956, D Loss: 1.2383748292922974, alpha: 0.13681492775929927\n",
      "epoch 1308 iteration0, G Loss: 0.8555804491043091, D Loss: 1.2378103733062744, alpha: 0.13610789097183962\n",
      "epoch 1308 iteration100, G Loss: 1.1885340213775635, D Loss: 1.345060110092163, alpha: 0.13610789097183962\n",
      "epoch 1309 iteration0, G Loss: 0.9393211603164673, D Loss: 1.197638988494873, alpha: 0.1354039348702074\n",
      "epoch 1309 iteration100, G Loss: 1.1719383001327515, D Loss: 1.2428655624389648, alpha: 0.1354039348702074\n",
      "epoch 1310 iteration0, G Loss: 0.9847850799560547, D Loss: 1.2605352401733398, alpha: 0.13470305195202803\n",
      "epoch 1310 iteration100, G Loss: 0.8653351664543152, D Loss: 1.198373556137085, alpha: 0.13470305195202803\n",
      "epoch 1311 iteration0, G Loss: 0.844970166683197, D Loss: 1.2551820278167725, alpha: 0.1340052346701378\n",
      "epoch 1311 iteration100, G Loss: 1.1098605394363403, D Loss: 1.1880769729614258, alpha: 0.1340052346701378\n",
      "epoch 1312 iteration0, G Loss: 1.1013646125793457, D Loss: 1.1961088180541992, alpha: 0.1333104754333705\n",
      "epoch 1312 iteration100, G Loss: 0.9349365234375, D Loss: 1.1945074796676636, alpha: 0.1333104754333705\n",
      "epoch 1313 iteration0, G Loss: 0.8997370600700378, D Loss: 1.2610681056976318, alpha: 0.1326187666073404\n",
      "epoch 1313 iteration100, G Loss: 1.0465384721755981, D Loss: 1.2253941297531128, alpha: 0.1326187666073404\n",
      "epoch 1314 iteration0, G Loss: 1.022810459136963, D Loss: 1.2656745910644531, alpha: 0.13193010051522203\n",
      "epoch 1314 iteration100, G Loss: 0.9256384968757629, D Loss: 1.206649899482727, alpha: 0.13193010051522203\n",
      "epoch 1315 iteration0, G Loss: 0.9065704345703125, D Loss: 1.2789952754974365, alpha: 0.1312444694385232\n",
      "epoch 1315 iteration100, G Loss: 1.1229809522628784, D Loss: 1.206944465637207, alpha: 0.1312444694385232\n",
      "epoch 1316 iteration0, G Loss: 0.8288743495941162, D Loss: 1.1639609336853027, alpha: 0.13056186561785588\n",
      "epoch 1316 iteration100, G Loss: 0.9881131052970886, D Loss: 1.2006826400756836, alpha: 0.13056186561785588\n",
      "epoch 1317 iteration0, G Loss: 0.8855443596839905, D Loss: 1.2792372703552246, alpha: 0.12988228125370027\n",
      "epoch 1317 iteration100, G Loss: 1.4095523357391357, D Loss: 1.1616497039794922, alpha: 0.12988228125370027\n",
      "epoch 1318 iteration0, G Loss: 0.9423915147781372, D Loss: 1.227092981338501, alpha: 0.12920570850716606\n",
      "epoch 1318 iteration100, G Loss: 1.0058329105377197, D Loss: 1.2387069463729858, alpha: 0.12920570850716606\n",
      "epoch 1319 iteration0, G Loss: 1.1401820182800293, D Loss: 1.1975159645080566, alpha: 0.12853213950074893\n",
      "epoch 1319 iteration100, G Loss: 1.0428553819656372, D Loss: 1.1938968896865845, alpha: 0.12853213950074893\n",
      "epoch 1320 iteration0, G Loss: 0.928952693939209, D Loss: 1.2355204820632935, alpha: 0.1278615663190813\n",
      "epoch 1320 iteration100, G Loss: 0.9614329934120178, D Loss: 1.2264549732208252, alpha: 0.1278615663190813\n",
      "epoch 1321 iteration0, G Loss: 0.7772684693336487, D Loss: 1.1920922994613647, alpha: 0.12719398100967938\n",
      "epoch 1321 iteration100, G Loss: 0.8095986247062683, D Loss: 1.281726360321045, alpha: 0.12719398100967938\n",
      "epoch 1322 iteration0, G Loss: 0.8749933242797852, D Loss: 1.0632481575012207, alpha: 0.12652937558368527\n",
      "epoch 1322 iteration100, G Loss: 1.1510056257247925, D Loss: 1.1976031064987183, alpha: 0.12652937558368527\n",
      "epoch 1323 iteration0, G Loss: 0.826320469379425, D Loss: 1.2273019552230835, alpha: 0.1258677420166049\n",
      "epoch 1323 iteration100, G Loss: 0.9031534790992737, D Loss: 1.2185217142105103, alpha: 0.1258677420166049\n",
      "epoch 1324 iteration0, G Loss: 0.8894410133361816, D Loss: 1.1814429759979248, alpha: 0.12520907224903988\n",
      "epoch 1324 iteration100, G Loss: 0.9842343330383301, D Loss: 1.237858533859253, alpha: 0.12520907224903988\n",
      "epoch 1325 iteration0, G Loss: 0.805627167224884, D Loss: 1.2202115058898926, alpha: 0.12455335818741642\n",
      "epoch 1325 iteration100, G Loss: 0.9178509712219238, D Loss: 1.2776669263839722, alpha: 0.12455335818741642\n",
      "epoch 1326 iteration0, G Loss: 0.9045844674110413, D Loss: 1.0984491109848022, alpha: 0.12390059170470769\n",
      "epoch 1326 iteration100, G Loss: 1.2285176515579224, D Loss: 1.2242393493652344, alpha: 0.12390059170470769\n",
      "epoch 1327 iteration0, G Loss: 0.798672080039978, D Loss: 1.2154756784439087, alpha: 0.1232507646411527\n",
      "epoch 1327 iteration100, G Loss: 0.9589083194732666, D Loss: 1.212117314338684, alpha: 0.1232507646411527\n",
      "epoch 1328 iteration0, G Loss: 1.0501770973205566, D Loss: 1.1693313121795654, alpha: 0.12260386880496976\n",
      "epoch 1328 iteration100, G Loss: 0.9725432991981506, D Loss: 1.2937581539154053, alpha: 0.12260386880496976\n",
      "epoch 1329 iteration0, G Loss: 0.9495455026626587, D Loss: 1.2363591194152832, alpha: 0.121959895973065\n",
      "epoch 1329 iteration100, G Loss: 0.83741295337677, D Loss: 1.2509456872940063, alpha: 0.121959895973065\n",
      "epoch 1330 iteration0, G Loss: 0.9336415529251099, D Loss: 1.1087095737457275, alpha: 0.12131883789173681\n",
      "epoch 1330 iteration100, G Loss: 0.67613685131073, D Loss: 1.2263505458831787, alpha: 0.12131883789173681\n",
      "epoch 1331 iteration0, G Loss: 0.8370435833930969, D Loss: 1.2376295328140259, alpha: 0.12068068627737405\n",
      "epoch 1331 iteration100, G Loss: 1.0798859596252441, D Loss: 1.286380648612976, alpha: 0.12068068627737405\n",
      "epoch 1332 iteration0, G Loss: 1.026079535484314, D Loss: 1.1640123128890991, alpha: 0.12004543281715074\n",
      "epoch 1332 iteration100, G Loss: 0.9935173392295837, D Loss: 1.2049481868743896, alpha: 0.12004543281715074\n",
      "epoch 1333 iteration0, G Loss: 0.9216849207878113, D Loss: 1.3253233432769775, alpha: 0.11941306916971495\n",
      "epoch 1333 iteration100, G Loss: 1.1394984722137451, D Loss: 1.2664216756820679, alpha: 0.11941306916971495\n",
      "epoch 1334 iteration0, G Loss: 0.9395567178726196, D Loss: 1.140251636505127, alpha: 0.11878358696587321\n",
      "epoch 1334 iteration100, G Loss: 0.9839513301849365, D Loss: 1.139827013015747, alpha: 0.11878358696587321\n",
      "epoch 1335 iteration0, G Loss: 0.9104565978050232, D Loss: 1.2796587944030762, alpha: 0.11815697780926959\n",
      "epoch 1335 iteration100, G Loss: 0.9632671475410461, D Loss: 1.2042789459228516, alpha: 0.11815697780926959\n",
      "epoch 1336 iteration0, G Loss: 0.8991777300834656, D Loss: 1.2426236867904663, alpha: 0.11753323327706\n",
      "epoch 1336 iteration100, G Loss: 0.7768859267234802, D Loss: 1.2642771005630493, alpha: 0.11753323327706\n",
      "epoch 1337 iteration0, G Loss: 0.9781258702278137, D Loss: 1.273130178451538, alpha: 0.11691234492058222\n",
      "epoch 1337 iteration100, G Loss: 0.8925091624259949, D Loss: 1.309194564819336, alpha: 0.11691234492058222\n",
      "epoch 1338 iteration0, G Loss: 1.0676751136779785, D Loss: 1.1457442045211792, alpha: 0.11629430426601906\n",
      "epoch 1338 iteration100, G Loss: 1.2616076469421387, D Loss: 1.2118277549743652, alpha: 0.11629430426601906\n",
      "epoch 1339 iteration0, G Loss: 0.7913606762886047, D Loss: 1.280195951461792, alpha: 0.11567910281505911\n",
      "epoch 1339 iteration100, G Loss: 1.1595019102096558, D Loss: 1.235478401184082, alpha: 0.11567910281505911\n",
      "epoch 1340 iteration0, G Loss: 0.8590129613876343, D Loss: 1.239192008972168, alpha: 0.11506673204554962\n",
      "epoch 1340 iteration100, G Loss: 1.1635814905166626, D Loss: 1.1823614835739136, alpha: 0.11506673204554962\n",
      "epoch 1341 iteration0, G Loss: 0.8949442505836487, D Loss: 1.1174945831298828, alpha: 0.11445718341214783\n",
      "epoch 1341 iteration100, G Loss: 1.2459908723831177, D Loss: 1.2628686428070068, alpha: 0.11445718341214783\n",
      "epoch 1342 iteration0, G Loss: 0.9215580224990845, D Loss: 1.0532729625701904, alpha: 0.11385044834696267\n",
      "epoch 1342 iteration100, G Loss: 0.9565379023551941, D Loss: 1.3288905620574951, alpha: 0.11385044834696267\n",
      "epoch 1343 iteration0, G Loss: 0.7040296196937561, D Loss: 1.2573316097259521, alpha: 0.11324651826019627\n",
      "epoch 1343 iteration100, G Loss: 0.8750476837158203, D Loss: 1.226555347442627, alpha: 0.11324651826019627\n",
      "epoch 1344 iteration0, G Loss: 1.0415996313095093, D Loss: 1.205803632736206, alpha: 0.11264538454077722\n",
      "epoch 1344 iteration100, G Loss: 1.1300996541976929, D Loss: 1.1505494117736816, alpha: 0.11264538454077722\n",
      "epoch 1345 iteration0, G Loss: 0.944229006767273, D Loss: 1.1177470684051514, alpha: 0.11204703855699027\n",
      "epoch 1345 iteration100, G Loss: 0.9929940104484558, D Loss: 1.2068078517913818, alpha: 0.11204703855699027\n",
      "epoch 1346 iteration0, G Loss: 0.7951220273971558, D Loss: 1.2452569007873535, alpha: 0.11145147165709957\n",
      "epoch 1346 iteration100, G Loss: 1.3463008403778076, D Loss: 1.2089565992355347, alpha: 0.11145147165709957\n",
      "epoch 1347 iteration0, G Loss: 0.9762107729911804, D Loss: 1.2131073474884033, alpha: 0.11085867516996861\n",
      "epoch 1347 iteration100, G Loss: 0.9670358300209045, D Loss: 1.2282130718231201, alpha: 0.11085867516996861\n",
      "epoch 1348 iteration0, G Loss: 0.9744738340377808, D Loss: 1.1178125143051147, alpha: 0.11026864040567386\n",
      "epoch 1348 iteration100, G Loss: 0.7721602320671082, D Loss: 1.2824909687042236, alpha: 0.11026864040567386\n",
      "epoch 1349 iteration0, G Loss: 0.8095154166221619, D Loss: 1.293436050415039, alpha: 0.10968135865611406\n",
      "epoch 1349 iteration100, G Loss: 1.218637466430664, D Loss: 1.1744965314865112, alpha: 0.10968135865611406\n",
      "epoch 1350 iteration0, G Loss: 0.9107745289802551, D Loss: 1.0983670949935913, alpha: 0.10909682119561293\n",
      "epoch 1350 iteration100, G Loss: 1.1477361917495728, D Loss: 1.1485955715179443, alpha: 0.10909682119561293\n",
      "Saving content.\n",
      "epoch 1351 iteration0, G Loss: 1.0108888149261475, D Loss: 1.3221523761749268, alpha: 0.10851501928151974\n",
      "epoch 1351 iteration100, G Loss: 0.8238745331764221, D Loss: 1.2328376770019531, alpha: 0.10851501928151974\n",
      "epoch 1352 iteration0, G Loss: 0.7928377985954285, D Loss: 1.165360927581787, alpha: 0.1079359441548019\n",
      "epoch 1352 iteration100, G Loss: 1.141871452331543, D Loss: 1.2298780679702759, alpha: 0.1079359441548019\n",
      "epoch 1353 iteration0, G Loss: 1.0344536304473877, D Loss: 1.2333332300186157, alpha: 0.10735958704063364\n",
      "epoch 1353 iteration100, G Loss: 1.159551739692688, D Loss: 1.2676465511322021, alpha: 0.10735958704063364\n",
      "epoch 1354 iteration0, G Loss: 0.9700920581817627, D Loss: 1.1533633470535278, alpha: 0.10678593914898027\n",
      "epoch 1354 iteration100, G Loss: 1.1424003839492798, D Loss: 1.1795347929000854, alpha: 0.10678593914898027\n",
      "epoch 1355 iteration0, G Loss: 0.9988186359405518, D Loss: 1.122105598449707, alpha: 0.10621499167517556\n",
      "epoch 1355 iteration100, G Loss: 1.3952832221984863, D Loss: 1.1773202419281006, alpha: 0.10621499167517556\n",
      "epoch 1356 iteration0, G Loss: 1.0398907661437988, D Loss: 1.2776618003845215, alpha: 0.10564673580049633\n",
      "epoch 1356 iteration100, G Loss: 1.0636845827102661, D Loss: 1.1612756252288818, alpha: 0.10564673580049633\n",
      "epoch 1357 iteration0, G Loss: 1.0549777746200562, D Loss: 1.3756375312805176, alpha: 0.10508116269273093\n",
      "epoch 1357 iteration100, G Loss: 1.115251898765564, D Loss: 1.1407220363616943, alpha: 0.10508116269273093\n",
      "epoch 1358 iteration0, G Loss: 1.0613579750061035, D Loss: 1.1687614917755127, alpha: 0.10451826350674043\n",
      "epoch 1358 iteration100, G Loss: 1.1992374658584595, D Loss: 1.2024424076080322, alpha: 0.10451826350674043\n",
      "epoch 1359 iteration0, G Loss: 0.8961456418037415, D Loss: 1.2018134593963623, alpha: 0.10395802938501986\n",
      "epoch 1359 iteration100, G Loss: 0.84666907787323, D Loss: 1.2574595212936401, alpha: 0.10395802938501986\n",
      "epoch 1360 iteration0, G Loss: 0.8873257637023926, D Loss: 1.2352935075759888, alpha: 0.10340045145824961\n",
      "epoch 1360 iteration100, G Loss: 1.1525983810424805, D Loss: 1.162369728088379, alpha: 0.10340045145824961\n",
      "epoch 1361 iteration0, G Loss: 0.9081002473831177, D Loss: 1.1081182956695557, alpha: 0.10284552084584364\n",
      "epoch 1361 iteration100, G Loss: 0.9844933748245239, D Loss: 1.1963651180267334, alpha: 0.10284552084584364\n",
      "epoch 1362 iteration0, G Loss: 0.7773741483688354, D Loss: 1.2731436491012573, alpha: 0.10229322865649326\n",
      "epoch 1362 iteration100, G Loss: 1.1382914781570435, D Loss: 1.207900047302246, alpha: 0.10229322865649326\n",
      "epoch 1363 iteration0, G Loss: 0.9898295998573303, D Loss: 1.1561634540557861, alpha: 0.1017435659887046\n",
      "epoch 1363 iteration100, G Loss: 1.0827786922454834, D Loss: 1.263018012046814, alpha: 0.1017435659887046\n",
      "epoch 1364 iteration0, G Loss: 0.9139875769615173, D Loss: 1.2191555500030518, alpha: 0.10119652393133227\n",
      "epoch 1364 iteration100, G Loss: 1.038022518157959, D Loss: 1.2146594524383545, alpha: 0.10119652393133227\n",
      "epoch 1365 iteration0, G Loss: 0.8743045330047607, D Loss: 1.2366387844085693, alpha: 0.10065209356410687\n",
      "epoch 1365 iteration100, G Loss: 0.8979512453079224, D Loss: 1.3074501752853394, alpha: 0.10065209356410687\n",
      "epoch 1366 iteration0, G Loss: 0.8001038432121277, D Loss: 1.2122812271118164, alpha: 0.10011026595815764\n",
      "epoch 1366 iteration100, G Loss: 1.0861802101135254, D Loss: 1.3333885669708252, alpha: 0.10011026595815764\n",
      "epoch 1367 iteration0, G Loss: 0.8523889183998108, D Loss: 1.2205090522766113, alpha: 0.0995710321765314\n",
      "epoch 1367 iteration100, G Loss: 1.0604437589645386, D Loss: 1.2410067319869995, alpha: 0.0995710321765314\n",
      "epoch 1368 iteration0, G Loss: 0.8077118396759033, D Loss: 1.1727867126464844, alpha: 0.09903438327470526\n",
      "epoch 1368 iteration100, G Loss: 1.3572107553482056, D Loss: 1.2084360122680664, alpha: 0.09903438327470526\n",
      "epoch 1369 iteration0, G Loss: 0.8078314661979675, D Loss: 1.2811369895935059, alpha: 0.09850031030109396\n",
      "epoch 1369 iteration100, G Loss: 1.140135645866394, D Loss: 1.2689640522003174, alpha: 0.09850031030109396\n",
      "epoch 1370 iteration0, G Loss: 1.013921856880188, D Loss: 1.1353363990783691, alpha: 0.09796880429755384\n",
      "epoch 1370 iteration100, G Loss: 0.9376684427261353, D Loss: 1.189491629600525, alpha: 0.09796880429755384\n",
      "epoch 1371 iteration0, G Loss: 1.0663394927978516, D Loss: 1.2500667572021484, alpha: 0.09743985629988028\n",
      "epoch 1371 iteration100, G Loss: 1.1410309076309204, D Loss: 1.266722559928894, alpha: 0.09743985629988028\n",
      "epoch 1372 iteration0, G Loss: 0.8797420859336853, D Loss: 1.1621685028076172, alpha: 0.09691345733830126\n",
      "epoch 1372 iteration100, G Loss: 1.5049232244491577, D Loss: 1.2227308750152588, alpha: 0.09691345733830126\n",
      "epoch 1373 iteration0, G Loss: 1.0302417278289795, D Loss: 1.272162675857544, alpha: 0.09638959843796457\n",
      "epoch 1373 iteration100, G Loss: 1.420461893081665, D Loss: 1.1971921920776367, alpha: 0.09638959843796457\n",
      "epoch 1374 iteration0, G Loss: 0.9114323854446411, D Loss: 1.2992857694625854, alpha: 0.09586827061942282\n",
      "epoch 1374 iteration100, G Loss: 1.2740966081619263, D Loss: 1.1670668125152588, alpha: 0.09586827061942282\n",
      "epoch 1375 iteration0, G Loss: 0.9516773819923401, D Loss: 1.1736599206924438, alpha: 0.09534946489910945\n",
      "epoch 1375 iteration100, G Loss: 1.326282024383545, D Loss: 1.1934839487075806, alpha: 0.09534946489910945\n",
      "epoch 1376 iteration0, G Loss: 0.7802247405052185, D Loss: 1.1947977542877197, alpha: 0.0948331722898147\n",
      "epoch 1376 iteration100, G Loss: 0.8144175410270691, D Loss: 1.193702220916748, alpha: 0.0948331722898147\n",
      "epoch 1377 iteration0, G Loss: 0.9138060808181763, D Loss: 1.1725993156433105, alpha: 0.09431938380115201\n",
      "epoch 1377 iteration100, G Loss: 1.0151209831237793, D Loss: 1.286221981048584, alpha: 0.09431938380115201\n",
      "epoch 1378 iteration0, G Loss: 1.080790400505066, D Loss: 1.2132246494293213, alpha: 0.0938080904400228\n",
      "epoch 1378 iteration100, G Loss: 0.9115344285964966, D Loss: 1.199985146522522, alpha: 0.0938080904400228\n",
      "epoch 1379 iteration0, G Loss: 0.9426375031471252, D Loss: 1.1767852306365967, alpha: 0.09329928321107495\n",
      "epoch 1379 iteration100, G Loss: 1.1530946493148804, D Loss: 1.112836241722107, alpha: 0.09329928321107495\n",
      "epoch 1380 iteration0, G Loss: 0.881726086139679, D Loss: 1.1800153255462646, alpha: 0.09279295311715707\n",
      "epoch 1380 iteration100, G Loss: 0.9643244743347168, D Loss: 1.2285493612289429, alpha: 0.09279295311715707\n",
      "epoch 1381 iteration0, G Loss: 0.8693079352378845, D Loss: 1.1934062242507935, alpha: 0.09228909115976647\n",
      "epoch 1381 iteration100, G Loss: 1.242167353630066, D Loss: 1.3809490203857422, alpha: 0.09228909115976647\n",
      "epoch 1382 iteration0, G Loss: 1.0878287553787231, D Loss: 1.2023999691009521, alpha: 0.09178768833949524\n",
      "epoch 1382 iteration100, G Loss: 1.0568796396255493, D Loss: 1.202242136001587, alpha: 0.09178768833949524\n",
      "epoch 1383 iteration0, G Loss: 0.9540345072746277, D Loss: 1.2134596109390259, alpha: 0.09128873565646867\n",
      "epoch 1383 iteration100, G Loss: 0.7885634303092957, D Loss: 1.1943351030349731, alpha: 0.09128873565646867\n",
      "epoch 1384 iteration0, G Loss: 0.9998412728309631, D Loss: 1.2474950551986694, alpha: 0.09079222411077958\n",
      "epoch 1384 iteration100, G Loss: 1.122368335723877, D Loss: 1.2979474067687988, alpha: 0.09079222411077958\n",
      "epoch 1385 iteration0, G Loss: 0.7995461821556091, D Loss: 1.3166499137878418, alpha: 0.09029814470291975\n",
      "epoch 1385 iteration100, G Loss: 0.8408353328704834, D Loss: 1.2786312103271484, alpha: 0.09029814470291975\n",
      "epoch 1386 iteration0, G Loss: 0.8881497979164124, D Loss: 1.1560702323913574, alpha: 0.0898064884342038\n",
      "epoch 1386 iteration100, G Loss: 1.1199512481689453, D Loss: 1.1952857971191406, alpha: 0.0898064884342038\n",
      "epoch 1387 iteration0, G Loss: 0.978031575679779, D Loss: 1.1213514804840088, alpha: 0.08931724630718973\n",
      "epoch 1387 iteration100, G Loss: 1.177070140838623, D Loss: 1.097559928894043, alpha: 0.08931724630718973\n",
      "epoch 1388 iteration0, G Loss: 0.9713023900985718, D Loss: 1.2143690586090088, alpha: 0.0888304093260962\n",
      "epoch 1388 iteration100, G Loss: 1.2188161611557007, D Loss: 1.2861878871917725, alpha: 0.0888304093260962\n",
      "epoch 1389 iteration0, G Loss: 0.8199431896209717, D Loss: 1.0754456520080566, alpha: 0.08834596849721144\n",
      "epoch 1389 iteration100, G Loss: 0.8819392919540405, D Loss: 1.161214828491211, alpha: 0.08834596849721144\n",
      "epoch 1390 iteration0, G Loss: 0.9911472201347351, D Loss: 1.2685446739196777, alpha: 0.08786391482930123\n",
      "epoch 1390 iteration100, G Loss: 1.1559830904006958, D Loss: 1.1094566583633423, alpha: 0.08786391482930123\n",
      "epoch 1391 iteration0, G Loss: 0.7715559601783752, D Loss: 1.1918481588363647, alpha: 0.08738423933401052\n",
      "epoch 1391 iteration100, G Loss: 0.9425497651100159, D Loss: 1.250148057937622, alpha: 0.08738423933401052\n",
      "epoch 1392 iteration0, G Loss: 0.9073296189308167, D Loss: 1.177522897720337, alpha: 0.08690693302625996\n",
      "epoch 1392 iteration100, G Loss: 0.9688048958778381, D Loss: 1.2561558485031128, alpha: 0.08690693302625996\n",
      "epoch 1393 iteration0, G Loss: 0.8146704435348511, D Loss: 1.08164644241333, alpha: 0.0864319869246385\n",
      "epoch 1393 iteration100, G Loss: 0.9466242790222168, D Loss: 1.237309217453003, alpha: 0.0864319869246385\n",
      "epoch 1394 iteration0, G Loss: 0.9353853464126587, D Loss: 1.14853036403656, alpha: 0.08595939205179226\n",
      "epoch 1394 iteration100, G Loss: 1.0955711603164673, D Loss: 1.189413070678711, alpha: 0.08595939205179226\n",
      "epoch 1395 iteration0, G Loss: 0.8401443362236023, D Loss: 1.3266618251800537, alpha: 0.0854891394348064\n",
      "epoch 1395 iteration100, G Loss: 1.2072309255599976, D Loss: 1.1507141590118408, alpha: 0.0854891394348064\n",
      "epoch 1396 iteration0, G Loss: 0.8816439509391785, D Loss: 1.2842398881912231, alpha: 0.08502122010558566\n",
      "epoch 1396 iteration100, G Loss: 1.2087328433990479, D Loss: 1.2664626836776733, alpha: 0.08502122010558566\n",
      "epoch 1397 iteration0, G Loss: 0.8594457507133484, D Loss: 1.1496167182922363, alpha: 0.08455562510122672\n",
      "epoch 1397 iteration100, G Loss: 1.0609053373336792, D Loss: 1.1689014434814453, alpha: 0.08455562510122672\n",
      "epoch 1398 iteration0, G Loss: 0.8204531073570251, D Loss: 1.1832151412963867, alpha: 0.08409234546438982\n",
      "epoch 1398 iteration100, G Loss: 1.151611566543579, D Loss: 1.2474009990692139, alpha: 0.08409234546438982\n",
      "epoch 1399 iteration0, G Loss: 0.9193952083587646, D Loss: 1.2336454391479492, alpha: 0.08363137224366268\n",
      "epoch 1399 iteration100, G Loss: 1.0140239000320435, D Loss: 1.18307626247406, alpha: 0.08363137224366268\n",
      "epoch 1400 iteration0, G Loss: 0.9487487077713013, D Loss: 1.0923364162445068, alpha: 0.08317269649392234\n",
      "epoch 1400 iteration100, G Loss: 1.4924817085266113, D Loss: 1.2591806650161743, alpha: 0.08317269649392234\n",
      "Saving content.\n",
      "epoch 1401 iteration0, G Loss: 0.8594275712966919, D Loss: 1.2064363956451416, alpha: 0.08271630927669082\n",
      "epoch 1401 iteration100, G Loss: 1.1637927293777466, D Loss: 1.291462779045105, alpha: 0.08271630927669082\n",
      "epoch 1402 iteration0, G Loss: 0.9685384631156921, D Loss: 1.1936862468719482, alpha: 0.08226220166048714\n",
      "epoch 1402 iteration100, G Loss: 0.854362428188324, D Loss: 1.206007719039917, alpha: 0.08226220166048714\n",
      "epoch 1403 iteration0, G Loss: 0.9527377486228943, D Loss: 1.1310055255889893, alpha: 0.08181036472117575\n",
      "epoch 1403 iteration100, G Loss: 0.9393196105957031, D Loss: 1.2295336723327637, alpha: 0.08181036472117575\n",
      "epoch 1404 iteration0, G Loss: 0.7914599180221558, D Loss: 1.1199617385864258, alpha: 0.08136078954230908\n",
      "epoch 1404 iteration100, G Loss: 1.0048940181732178, D Loss: 1.2502622604370117, alpha: 0.08136078954230908\n",
      "epoch 1405 iteration0, G Loss: 0.9480828046798706, D Loss: 1.1201131343841553, alpha: 0.08091346721546533\n",
      "epoch 1405 iteration100, G Loss: 1.1671556234359741, D Loss: 1.115225076675415, alpha: 0.08091346721546533\n",
      "epoch 1406 iteration0, G Loss: 0.8355789184570312, D Loss: 1.1490976810455322, alpha: 0.08046838884058549\n",
      "epoch 1406 iteration100, G Loss: 1.2924569845199585, D Loss: 1.2053124904632568, alpha: 0.08046838884058549\n",
      "epoch 1407 iteration0, G Loss: 0.9918433427810669, D Loss: 1.1569615602493286, alpha: 0.08002554552630159\n",
      "epoch 1407 iteration100, G Loss: 1.024670124053955, D Loss: 1.2263989448547363, alpha: 0.08002554552630159\n",
      "epoch 1408 iteration0, G Loss: 0.9480969309806824, D Loss: 1.2230535745620728, alpha: 0.0795849283902631\n",
      "epoch 1408 iteration100, G Loss: 1.205060362815857, D Loss: 1.281203031539917, alpha: 0.0795849283902631\n",
      "epoch 1409 iteration0, G Loss: 0.8091027140617371, D Loss: 1.187359094619751, alpha: 0.07914652855945903\n",
      "epoch 1409 iteration100, G Loss: 0.9129028916358948, D Loss: 1.2042697668075562, alpha: 0.07914652855945903\n",
      "epoch 1410 iteration0, G Loss: 0.9875606894493103, D Loss: 1.3488824367523193, alpha: 0.0787103371705351\n",
      "epoch 1410 iteration100, G Loss: 0.8407796621322632, D Loss: 1.2817920446395874, alpha: 0.0787103371705351\n",
      "epoch 1411 iteration0, G Loss: 0.8565351963043213, D Loss: 1.2398536205291748, alpha: 0.0782763453701073\n",
      "epoch 1411 iteration100, G Loss: 1.0936520099639893, D Loss: 1.207316517829895, alpha: 0.0782763453701073\n",
      "epoch 1412 iteration0, G Loss: 0.9122917056083679, D Loss: 1.1296396255493164, alpha: 0.07784454431507004\n",
      "epoch 1412 iteration100, G Loss: 1.2038261890411377, D Loss: 1.19478440284729, alpha: 0.07784454431507004\n",
      "epoch 1413 iteration0, G Loss: 0.8428072333335876, D Loss: 1.1973974704742432, alpha: 0.0774149251729025\n",
      "epoch 1413 iteration100, G Loss: 1.1251286268234253, D Loss: 1.137102723121643, alpha: 0.0774149251729025\n",
      "epoch 1414 iteration0, G Loss: 0.8716202974319458, D Loss: 1.166632056236267, alpha: 0.07698747912196802\n",
      "epoch 1414 iteration100, G Loss: 1.0444014072418213, D Loss: 1.1509349346160889, alpha: 0.07698747912196802\n",
      "epoch 1415 iteration0, G Loss: 0.7629997730255127, D Loss: 1.2864458560943604, alpha: 0.07656219735181213\n",
      "epoch 1415 iteration100, G Loss: 1.085249423980713, D Loss: 1.2155107259750366, alpha: 0.07656219735181213\n",
      "epoch 1416 iteration0, G Loss: 0.8396731019020081, D Loss: 1.2088768482208252, alpha: 0.07613907106345408\n",
      "epoch 1416 iteration100, G Loss: 1.304582118988037, D Loss: 1.2386174201965332, alpha: 0.07613907106345408\n",
      "epoch 1417 iteration0, G Loss: 0.9444759488105774, D Loss: 1.2343448400497437, alpha: 0.0757180914696759\n",
      "epoch 1417 iteration100, G Loss: 0.9482714533805847, D Loss: 1.2355518341064453, alpha: 0.0757180914696759\n",
      "epoch 1418 iteration0, G Loss: 0.8892865777015686, D Loss: 1.2002031803131104, alpha: 0.07529924979530678\n",
      "epoch 1418 iteration100, G Loss: 0.9237097501754761, D Loss: 1.1771752834320068, alpha: 0.07529924979530678\n",
      "epoch 1419 iteration0, G Loss: 1.004917025566101, D Loss: 1.1599493026733398, alpha: 0.07488253727750394\n",
      "epoch 1419 iteration100, G Loss: 1.2156238555908203, D Loss: 1.2128957509994507, alpha: 0.07488253727750394\n",
      "epoch 1420 iteration0, G Loss: 1.0017564296722412, D Loss: 1.19394850730896, alpha: 0.07446794516602806\n",
      "epoch 1420 iteration100, G Loss: 1.1839747428894043, D Loss: 1.2211289405822754, alpha: 0.07446794516602806\n",
      "epoch 1421 iteration0, G Loss: 0.9236356019973755, D Loss: 1.239469051361084, alpha: 0.07405546472351765\n",
      "epoch 1421 iteration100, G Loss: 0.8778606057167053, D Loss: 1.2103967666625977, alpha: 0.07405546472351765\n",
      "epoch 1422 iteration0, G Loss: 0.9837400913238525, D Loss: 1.2323074340820312, alpha: 0.07364508722575613\n",
      "epoch 1422 iteration100, G Loss: 0.9572530388832092, D Loss: 1.1901044845581055, alpha: 0.07364508722575613\n",
      "epoch 1423 iteration0, G Loss: 0.9241783022880554, D Loss: 1.1770387887954712, alpha: 0.07323680396193766\n",
      "epoch 1423 iteration100, G Loss: 1.2069716453552246, D Loss: 1.1785880327224731, alpha: 0.07323680396193766\n",
      "epoch 1424 iteration0, G Loss: 1.0110185146331787, D Loss: 1.1896765232086182, alpha: 0.0728306062349271\n",
      "epoch 1424 iteration100, G Loss: 1.1644585132598877, D Loss: 1.2221064567565918, alpha: 0.0728306062349271\n",
      "epoch 1425 iteration0, G Loss: 0.8987348079681396, D Loss: 1.201293706893921, alpha: 0.07242648536151775\n",
      "epoch 1425 iteration100, G Loss: 0.9584841728210449, D Loss: 1.1463768482208252, alpha: 0.07242648536151775\n",
      "epoch 1426 iteration0, G Loss: 0.874344527721405, D Loss: 1.158174753189087, alpha: 0.07202443267268421\n",
      "epoch 1426 iteration100, G Loss: 1.1714328527450562, D Loss: 1.1976323127746582, alpha: 0.07202443267268421\n",
      "epoch 1427 iteration0, G Loss: 0.9306451678276062, D Loss: 1.2294820547103882, alpha: 0.07162443951383246\n",
      "epoch 1427 iteration100, G Loss: 1.1014491319656372, D Loss: 1.238197922706604, alpha: 0.07162443951383246\n",
      "epoch 1428 iteration0, G Loss: 0.9122905731201172, D Loss: 1.2669692039489746, alpha: 0.07122649724504404\n",
      "epoch 1428 iteration100, G Loss: 1.0220316648483276, D Loss: 1.2265582084655762, alpha: 0.07122649724504404\n",
      "epoch 1429 iteration0, G Loss: 1.0777713060379028, D Loss: 1.2907788753509521, alpha: 0.0708305972413199\n",
      "epoch 1429 iteration100, G Loss: 1.2014312744140625, D Loss: 1.239189624786377, alpha: 0.0708305972413199\n",
      "epoch 1430 iteration0, G Loss: 1.0448111295700073, D Loss: 1.217212438583374, alpha: 0.07043673089281699\n",
      "epoch 1430 iteration100, G Loss: 0.957586407661438, D Loss: 1.2187464237213135, alpha: 0.07043673089281699\n",
      "epoch 1431 iteration0, G Loss: 1.0011460781097412, D Loss: 1.2983131408691406, alpha: 0.0700448896050837\n",
      "epoch 1431 iteration100, G Loss: 1.176802158355713, D Loss: 1.1963778734207153, alpha: 0.0700448896050837\n",
      "epoch 1432 iteration0, G Loss: 1.0776339769363403, D Loss: 1.1633211374282837, alpha: 0.06965506479929007\n",
      "epoch 1432 iteration100, G Loss: 1.0210436582565308, D Loss: 1.2355018854141235, alpha: 0.06965506479929007\n",
      "epoch 1433 iteration0, G Loss: 0.82087242603302, D Loss: 1.1902542114257812, alpha: 0.06926724791245575\n",
      "epoch 1433 iteration100, G Loss: 0.8624127507209778, D Loss: 1.2093331813812256, alpha: 0.06926724791245575\n",
      "epoch 1434 iteration0, G Loss: 0.8452355265617371, D Loss: 1.2033945322036743, alpha: 0.0688814303976727\n",
      "epoch 1434 iteration100, G Loss: 0.9853717088699341, D Loss: 1.190033197402954, alpha: 0.0688814303976727\n",
      "epoch 1435 iteration0, G Loss: 0.7829452157020569, D Loss: 1.2269363403320312, alpha: 0.06849760372432623\n",
      "epoch 1435 iteration100, G Loss: 0.8924330472946167, D Loss: 1.1415472030639648, alpha: 0.06849760372432623\n",
      "epoch 1436 iteration0, G Loss: 0.860360860824585, D Loss: 1.1100707054138184, alpha: 0.06811575937831016\n",
      "epoch 1436 iteration100, G Loss: 1.0355201959609985, D Loss: 1.232602596282959, alpha: 0.06811575937831016\n",
      "epoch 1437 iteration0, G Loss: 1.0603896379470825, D Loss: 1.1636111736297607, alpha: 0.06773588886224158\n",
      "epoch 1437 iteration100, G Loss: 1.0156729221343994, D Loss: 1.214287519454956, alpha: 0.06773588886224158\n",
      "epoch 1438 iteration0, G Loss: 0.7781355381011963, D Loss: 1.2125989198684692, alpha: 0.06735798369566814\n",
      "epoch 1438 iteration100, G Loss: 0.9783010482788086, D Loss: 1.3162416219711304, alpha: 0.06735798369566814\n",
      "epoch 1439 iteration0, G Loss: 0.8768789172172546, D Loss: 1.2554051876068115, alpha: 0.06698203541527592\n",
      "epoch 1439 iteration100, G Loss: 1.2104556560516357, D Loss: 1.2102975845336914, alpha: 0.06698203541527592\n",
      "epoch 1440 iteration0, G Loss: 0.7311744689941406, D Loss: 1.2957156896591187, alpha: 0.06660803557509065\n",
      "epoch 1440 iteration100, G Loss: 1.0032910108566284, D Loss: 1.2430710792541504, alpha: 0.06660803557509065\n",
      "epoch 1441 iteration0, G Loss: 0.9751185178756714, D Loss: 1.1720342636108398, alpha: 0.06623597574667739\n",
      "epoch 1441 iteration100, G Loss: 1.2355132102966309, D Loss: 1.1934609413146973, alpha: 0.06623597574667739\n",
      "epoch 1442 iteration0, G Loss: 0.8790851831436157, D Loss: 1.1569132804870605, alpha: 0.06586584751933644\n",
      "epoch 1442 iteration100, G Loss: 1.2196271419525146, D Loss: 1.2237606048583984, alpha: 0.06586584751933644\n",
      "epoch 1443 iteration0, G Loss: 0.8627537488937378, D Loss: 1.1449878215789795, alpha: 0.06549764250029477\n",
      "epoch 1443 iteration100, G Loss: 1.4276536703109741, D Loss: 1.1435155868530273, alpha: 0.06549764250029477\n",
      "epoch 1444 iteration0, G Loss: 0.8586368560791016, D Loss: 1.1569206714630127, alpha: 0.06513135231489586\n",
      "epoch 1444 iteration100, G Loss: 0.9904012680053711, D Loss: 1.2591724395751953, alpha: 0.06513135231489586\n",
      "epoch 1445 iteration0, G Loss: 0.839928925037384, D Loss: 1.2535675764083862, alpha: 0.06476696860678555\n",
      "epoch 1445 iteration100, G Loss: 1.0216662883758545, D Loss: 1.2518703937530518, alpha: 0.06476696860678555\n",
      "epoch 1446 iteration0, G Loss: 0.9637923836708069, D Loss: 1.2029378414154053, alpha: 0.06440448303809332\n",
      "epoch 1446 iteration100, G Loss: 1.3001517057418823, D Loss: 1.1905732154846191, alpha: 0.06440448303809332\n",
      "epoch 1447 iteration0, G Loss: 0.8736308813095093, D Loss: 1.2291233539581299, alpha: 0.06404388728961274\n",
      "epoch 1447 iteration100, G Loss: 0.9142895936965942, D Loss: 1.2245230674743652, alpha: 0.06404388728961274\n",
      "epoch 1448 iteration0, G Loss: 0.8940670490264893, D Loss: 1.2256927490234375, alpha: 0.0636851730609761\n",
      "epoch 1448 iteration100, G Loss: 1.1667520999908447, D Loss: 1.18477201461792, alpha: 0.0636851730609761\n",
      "epoch 1449 iteration0, G Loss: 1.0030527114868164, D Loss: 1.1972604990005493, alpha: 0.06332833207082855\n",
      "epoch 1449 iteration100, G Loss: 0.9397323727607727, D Loss: 1.1919846534729004, alpha: 0.06332833207082855\n",
      "epoch 1450 iteration0, G Loss: 0.9825326800346375, D Loss: 1.2085802555084229, alpha: 0.0629733560569965\n",
      "epoch 1450 iteration100, G Loss: 0.9123779535293579, D Loss: 1.2543262243270874, alpha: 0.0629733560569965\n",
      "Saving content.\n",
      "epoch 1451 iteration0, G Loss: 0.9783472418785095, D Loss: 1.2736705541610718, alpha: 0.06262023677665418\n",
      "epoch 1451 iteration100, G Loss: 1.1611826419830322, D Loss: 1.1123366355895996, alpha: 0.06262023677665418\n",
      "epoch 1452 iteration0, G Loss: 0.9817608594894409, D Loss: 1.2072207927703857, alpha: 0.06226896600648746\n",
      "epoch 1452 iteration100, G Loss: 0.7818792462348938, D Loss: 1.2732144594192505, alpha: 0.06226896600648746\n",
      "epoch 1453 iteration0, G Loss: 0.8267602920532227, D Loss: 1.2850052118301392, alpha: 0.06191953554285334\n",
      "epoch 1453 iteration100, G Loss: 1.0239945650100708, D Loss: 1.1742868423461914, alpha: 0.06191953554285334\n",
      "epoch 1454 iteration0, G Loss: 0.890390932559967, D Loss: 1.1465290784835815, alpha: 0.06157193720193743\n",
      "epoch 1454 iteration100, G Loss: 0.9732751250267029, D Loss: 1.211533546447754, alpha: 0.06157193720193743\n",
      "epoch 1455 iteration0, G Loss: 0.8585671782493591, D Loss: 1.206778645515442, alpha: 0.06122616281990789\n",
      "epoch 1455 iteration100, G Loss: 1.2445709705352783, D Loss: 1.1666769981384277, alpha: 0.06122616281990789\n",
      "epoch 1456 iteration0, G Loss: 0.9075534343719482, D Loss: 1.1292078495025635, alpha: 0.060882204253066674\n",
      "epoch 1456 iteration100, G Loss: 1.274408221244812, D Loss: 1.161773443222046, alpha: 0.060882204253066674\n",
      "epoch 1457 iteration0, G Loss: 0.944697916507721, D Loss: 1.1456735134124756, alpha: 0.06054005337799706\n",
      "epoch 1457 iteration100, G Loss: 1.1480302810668945, D Loss: 1.227655053138733, alpha: 0.06054005337799706\n",
      "epoch 1458 iteration0, G Loss: 0.7976812720298767, D Loss: 1.2051082849502563, alpha: 0.060199702091708995\n",
      "epoch 1458 iteration100, G Loss: 1.1579833030700684, D Loss: 1.233224630355835, alpha: 0.060199702091708995\n",
      "epoch 1459 iteration0, G Loss: 0.9472227096557617, D Loss: 1.1679004430770874, alpha: 0.059861142311781634\n",
      "epoch 1459 iteration100, G Loss: 1.093062162399292, D Loss: 1.2610790729522705, alpha: 0.059861142311781634\n",
      "epoch 1460 iteration0, G Loss: 0.7319954633712769, D Loss: 1.2790738344192505, alpha: 0.05952436597650157\n",
      "epoch 1460 iteration100, G Loss: 1.1252385377883911, D Loss: 1.245045781135559, alpha: 0.05952436597650157\n",
      "epoch 1461 iteration0, G Loss: 0.818716824054718, D Loss: 1.1996288299560547, alpha: 0.059189365045000386\n",
      "epoch 1461 iteration100, G Loss: 1.2008649110794067, D Loss: 1.234605312347412, alpha: 0.059189365045000386\n",
      "epoch 1462 iteration0, G Loss: 1.0537041425704956, D Loss: 1.2275605201721191, alpha: 0.05885613149738722\n",
      "epoch 1462 iteration100, G Loss: 1.0644336938858032, D Loss: 1.2845268249511719, alpha: 0.05885613149738722\n",
      "epoch 1463 iteration0, G Loss: 0.9141985177993774, D Loss: 1.3064947128295898, alpha: 0.05852465733487999\n",
      "epoch 1463 iteration100, G Loss: 1.1081640720367432, D Loss: 1.231752872467041, alpha: 0.05852465733487999\n",
      "epoch 1464 iteration0, G Loss: 1.0479154586791992, D Loss: 1.2801271677017212, alpha: 0.05819493457993252\n",
      "epoch 1464 iteration100, G Loss: 0.9685011506080627, D Loss: 1.174269199371338, alpha: 0.05819493457993252\n",
      "epoch 1465 iteration0, G Loss: 0.8394076824188232, D Loss: 1.3208396434783936, alpha: 0.05786695527636099\n",
      "epoch 1465 iteration100, G Loss: 0.8747144341468811, D Loss: 1.1575427055358887, alpha: 0.05786695527636099\n",
      "epoch 1466 iteration0, G Loss: 0.8377920389175415, D Loss: 1.1161284446716309, alpha: 0.05754071148946438\n",
      "epoch 1466 iteration100, G Loss: 1.1126410961151123, D Loss: 1.177610158920288, alpha: 0.05754071148946438\n",
      "epoch 1467 iteration0, G Loss: 0.8129020929336548, D Loss: 1.2255427837371826, alpha: 0.0572161953061453\n",
      "epoch 1467 iteration100, G Loss: 1.2631415128707886, D Loss: 1.191551685333252, alpha: 0.0572161953061453\n",
      "epoch 1468 iteration0, G Loss: 0.9924837946891785, D Loss: 1.1023893356323242, alpha: 0.056893398835026865\n",
      "epoch 1468 iteration100, G Loss: 1.280353307723999, D Loss: 1.1855459213256836, alpha: 0.056893398835026865\n",
      "epoch 1469 iteration0, G Loss: 1.0514552593231201, D Loss: 1.2260570526123047, alpha: 0.0565723142065665\n",
      "epoch 1469 iteration100, G Loss: 1.0838167667388916, D Loss: 1.2507809400558472, alpha: 0.0565723142065665\n",
      "epoch 1470 iteration0, G Loss: 0.865121603012085, D Loss: 1.2013089656829834, alpha: 0.056252933573167296\n",
      "epoch 1470 iteration100, G Loss: 1.1852377653121948, D Loss: 1.233860969543457, alpha: 0.056252933573167296\n",
      "epoch 1471 iteration0, G Loss: 0.8326707482337952, D Loss: 1.2241145372390747, alpha: 0.05593524910928804\n",
      "epoch 1471 iteration100, G Loss: 1.2098277807235718, D Loss: 1.1361732482910156, alpha: 0.05593524910928804\n",
      "epoch 1472 iteration0, G Loss: 1.0583164691925049, D Loss: 1.2359360456466675, alpha: 0.05561925301154802\n",
      "epoch 1472 iteration100, G Loss: 1.012047290802002, D Loss: 1.1660611629486084, alpha: 0.05561925301154802\n",
      "epoch 1473 iteration0, G Loss: 1.0057368278503418, D Loss: 1.2664806842803955, alpha: 0.05530493749883214\n",
      "epoch 1473 iteration100, G Loss: 1.2405297756195068, D Loss: 1.1760066747665405, alpha: 0.05530493749883214\n",
      "epoch 1474 iteration0, G Loss: 0.787688672542572, D Loss: 1.2410986423492432, alpha: 0.05499229481239121\n",
      "epoch 1474 iteration100, G Loss: 1.5494184494018555, D Loss: 1.1260292530059814, alpha: 0.05499229481239121\n",
      "epoch 1475 iteration0, G Loss: 0.9989532828330994, D Loss: 1.1362301111221313, alpha: 0.05468131721594083\n",
      "epoch 1475 iteration100, G Loss: 0.9643813371658325, D Loss: 1.1871072053909302, alpha: 0.05468131721594083\n",
      "epoch 1476 iteration0, G Loss: 0.840249240398407, D Loss: 1.1517239809036255, alpha: 0.05437199699575812\n",
      "epoch 1476 iteration100, G Loss: 1.1109539270401, D Loss: 1.2307419776916504, alpha: 0.05437199699575812\n",
      "epoch 1477 iteration0, G Loss: 0.7558675408363342, D Loss: 1.2251403331756592, alpha: 0.05406432646077497\n",
      "epoch 1477 iteration100, G Loss: 0.757610023021698, D Loss: 1.1950640678405762, alpha: 0.05406432646077497\n",
      "epoch 1478 iteration0, G Loss: 1.0515706539154053, D Loss: 1.2019160985946655, alpha: 0.053758297942669175\n",
      "epoch 1478 iteration100, G Loss: 1.27909255027771, D Loss: 1.2385852336883545, alpha: 0.053758297942669175\n",
      "epoch 1479 iteration0, G Loss: 0.7988670468330383, D Loss: 1.1819729804992676, alpha: 0.05345390379595405\n",
      "epoch 1479 iteration100, G Loss: 1.1120275259017944, D Loss: 1.2563228607177734, alpha: 0.05345390379595405\n",
      "epoch 1480 iteration0, G Loss: 0.7945975065231323, D Loss: 1.2592778205871582, alpha: 0.05315113639806379\n",
      "epoch 1480 iteration100, G Loss: 1.1137385368347168, D Loss: 1.2579299211502075, alpha: 0.05315113639806379\n",
      "epoch 1481 iteration0, G Loss: 1.1268950700759888, D Loss: 1.303641438484192, alpha: 0.05284998814943809\n",
      "epoch 1481 iteration100, G Loss: 0.951912522315979, D Loss: 1.2178653478622437, alpha: 0.05284998814943809\n",
      "epoch 1482 iteration0, G Loss: 0.9386380314826965, D Loss: 1.3009016513824463, alpha: 0.052550451473604154\n",
      "epoch 1482 iteration100, G Loss: 0.9677979946136475, D Loss: 1.2887355089187622, alpha: 0.052550451473604154\n",
      "epoch 1483 iteration0, G Loss: 0.8574886322021484, D Loss: 1.1850740909576416, alpha: 0.05225251881725579\n",
      "epoch 1483 iteration100, G Loss: 0.7664538621902466, D Loss: 1.2463774681091309, alpha: 0.05225251881725579\n",
      "epoch 1484 iteration0, G Loss: 0.958686888217926, D Loss: 1.2679181098937988, alpha: 0.05195618265033075\n",
      "epoch 1484 iteration100, G Loss: 0.8806117177009583, D Loss: 1.2679967880249023, alpha: 0.05195618265033075\n",
      "epoch 1485 iteration0, G Loss: 0.9206405878067017, D Loss: 1.1377339363098145, alpha: 0.051661435466084815\n",
      "epoch 1485 iteration100, G Loss: 1.0631312131881714, D Loss: 1.1888208389282227, alpha: 0.051661435466084815\n",
      "epoch 1486 iteration0, G Loss: 0.8839185833930969, D Loss: 1.3416786193847656, alpha: 0.05136826978116549\n",
      "epoch 1486 iteration100, G Loss: 1.4170032739639282, D Loss: 1.1606389284133911, alpha: 0.05136826978116549\n",
      "epoch 1487 iteration0, G Loss: 0.9845218062400818, D Loss: 1.166680097579956, alpha: 0.051076678135681286\n",
      "epoch 1487 iteration100, G Loss: 1.2708576917648315, D Loss: 1.2009081840515137, alpha: 0.051076678135681286\n",
      "epoch 1488 iteration0, G Loss: 0.875363826751709, D Loss: 1.2156832218170166, alpha: 0.050786653093270684\n",
      "epoch 1488 iteration100, G Loss: 1.1038769483566284, D Loss: 1.2621304988861084, alpha: 0.050786653093270684\n",
      "epoch 1489 iteration0, G Loss: 0.9201579689979553, D Loss: 1.2686190605163574, alpha: 0.05049818724116817\n",
      "epoch 1489 iteration100, G Loss: 1.0202215909957886, D Loss: 1.3524610996246338, alpha: 0.05049818724116817\n",
      "epoch 1490 iteration0, G Loss: 0.9953169822692871, D Loss: 1.199661374092102, alpha: 0.050211273190266636\n",
      "epoch 1490 iteration100, G Loss: 1.2679331302642822, D Loss: 1.187644600868225, alpha: 0.050211273190266636\n",
      "epoch 1491 iteration0, G Loss: 0.8309388160705566, D Loss: 1.1450506448745728, alpha: 0.049925903575180564\n",
      "epoch 1491 iteration100, G Loss: 1.0931925773620605, D Loss: 1.1654863357543945, alpha: 0.049925903575180564\n",
      "epoch 1492 iteration0, G Loss: 0.9384623169898987, D Loss: 1.2760593891143799, alpha: 0.049642071054305514\n",
      "epoch 1492 iteration100, G Loss: 1.355193853378296, D Loss: 1.152017593383789, alpha: 0.049642071054305514\n",
      "epoch 1493 iteration0, G Loss: 0.9382245540618896, D Loss: 1.2168971300125122, alpha: 0.04935976830987465\n",
      "epoch 1493 iteration100, G Loss: 1.0387886762619019, D Loss: 1.206169605255127, alpha: 0.04935976830987465\n",
      "epoch 1494 iteration0, G Loss: 0.9366359710693359, D Loss: 1.2910116910934448, alpha: 0.049078988048014804\n",
      "epoch 1494 iteration100, G Loss: 1.1312140226364136, D Loss: 1.2006089687347412, alpha: 0.049078988048014804\n",
      "epoch 1495 iteration0, G Loss: 0.8738836050033569, D Loss: 1.2256076335906982, alpha: 0.04879972299879998\n",
      "epoch 1495 iteration100, G Loss: 1.1233844757080078, D Loss: 1.165773630142212, alpha: 0.04879972299879998\n",
      "epoch 1496 iteration0, G Loss: 0.7526925802230835, D Loss: 1.1844408512115479, alpha: 0.04852196591630187\n",
      "epoch 1496 iteration100, G Loss: 1.304283618927002, D Loss: 1.1964683532714844, alpha: 0.04852196591630187\n",
      "epoch 1497 iteration0, G Loss: 1.0227090120315552, D Loss: 1.241621971130371, alpha: 0.04824570957864016\n",
      "epoch 1497 iteration100, G Loss: 1.0506483316421509, D Loss: 1.2607135772705078, alpha: 0.04824570957864016\n",
      "epoch 1498 iteration0, G Loss: 0.8622957468032837, D Loss: 1.226859211921692, alpha: 0.04797094678802982\n",
      "epoch 1498 iteration100, G Loss: 1.0297377109527588, D Loss: 1.2035762071609497, alpha: 0.04797094678802982\n",
      "epoch 1499 iteration0, G Loss: 0.9470254778862, D Loss: 1.193446397781372, alpha: 0.04769767037082562\n",
      "epoch 1499 iteration100, G Loss: 1.3874173164367676, D Loss: 1.1895129680633545, alpha: 0.04769767037082562\n",
      "epoch 1500 iteration0, G Loss: 0.8365262150764465, D Loss: 1.2261117696762085, alpha: 0.047425873177566635\n",
      "epoch 1500 iteration100, G Loss: 1.2118854522705078, D Loss: 1.2375844717025757, alpha: 0.047425873177566635\n",
      "Saving content.\n",
      "epoch 1501 iteration0, G Loss: 0.9654138684272766, D Loss: 1.2189445495605469, alpha: 0.04715554808301792\n",
      "epoch 1501 iteration100, G Loss: 0.9921520352363586, D Loss: 1.2149460315704346, alpha: 0.04715554808301792\n",
      "epoch 1502 iteration0, G Loss: 0.7784719467163086, D Loss: 1.2114837169647217, alpha: 0.046886687986208764\n",
      "epoch 1502 iteration100, G Loss: 1.1524001359939575, D Loss: 1.1106641292572021, alpha: 0.046886687986208764\n",
      "epoch 1503 iteration0, G Loss: 0.9949048161506653, D Loss: 1.2204880714416504, alpha: 0.046619285810472255\n",
      "epoch 1503 iteration100, G Loss: 1.4917455911636353, D Loss: 1.1792144775390625, alpha: 0.046619285810472255\n",
      "epoch 1504 iteration0, G Loss: 1.2324830293655396, D Loss: 1.1290123462677002, alpha: 0.04635333450348078\n",
      "epoch 1504 iteration100, G Loss: 0.9058446288108826, D Loss: 1.0968234539031982, alpha: 0.04635333450348078\n",
      "epoch 1505 iteration0, G Loss: 0.8867594003677368, D Loss: 1.2025389671325684, alpha: 0.04608882703727968\n",
      "epoch 1505 iteration100, G Loss: 0.8513513207435608, D Loss: 1.1772856712341309, alpha: 0.04608882703727968\n",
      "epoch 1506 iteration0, G Loss: 0.9629241228103638, D Loss: 1.0939855575561523, alpha: 0.045825756408319984\n",
      "epoch 1506 iteration100, G Loss: 1.0950032472610474, D Loss: 1.2030558586120605, alpha: 0.045825756408319984\n",
      "epoch 1507 iteration0, G Loss: 0.886271595954895, D Loss: 1.1730592250823975, alpha: 0.04556411563748952\n",
      "epoch 1507 iteration100, G Loss: 0.9547086358070374, D Loss: 1.2460678815841675, alpha: 0.04556411563748952\n",
      "epoch 1508 iteration0, G Loss: 0.7891470789909363, D Loss: 1.1809720993041992, alpha: 0.045303897770140655\n",
      "epoch 1508 iteration100, G Loss: 1.282059907913208, D Loss: 1.2013731002807617, alpha: 0.045303897770140655\n",
      "epoch 1509 iteration0, G Loss: 0.9081212878227234, D Loss: 1.2610386610031128, alpha: 0.045045095876118824\n",
      "epoch 1509 iteration100, G Loss: 0.7412205934524536, D Loss: 1.2120028734207153, alpha: 0.045045095876118824\n",
      "epoch 1510 iteration0, G Loss: 0.9507737159729004, D Loss: 1.202955722808838, alpha: 0.04478770304978663\n",
      "epoch 1510 iteration100, G Loss: 1.00775945186615, D Loss: 1.1711468696594238, alpha: 0.04478770304978663\n",
      "epoch 1511 iteration0, G Loss: 0.6423777341842651, D Loss: 1.1653690338134766, alpha: 0.04453171241004905\n",
      "epoch 1511 iteration100, G Loss: 0.9551997780799866, D Loss: 1.209902048110962, alpha: 0.04453171241004905\n",
      "epoch 1512 iteration0, G Loss: 1.1120259761810303, D Loss: 1.1639201641082764, alpha: 0.04427711710037352\n",
      "epoch 1512 iteration100, G Loss: 0.9523575901985168, D Loss: 1.210805058479309, alpha: 0.04427711710037352\n",
      "epoch 1513 iteration0, G Loss: 0.8250721096992493, D Loss: 1.227829933166504, alpha: 0.04402391028881247\n",
      "epoch 1513 iteration100, G Loss: 0.9725716710090637, D Loss: 1.2585052251815796, alpha: 0.04402391028881247\n",
      "epoch 1514 iteration0, G Loss: 0.7211894989013672, D Loss: 1.2071585655212402, alpha: 0.043772085168020336\n",
      "epoch 1514 iteration100, G Loss: 1.3928340673446655, D Loss: 1.2015750408172607, alpha: 0.043772085168020336\n",
      "epoch 1515 iteration0, G Loss: 1.0431262254714966, D Loss: 1.1743453741073608, alpha: 0.04352163495527217\n",
      "epoch 1515 iteration100, G Loss: 0.9625977277755737, D Loss: 1.2397816181182861, alpha: 0.04352163495527217\n",
      "epoch 1516 iteration0, G Loss: 0.873406171798706, D Loss: 1.154988408088684, alpha: 0.04327255289247811\n",
      "epoch 1516 iteration100, G Loss: 1.3711212873458862, D Loss: 1.1541180610656738, alpha: 0.04327255289247811\n",
      "epoch 1517 iteration0, G Loss: 0.8769487142562866, D Loss: 1.0964453220367432, alpha: 0.04302483224619791\n",
      "epoch 1517 iteration100, G Loss: 1.1149789094924927, D Loss: 1.1631786823272705, alpha: 0.04302483224619791\n",
      "epoch 1518 iteration0, G Loss: 0.9151853322982788, D Loss: 1.2349133491516113, alpha: 0.042778466307653695\n",
      "epoch 1518 iteration100, G Loss: 1.0215011835098267, D Loss: 1.1706382036209106, alpha: 0.042778466307653695\n",
      "epoch 1519 iteration0, G Loss: 0.7827707529067993, D Loss: 1.2196853160858154, alpha: 0.04253344839273965\n",
      "epoch 1519 iteration100, G Loss: 0.8024740815162659, D Loss: 1.2499949932098389, alpha: 0.04253344839273965\n",
      "epoch 1520 iteration0, G Loss: 1.031235933303833, D Loss: 1.1971030235290527, alpha: 0.04228977184203375\n",
      "epoch 1520 iteration100, G Loss: 1.3282363414764404, D Loss: 1.239793062210083, alpha: 0.04228977184203375\n",
      "epoch 1521 iteration0, G Loss: 0.9865890145301819, D Loss: 1.1867084503173828, alpha: 0.042047430020803134\n",
      "epoch 1521 iteration100, G Loss: 1.2602999210357666, D Loss: 1.2436132431030273, alpha: 0.042047430020803134\n",
      "epoch 1522 iteration0, G Loss: 0.9175846576690674, D Loss: 1.0822958946228027, alpha: 0.04180641631901194\n",
      "epoch 1522 iteration100, G Loss: 0.9744404554367065, D Loss: 1.3209857940673828, alpha: 0.04180641631901194\n",
      "epoch 1523 iteration0, G Loss: 0.911296010017395, D Loss: 1.2051360607147217, alpha: 0.04156672415132612\n",
      "epoch 1523 iteration100, G Loss: 1.344162106513977, D Loss: 1.0675758123397827, alpha: 0.04156672415132612\n",
      "epoch 1524 iteration0, G Loss: 0.8627263903617859, D Loss: 1.1620209217071533, alpha: 0.04132834695711762\n",
      "epoch 1524 iteration100, G Loss: 1.2476692199707031, D Loss: 1.1762642860412598, alpha: 0.04132834695711762\n",
      "epoch 1525 iteration0, G Loss: 0.8692915439605713, D Loss: 1.1719828844070435, alpha: 0.04109127820046499\n",
      "epoch 1525 iteration100, G Loss: 1.4129791259765625, D Loss: 1.1050338745117188, alpha: 0.04109127820046499\n",
      "epoch 1526 iteration0, G Loss: 0.9241676330566406, D Loss: 1.1541225910186768, alpha: 0.04085551137015564\n",
      "epoch 1526 iteration100, G Loss: 1.1156156063079834, D Loss: 1.252968668937683, alpha: 0.04085551137015564\n",
      "epoch 1527 iteration0, G Loss: 1.1647449731826782, D Loss: 1.1165804862976074, alpha: 0.04062103997968447\n",
      "epoch 1527 iteration100, G Loss: 1.0290420055389404, D Loss: 1.2076679468154907, alpha: 0.04062103997968447\n",
      "epoch 1528 iteration0, G Loss: 0.8119531869888306, D Loss: 1.1015100479125977, alpha: 0.04038785756725205\n",
      "epoch 1528 iteration100, G Loss: 1.1034420728683472, D Loss: 1.1567384004592896, alpha: 0.04038785756725205\n",
      "epoch 1529 iteration0, G Loss: 1.0071316957473755, D Loss: 1.1866077184677124, alpha: 0.040155957695761635\n",
      "epoch 1529 iteration100, G Loss: 1.1943597793579102, D Loss: 1.2064025402069092, alpha: 0.040155957695761635\n",
      "epoch 1530 iteration0, G Loss: 0.7620612382888794, D Loss: 1.234539270401001, alpha: 0.039925333952813946\n",
      "epoch 1530 iteration100, G Loss: 1.2318508625030518, D Loss: 1.0986589193344116, alpha: 0.039925333952813946\n",
      "epoch 1531 iteration0, G Loss: 0.8267083168029785, D Loss: 1.18655264377594, alpha: 0.03969597995070151\n",
      "epoch 1531 iteration100, G Loss: 1.0143383741378784, D Loss: 1.1808985471725464, alpha: 0.03969597995070151\n",
      "epoch 1532 iteration0, G Loss: 0.7571043968200684, D Loss: 1.1713488101959229, alpha: 0.039467889326402106\n",
      "epoch 1532 iteration100, G Loss: 0.9248294234275818, D Loss: 1.1971356868743896, alpha: 0.039467889326402106\n",
      "epoch 1533 iteration0, G Loss: 0.7509655952453613, D Loss: 1.1586902141571045, alpha: 0.039241055741568776\n",
      "epoch 1533 iteration100, G Loss: 1.3844468593597412, D Loss: 1.2049083709716797, alpha: 0.039241055741568776\n",
      "epoch 1534 iteration0, G Loss: 0.883267343044281, D Loss: 1.130774736404419, alpha: 0.03901547288252172\n",
      "epoch 1534 iteration100, G Loss: 1.1403110027313232, D Loss: 1.2754836082458496, alpha: 0.03901547288252172\n",
      "epoch 1535 iteration0, G Loss: 1.0612530708312988, D Loss: 1.140510082244873, alpha: 0.038791134460236076\n",
      "epoch 1535 iteration100, G Loss: 1.0401005744934082, D Loss: 1.1918067932128906, alpha: 0.038791134460236076\n",
      "epoch 1536 iteration0, G Loss: 1.1299786567687988, D Loss: 1.1558880805969238, alpha: 0.03856803421033017\n",
      "epoch 1536 iteration100, G Loss: 1.0366343259811401, D Loss: 1.262898564338684, alpha: 0.03856803421033017\n",
      "epoch 1537 iteration0, G Loss: 0.804306149482727, D Loss: 1.182137370109558, alpha: 0.03834616589305262\n",
      "epoch 1537 iteration100, G Loss: 1.0570217370986938, D Loss: 1.132370114326477, alpha: 0.03834616589305262\n",
      "epoch 1538 iteration0, G Loss: 0.8716070055961609, D Loss: 1.2032057046890259, alpha: 0.038125523293266794\n",
      "epoch 1538 iteration100, G Loss: 1.076559066772461, D Loss: 1.2111002206802368, alpha: 0.038125523293266794\n",
      "epoch 1539 iteration0, G Loss: 0.8473623991012573, D Loss: 1.2202715873718262, alpha: 0.037906100220435945\n",
      "epoch 1539 iteration100, G Loss: 0.997294545173645, D Loss: 1.1501705646514893, alpha: 0.037906100220435945\n",
      "epoch 1540 iteration0, G Loss: 0.578039288520813, D Loss: 1.26872718334198, alpha: 0.03768789050860588\n",
      "epoch 1540 iteration100, G Loss: 0.9151707887649536, D Loss: 1.237959384918213, alpha: 0.03768789050860588\n",
      "epoch 1541 iteration0, G Loss: 0.9921866059303284, D Loss: 1.0929889678955078, alpha: 0.03747088801638698\n",
      "epoch 1541 iteration100, G Loss: 1.1152667999267578, D Loss: 1.2724974155426025, alpha: 0.03747088801638698\n",
      "epoch 1542 iteration0, G Loss: 0.8514236211776733, D Loss: 1.148991346359253, alpha: 0.037255086626935\n",
      "epoch 1542 iteration100, G Loss: 1.035404920578003, D Loss: 1.039297103881836, alpha: 0.037255086626935\n",
      "epoch 1543 iteration0, G Loss: 0.8651981949806213, D Loss: 1.1720815896987915, alpha: 0.03704048024793116\n",
      "epoch 1543 iteration100, G Loss: 1.1992032527923584, D Loss: 1.1357322931289673, alpha: 0.03704048024793116\n",
      "epoch 1544 iteration0, G Loss: 0.8532938957214355, D Loss: 1.1181278228759766, alpha: 0.036827062811560674\n",
      "epoch 1544 iteration100, G Loss: 1.1153680086135864, D Loss: 1.1643359661102295, alpha: 0.036827062811560674\n",
      "epoch 1545 iteration0, G Loss: 0.7670122981071472, D Loss: 1.1616920232772827, alpha: 0.03661482827448992\n",
      "epoch 1545 iteration100, G Loss: 1.3686623573303223, D Loss: 1.1855721473693848, alpha: 0.03661482827448992\n",
      "epoch 1546 iteration0, G Loss: 0.8860180974006653, D Loss: 1.1710968017578125, alpha: 0.036403770617843834\n",
      "epoch 1546 iteration100, G Loss: 0.8847826719284058, D Loss: 1.167805790901184, alpha: 0.036403770617843834\n",
      "epoch 1547 iteration0, G Loss: 0.8080209493637085, D Loss: 1.1703855991363525, alpha: 0.0361938838471807\n",
      "epoch 1547 iteration100, G Loss: 1.293275237083435, D Loss: 1.1906496286392212, alpha: 0.0361938838471807\n",
      "epoch 1548 iteration0, G Loss: 0.7369555830955505, D Loss: 1.2390305995941162, alpha: 0.03598516199246715\n",
      "epoch 1548 iteration100, G Loss: 1.3026262521743774, D Loss: 1.2181477546691895, alpha: 0.03598516199246715\n",
      "epoch 1549 iteration0, G Loss: 0.9387251734733582, D Loss: 1.284395456314087, alpha: 0.03577759910805145\n",
      "epoch 1549 iteration100, G Loss: 1.3364555835723877, D Loss: 1.2345044612884521, alpha: 0.03577759910805145\n",
      "epoch 1550 iteration0, G Loss: 0.8259695768356323, D Loss: 1.1309394836425781, alpha: 0.03557118927263614\n",
      "epoch 1550 iteration100, G Loss: 1.2075914144515991, D Loss: 1.1186189651489258, alpha: 0.03557118927263614\n",
      "Saving content.\n",
      "epoch 1551 iteration0, G Loss: 1.202894687652588, D Loss: 1.2204453945159912, alpha: 0.0353659265892492\n",
      "epoch 1551 iteration100, G Loss: 1.1834124326705933, D Loss: 1.1872289180755615, alpha: 0.0353659265892492\n",
      "epoch 1552 iteration0, G Loss: 0.8847532868385315, D Loss: 1.1830639839172363, alpha: 0.03516180518521517\n",
      "epoch 1552 iteration100, G Loss: 0.7685401439666748, D Loss: 1.1579840183258057, alpha: 0.03516180518521517\n",
      "epoch 1553 iteration0, G Loss: 0.9585292935371399, D Loss: 1.1622354984283447, alpha: 0.034958819212124626\n",
      "epoch 1553 iteration100, G Loss: 0.8228937983512878, D Loss: 1.209169864654541, alpha: 0.034958819212124626\n",
      "epoch 1554 iteration0, G Loss: 0.870962917804718, D Loss: 1.2513492107391357, alpha: 0.03475696284580243\n",
      "epoch 1554 iteration100, G Loss: 0.9308398962020874, D Loss: 1.2058717012405396, alpha: 0.03475696284580243\n",
      "epoch 1555 iteration0, G Loss: 0.7616521716117859, D Loss: 1.189310073852539, alpha: 0.03455623028627641\n",
      "epoch 1555 iteration100, G Loss: 1.1071975231170654, D Loss: 1.222702145576477, alpha: 0.03455623028627641\n",
      "epoch 1556 iteration0, G Loss: 1.0722465515136719, D Loss: 1.2116572856903076, alpha: 0.034356615757743514\n",
      "epoch 1556 iteration100, G Loss: 1.0902858972549438, D Loss: 1.10591721534729, alpha: 0.034356615757743514\n",
      "epoch 1557 iteration0, G Loss: 0.7869175672531128, D Loss: 1.2705259323120117, alpha: 0.03415811350853604\n",
      "epoch 1557 iteration100, G Loss: 1.2716889381408691, D Loss: 1.252021312713623, alpha: 0.03415811350853604\n",
      "epoch 1558 iteration0, G Loss: 0.673306405544281, D Loss: 1.1900227069854736, alpha: 0.03396071781108678\n",
      "epoch 1558 iteration100, G Loss: 1.4637539386749268, D Loss: 1.1064391136169434, alpha: 0.03396071781108678\n",
      "epoch 1559 iteration0, G Loss: 0.9348598718643188, D Loss: 1.2955511808395386, alpha: 0.033764422961893636\n",
      "epoch 1559 iteration100, G Loss: 1.2271887063980103, D Loss: 1.1926637887954712, alpha: 0.033764422961893636\n",
      "epoch 1560 iteration0, G Loss: 0.8309919834136963, D Loss: 1.1642675399780273, alpha: 0.033569223281482485\n",
      "epoch 1560 iteration100, G Loss: 0.8918402194976807, D Loss: 1.130442500114441, alpha: 0.033569223281482485\n",
      "epoch 1561 iteration0, G Loss: 0.7636401653289795, D Loss: 1.1943509578704834, alpha: 0.03337511311437025\n",
      "epoch 1561 iteration100, G Loss: 1.1004854440689087, D Loss: 1.235650658607483, alpha: 0.03337511311437025\n",
      "epoch 1562 iteration0, G Loss: 1.011887550354004, D Loss: 1.1964634656906128, alpha: 0.033182086829026125\n",
      "epoch 1562 iteration100, G Loss: 1.0211125612258911, D Loss: 1.201556921005249, alpha: 0.033182086829026125\n",
      "epoch 1563 iteration0, G Loss: 0.9126001596450806, D Loss: 1.2191195487976074, alpha: 0.03299013881783386\n",
      "epoch 1563 iteration100, G Loss: 1.046203374862671, D Loss: 1.2068254947662354, alpha: 0.03299013881783386\n",
      "epoch 1564 iteration0, G Loss: 0.742432713508606, D Loss: 1.325777292251587, alpha: 0.03279926349705031\n",
      "epoch 1564 iteration100, G Loss: 1.2418410778045654, D Loss: 1.2147409915924072, alpha: 0.03279926349705031\n",
      "epoch 1565 iteration0, G Loss: 0.8836612105369568, D Loss: 1.206939935684204, alpha: 0.03260945530676562\n",
      "epoch 1565 iteration100, G Loss: 1.0639678239822388, D Loss: 1.2204749584197998, alpha: 0.03260945530676562\n",
      "epoch 1566 iteration0, G Loss: 0.8643442392349243, D Loss: 1.1231811046600342, alpha: 0.032420708710862445\n",
      "epoch 1566 iteration100, G Loss: 1.1489477157592773, D Loss: 1.142732858657837, alpha: 0.032420708710862445\n",
      "epoch 1567 iteration0, G Loss: 0.9454420208930969, D Loss: 1.1680948734283447, alpha: 0.03223301819697311\n",
      "epoch 1567 iteration100, G Loss: 1.1512314081192017, D Loss: 1.124690294265747, alpha: 0.03223301819697311\n",
      "epoch 1568 iteration0, G Loss: 0.6605456471443176, D Loss: 1.1202025413513184, alpha: 0.03204637827643719\n",
      "epoch 1568 iteration100, G Loss: 1.0952273607254028, D Loss: 1.257603645324707, alpha: 0.03204637827643719\n",
      "epoch 1569 iteration0, G Loss: 0.8753037452697754, D Loss: 1.195779800415039, alpha: 0.03186078348425747\n",
      "epoch 1569 iteration100, G Loss: 1.114905834197998, D Loss: 1.085815191268921, alpha: 0.03186078348425747\n",
      "epoch 1570 iteration0, G Loss: 1.0385736227035522, D Loss: 1.1235454082489014, alpha: 0.03167622837905637\n",
      "epoch 1570 iteration100, G Loss: 1.1529288291931152, D Loss: 1.1645845174789429, alpha: 0.03167622837905637\n",
      "epoch 1571 iteration0, G Loss: 1.159300684928894, D Loss: 1.1626601219177246, alpha: 0.03149270754303091\n",
      "epoch 1571 iteration100, G Loss: 1.0165475606918335, D Loss: 1.1689085960388184, alpha: 0.03149270754303091\n",
      "epoch 1572 iteration0, G Loss: 0.9450652599334717, D Loss: 1.2967313528060913, alpha: 0.031310215581906053\n",
      "epoch 1572 iteration100, G Loss: 0.8494537472724915, D Loss: 1.2110469341278076, alpha: 0.031310215581906053\n",
      "epoch 1573 iteration0, G Loss: 0.8528433442115784, D Loss: 1.1860859394073486, alpha: 0.031128747124890443\n",
      "epoch 1573 iteration100, G Loss: 1.0241880416870117, D Loss: 1.2799303531646729, alpha: 0.031128747124890443\n",
      "epoch 1574 iteration0, G Loss: 0.7965900897979736, D Loss: 1.1428067684173584, alpha: 0.030948296824627186\n",
      "epoch 1574 iteration100, G Loss: 1.3812572956085205, D Loss: 1.2087370157241821, alpha: 0.030948296824627186\n",
      "epoch 1575 iteration0, G Loss: 0.7851823568344116, D Loss: 1.0575542449951172, alpha: 0.030768859357148015\n",
      "epoch 1575 iteration100, G Loss: 1.3251482248306274, D Loss: 1.036751389503479, alpha: 0.030768859357148015\n",
      "epoch 1576 iteration0, G Loss: 0.8070713877677917, D Loss: 1.1083357334136963, alpha: 0.030590429421823995\n",
      "epoch 1576 iteration100, G Loss: 1.1927441358566284, D Loss: 1.2127633094787598, alpha: 0.030590429421823995\n",
      "epoch 1577 iteration0, G Loss: 0.9500553607940674, D Loss: 1.2075512409210205, alpha: 0.030413001741316892\n",
      "epoch 1577 iteration100, G Loss: 1.2721502780914307, D Loss: 1.2418673038482666, alpha: 0.030413001741316892\n",
      "epoch 1578 iteration0, G Loss: 0.9025614857673645, D Loss: 1.2079133987426758, alpha: 0.030236571061529993\n",
      "epoch 1578 iteration100, G Loss: 0.8836033940315247, D Loss: 1.1980048418045044, alpha: 0.030236571061529993\n",
      "epoch 1579 iteration0, G Loss: 1.1056610345840454, D Loss: 1.3261915445327759, alpha: 0.030061132151558256\n",
      "epoch 1579 iteration100, G Loss: 1.4135034084320068, D Loss: 1.1820815801620483, alpha: 0.030061132151558256\n",
      "epoch 1580 iteration0, G Loss: 0.9212993383407593, D Loss: 1.0838699340820312, alpha: 0.02988667980363613\n",
      "epoch 1580 iteration100, G Loss: 1.0288152694702148, D Loss: 1.1884629726409912, alpha: 0.02988667980363613\n",
      "epoch 1581 iteration0, G Loss: 0.8179305195808411, D Loss: 1.1259678602218628, alpha: 0.0297132088330887\n",
      "epoch 1581 iteration100, G Loss: 1.5436309576034546, D Loss: 1.0698275566101074, alpha: 0.0297132088330887\n",
      "epoch 1582 iteration0, G Loss: 1.0226993560791016, D Loss: 1.1682138442993164, alpha: 0.02954071407827752\n",
      "epoch 1582 iteration100, G Loss: 1.327074646949768, D Loss: 1.2339537143707275, alpha: 0.02954071407827752\n",
      "epoch 1583 iteration0, G Loss: 0.9628820419311523, D Loss: 1.163779377937317, alpha: 0.02936919040054975\n",
      "epoch 1583 iteration100, G Loss: 1.0476360321044922, D Loss: 1.1654033660888672, alpha: 0.02936919040054975\n",
      "epoch 1584 iteration0, G Loss: 0.875704824924469, D Loss: 1.1035436391830444, alpha: 0.029198632684184767\n",
      "epoch 1584 iteration100, G Loss: 1.0977219343185425, D Loss: 1.1279603242874146, alpha: 0.029198632684184767\n",
      "epoch 1585 iteration0, G Loss: 0.9056653380393982, D Loss: 1.23543381690979, alpha: 0.029029035836340755\n",
      "epoch 1585 iteration100, G Loss: 0.8872929811477661, D Loss: 1.111152172088623, alpha: 0.029029035836340755\n",
      "epoch 1586 iteration0, G Loss: 1.1831188201904297, D Loss: 1.172516942024231, alpha: 0.028860394787000865\n",
      "epoch 1586 iteration100, G Loss: 1.276975154876709, D Loss: 1.2037010192871094, alpha: 0.028860394787000865\n",
      "epoch 1587 iteration0, G Loss: 0.9487867951393127, D Loss: 1.2148406505584717, alpha: 0.02869270448891792\n",
      "epoch 1587 iteration100, G Loss: 1.3469831943511963, D Loss: 1.2346206903457642, alpha: 0.02869270448891792\n",
      "epoch 1588 iteration0, G Loss: 0.7155205011367798, D Loss: 1.1502183675765991, alpha: 0.028525959917561017\n",
      "epoch 1588 iteration100, G Loss: 0.8738825917243958, D Loss: 1.1785900592803955, alpha: 0.028525959917561017\n",
      "epoch 1589 iteration0, G Loss: 0.96940678358078, D Loss: 1.192545771598816, alpha: 0.028360156071058462\n",
      "epoch 1589 iteration100, G Loss: 0.9226619601249695, D Loss: 1.2598905563354492, alpha: 0.028360156071058462\n",
      "epoch 1590 iteration0, G Loss: 0.978760838508606, D Loss: 1.1875014305114746, alpha: 0.02819528797014259\n",
      "epoch 1590 iteration100, G Loss: 1.2376261949539185, D Loss: 1.2260103225708008, alpha: 0.02819528797014259\n",
      "epoch 1591 iteration0, G Loss: 0.8097367286682129, D Loss: 1.0826886892318726, alpha: 0.028031350658093368\n",
      "epoch 1591 iteration100, G Loss: 1.2220879793167114, D Loss: 1.1441407203674316, alpha: 0.028031350658093368\n",
      "epoch 1592 iteration0, G Loss: 0.8061066269874573, D Loss: 1.1169369220733643, alpha: 0.027868339200681658\n",
      "epoch 1592 iteration100, G Loss: 1.2180252075195312, D Loss: 1.1548216342926025, alpha: 0.027868339200681658\n",
      "epoch 1593 iteration0, G Loss: 0.8114347457885742, D Loss: 1.1567604541778564, alpha: 0.0277062486861106\n",
      "epoch 1593 iteration100, G Loss: 1.0804557800292969, D Loss: 1.1133750677108765, alpha: 0.0277062486861106\n",
      "epoch 1594 iteration0, G Loss: 1.0212135314941406, D Loss: 1.1824910640716553, alpha: 0.027545074224959776\n",
      "epoch 1594 iteration100, G Loss: 1.0560604333877563, D Loss: 1.3312857151031494, alpha: 0.027545074224959776\n",
      "epoch 1595 iteration0, G Loss: 0.79229736328125, D Loss: 1.182600975036621, alpha: 0.027384810950125682\n",
      "epoch 1595 iteration100, G Loss: 1.2046211957931519, D Loss: 1.1586213111877441, alpha: 0.027384810950125682\n",
      "epoch 1596 iteration0, G Loss: 0.7576653957366943, D Loss: 1.0569610595703125, alpha: 0.02722545401676313\n",
      "epoch 1596 iteration100, G Loss: 0.9724728465080261, D Loss: 1.2430212497711182, alpha: 0.02722545401676313\n",
      "epoch 1597 iteration0, G Loss: 0.8053051233291626, D Loss: 1.1422147750854492, alpha: 0.027066998602227055\n",
      "epoch 1597 iteration100, G Loss: 1.1793193817138672, D Loss: 1.164206624031067, alpha: 0.027066998602227055\n",
      "epoch 1598 iteration0, G Loss: 0.8984599113464355, D Loss: 1.17795729637146, alpha: 0.026909439906012023\n",
      "epoch 1598 iteration100, G Loss: 1.1882879734039307, D Loss: 1.0614657402038574, alpha: 0.026909439906012023\n",
      "epoch 1599 iteration0, G Loss: 1.0276739597320557, D Loss: 1.265180230140686, alpha: 0.026752773149693376\n",
      "epoch 1599 iteration100, G Loss: 1.1571710109710693, D Loss: 1.2092877626419067, alpha: 0.026752773149693376\n",
      "epoch 1600 iteration0, G Loss: 1.0451656579971313, D Loss: 1.2383882999420166, alpha: 0.026596993576865957\n",
      "epoch 1600 iteration100, G Loss: 0.9138326048851013, D Loss: 1.2085331678390503, alpha: 0.026596993576865957\n",
      "Saving content.\n",
      "epoch 1601 iteration0, G Loss: 0.7953681349754333, D Loss: 1.1129285097122192, alpha: 0.026442096453084263\n",
      "epoch 1601 iteration100, G Loss: 1.2597426176071167, D Loss: 1.230905532836914, alpha: 0.026442096453084263\n",
      "epoch 1602 iteration0, G Loss: 1.001313328742981, D Loss: 1.2293773889541626, alpha: 0.026288077065801607\n",
      "epoch 1602 iteration100, G Loss: 0.8178910613059998, D Loss: 1.1925785541534424, alpha: 0.026288077065801607\n",
      "epoch 1603 iteration0, G Loss: 0.9292387366294861, D Loss: 1.1486338376998901, alpha: 0.026134930724307837\n",
      "epoch 1603 iteration100, G Loss: 1.3171306848526, D Loss: 1.2722938060760498, alpha: 0.026134930724307837\n",
      "epoch 1604 iteration0, G Loss: 0.8739434480667114, D Loss: 1.2529935836791992, alpha: 0.025982652759669045\n",
      "epoch 1604 iteration100, G Loss: 1.4305341243743896, D Loss: 1.092523217201233, alpha: 0.025982652759669045\n",
      "epoch 1605 iteration0, G Loss: 0.9807472229003906, D Loss: 1.0977566242218018, alpha: 0.02583123852466407\n",
      "epoch 1605 iteration100, G Loss: 1.1755019426345825, D Loss: 1.1621402502059937, alpha: 0.02583123852466407\n",
      "epoch 1606 iteration0, G Loss: 0.975005567073822, D Loss: 1.1459929943084717, alpha: 0.025680683393723314\n",
      "epoch 1606 iteration100, G Loss: 1.0848236083984375, D Loss: 1.290778398513794, alpha: 0.025680683393723314\n",
      "epoch 1607 iteration0, G Loss: 0.723467230796814, D Loss: 1.3291223049163818, alpha: 0.025530982762865584\n",
      "epoch 1607 iteration100, G Loss: 0.9834520220756531, D Loss: 1.130336880683899, alpha: 0.025530982762865584\n",
      "epoch 1608 iteration0, G Loss: 0.9422268271446228, D Loss: 1.1895756721496582, alpha: 0.02538213204963491\n",
      "epoch 1608 iteration100, G Loss: 1.1230816841125488, D Loss: 1.2416484355926514, alpha: 0.02538213204963491\n",
      "epoch 1609 iteration0, G Loss: 0.8001306056976318, D Loss: 1.1851274967193604, alpha: 0.02523412669303815\n",
      "epoch 1609 iteration100, G Loss: 1.297570824623108, D Loss: 1.089917540550232, alpha: 0.02523412669303815\n",
      "epoch 1610 iteration0, G Loss: 0.9958332180976868, D Loss: 1.1379327774047852, alpha: 0.02508696215347972\n",
      "epoch 1610 iteration100, G Loss: 1.2778841257095337, D Loss: 1.2088159322738647, alpha: 0.02508696215347972\n",
      "epoch 1611 iteration0, G Loss: 0.9618140459060669, D Loss: 1.1197267770767212, alpha: 0.024940633912700072\n",
      "epoch 1611 iteration100, G Loss: 1.244341492652893, D Loss: 1.0976630449295044, alpha: 0.024940633912700072\n",
      "epoch 1612 iteration0, G Loss: 0.9830849766731262, D Loss: 1.173084020614624, alpha: 0.024795137473709206\n",
      "epoch 1612 iteration100, G Loss: 1.2308616638183594, D Loss: 1.2737724781036377, alpha: 0.024795137473709206\n",
      "epoch 1613 iteration0, G Loss: 0.8759661912918091, D Loss: 1.2165776491165161, alpha: 0.02465046836072382\n",
      "epoch 1613 iteration100, G Loss: 1.0889426469802856, D Loss: 1.1942553520202637, alpha: 0.02465046836072382\n",
      "epoch 1614 iteration0, G Loss: 1.04034423828125, D Loss: 1.1594014167785645, alpha: 0.024506622119101706\n",
      "epoch 1614 iteration100, G Loss: 0.8834390044212341, D Loss: 1.2616596221923828, alpha: 0.024506622119101706\n",
      "epoch 1615 iteration0, G Loss: 0.7168149948120117, D Loss: 1.1715097427368164, alpha: 0.024363594315277792\n",
      "epoch 1615 iteration100, G Loss: 1.0775927305221558, D Loss: 1.2378437519073486, alpha: 0.024363594315277792\n",
      "epoch 1616 iteration0, G Loss: 0.9679903388023376, D Loss: 1.2226442098617554, alpha: 0.02422138053669798\n",
      "epoch 1616 iteration100, G Loss: 0.8836873173713684, D Loss: 1.1962566375732422, alpha: 0.02422138053669798\n",
      "epoch 1617 iteration0, G Loss: 0.811369776725769, D Loss: 1.133179783821106, alpha: 0.024079976391753632\n",
      "epoch 1617 iteration100, G Loss: 1.424311637878418, D Loss: 1.2057533264160156, alpha: 0.024079976391753632\n",
      "epoch 1618 iteration0, G Loss: 0.7943826913833618, D Loss: 1.1631954908370972, alpha: 0.023939377509717197\n",
      "epoch 1618 iteration100, G Loss: 1.1899659633636475, D Loss: 1.1446921825408936, alpha: 0.023939377509717197\n",
      "epoch 1619 iteration0, G Loss: 0.7242326140403748, D Loss: 1.1069318056106567, alpha: 0.02379957954067491\n",
      "epoch 1619 iteration100, G Loss: 1.1689645051956177, D Loss: 1.2312226295471191, alpha: 0.02379957954067491\n",
      "epoch 1620 iteration0, G Loss: 0.9401452541351318, D Loss: 1.1536014080047607, alpha: 0.023660578155461187\n",
      "epoch 1620 iteration100, G Loss: 1.1570557355880737, D Loss: 1.2269136905670166, alpha: 0.023660578155461187\n",
      "epoch 1621 iteration0, G Loss: 1.0329163074493408, D Loss: 1.1546831130981445, alpha: 0.02352236904559235\n",
      "epoch 1621 iteration100, G Loss: 1.142241358757019, D Loss: 1.3046692609786987, alpha: 0.02352236904559235\n",
      "epoch 1622 iteration0, G Loss: 1.0329656600952148, D Loss: 1.1216702461242676, alpha: 0.023384947923200006\n",
      "epoch 1622 iteration100, G Loss: 1.0388764142990112, D Loss: 1.2045767307281494, alpha: 0.023384947923200006\n",
      "epoch 1623 iteration0, G Loss: 0.8261547088623047, D Loss: 1.1352460384368896, alpha: 0.023248310520964544\n",
      "epoch 1623 iteration100, G Loss: 1.3467968702316284, D Loss: 1.1585015058517456, alpha: 0.023248310520964544\n",
      "epoch 1624 iteration0, G Loss: 0.9063826203346252, D Loss: 1.272873878479004, alpha: 0.02311245259204764\n",
      "epoch 1624 iteration100, G Loss: 0.915010392665863, D Loss: 1.1025809049606323, alpha: 0.02311245259204764\n",
      "epoch 1625 iteration0, G Loss: 0.7127505540847778, D Loss: 1.0554643869400024, alpha: 0.022977369910025636\n",
      "epoch 1625 iteration100, G Loss: 1.1311709880828857, D Loss: 1.1859875917434692, alpha: 0.022977369910025636\n",
      "epoch 1626 iteration0, G Loss: 0.9609437584877014, D Loss: 1.239774227142334, alpha: 0.022843058268822047\n",
      "epoch 1626 iteration100, G Loss: 1.3641295433044434, D Loss: 1.119782567024231, alpha: 0.022843058268822047\n",
      "epoch 1627 iteration0, G Loss: 0.9900102019309998, D Loss: 1.1388096809387207, alpha: 0.022709513482640276\n",
      "epoch 1627 iteration100, G Loss: 1.2142062187194824, D Loss: 1.1600885391235352, alpha: 0.022709513482640276\n",
      "epoch 1628 iteration0, G Loss: 0.8255828022956848, D Loss: 1.1708455085754395, alpha: 0.022576731385895554\n",
      "epoch 1628 iteration100, G Loss: 0.9680642485618591, D Loss: 1.3016926050186157, alpha: 0.022576731385895554\n",
      "epoch 1629 iteration0, G Loss: 0.9998895525932312, D Loss: 1.1093225479125977, alpha: 0.02244470783314756\n",
      "epoch 1629 iteration100, G Loss: 0.8858233690261841, D Loss: 1.247607707977295, alpha: 0.02244470783314756\n",
      "epoch 1630 iteration0, G Loss: 0.973953902721405, D Loss: 1.2535498142242432, alpha: 0.02231343869903235\n",
      "epoch 1630 iteration100, G Loss: 1.0562189817428589, D Loss: 1.2017838954925537, alpha: 0.02231343869903235\n",
      "epoch 1631 iteration0, G Loss: 1.0167059898376465, D Loss: 1.1903610229492188, alpha: 0.022182919878194096\n",
      "epoch 1631 iteration100, G Loss: 1.1342211961746216, D Loss: 1.066605806350708, alpha: 0.022182919878194096\n",
      "epoch 1632 iteration0, G Loss: 1.1798646450042725, D Loss: 1.260331153869629, alpha: 0.022053147285217123\n",
      "epoch 1632 iteration100, G Loss: 1.1427468061447144, D Loss: 1.2532150745391846, alpha: 0.022053147285217123\n",
      "epoch 1633 iteration0, G Loss: 0.9498237371444702, D Loss: 1.1577796936035156, alpha: 0.021924116854557196\n",
      "epoch 1633 iteration100, G Loss: 1.2438578605651855, D Loss: 1.2912185192108154, alpha: 0.021924116854557196\n",
      "epoch 1634 iteration0, G Loss: 0.9537997245788574, D Loss: 1.1349204778671265, alpha: 0.021795824540473907\n",
      "epoch 1634 iteration100, G Loss: 1.123727798461914, D Loss: 1.1184200048446655, alpha: 0.021795824540473907\n",
      "epoch 1635 iteration0, G Loss: 1.0584743022918701, D Loss: 1.1892489194869995, alpha: 0.021668266316960505\n",
      "epoch 1635 iteration100, G Loss: 1.0963398218154907, D Loss: 1.1833763122558594, alpha: 0.021668266316960505\n",
      "epoch 1636 iteration0, G Loss: 0.9386441111564636, D Loss: 1.3025028705596924, alpha: 0.02154143817767651\n",
      "epoch 1636 iteration100, G Loss: 0.8937943577766418, D Loss: 1.2527536153793335, alpha: 0.02154143817767651\n",
      "epoch 1637 iteration0, G Loss: 0.889106273651123, D Loss: 1.1995534896850586, alpha: 0.021415336135878316\n",
      "epoch 1637 iteration100, G Loss: 1.6672900915145874, D Loss: 1.144575595855713, alpha: 0.021415336135878316\n",
      "epoch 1638 iteration0, G Loss: 0.8036438822746277, D Loss: 1.283478856086731, alpha: 0.02128995622435026\n",
      "epoch 1638 iteration100, G Loss: 1.3432878255844116, D Loss: 1.039025068283081, alpha: 0.02128995622435026\n",
      "epoch 1639 iteration0, G Loss: 0.8210505247116089, D Loss: 1.0998178720474243, alpha: 0.021165294495335885\n",
      "epoch 1639 iteration100, G Loss: 1.0414013862609863, D Loss: 1.2501202821731567, alpha: 0.021165294495335885\n",
      "epoch 1640 iteration0, G Loss: 0.9047457575798035, D Loss: 1.1490694284439087, alpha: 0.021041347020468337\n",
      "epoch 1640 iteration100, G Loss: 1.3469460010528564, D Loss: 1.1146036386489868, alpha: 0.021041347020468337\n",
      "epoch 1641 iteration0, G Loss: 0.8349106311798096, D Loss: 1.115280270576477, alpha: 0.02091810989070131\n",
      "epoch 1641 iteration100, G Loss: 0.8078855872154236, D Loss: 1.2296457290649414, alpha: 0.02091810989070131\n",
      "epoch 1642 iteration0, G Loss: 0.6910212635993958, D Loss: 1.1071834564208984, alpha: 0.020795579216239868\n",
      "epoch 1642 iteration100, G Loss: 0.9363561272621155, D Loss: 1.1848418712615967, alpha: 0.020795579216239868\n",
      "epoch 1643 iteration0, G Loss: 0.8740434646606445, D Loss: 1.1709120273590088, alpha: 0.020673751126471407\n",
      "epoch 1643 iteration100, G Loss: 1.15311598777771, D Loss: 1.1283440589904785, alpha: 0.020673751126471407\n",
      "epoch 1644 iteration0, G Loss: 0.9964738488197327, D Loss: 1.1971614360809326, alpha: 0.020552621769894808\n",
      "epoch 1644 iteration100, G Loss: 0.990982711315155, D Loss: 1.1973490715026855, alpha: 0.020552621769894808\n",
      "epoch 1645 iteration0, G Loss: 0.7735233306884766, D Loss: 1.1884288787841797, alpha: 0.02043218731405294\n",
      "epoch 1645 iteration100, G Loss: 1.1600639820098877, D Loss: 1.1868491172790527, alpha: 0.02043218731405294\n",
      "epoch 1646 iteration0, G Loss: 0.8290188908576965, D Loss: 1.203166127204895, alpha: 0.02031244394546139\n",
      "epoch 1646 iteration100, G Loss: 1.130406141281128, D Loss: 1.132110834121704, alpha: 0.02031244394546139\n",
      "epoch 1647 iteration0, G Loss: 0.8166188597679138, D Loss: 1.0936479568481445, alpha: 0.020193387869539503\n",
      "epoch 1647 iteration100, G Loss: 0.9479911923408508, D Loss: 1.1771223545074463, alpha: 0.020193387869539503\n",
      "epoch 1648 iteration0, G Loss: 0.8434695601463318, D Loss: 1.19853675365448, alpha: 0.020075015310540567\n",
      "epoch 1648 iteration100, G Loss: 1.2736581563949585, D Loss: 1.2325581312179565, alpha: 0.020075015310540567\n",
      "epoch 1649 iteration0, G Loss: 1.0883678197860718, D Loss: 1.2092421054840088, alpha: 0.01995732251148241\n",
      "epoch 1649 iteration100, G Loss: 1.2021923065185547, D Loss: 1.313215732574463, alpha: 0.01995732251148241\n",
      "epoch 1650 iteration0, G Loss: 0.8288105130195618, D Loss: 1.2233126163482666, alpha: 0.019840305734077468\n",
      "epoch 1650 iteration100, G Loss: 0.8964681029319763, D Loss: 1.1742470264434814, alpha: 0.019840305734077468\n",
      "Saving content.\n",
      "epoch 1651 iteration0, G Loss: 0.9476585984230042, D Loss: 1.1909120082855225, alpha: 0.019723961258662492\n",
      "epoch 1651 iteration100, G Loss: 1.2321832180023193, D Loss: 1.1987464427947998, alpha: 0.019723961258662492\n",
      "epoch 1652 iteration0, G Loss: 0.8183515667915344, D Loss: 1.0784618854522705, alpha: 0.019608285384129065\n",
      "epoch 1652 iteration100, G Loss: 1.3164432048797607, D Loss: 1.2163273096084595, alpha: 0.019608285384129065\n",
      "epoch 1653 iteration0, G Loss: 0.9197136759757996, D Loss: 1.1714943647384644, alpha: 0.0194932744278542\n",
      "epoch 1653 iteration100, G Loss: 1.263200283050537, D Loss: 1.301276445388794, alpha: 0.0194932744278542\n",
      "epoch 1654 iteration0, G Loss: 0.8402188420295715, D Loss: 1.0846641063690186, alpha: 0.019378924725629187\n",
      "epoch 1654 iteration100, G Loss: 0.8419399261474609, D Loss: 1.1947381496429443, alpha: 0.019378924725629187\n",
      "epoch 1655 iteration0, G Loss: 1.0135314464569092, D Loss: 1.2058565616607666, alpha: 0.019265232631591744\n",
      "epoch 1655 iteration100, G Loss: 1.4845361709594727, D Loss: 1.1292381286621094, alpha: 0.019265232631591744\n",
      "epoch 1656 iteration0, G Loss: 0.8804686665534973, D Loss: 1.239396333694458, alpha: 0.01915219451815342\n",
      "epoch 1656 iteration100, G Loss: 1.0405603647232056, D Loss: 1.1629295349121094, alpha: 0.01915219451815342\n",
      "epoch 1657 iteration0, G Loss: 0.9804742336273193, D Loss: 1.2334223985671997, alpha: 0.019039806775931756\n",
      "epoch 1657 iteration100, G Loss: 1.128456711769104, D Loss: 1.218589425086975, alpha: 0.019039806775931756\n",
      "epoch 1658 iteration0, G Loss: 0.7548649311065674, D Loss: 1.2059178352355957, alpha: 0.018928065813680117\n",
      "epoch 1658 iteration100, G Loss: 1.4516444206237793, D Loss: 1.2140777111053467, alpha: 0.018928065813680117\n",
      "epoch 1659 iteration0, G Loss: 0.9727254509925842, D Loss: 1.1526429653167725, alpha: 0.018816968058216532\n",
      "epoch 1659 iteration100, G Loss: 1.020970344543457, D Loss: 1.1782071590423584, alpha: 0.018816968058216532\n",
      "epoch 1660 iteration0, G Loss: 0.8467389345169067, D Loss: 1.1706466674804688, alpha: 0.018706509954354522\n",
      "epoch 1660 iteration100, G Loss: 1.1414921283721924, D Loss: 1.2058520317077637, alpha: 0.018706509954354522\n",
      "epoch 1661 iteration0, G Loss: 1.1142578125, D Loss: 1.2624396085739136, alpha: 0.018596687964833936\n",
      "epoch 1661 iteration100, G Loss: 1.0323612689971924, D Loss: 1.2233695983886719, alpha: 0.018596687964833936\n",
      "epoch 1662 iteration0, G Loss: 0.8902891278266907, D Loss: 1.2114062309265137, alpha: 0.018487498570249672\n",
      "epoch 1662 iteration100, G Loss: 1.2199511528015137, D Loss: 1.21006178855896, alpha: 0.018487498570249672\n",
      "epoch 1663 iteration0, G Loss: 0.9248907566070557, D Loss: 1.1542787551879883, alpha: 0.018378938268982514\n",
      "epoch 1663 iteration100, G Loss: 0.8953021764755249, D Loss: 1.2226636409759521, alpha: 0.018378938268982514\n",
      "epoch 1664 iteration0, G Loss: 0.9933290481567383, D Loss: 1.1675249338150024, alpha: 0.018271003577129186\n",
      "epoch 1664 iteration100, G Loss: 0.8489101529121399, D Loss: 1.2924116849899292, alpha: 0.018271003577129186\n",
      "epoch 1665 iteration0, G Loss: 0.9267457127571106, D Loss: 1.1990351676940918, alpha: 0.018163691028432627\n",
      "epoch 1665 iteration100, G Loss: 1.3174747228622437, D Loss: 1.1540088653564453, alpha: 0.018163691028432627\n",
      "epoch 1666 iteration0, G Loss: 0.9384738802909851, D Loss: 1.0587167739868164, alpha: 0.018056997174211276\n",
      "epoch 1666 iteration100, G Loss: 1.1831218004226685, D Loss: 1.2570679187774658, alpha: 0.018056997174211276\n",
      "epoch 1667 iteration0, G Loss: 1.026740312576294, D Loss: 1.1727402210235596, alpha: 0.01795091858329123\n",
      "epoch 1667 iteration100, G Loss: 1.263834834098816, D Loss: 1.1328235864639282, alpha: 0.01795091858329123\n",
      "epoch 1668 iteration0, G Loss: 1.0981862545013428, D Loss: 1.18748140335083, alpha: 0.0178454518419342\n",
      "epoch 1668 iteration100, G Loss: 1.0303232669830322, D Loss: 1.1623101234436035, alpha: 0.0178454518419342\n",
      "epoch 1669 iteration0, G Loss: 0.9148305654525757, D Loss: 1.144594430923462, alpha: 0.017740593553769224\n",
      "epoch 1669 iteration100, G Loss: 1.2021106481552124, D Loss: 1.1663575172424316, alpha: 0.017740593553769224\n",
      "epoch 1670 iteration0, G Loss: 0.9470401406288147, D Loss: 1.1881194114685059, alpha: 0.017636340339722723\n",
      "epoch 1670 iteration100, G Loss: 1.1274245977401733, D Loss: 1.2030202150344849, alpha: 0.017636340339722723\n",
      "epoch 1671 iteration0, G Loss: 0.8748247027397156, D Loss: 1.0943052768707275, alpha: 0.01753268883794845\n",
      "epoch 1671 iteration100, G Loss: 1.1188849210739136, D Loss: 1.266422986984253, alpha: 0.01753268883794845\n",
      "epoch 1672 iteration0, G Loss: 0.8467123508453369, D Loss: 1.239575982093811, alpha: 0.01742963570375866\n",
      "epoch 1672 iteration100, G Loss: 0.853013277053833, D Loss: 1.2723798751831055, alpha: 0.01742963570375866\n",
      "epoch 1673 iteration0, G Loss: 0.7362856268882751, D Loss: 1.2556893825531006, alpha: 0.017327177609553934\n",
      "epoch 1673 iteration100, G Loss: 1.2552225589752197, D Loss: 1.2514729499816895, alpha: 0.017327177609553934\n",
      "epoch 1674 iteration0, G Loss: 0.8093059062957764, D Loss: 1.1356605291366577, alpha: 0.017225311244753683\n",
      "epoch 1674 iteration100, G Loss: 1.0470595359802246, D Loss: 1.1256351470947266, alpha: 0.017225311244753683\n",
      "epoch 1675 iteration0, G Loss: 0.9456956386566162, D Loss: 1.1577361822128296, alpha: 0.01712403331572765\n",
      "epoch 1675 iteration100, G Loss: 0.9188331365585327, D Loss: 1.1379241943359375, alpha: 0.01712403331572765\n",
      "epoch 1676 iteration0, G Loss: 1.0031620264053345, D Loss: 1.1354703903198242, alpha: 0.017023340545725296\n",
      "epoch 1676 iteration100, G Loss: 1.2628281116485596, D Loss: 1.12066650390625, alpha: 0.017023340545725296\n",
      "epoch 1677 iteration0, G Loss: 0.9749746918678284, D Loss: 1.1762356758117676, alpha: 0.016923229674807527\n",
      "epoch 1677 iteration100, G Loss: 1.4168407917022705, D Loss: 1.2686901092529297, alpha: 0.016923229674807527\n",
      "epoch 1678 iteration0, G Loss: 0.8184583187103271, D Loss: 1.1938921213150024, alpha: 0.016823697459776854\n",
      "epoch 1678 iteration100, G Loss: 1.1399297714233398, D Loss: 1.1315916776657104, alpha: 0.016823697459776854\n",
      "epoch 1679 iteration0, G Loss: 1.0393526554107666, D Loss: 1.1819955110549927, alpha: 0.01672474067410845\n",
      "epoch 1679 iteration100, G Loss: 1.2486116886138916, D Loss: 1.2598098516464233, alpha: 0.01672474067410845\n",
      "epoch 1680 iteration0, G Loss: 0.9412019848823547, D Loss: 1.217625379562378, alpha: 0.016626356107881657\n",
      "epoch 1680 iteration100, G Loss: 1.2674880027770996, D Loss: 1.1937700510025024, alpha: 0.016626356107881657\n",
      "epoch 1681 iteration0, G Loss: 0.9456361532211304, D Loss: 1.145813226699829, alpha: 0.016528540567709915\n",
      "epoch 1681 iteration100, G Loss: 0.927086591720581, D Loss: 1.234474778175354, alpha: 0.016528540567709915\n",
      "epoch 1682 iteration0, G Loss: 0.7983909845352173, D Loss: 1.166640043258667, alpha: 0.0164312908766725\n",
      "epoch 1682 iteration100, G Loss: 1.1068823337554932, D Loss: 1.206519365310669, alpha: 0.0164312908766725\n",
      "epoch 1683 iteration0, G Loss: 1.070940375328064, D Loss: 1.0448360443115234, alpha: 0.016334603874246345\n",
      "epoch 1683 iteration100, G Loss: 1.3504912853240967, D Loss: 1.0787854194641113, alpha: 0.016334603874246345\n",
      "epoch 1684 iteration0, G Loss: 0.9323134422302246, D Loss: 1.1613292694091797, alpha: 0.01623847641623566\n",
      "epoch 1684 iteration100, G Loss: 1.2884138822555542, D Loss: 1.1261029243469238, alpha: 0.01623847641623566\n",
      "epoch 1685 iteration0, G Loss: 1.0949887037277222, D Loss: 1.2979915142059326, alpha: 0.016142905374705308\n",
      "epoch 1685 iteration100, G Loss: 0.9223194718360901, D Loss: 1.1156576871871948, alpha: 0.016142905374705308\n",
      "epoch 1686 iteration0, G Loss: 0.9081804156303406, D Loss: 1.2441344261169434, alpha: 0.016047887637909986\n",
      "epoch 1686 iteration100, G Loss: 1.0017858743667603, D Loss: 1.221380352973938, alpha: 0.016047887637909986\n",
      "epoch 1687 iteration0, G Loss: 1.0506343841552734, D Loss: 1.1582255363464355, alpha: 0.015953420110228267\n",
      "epoch 1687 iteration100, G Loss: 1.0995070934295654, D Loss: 1.135284185409546, alpha: 0.015953420110228267\n",
      "epoch 1688 iteration0, G Loss: 0.9952245950698853, D Loss: 1.0440846681594849, alpha: 0.015859499712092218\n",
      "epoch 1688 iteration100, G Loss: 1.0785192251205444, D Loss: 1.154557704925537, alpha: 0.015859499712092218\n",
      "epoch 1689 iteration0, G Loss: 0.7043198943138123, D Loss: 1.0790884494781494, alpha: 0.015766123379920116\n",
      "epoch 1689 iteration100, G Loss: 0.9529048204421997, D Loss: 1.2078194618225098, alpha: 0.015766123379920116\n",
      "epoch 1690 iteration0, G Loss: 1.051620364189148, D Loss: 1.1613337993621826, alpha: 0.01567328806604862\n",
      "epoch 1690 iteration100, G Loss: 1.2924445867538452, D Loss: 1.2355729341506958, alpha: 0.01567328806604862\n",
      "epoch 1691 iteration0, G Loss: 0.8760358691215515, D Loss: 1.2694308757781982, alpha: 0.01558099073866337\n",
      "epoch 1691 iteration100, G Loss: 1.323462963104248, D Loss: 1.1076109409332275, alpha: 0.01558099073866337\n",
      "epoch 1692 iteration0, G Loss: 0.9912821054458618, D Loss: 1.2173457145690918, alpha: 0.015489228381733056\n",
      "epoch 1692 iteration100, G Loss: 1.1489182710647583, D Loss: 1.0947500467300415, alpha: 0.015489228381733056\n",
      "epoch 1693 iteration0, G Loss: 0.9320470094680786, D Loss: 1.2707171440124512, alpha: 0.01539799799493946\n",
      "epoch 1693 iteration100, G Loss: 1.0402523279190063, D Loss: 1.1034371852874756, alpha: 0.01539799799493946\n",
      "epoch 1694 iteration0, G Loss: 0.764148473739624, D Loss: 1.0935356616973877, alpha: 0.015307296593611186\n",
      "epoch 1694 iteration100, G Loss: 1.037979245185852, D Loss: 1.2043758630752563, alpha: 0.015307296593611186\n",
      "epoch 1695 iteration0, G Loss: 0.68756502866745, D Loss: 1.1716721057891846, alpha: 0.01521712120865637\n",
      "epoch 1695 iteration100, G Loss: 1.215508222579956, D Loss: 1.070318579673767, alpha: 0.01521712120865637\n",
      "epoch 1696 iteration0, G Loss: 0.9301458597183228, D Loss: 1.2422248125076294, alpha: 0.015127468886493411\n",
      "epoch 1696 iteration100, G Loss: 1.224122405052185, D Loss: 1.1728798151016235, alpha: 0.015127468886493411\n",
      "epoch 1697 iteration0, G Loss: 0.8111307621002197, D Loss: 1.2078436613082886, alpha: 0.015038336688985465\n",
      "epoch 1697 iteration100, G Loss: 0.9551800489425659, D Loss: 1.191304087638855, alpha: 0.015038336688985465\n",
      "epoch 1698 iteration0, G Loss: 0.895412802696228, D Loss: 1.0981431007385254, alpha: 0.01494972169337272\n",
      "epoch 1698 iteration100, G Loss: 1.1796796321868896, D Loss: 1.0579034090042114, alpha: 0.01494972169337272\n",
      "epoch 1699 iteration0, G Loss: 1.0128190517425537, D Loss: 1.1723151206970215, alpha: 0.01486162099220456\n",
      "epoch 1699 iteration100, G Loss: 0.8382593989372253, D Loss: 1.1685642004013062, alpha: 0.01486162099220456\n",
      "epoch 1700 iteration0, G Loss: 1.1348505020141602, D Loss: 1.1761090755462646, alpha: 0.01477403169327307\n",
      "epoch 1700 iteration100, G Loss: 1.3838787078857422, D Loss: 1.2183822393417358, alpha: 0.01477403169327307\n",
      "Saving content.\n",
      "epoch 1701 iteration0, G Loss: 1.17369544506073, D Loss: 1.1250141859054565, alpha: 0.01468695091954697\n",
      "epoch 1701 iteration100, G Loss: 1.0314550399780273, D Loss: 1.1419117450714111, alpha: 0.01468695091954697\n",
      "epoch 1702 iteration0, G Loss: 0.83903568983078, D Loss: 1.1751054525375366, alpha: 0.01460037580910356\n",
      "epoch 1702 iteration100, G Loss: 1.411926031112671, D Loss: 1.1299163103103638, alpha: 0.01460037580910356\n",
      "epoch 1703 iteration0, G Loss: 0.924743115901947, D Loss: 1.108972430229187, alpha: 0.014514303515063554\n",
      "epoch 1703 iteration100, G Loss: 1.4236010313034058, D Loss: 1.1630436182022095, alpha: 0.014514303515063554\n",
      "epoch 1704 iteration0, G Loss: 0.9106360673904419, D Loss: 1.14850652217865, alpha: 0.014428731205522793\n",
      "epoch 1704 iteration100, G Loss: 1.100894808769226, D Loss: 1.1835986375808716, alpha: 0.014428731205522793\n",
      "epoch 1705 iteration0, G Loss: 0.8953463435173035, D Loss: 1.200451374053955, alpha: 0.014343656063488086\n",
      "epoch 1705 iteration100, G Loss: 1.031139850616455, D Loss: 1.1276642084121704, alpha: 0.014343656063488086\n",
      "epoch 1706 iteration0, G Loss: 0.9225279688835144, D Loss: 1.1916546821594238, alpha: 0.014259075286809586\n",
      "epoch 1706 iteration100, G Loss: 1.081899881362915, D Loss: 1.1537542343139648, alpha: 0.014259075286809586\n",
      "epoch 1707 iteration0, G Loss: 1.0040637254714966, D Loss: 1.1289162635803223, alpha: 0.014174986088115071\n",
      "epoch 1707 iteration100, G Loss: 1.0429189205169678, D Loss: 1.227079153060913, alpha: 0.014174986088115071\n",
      "epoch 1708 iteration0, G Loss: 0.7937089800834656, D Loss: 1.1489806175231934, alpha: 0.014091385694744774\n",
      "epoch 1708 iteration100, G Loss: 0.951668918132782, D Loss: 1.1433305740356445, alpha: 0.014091385694744774\n",
      "epoch 1709 iteration0, G Loss: 0.8033645153045654, D Loss: 1.1659975051879883, alpha: 0.01400827134868421\n",
      "epoch 1709 iteration100, G Loss: 1.4767285585403442, D Loss: 1.0690821409225464, alpha: 0.01400827134868421\n",
      "epoch 1710 iteration0, G Loss: 0.9623132944107056, D Loss: 1.2411015033721924, alpha: 0.013925640306500453\n",
      "epoch 1710 iteration100, G Loss: 1.2885262966156006, D Loss: 1.1258008480072021, alpha: 0.013925640306500453\n",
      "epoch 1711 iteration0, G Loss: 0.8318725228309631, D Loss: 1.1990022659301758, alpha: 0.01384348983927497\n",
      "epoch 1711 iteration100, G Loss: 1.3595380783081055, D Loss: 1.1477839946746826, alpha: 0.01384348983927497\n",
      "epoch 1712 iteration0, G Loss: 0.9487337470054626, D Loss: 1.1490988731384277, alpha: 0.01376181723253933\n",
      "epoch 1712 iteration100, G Loss: 0.9403005838394165, D Loss: 1.2039506435394287, alpha: 0.01376181723253933\n",
      "epoch 1713 iteration0, G Loss: 0.8891042470932007, D Loss: 1.1725378036499023, alpha: 0.013680619786209824\n",
      "epoch 1713 iteration100, G Loss: 1.0394717454910278, D Loss: 1.2328205108642578, alpha: 0.013680619786209824\n",
      "epoch 1714 iteration0, G Loss: 0.8328807950019836, D Loss: 1.189939022064209, alpha: 0.01359989481452295\n",
      "epoch 1714 iteration100, G Loss: 1.2352432012557983, D Loss: 1.1380702257156372, alpha: 0.01359989481452295\n",
      "epoch 1715 iteration0, G Loss: 0.7594350576400757, D Loss: 1.1904820203781128, alpha: 0.013519639645969583\n",
      "epoch 1715 iteration100, G Loss: 1.3346376419067383, D Loss: 1.262529969215393, alpha: 0.013519639645969583\n",
      "epoch 1716 iteration0, G Loss: 0.9768214821815491, D Loss: 1.1646544933319092, alpha: 0.013439851623231136\n",
      "epoch 1716 iteration100, G Loss: 0.8791146874427795, D Loss: 1.2033358812332153, alpha: 0.013439851623231136\n",
      "epoch 1717 iteration0, G Loss: 0.953874409198761, D Loss: 1.227311611175537, alpha: 0.013360528103114278\n",
      "epoch 1717 iteration100, G Loss: 1.0869802236557007, D Loss: 1.2120113372802734, alpha: 0.013360528103114278\n",
      "epoch 1718 iteration0, G Loss: 0.9849656224250793, D Loss: 1.0561795234680176, alpha: 0.013281666456487984\n",
      "epoch 1718 iteration100, G Loss: 0.7044670581817627, D Loss: 1.219372034072876, alpha: 0.013281666456487984\n",
      "epoch 1719 iteration0, G Loss: 0.8841718435287476, D Loss: 1.2041349411010742, alpha: 0.013203264068217813\n",
      "epoch 1719 iteration100, G Loss: 1.2184611558914185, D Loss: 1.028167724609375, alpha: 0.013203264068217813\n",
      "epoch 1720 iteration0, G Loss: 0.9016112685203552, D Loss: 1.1637122631072998, alpha: 0.013125318337102843\n",
      "epoch 1720 iteration100, G Loss: 1.315457820892334, D Loss: 1.1133918762207031, alpha: 0.013125318337102843\n",
      "epoch 1721 iteration0, G Loss: 0.8989238739013672, D Loss: 1.2810113430023193, alpha: 0.01304782667581128\n",
      "epoch 1721 iteration100, G Loss: 1.2637791633605957, D Loss: 1.026158332824707, alpha: 0.01304782667581128\n",
      "epoch 1722 iteration0, G Loss: 0.9589337110519409, D Loss: 1.0992461442947388, alpha: 0.012970786510817178\n",
      "epoch 1722 iteration100, G Loss: 0.9085137844085693, D Loss: 1.152793288230896, alpha: 0.012970786510817178\n",
      "epoch 1723 iteration0, G Loss: 0.7199844121932983, D Loss: 1.1160839796066284, alpha: 0.012894195282336818\n",
      "epoch 1723 iteration100, G Loss: 1.1436034440994263, D Loss: 1.1314589977264404, alpha: 0.012894195282336818\n",
      "epoch 1724 iteration0, G Loss: 0.7370743155479431, D Loss: 1.1119818687438965, alpha: 0.012818050444264761\n",
      "epoch 1724 iteration100, G Loss: 0.8614634871482849, D Loss: 1.1691588163375854, alpha: 0.012818050444264761\n",
      "epoch 1725 iteration0, G Loss: 0.8547999858856201, D Loss: 1.1384508609771729, alpha: 0.012742349464111569\n",
      "epoch 1725 iteration100, G Loss: 1.1503369808197021, D Loss: 1.2140971422195435, alpha: 0.012742349464111569\n",
      "epoch 1726 iteration0, G Loss: 0.9339523315429688, D Loss: 1.212716817855835, alpha: 0.012667089822940625\n",
      "epoch 1726 iteration100, G Loss: 0.8540424704551697, D Loss: 1.154557466506958, alpha: 0.012667089822940625\n",
      "epoch 1727 iteration0, G Loss: 0.7295358777046204, D Loss: 1.0555551052093506, alpha: 0.012592269015304303\n",
      "epoch 1727 iteration100, G Loss: 1.200190544128418, D Loss: 1.211223840713501, alpha: 0.012592269015304303\n",
      "epoch 1728 iteration0, G Loss: 0.9912393689155579, D Loss: 1.1224987506866455, alpha: 0.012517884549182567\n",
      "epoch 1728 iteration100, G Loss: 1.2526501417160034, D Loss: 1.0944218635559082, alpha: 0.012517884549182567\n",
      "epoch 1729 iteration0, G Loss: 0.8668625354766846, D Loss: 1.1950680017471313, alpha: 0.012443933945919694\n",
      "epoch 1729 iteration100, G Loss: 0.8785698413848877, D Loss: 1.0982458591461182, alpha: 0.012443933945919694\n",
      "epoch 1730 iteration0, G Loss: 0.7267279624938965, D Loss: 1.2391737699508667, alpha: 0.012370414740162317\n",
      "epoch 1730 iteration100, G Loss: 1.0870273113250732, D Loss: 1.0956894159317017, alpha: 0.012370414740162317\n",
      "epoch 1731 iteration0, G Loss: 0.9282092452049255, D Loss: 1.1214598417282104, alpha: 0.012297324479797256\n",
      "epoch 1731 iteration100, G Loss: 1.8005497455596924, D Loss: 1.1131622791290283, alpha: 0.012297324479797256\n",
      "epoch 1732 iteration0, G Loss: 0.8740311861038208, D Loss: 1.187448501586914, alpha: 0.012224660725888903\n",
      "epoch 1732 iteration100, G Loss: 1.4136574268341064, D Loss: 1.1652251482009888, alpha: 0.012224660725888903\n",
      "epoch 1733 iteration0, G Loss: 0.8757066130638123, D Loss: 1.3285977840423584, alpha: 0.0121524210526186\n",
      "epoch 1733 iteration100, G Loss: 1.066779375076294, D Loss: 1.1785629987716675, alpha: 0.0121524210526186\n",
      "epoch 1734 iteration0, G Loss: 0.8897034525871277, D Loss: 1.1441802978515625, alpha: 0.012080603047221694\n",
      "epoch 1734 iteration100, G Loss: 0.9474828839302063, D Loss: 1.2295551300048828, alpha: 0.012080603047221694\n",
      "epoch 1735 iteration0, G Loss: 0.9888457655906677, D Loss: 1.3115030527114868, alpha: 0.012009204309927468\n",
      "epoch 1735 iteration100, G Loss: 1.1445376873016357, D Loss: 1.2097735404968262, alpha: 0.012009204309927468\n",
      "epoch 1736 iteration0, G Loss: 0.7648120522499084, D Loss: 1.1065664291381836, alpha: 0.01193822245389664\n",
      "epoch 1736 iteration100, G Loss: 1.3094680309295654, D Loss: 1.1709392070770264, alpha: 0.01193822245389664\n",
      "epoch 1737 iteration0, G Loss: 0.7748852372169495, D Loss: 1.2562224864959717, alpha: 0.011867655105161412\n",
      "epoch 1737 iteration100, G Loss: 1.1604053974151611, D Loss: 1.1789644956588745, alpha: 0.011867655105161412\n",
      "epoch 1738 iteration0, G Loss: 0.8988775014877319, D Loss: 1.0768135786056519, alpha: 0.011797499902563291\n",
      "epoch 1738 iteration100, G Loss: 1.0118951797485352, D Loss: 1.0590393543243408, alpha: 0.011797499902563291\n",
      "epoch 1739 iteration0, G Loss: 0.7071462869644165, D Loss: 1.1368293762207031, alpha: 0.01172775449769381\n",
      "epoch 1739 iteration100, G Loss: 1.1549513339996338, D Loss: 1.1612915992736816, alpha: 0.01172775449769381\n",
      "epoch 1740 iteration0, G Loss: 0.8986847996711731, D Loss: 1.2134182453155518, alpha: 0.011658416554833018\n",
      "epoch 1740 iteration100, G Loss: 1.2521342039108276, D Loss: 1.2412861585617065, alpha: 0.011658416554833018\n",
      "epoch 1741 iteration0, G Loss: 0.7486653327941895, D Loss: 1.3267271518707275, alpha: 0.01158948375088964\n",
      "epoch 1741 iteration100, G Loss: 1.4096704721450806, D Loss: 1.235424518585205, alpha: 0.01158948375088964\n",
      "epoch 1742 iteration0, G Loss: 0.8172071576118469, D Loss: 1.1163885593414307, alpha: 0.011520953775340015\n",
      "epoch 1742 iteration100, G Loss: 1.1541006565093994, D Loss: 1.1513960361480713, alpha: 0.011520953775340015\n",
      "epoch 1743 iteration0, G Loss: 0.9512283802032471, D Loss: 1.2480307817459106, alpha: 0.01145282433017003\n",
      "epoch 1743 iteration100, G Loss: 1.0371103286743164, D Loss: 1.1500147581100464, alpha: 0.01145282433017003\n",
      "epoch 1744 iteration0, G Loss: 0.8676679730415344, D Loss: 1.1747517585754395, alpha: 0.011385093129813062\n",
      "epoch 1744 iteration100, G Loss: 1.0290745496749878, D Loss: 1.1718337535858154, alpha: 0.011385093129813062\n",
      "epoch 1745 iteration0, G Loss: 1.0119878053665161, D Loss: 1.148787260055542, alpha: 0.011317757901092351\n",
      "epoch 1745 iteration100, G Loss: 0.8907137513160706, D Loss: 1.1288654804229736, alpha: 0.011317757901092351\n",
      "epoch 1746 iteration0, G Loss: 0.7670789957046509, D Loss: 1.1877338886260986, alpha: 0.011250816383160167\n",
      "epoch 1746 iteration100, G Loss: 0.8996756672859192, D Loss: 1.1061856746673584, alpha: 0.011250816383160167\n",
      "epoch 1747 iteration0, G Loss: 0.8900798559188843, D Loss: 1.151206612586975, alpha: 0.011184266327439296\n",
      "epoch 1747 iteration100, G Loss: 1.3585505485534668, D Loss: 1.0714809894561768, alpha: 0.011184266327439296\n",
      "epoch 1748 iteration0, G Loss: 0.9928943514823914, D Loss: 1.2252429723739624, alpha: 0.011118105497564423\n",
      "epoch 1748 iteration100, G Loss: 1.1956535577774048, D Loss: 1.296778678894043, alpha: 0.011118105497564423\n",
      "epoch 1749 iteration0, G Loss: 1.1180553436279297, D Loss: 1.1954604387283325, alpha: 0.011052331669322069\n",
      "epoch 1749 iteration100, G Loss: 1.1358237266540527, D Loss: 1.2638564109802246, alpha: 0.011052331669322069\n",
      "epoch 1750 iteration0, G Loss: 0.9115591049194336, D Loss: 1.1430716514587402, alpha: 0.010986942630593188\n",
      "epoch 1750 iteration100, G Loss: 0.9952548742294312, D Loss: 1.203363299369812, alpha: 0.010986942630593188\n",
      "Saving content.\n",
      "epoch 1751 iteration0, G Loss: 0.8269473910331726, D Loss: 1.1807303428649902, alpha: 0.010921936181294112\n",
      "epoch 1751 iteration100, G Loss: 1.3197580575942993, D Loss: 1.208190679550171, alpha: 0.010921936181294112\n",
      "epoch 1752 iteration0, G Loss: 1.03675377368927, D Loss: 1.3131842613220215, alpha: 0.010857310133318587\n",
      "epoch 1752 iteration100, G Loss: 1.053891897201538, D Loss: 1.0945589542388916, alpha: 0.010857310133318587\n",
      "epoch 1753 iteration0, G Loss: 0.9486774206161499, D Loss: 1.1187560558319092, alpha: 0.010793062310479495\n",
      "epoch 1753 iteration100, G Loss: 0.9726426005363464, D Loss: 1.2001079320907593, alpha: 0.010793062310479495\n",
      "epoch 1754 iteration0, G Loss: 1.1486090421676636, D Loss: 1.158551812171936, alpha: 0.010729190548450562\n",
      "epoch 1754 iteration100, G Loss: 0.9117701053619385, D Loss: 1.159071683883667, alpha: 0.010729190548450562\n",
      "epoch 1755 iteration0, G Loss: 0.9758798480033875, D Loss: 1.155399203300476, alpha: 0.010665692694710072\n",
      "epoch 1755 iteration100, G Loss: 0.9095483422279358, D Loss: 1.1385685205459595, alpha: 0.010665692694710072\n",
      "epoch 1756 iteration0, G Loss: 0.7900925278663635, D Loss: 1.1916385889053345, alpha: 0.0106025666084818\n",
      "epoch 1756 iteration100, G Loss: 0.9550116062164307, D Loss: 1.162682056427002, alpha: 0.0106025666084818\n",
      "epoch 1757 iteration0, G Loss: 0.8971377015113831, D Loss: 1.1323976516723633, alpha: 0.010539810160679175\n",
      "epoch 1757 iteration100, G Loss: 1.4589649438858032, D Loss: 1.0222004652023315, alpha: 0.010539810160679175\n",
      "epoch 1758 iteration0, G Loss: 0.8021293878555298, D Loss: 1.114012598991394, alpha: 0.010477421233847095\n",
      "epoch 1758 iteration100, G Loss: 1.0957586765289307, D Loss: 1.2292377948760986, alpha: 0.010477421233847095\n",
      "epoch 1759 iteration0, G Loss: 1.1144888401031494, D Loss: 1.0643467903137207, alpha: 0.01041539772210498\n",
      "epoch 1759 iteration100, G Loss: 1.0163058042526245, D Loss: 1.108886480331421, alpha: 0.01041539772210498\n",
      "epoch 1760 iteration0, G Loss: 0.9706462025642395, D Loss: 1.147562026977539, alpha: 0.0103537375310917\n",
      "epoch 1760 iteration100, G Loss: 1.2940397262573242, D Loss: 1.2228577136993408, alpha: 0.0103537375310917\n",
      "epoch 1761 iteration0, G Loss: 0.9860003590583801, D Loss: 1.2146143913269043, alpha: 0.01029243857790707\n",
      "epoch 1761 iteration100, G Loss: 1.463012456893921, D Loss: 1.199782371520996, alpha: 0.01029243857790707\n",
      "epoch 1762 iteration0, G Loss: 0.7310773730278015, D Loss: 1.077650547027588, alpha: 0.010231498791056559\n",
      "epoch 1762 iteration100, G Loss: 1.1986252069473267, D Loss: 1.1921383142471313, alpha: 0.010231498791056559\n",
      "epoch 1763 iteration0, G Loss: 0.7757501602172852, D Loss: 1.2041044235229492, alpha: 0.010170916110395445\n",
      "epoch 1763 iteration100, G Loss: 1.1159358024597168, D Loss: 1.2490644454956055, alpha: 0.010170916110395445\n",
      "epoch 1764 iteration0, G Loss: 1.0279983282089233, D Loss: 1.1125984191894531, alpha: 0.010110688487072417\n",
      "epoch 1764 iteration100, G Loss: 1.1727677583694458, D Loss: 1.2313103675842285, alpha: 0.010110688487072417\n",
      "epoch 1765 iteration0, G Loss: 0.9315150380134583, D Loss: 1.342057704925537, alpha: 0.01005081388347362\n",
      "epoch 1765 iteration100, G Loss: 1.0080199241638184, D Loss: 1.2876746654510498, alpha: 0.01005081388347362\n",
      "epoch 1766 iteration0, G Loss: 0.8877679109573364, D Loss: 1.0480811595916748, alpha: 0.009991290273168474\n",
      "epoch 1766 iteration100, G Loss: 0.9340664744377136, D Loss: 1.1067848205566406, alpha: 0.009991290273168474\n",
      "epoch 1767 iteration0, G Loss: 1.135736346244812, D Loss: 1.1227147579193115, alpha: 0.009932115640852612\n",
      "epoch 1767 iteration100, G Loss: 1.1568657159805298, D Loss: 1.1557725667953491, alpha: 0.009932115640852612\n",
      "epoch 1768 iteration0, G Loss: 0.7564578652381897, D Loss: 1.1077345609664917, alpha: 0.009873287982294032\n",
      "epoch 1768 iteration100, G Loss: 1.0227025747299194, D Loss: 1.1040431261062622, alpha: 0.009873287982294032\n",
      "epoch 1769 iteration0, G Loss: 1.172677993774414, D Loss: 1.1444370746612549, alpha: 0.009814805304277807\n",
      "epoch 1769 iteration100, G Loss: 0.9458763599395752, D Loss: 1.2193107604980469, alpha: 0.009814805304277807\n",
      "epoch 1770 iteration0, G Loss: 1.0199642181396484, D Loss: 1.0321016311645508, alpha: 0.009756665624551242\n",
      "epoch 1770 iteration100, G Loss: 1.271798849105835, D Loss: 1.1655522584915161, alpha: 0.009756665624551242\n",
      "epoch 1771 iteration0, G Loss: 0.9370961785316467, D Loss: 0.9398132562637329, alpha: 0.009698866971770248\n",
      "epoch 1771 iteration100, G Loss: 1.304322600364685, D Loss: 1.1971334218978882, alpha: 0.009698866971770248\n",
      "epoch 1772 iteration0, G Loss: 0.9277323484420776, D Loss: 1.2913551330566406, alpha: 0.009641407385442946\n",
      "epoch 1772 iteration100, G Loss: 1.1642251014709473, D Loss: 1.1985843181610107, alpha: 0.009641407385442946\n",
      "epoch 1773 iteration0, G Loss: 0.901721179485321, D Loss: 1.2334117889404297, alpha: 0.009584284915878705\n",
      "epoch 1773 iteration100, G Loss: 1.1683635711669922, D Loss: 1.2125924825668335, alpha: 0.009584284915878705\n",
      "epoch 1774 iteration0, G Loss: 0.8138247132301331, D Loss: 1.1073626279830933, alpha: 0.009527497624130965\n",
      "epoch 1774 iteration100, G Loss: 1.0463111400604248, D Loss: 1.290618896484375, alpha: 0.009527497624130965\n",
      "epoch 1775 iteration0, G Loss: 0.8992371559143066, D Loss: 1.1145230531692505, alpha: 0.00947104358194617\n",
      "epoch 1775 iteration100, G Loss: 1.245550274848938, D Loss: 1.0318455696105957, alpha: 0.00947104358194617\n",
      "epoch 1776 iteration0, G Loss: 0.8345381021499634, D Loss: 1.078649640083313, alpha: 0.009414920871708587\n",
      "epoch 1776 iteration100, G Loss: 1.172412633895874, D Loss: 1.233663558959961, alpha: 0.009414920871708587\n",
      "epoch 1777 iteration0, G Loss: 0.914542555809021, D Loss: 1.2110021114349365, alpha: 0.009359127586387905\n",
      "epoch 1777 iteration100, G Loss: 1.1763814687728882, D Loss: 1.2650361061096191, alpha: 0.009359127586387905\n",
      "epoch 1778 iteration0, G Loss: 0.868408739566803, D Loss: 1.080925464630127, alpha: 0.009303661829485943\n",
      "epoch 1778 iteration100, G Loss: 0.9046326279640198, D Loss: 1.1945178508758545, alpha: 0.009303661829485943\n",
      "epoch 1779 iteration0, G Loss: 0.7638033032417297, D Loss: 1.172574758529663, alpha: 0.009248521714983582\n",
      "epoch 1779 iteration100, G Loss: 1.0706337690353394, D Loss: 1.0901007652282715, alpha: 0.009248521714983582\n",
      "epoch 1780 iteration0, G Loss: 0.9589659571647644, D Loss: 1.172302007675171, alpha: 0.00919370536728803\n",
      "epoch 1780 iteration100, G Loss: 1.1525707244873047, D Loss: 1.1325926780700684, alpha: 0.00919370536728803\n",
      "epoch 1781 iteration0, G Loss: 0.8566951155662537, D Loss: 1.1980323791503906, alpha: 0.009139210921180863\n",
      "epoch 1781 iteration100, G Loss: 1.1562474966049194, D Loss: 1.2151198387145996, alpha: 0.009139210921180863\n",
      "epoch 1782 iteration0, G Loss: 0.7676198482513428, D Loss: 1.0963841676712036, alpha: 0.009085036521765177\n",
      "epoch 1782 iteration100, G Loss: 1.0357158184051514, D Loss: 1.1944962739944458, alpha: 0.009085036521765177\n",
      "epoch 1783 iteration0, G Loss: 0.7746018171310425, D Loss: 1.0812963247299194, alpha: 0.009031180324413524\n",
      "epoch 1783 iteration100, G Loss: 1.2213162183761597, D Loss: 1.166534423828125, alpha: 0.009031180324413524\n",
      "epoch 1784 iteration0, G Loss: 0.9369032382965088, D Loss: 1.235231637954712, alpha: 0.008977640494716721\n",
      "epoch 1784 iteration100, G Loss: 1.1589974164962769, D Loss: 1.2494916915893555, alpha: 0.008977640494716721\n",
      "epoch 1785 iteration0, G Loss: 0.9647175073623657, D Loss: 1.285189151763916, alpha: 0.008924415208431236\n",
      "epoch 1785 iteration100, G Loss: 0.9919609427452087, D Loss: 1.2454442977905273, alpha: 0.008924415208431236\n",
      "epoch 1786 iteration0, G Loss: 0.7032928466796875, D Loss: 1.0815751552581787, alpha: 0.008871502651428331\n",
      "epoch 1786 iteration100, G Loss: 0.963929295539856, D Loss: 1.1788817644119263, alpha: 0.008871502651428331\n",
      "epoch 1787 iteration0, G Loss: 0.7733587026596069, D Loss: 1.0303337574005127, alpha: 0.008818901019642666\n",
      "epoch 1787 iteration100, G Loss: 1.140088438987732, D Loss: 1.253225564956665, alpha: 0.008818901019642666\n",
      "epoch 1788 iteration0, G Loss: 0.817085862159729, D Loss: 1.1365957260131836, alpha: 0.008766608519021002\n",
      "epoch 1788 iteration100, G Loss: 1.6373615264892578, D Loss: 1.1577212810516357, alpha: 0.008766608519021002\n",
      "epoch 1789 iteration0, G Loss: 1.2301620244979858, D Loss: 1.2241584062576294, alpha: 0.008714623365471352\n",
      "epoch 1789 iteration100, G Loss: 1.0484521389007568, D Loss: 1.153914213180542, alpha: 0.008714623365471352\n",
      "epoch 1790 iteration0, G Loss: 0.8916583061218262, D Loss: 1.1803593635559082, alpha: 0.008662943784813137\n",
      "epoch 1790 iteration100, G Loss: 0.8637230396270752, D Loss: 1.1777710914611816, alpha: 0.008662943784813137\n",
      "epoch 1791 iteration0, G Loss: 0.7865311503410339, D Loss: 1.309122085571289, alpha: 0.008611568012725446\n",
      "epoch 1791 iteration100, G Loss: 1.6323188543319702, D Loss: 1.280116081237793, alpha: 0.008611568012725446\n",
      "epoch 1792 iteration0, G Loss: 1.0088937282562256, D Loss: 1.192014217376709, alpha: 0.008560494294697074\n",
      "epoch 1792 iteration100, G Loss: 0.9554399251937866, D Loss: 1.269336223602295, alpha: 0.008560494294697074\n",
      "epoch 1793 iteration0, G Loss: 0.9370340704917908, D Loss: 1.2252299785614014, alpha: 0.00850972088597779\n",
      "epoch 1793 iteration100, G Loss: 1.3935706615447998, D Loss: 1.1619179248809814, alpha: 0.00850972088597779\n",
      "epoch 1794 iteration0, G Loss: 0.9912385940551758, D Loss: 1.1868315935134888, alpha: 0.008459246051526592\n",
      "epoch 1794 iteration100, G Loss: 1.0156863927841187, D Loss: 1.1937187910079956, alpha: 0.008459246051526592\n",
      "epoch 1795 iteration0, G Loss: 0.8868192434310913, D Loss: 1.156581163406372, alpha: 0.008409068065963088\n",
      "epoch 1795 iteration100, G Loss: 1.3276586532592773, D Loss: 1.174654483795166, alpha: 0.008409068065963088\n",
      "epoch 1796 iteration0, G Loss: 0.9990953207015991, D Loss: 1.090401530265808, alpha: 0.00835918521351764\n",
      "epoch 1796 iteration100, G Loss: 1.033390998840332, D Loss: 1.2009375095367432, alpha: 0.00835918521351764\n",
      "epoch 1797 iteration0, G Loss: 0.7276305556297302, D Loss: 1.1552180051803589, alpha: 0.008309595787982627\n",
      "epoch 1797 iteration100, G Loss: 1.0129121541976929, D Loss: 1.2379356622695923, alpha: 0.008309595787982627\n",
      "epoch 1798 iteration0, G Loss: 0.7523596286773682, D Loss: 1.1877868175506592, alpha: 0.008260298092663154\n",
      "epoch 1798 iteration100, G Loss: 1.209307074546814, D Loss: 1.1603018045425415, alpha: 0.008260298092663154\n",
      "epoch 1799 iteration0, G Loss: 0.9137648940086365, D Loss: 1.2977063655853271, alpha: 0.008211290440327756\n",
      "epoch 1799 iteration100, G Loss: 1.0385299921035767, D Loss: 1.1733800172805786, alpha: 0.008211290440327756\n",
      "epoch 1800 iteration0, G Loss: 0.7820914387702942, D Loss: 1.1821906566619873, alpha: 0.008162571153159881\n",
      "epoch 1800 iteration100, G Loss: 1.0137999057769775, D Loss: 1.2573933601379395, alpha: 0.008162571153159881\n",
      "Saving content.\n",
      "epoch 1801 iteration0, G Loss: 0.9233015179634094, D Loss: 1.114471197128296, alpha: 0.00811413856271015\n",
      "epoch 1801 iteration100, G Loss: 1.1547778844833374, D Loss: 1.193213939666748, alpha: 0.00811413856271015\n",
      "epoch 1802 iteration0, G Loss: 0.7345678806304932, D Loss: 1.2283422946929932, alpha: 0.008065991009847284\n",
      "epoch 1802 iteration100, G Loss: 0.9963502287864685, D Loss: 1.2566773891448975, alpha: 0.008065991009847284\n",
      "epoch 1803 iteration0, G Loss: 0.9024643301963806, D Loss: 1.1417901515960693, alpha: 0.00801812684471015\n",
      "epoch 1803 iteration100, G Loss: 0.9545335173606873, D Loss: 1.2191083431243896, alpha: 0.00801812684471015\n",
      "epoch 1804 iteration0, G Loss: 0.7984862327575684, D Loss: 1.119866132736206, alpha: 0.007970544426660675\n",
      "epoch 1804 iteration100, G Loss: 1.276376724243164, D Loss: 1.1763529777526855, alpha: 0.007970544426660675\n",
      "epoch 1805 iteration0, G Loss: 0.8902120590209961, D Loss: 1.2309776544570923, alpha: 0.007923242124235008\n",
      "epoch 1805 iteration100, G Loss: 1.1636987924575806, D Loss: 1.1616814136505127, alpha: 0.007923242124235008\n",
      "epoch 1806 iteration0, G Loss: 0.801816463470459, D Loss: 1.2927824258804321, alpha: 0.007876218315096772\n",
      "epoch 1806 iteration100, G Loss: 1.259889006614685, D Loss: 1.1711256504058838, alpha: 0.007876218315096772\n",
      "epoch 1807 iteration0, G Loss: 1.068576455116272, D Loss: 1.120368480682373, alpha: 0.007829471385989772\n",
      "epoch 1807 iteration100, G Loss: 1.0078213214874268, D Loss: 1.1925759315490723, alpha: 0.007829471385989772\n",
      "epoch 1808 iteration0, G Loss: 0.7864060997962952, D Loss: 1.1354916095733643, alpha: 0.00778299973269081\n",
      "epoch 1808 iteration100, G Loss: 0.9987570643424988, D Loss: 1.265071153640747, alpha: 0.00778299973269081\n",
      "epoch 1809 iteration0, G Loss: 1.0059510469436646, D Loss: 1.129659652709961, alpha: 0.00773680175996283\n",
      "epoch 1809 iteration100, G Loss: 1.6385060548782349, D Loss: 1.1471807956695557, alpha: 0.00773680175996283\n",
      "epoch 1810 iteration0, G Loss: 0.8661144375801086, D Loss: 1.1603078842163086, alpha: 0.007690875881508297\n",
      "epoch 1810 iteration100, G Loss: 1.0330209732055664, D Loss: 1.16811203956604, alpha: 0.007690875881508297\n",
      "epoch 1811 iteration0, G Loss: 1.0471041202545166, D Loss: 1.1584234237670898, alpha: 0.007645220519922669\n",
      "epoch 1811 iteration100, G Loss: 1.188088059425354, D Loss: 1.155473232269287, alpha: 0.007645220519922669\n",
      "epoch 1812 iteration0, G Loss: 0.7470557689666748, D Loss: 1.2335455417633057, alpha: 0.007599834106647996\n",
      "epoch 1812 iteration100, G Loss: 0.9694985151290894, D Loss: 1.1008820533752441, alpha: 0.007599834106647996\n",
      "epoch 1813 iteration0, G Loss: 0.8528560996055603, D Loss: 1.12794828414917, alpha: 0.00755471508192751\n",
      "epoch 1813 iteration100, G Loss: 1.349850058555603, D Loss: 1.088744878768921, alpha: 0.00755471508192751\n",
      "epoch 1814 iteration0, G Loss: 0.9247243404388428, D Loss: 1.2316710948944092, alpha: 0.0075098618947582185\n",
      "epoch 1814 iteration100, G Loss: 1.0486621856689453, D Loss: 1.1128382682800293, alpha: 0.0075098618947582185\n",
      "epoch 1815 iteration0, G Loss: 0.7477225661277771, D Loss: 1.1918865442276, alpha: 0.0074652730028477166\n",
      "epoch 1815 iteration100, G Loss: 0.9896736741065979, D Loss: 1.158203363418579, alpha: 0.0074652730028477166\n",
      "epoch 1816 iteration0, G Loss: 0.8404631018638611, D Loss: 1.192831039428711, alpha: 0.007420946872565892\n",
      "epoch 1816 iteration100, G Loss: 0.9553385972976685, D Loss: 1.1143808364868164, alpha: 0.007420946872565892\n",
      "epoch 1817 iteration0, G Loss: 0.7344092130661011, D Loss: 1.0699974298477173, alpha: 0.007376881978901517\n",
      "epoch 1817 iteration100, G Loss: 1.6141775846481323, D Loss: 1.128427505493164, alpha: 0.007376881978901517\n",
      "epoch 1818 iteration0, G Loss: 0.978945255279541, D Loss: 1.1944010257720947, alpha: 0.007333076805416838\n",
      "epoch 1818 iteration100, G Loss: 1.2605324983596802, D Loss: 1.173175573348999, alpha: 0.007333076805416838\n",
      "epoch 1819 iteration0, G Loss: 0.8842573761940002, D Loss: 1.2078337669372559, alpha: 0.007289529844202169\n",
      "epoch 1819 iteration100, G Loss: 1.2584625482559204, D Loss: 1.242660641670227, alpha: 0.007289529844202169\n",
      "epoch 1820 iteration0, G Loss: 0.9674698114395142, D Loss: 1.1546204090118408, alpha: 0.007246239595831483\n",
      "epoch 1820 iteration100, G Loss: 1.2283644676208496, D Loss: 1.1211881637573242, alpha: 0.007246239595831483\n",
      "epoch 1821 iteration0, G Loss: 1.0019100904464722, D Loss: 1.1949087381362915, alpha: 0.007203204569317889\n",
      "epoch 1821 iteration100, G Loss: 1.1967864036560059, D Loss: 1.177334189414978, alpha: 0.007203204569317889\n",
      "epoch 1822 iteration0, G Loss: 0.8598703145980835, D Loss: 1.1496559381484985, alpha: 0.007160423282069783\n",
      "epoch 1822 iteration100, G Loss: 1.0458117723464966, D Loss: 1.2054674625396729, alpha: 0.007160423282069783\n",
      "epoch 1823 iteration0, G Loss: 1.0024378299713135, D Loss: 1.2880184650421143, alpha: 0.0071178942598456585\n",
      "epoch 1823 iteration100, G Loss: 1.4182499647140503, D Loss: 1.2017533779144287, alpha: 0.0071178942598456585\n",
      "epoch 1824 iteration0, G Loss: 1.0149598121643066, D Loss: 1.1648083925247192, alpha: 0.007075616036711363\n",
      "epoch 1824 iteration100, G Loss: 1.4988726377487183, D Loss: 1.2188977003097534, alpha: 0.007075616036711363\n",
      "epoch 1825 iteration0, G Loss: 0.87449711561203, D Loss: 1.102747917175293, alpha: 0.007033587154995136\n",
      "epoch 1825 iteration100, G Loss: 1.34456467628479, D Loss: 1.1143765449523926, alpha: 0.007033587154995136\n",
      "epoch 1826 iteration0, G Loss: 1.1103596687316895, D Loss: 1.0487072467803955, alpha: 0.00699180616524564\n",
      "epoch 1826 iteration100, G Loss: 1.6881152391433716, D Loss: 1.1151232719421387, alpha: 0.00699180616524564\n",
      "epoch 1827 iteration0, G Loss: 1.2765897512435913, D Loss: 1.04188072681427, alpha: 0.006950271626186888\n",
      "epoch 1827 iteration100, G Loss: 1.266911268234253, D Loss: 1.0059208869934082, alpha: 0.006950271626186888\n",
      "epoch 1828 iteration0, G Loss: 0.807851254940033, D Loss: 1.1480218172073364, alpha: 0.006908982104676498\n",
      "epoch 1828 iteration100, G Loss: 1.3618131875991821, D Loss: 1.1944860219955444, alpha: 0.006908982104676498\n",
      "epoch 1829 iteration0, G Loss: 0.7107365727424622, D Loss: 1.1928437948226929, alpha: 0.006867936175661837\n",
      "epoch 1829 iteration100, G Loss: 1.3783316612243652, D Loss: 1.1049158573150635, alpha: 0.006867936175661837\n",
      "epoch 1830 iteration0, G Loss: 0.8822278380393982, D Loss: 1.2055437564849854, alpha: 0.006827132422138282\n",
      "epoch 1830 iteration100, G Loss: 1.0884523391723633, D Loss: 1.1483889818191528, alpha: 0.006827132422138282\n",
      "epoch 1831 iteration0, G Loss: 0.9190332293510437, D Loss: 1.2166521549224854, alpha: 0.006786569435104695\n",
      "epoch 1831 iteration100, G Loss: 1.2324998378753662, D Loss: 1.1139419078826904, alpha: 0.006786569435104695\n",
      "epoch 1832 iteration0, G Loss: 0.7797777652740479, D Loss: 1.1258412599563599, alpha: 0.006746245813523566\n",
      "epoch 1832 iteration100, G Loss: 1.1950019598007202, D Loss: 1.1402373313903809, alpha: 0.006746245813523566\n",
      "epoch 1833 iteration0, G Loss: 0.8400751352310181, D Loss: 1.2438442707061768, alpha: 0.006706160164276609\n",
      "epoch 1833 iteration100, G Loss: 1.5406413078308105, D Loss: 1.1680463552474976, alpha: 0.006706160164276609\n",
      "epoch 1834 iteration0, G Loss: 0.8868648409843445, D Loss: 1.0658643245697021, alpha: 0.006666311102124123\n",
      "epoch 1834 iteration100, G Loss: 1.0976576805114746, D Loss: 1.098616361618042, alpha: 0.006666311102124123\n",
      "epoch 1835 iteration0, G Loss: 0.7273569703102112, D Loss: 1.1379672288894653, alpha: 0.006626697249663027\n",
      "epoch 1835 iteration100, G Loss: 1.1798515319824219, D Loss: 1.2386928796768188, alpha: 0.006626697249663027\n",
      "epoch 1836 iteration0, G Loss: 1.0297857522964478, D Loss: 1.099734902381897, alpha: 0.006587317237284118\n",
      "epoch 1836 iteration100, G Loss: 1.5832092761993408, D Loss: 1.1867636442184448, alpha: 0.006587317237284118\n",
      "epoch 1837 iteration0, G Loss: 1.0317672491073608, D Loss: 1.1177974939346313, alpha: 0.006548169703132545\n",
      "epoch 1837 iteration100, G Loss: 1.2836986780166626, D Loss: 1.3158308267593384, alpha: 0.006548169703132545\n",
      "epoch 1838 iteration0, G Loss: 0.8853726983070374, D Loss: 1.2316820621490479, alpha: 0.006509253293064288\n",
      "epoch 1838 iteration100, G Loss: 1.5096749067306519, D Loss: 1.1044094562530518, alpha: 0.006509253293064288\n",
      "epoch 1839 iteration0, G Loss: 0.7739972472190857, D Loss: 1.0849418640136719, alpha: 0.00647056666060708\n",
      "epoch 1839 iteration100, G Loss: 0.951614499092102, D Loss: 1.2501192092895508, alpha: 0.00647056666060708\n",
      "epoch 1840 iteration0, G Loss: 0.8447436094284058, D Loss: 1.1180851459503174, alpha: 0.006432108466918773\n",
      "epoch 1840 iteration100, G Loss: 1.0221002101898193, D Loss: 1.275853157043457, alpha: 0.006432108466918773\n",
      "epoch 1841 iteration0, G Loss: 0.8394843339920044, D Loss: 1.2201586961746216, alpha: 0.006393877380745927\n",
      "epoch 1841 iteration100, G Loss: 0.9696095585823059, D Loss: 1.096631646156311, alpha: 0.006393877380745927\n",
      "epoch 1842 iteration0, G Loss: 1.0900521278381348, D Loss: 1.1211034059524536, alpha: 0.006355872078384617\n",
      "epoch 1842 iteration100, G Loss: 1.5988171100616455, D Loss: 1.2041428089141846, alpha: 0.006355872078384617\n",
      "epoch 1843 iteration0, G Loss: 0.8986571431159973, D Loss: 1.203474521636963, alpha: 0.006318091243639246\n",
      "epoch 1843 iteration100, G Loss: 1.304675817489624, D Loss: 1.0773446559906006, alpha: 0.006318091243639246\n",
      "epoch 1844 iteration0, G Loss: 0.891808032989502, D Loss: 1.248549461364746, alpha: 0.006280533567782798\n",
      "epoch 1844 iteration100, G Loss: 1.277430534362793, D Loss: 1.218401312828064, alpha: 0.006280533567782798\n",
      "epoch 1845 iteration0, G Loss: 0.835008978843689, D Loss: 1.2166905403137207, alpha: 0.006243197749516538\n",
      "epoch 1845 iteration100, G Loss: 1.1687612533569336, D Loss: 1.164853811264038, alpha: 0.006243197749516538\n",
      "epoch 1846 iteration0, G Loss: 0.8206853866577148, D Loss: 1.187429666519165, alpha: 0.006206082494930487\n",
      "epoch 1846 iteration100, G Loss: 1.4506847858428955, D Loss: 1.2026758193969727, alpha: 0.006206082494930487\n",
      "epoch 1847 iteration0, G Loss: 0.822575569152832, D Loss: 1.1663565635681152, alpha: 0.006169186517464009\n",
      "epoch 1847 iteration100, G Loss: 1.1650397777557373, D Loss: 1.1220390796661377, alpha: 0.006169186517464009\n",
      "epoch 1848 iteration0, G Loss: 0.9206174612045288, D Loss: 1.2114101648330688, alpha: 0.006132508537865844\n",
      "epoch 1848 iteration100, G Loss: 1.0641814470291138, D Loss: 1.0981597900390625, alpha: 0.006132508537865844\n",
      "epoch 1849 iteration0, G Loss: 1.0012474060058594, D Loss: 1.244891881942749, alpha: 0.00609604728415547\n",
      "epoch 1849 iteration100, G Loss: 1.3095096349716187, D Loss: 1.2585811614990234, alpha: 0.00609604728415547\n",
      "epoch 1850 iteration0, G Loss: 0.8507065773010254, D Loss: 1.1206135749816895, alpha: 0.006059801491584249\n",
      "epoch 1850 iteration100, G Loss: 0.9500076770782471, D Loss: 1.2050774097442627, alpha: 0.006059801491584249\n",
      "Saving content.\n",
      "epoch 1851 iteration0, G Loss: 1.0985110998153687, D Loss: 1.1193082332611084, alpha: 0.006023769902595344\n",
      "epoch 1851 iteration100, G Loss: 1.0558350086212158, D Loss: 1.0939527750015259, alpha: 0.006023769902595344\n",
      "epoch 1852 iteration0, G Loss: 0.8528701066970825, D Loss: 1.100684404373169, alpha: 0.005987951266786751\n",
      "epoch 1852 iteration100, G Loss: 1.0871106386184692, D Loss: 1.224602222442627, alpha: 0.005987951266786751\n",
      "epoch 1853 iteration0, G Loss: 0.7395075559616089, D Loss: 1.0455796718597412, alpha: 0.0059523443408714405\n",
      "epoch 1853 iteration100, G Loss: 1.2538117170333862, D Loss: 1.0995404720306396, alpha: 0.0059523443408714405\n",
      "epoch 1854 iteration0, G Loss: 0.8962399363517761, D Loss: 1.1206610202789307, alpha: 0.005916947888639945\n",
      "epoch 1854 iteration100, G Loss: 1.23732590675354, D Loss: 1.1015996932983398, alpha: 0.005916947888639945\n",
      "epoch 1855 iteration0, G Loss: 0.701600968837738, D Loss: 1.210286021232605, alpha: 0.0058817606809214995\n",
      "epoch 1855 iteration100, G Loss: 1.4641914367675781, D Loss: 1.2077689170837402, alpha: 0.0058817606809214995\n",
      "epoch 1856 iteration0, G Loss: 0.8880914449691772, D Loss: 1.2006443738937378, alpha: 0.005846781495546738\n",
      "epoch 1856 iteration100, G Loss: 1.1132395267486572, D Loss: 1.1479098796844482, alpha: 0.005846781495546738\n",
      "epoch 1857 iteration0, G Loss: 0.7701518535614014, D Loss: 1.2287688255310059, alpha: 0.005812009117309391\n",
      "epoch 1857 iteration100, G Loss: 1.340075969696045, D Loss: 1.1768651008605957, alpha: 0.005812009117309391\n",
      "epoch 1858 iteration0, G Loss: 1.0311790704727173, D Loss: 1.0925745964050293, alpha: 0.005777442337929095\n",
      "epoch 1858 iteration100, G Loss: 0.9628480076789856, D Loss: 1.2980682849884033, alpha: 0.005777442337929095\n",
      "epoch 1859 iteration0, G Loss: 0.8577632904052734, D Loss: 1.1693120002746582, alpha: 0.0057430799560140855\n",
      "epoch 1859 iteration100, G Loss: 1.0915939807891846, D Loss: 1.127746820449829, alpha: 0.0057430799560140855\n",
      "epoch 1860 iteration0, G Loss: 0.828235387802124, D Loss: 1.1626842021942139, alpha: 0.005708920777023452\n",
      "epoch 1860 iteration100, G Loss: 1.1177676916122437, D Loss: 1.0933929681777954, alpha: 0.005708920777023452\n",
      "epoch 1861 iteration0, G Loss: 0.9409124851226807, D Loss: 1.105396032333374, alpha: 0.005674963613230055\n",
      "epoch 1861 iteration100, G Loss: 1.1299796104431152, D Loss: 1.2812767028808594, alpha: 0.005674963613230055\n",
      "epoch 1862 iteration0, G Loss: 1.0236611366271973, D Loss: 1.1738321781158447, alpha: 0.005641207283684779\n",
      "epoch 1862 iteration100, G Loss: 0.9366458654403687, D Loss: 1.1821064949035645, alpha: 0.005641207283684779\n",
      "epoch 1863 iteration0, G Loss: 0.9178737998008728, D Loss: 1.0531401634216309, alpha: 0.005607650614178117\n",
      "epoch 1863 iteration100, G Loss: 1.1644506454467773, D Loss: 1.1264019012451172, alpha: 0.005607650614178117\n",
      "epoch 1864 iteration0, G Loss: 0.7594398260116577, D Loss: 1.0857130289077759, alpha: 0.005574292437204642\n",
      "epoch 1864 iteration100, G Loss: 1.1317639350891113, D Loss: 1.2645047903060913, alpha: 0.005574292437204642\n",
      "epoch 1865 iteration0, G Loss: 0.7402145862579346, D Loss: 1.1103111505508423, alpha: 0.005541131591927484\n",
      "epoch 1865 iteration100, G Loss: 1.4785922765731812, D Loss: 1.1363940238952637, alpha: 0.005541131591927484\n",
      "epoch 1866 iteration0, G Loss: 0.9350023865699768, D Loss: 1.1464073657989502, alpha: 0.00550816692413969\n",
      "epoch 1866 iteration100, G Loss: 1.458141565322876, D Loss: 1.0747926235198975, alpha: 0.00550816692413969\n",
      "epoch 1867 iteration0, G Loss: 1.0032100677490234, D Loss: 1.0755062103271484, alpha: 0.00547539728623081\n",
      "epoch 1867 iteration100, G Loss: 1.0811278820037842, D Loss: 1.1544580459594727, alpha: 0.00547539728623081\n",
      "epoch 1868 iteration0, G Loss: 1.1591627597808838, D Loss: 1.1444885730743408, alpha: 0.005442821537149478\n",
      "epoch 1868 iteration100, G Loss: 1.4912443161010742, D Loss: 1.1449532508850098, alpha: 0.005442821537149478\n",
      "epoch 1869 iteration0, G Loss: 0.9642528891563416, D Loss: 1.0921597480773926, alpha: 0.005410438542368334\n",
      "epoch 1869 iteration100, G Loss: 1.3708828687667847, D Loss: 1.1936511993408203, alpha: 0.005410438542368334\n",
      "epoch 1870 iteration0, G Loss: 0.8788162469863892, D Loss: 1.231482982635498, alpha: 0.005378247173848605\n",
      "epoch 1870 iteration100, G Loss: 1.3050109148025513, D Loss: 1.0958043336868286, alpha: 0.005378247173848605\n",
      "epoch 1871 iteration0, G Loss: 0.9382891058921814, D Loss: 1.1158818006515503, alpha: 0.0053462463100042434\n",
      "epoch 1871 iteration100, G Loss: 1.2565139532089233, D Loss: 1.1686607599258423, alpha: 0.0053462463100042434\n",
      "epoch 1872 iteration0, G Loss: 0.8851567506790161, D Loss: 1.2306220531463623, alpha: 0.005314434835667403\n",
      "epoch 1872 iteration100, G Loss: 0.9096134305000305, D Loss: 1.280996322631836, alpha: 0.005314434835667403\n",
      "epoch 1873 iteration0, G Loss: 0.840765655040741, D Loss: 1.1928468942642212, alpha: 0.00528281164205302\n",
      "epoch 1873 iteration100, G Loss: 1.3146910667419434, D Loss: 1.1760337352752686, alpha: 0.00528281164205302\n",
      "epoch 1874 iteration0, G Loss: 0.8066733479499817, D Loss: 1.1642465591430664, alpha: 0.005251375626724508\n",
      "epoch 1874 iteration100, G Loss: 0.9945293068885803, D Loss: 1.1848427057266235, alpha: 0.005251375626724508\n",
      "epoch 1875 iteration0, G Loss: 0.7368358373641968, D Loss: 1.174450159072876, alpha: 0.005220125693558342\n",
      "epoch 1875 iteration100, G Loss: 1.2736188173294067, D Loss: 1.1716246604919434, alpha: 0.005220125693558342\n",
      "epoch 1876 iteration0, G Loss: 0.8861110210418701, D Loss: 1.2466974258422852, alpha: 0.005189060752710528\n",
      "epoch 1876 iteration100, G Loss: 1.1970032453536987, D Loss: 1.2027872800827026, alpha: 0.005189060752710528\n",
      "epoch 1877 iteration0, G Loss: 0.9675617814064026, D Loss: 1.2210514545440674, alpha: 0.005158179720581302\n",
      "epoch 1877 iteration100, G Loss: 1.3284080028533936, D Loss: 1.1723222732543945, alpha: 0.005158179720581302\n",
      "epoch 1878 iteration0, G Loss: 0.9831070303916931, D Loss: 1.198713779449463, alpha: 0.00512748151978204\n",
      "epoch 1878 iteration100, G Loss: 1.1062673330307007, D Loss: 1.1696734428405762, alpha: 0.00512748151978204\n",
      "epoch 1879 iteration0, G Loss: 1.0019333362579346, D Loss: 1.2745534181594849, alpha: 0.00509696507910018\n",
      "epoch 1879 iteration100, G Loss: 1.0621452331542969, D Loss: 1.1349350214004517, alpha: 0.00509696507910018\n",
      "epoch 1880 iteration0, G Loss: 0.8813748955726624, D Loss: 1.1549315452575684, alpha: 0.005066629333466244\n",
      "epoch 1880 iteration100, G Loss: 1.04461669921875, D Loss: 1.213402271270752, alpha: 0.005066629333466244\n",
      "epoch 1881 iteration0, G Loss: 0.7530698180198669, D Loss: 1.1505405902862549, alpha: 0.0050364732239203125\n",
      "epoch 1881 iteration100, G Loss: 1.1198680400848389, D Loss: 1.1613194942474365, alpha: 0.0050364732239203125\n",
      "epoch 1882 iteration0, G Loss: 0.8425169587135315, D Loss: 1.2314677238464355, alpha: 0.0050064956975774955\n",
      "epoch 1882 iteration100, G Loss: 1.5887433290481567, D Loss: 1.2458323240280151, alpha: 0.0050064956975774955\n",
      "epoch 1883 iteration0, G Loss: 0.8449811339378357, D Loss: 1.2157955169677734, alpha: 0.004976695707595624\n",
      "epoch 1883 iteration100, G Loss: 1.0076342821121216, D Loss: 1.111806869506836, alpha: 0.004976695707595624\n",
      "epoch 1884 iteration0, G Loss: 1.162996768951416, D Loss: 1.177505373954773, alpha: 0.004947072213142167\n",
      "epoch 1884 iteration100, G Loss: 1.3306719064712524, D Loss: 1.2298414707183838, alpha: 0.004947072213142167\n",
      "epoch 1885 iteration0, G Loss: 1.2170675992965698, D Loss: 1.1510469913482666, alpha: 0.004917624179360258\n",
      "epoch 1885 iteration100, G Loss: 1.0949103832244873, D Loss: 1.1584582328796387, alpha: 0.004917624179360258\n",
      "epoch 1886 iteration0, G Loss: 0.7596719264984131, D Loss: 1.1545424461364746, alpha: 0.004888350577336831\n",
      "epoch 1886 iteration100, G Loss: 1.1897578239440918, D Loss: 1.1652308702468872, alpha: 0.004888350577336831\n",
      "epoch 1887 iteration0, G Loss: 0.9777990579605103, D Loss: 1.232170820236206, alpha: 0.004859250384069869\n",
      "epoch 1887 iteration100, G Loss: 0.8342466354370117, D Loss: 1.1881223917007446, alpha: 0.004859250384069869\n",
      "epoch 1888 iteration0, G Loss: 1.0672441720962524, D Loss: 1.208268404006958, alpha: 0.004830322582434765\n",
      "epoch 1888 iteration100, G Loss: 1.2746437788009644, D Loss: 1.124707818031311, alpha: 0.004830322582434765\n",
      "epoch 1889 iteration0, G Loss: 0.9096352458000183, D Loss: 1.182969093322754, alpha: 0.004801566161154014\n",
      "epoch 1889 iteration100, G Loss: 0.8552544116973877, D Loss: 1.171588659286499, alpha: 0.004801566161154014\n",
      "epoch 1890 iteration0, G Loss: 0.8843689560890198, D Loss: 1.2366526126861572, alpha: 0.004772980114763237\n",
      "epoch 1890 iteration100, G Loss: 1.3395429849624634, D Loss: 1.2134149074554443, alpha: 0.004772980114763237\n",
      "epoch 1891 iteration0, G Loss: 0.983451247215271, D Loss: 1.1883306503295898, alpha: 0.0047445634435798745\n",
      "epoch 1891 iteration100, G Loss: 1.2608222961425781, D Loss: 1.0899221897125244, alpha: 0.0047445634435798745\n",
      "epoch 1892 iteration0, G Loss: 1.065406084060669, D Loss: 1.202789306640625, alpha: 0.0047163151536718795\n",
      "epoch 1892 iteration100, G Loss: 1.289604663848877, D Loss: 1.1190249919891357, alpha: 0.0047163151536718795\n",
      "epoch 1893 iteration0, G Loss: 0.9712811708450317, D Loss: 1.1299675703048706, alpha: 0.0046882342568246305\n",
      "epoch 1893 iteration100, G Loss: 1.1450523138046265, D Loss: 1.157585859298706, alpha: 0.0046882342568246305\n",
      "epoch 1894 iteration0, G Loss: 0.9439687728881836, D Loss: 1.289245843887329, alpha: 0.004660319770510846\n",
      "epoch 1894 iteration100, G Loss: 0.9669229388237, D Loss: 1.0682518482208252, alpha: 0.004660319770510846\n",
      "epoch 1895 iteration0, G Loss: 0.7969403862953186, D Loss: 1.209596872329712, alpha: 0.004632570717858164\n",
      "epoch 1895 iteration100, G Loss: 1.3253090381622314, D Loss: 1.2113916873931885, alpha: 0.004632570717858164\n",
      "epoch 1896 iteration0, G Loss: 1.1023095846176147, D Loss: 1.2872884273529053, alpha: 0.0046049861276189485\n",
      "epoch 1896 iteration100, G Loss: 1.212700605392456, D Loss: 1.206953763961792, alpha: 0.0046049861276189485\n",
      "epoch 1897 iteration0, G Loss: 0.8711866140365601, D Loss: 1.0967063903808594, alpha: 0.004577565034137643\n",
      "epoch 1897 iteration100, G Loss: 1.1327548027038574, D Loss: 1.2062381505966187, alpha: 0.004577565034137643\n",
      "epoch 1898 iteration0, G Loss: 1.0063673257827759, D Loss: 1.2563921213150024, alpha: 0.004550306477321908\n",
      "epoch 1898 iteration100, G Loss: 1.073230266571045, D Loss: 1.161012887954712, alpha: 0.004550306477321908\n",
      "epoch 1899 iteration0, G Loss: 0.7161950469017029, D Loss: 1.2343463897705078, alpha: 0.004523209502609982\n",
      "epoch 1899 iteration100, G Loss: 1.602766513824463, D Loss: 1.1505451202392578, alpha: 0.004523209502609982\n",
      "epoch 1900 iteration0, G Loss: 0.8635090589523315, D Loss: 1.187308669090271, alpha: 0.004496273160941144\n",
      "epoch 1900 iteration100, G Loss: 1.181894063949585, D Loss: 1.1402068138122559, alpha: 0.004496273160941144\n",
      "Saving content.\n",
      "epoch 1901 iteration0, G Loss: 0.7526742219924927, D Loss: 1.1839470863342285, alpha: 0.00446949650872519\n",
      "epoch 1901 iteration100, G Loss: 1.1426507234573364, D Loss: 1.0767767429351807, alpha: 0.00446949650872519\n",
      "epoch 1902 iteration0, G Loss: 0.932911217212677, D Loss: 1.057490348815918, alpha: 0.004442878607811895\n",
      "epoch 1902 iteration100, G Loss: 1.2110316753387451, D Loss: 1.2818100452423096, alpha: 0.004442878607811895\n",
      "epoch 1903 iteration0, G Loss: 0.8219460844993591, D Loss: 1.2735917568206787, alpha: 0.004416418525460597\n",
      "epoch 1903 iteration100, G Loss: 0.9415770173072815, D Loss: 1.2538402080535889, alpha: 0.004416418525460597\n",
      "epoch 1904 iteration0, G Loss: 1.0127900838851929, D Loss: 1.1939893960952759, alpha: 0.0043901153343109955\n",
      "epoch 1904 iteration100, G Loss: 1.1507269144058228, D Loss: 1.0681564807891846, alpha: 0.0043901153343109955\n",
      "epoch 1905 iteration0, G Loss: 0.8943633437156677, D Loss: 1.1978120803833008, alpha: 0.004363968112352512\n",
      "epoch 1905 iteration100, G Loss: 0.8601572513580322, D Loss: 1.1216514110565186, alpha: 0.004363968112352512\n",
      "epoch 1906 iteration0, G Loss: 0.8557953834533691, D Loss: 1.2262194156646729, alpha: 0.004337975942895422\n",
      "epoch 1906 iteration100, G Loss: 1.167572021484375, D Loss: 1.1562081575393677, alpha: 0.004337975942895422\n",
      "epoch 1907 iteration0, G Loss: 0.7272248268127441, D Loss: 1.2456390857696533, alpha: 0.004312137914540326\n",
      "epoch 1907 iteration100, G Loss: 0.9331039786338806, D Loss: 1.0988351106643677, alpha: 0.004312137914540326\n",
      "epoch 1908 iteration0, G Loss: 0.9380583167076111, D Loss: 1.0989923477172852, alpha: 0.004286453121149725\n",
      "epoch 1908 iteration100, G Loss: 1.1294082403182983, D Loss: 1.1257143020629883, alpha: 0.004286453121149725\n",
      "epoch 1909 iteration0, G Loss: 0.7523879408836365, D Loss: 1.1267831325531006, alpha: 0.004260920661818157\n",
      "epoch 1909 iteration100, G Loss: 1.3522979021072388, D Loss: 1.2013046741485596, alpha: 0.004260920661818157\n",
      "epoch 1910 iteration0, G Loss: 1.0008455514907837, D Loss: 1.214735507965088, alpha: 0.004235539640843444\n",
      "epoch 1910 iteration100, G Loss: 1.0313347578048706, D Loss: 1.1978940963745117, alpha: 0.004235539640843444\n",
      "epoch 1911 iteration0, G Loss: 0.9323843717575073, D Loss: 1.1569926738739014, alpha: 0.004210309167697379\n",
      "epoch 1911 iteration100, G Loss: 1.3244487047195435, D Loss: 1.1214821338653564, alpha: 0.004210309167697379\n",
      "epoch 1912 iteration0, G Loss: 0.8234424591064453, D Loss: 1.1654495000839233, alpha: 0.004185228356997639\n",
      "epoch 1912 iteration100, G Loss: 1.1713693141937256, D Loss: 1.2270243167877197, alpha: 0.004185228356997639\n",
      "epoch 1913 iteration0, G Loss: 0.9174622297286987, D Loss: 1.165806770324707, alpha: 0.004160296328478252\n",
      "epoch 1913 iteration100, G Loss: 1.0610488653182983, D Loss: 1.2873525619506836, alpha: 0.004160296328478252\n",
      "epoch 1914 iteration0, G Loss: 0.8398342728614807, D Loss: 1.1498562097549438, alpha: 0.004135512206961844\n",
      "epoch 1914 iteration100, G Loss: 0.9278969764709473, D Loss: 1.1780873537063599, alpha: 0.004135512206961844\n",
      "epoch 1915 iteration0, G Loss: 0.9378114938735962, D Loss: 1.1832339763641357, alpha: 0.004110875122330548\n",
      "epoch 1915 iteration100, G Loss: 1.0397900342941284, D Loss: 1.1775106191635132, alpha: 0.004110875122330548\n",
      "epoch 1916 iteration0, G Loss: 1.016438364982605, D Loss: 1.1669694185256958, alpha: 0.004086384209499028\n",
      "epoch 1916 iteration100, G Loss: 0.9255103468894958, D Loss: 1.239668369293213, alpha: 0.004086384209499028\n",
      "epoch 1917 iteration0, G Loss: 0.8355961441993713, D Loss: 1.1375463008880615, alpha: 0.0040620386083846105\n",
      "epoch 1917 iteration100, G Loss: 1.3209202289581299, D Loss: 1.1242748498916626, alpha: 0.0040620386083846105\n",
      "epoch 1918 iteration0, G Loss: 0.8509177565574646, D Loss: 1.174461841583252, alpha: 0.004037837463881311\n",
      "epoch 1918 iteration100, G Loss: 1.1340593099594116, D Loss: 1.1726577281951904, alpha: 0.004037837463881311\n",
      "epoch 1919 iteration0, G Loss: 1.0969529151916504, D Loss: 1.2026212215423584, alpha: 0.0040137799258304074\n",
      "epoch 1919 iteration100, G Loss: 1.4403126239776611, D Loss: 1.2143582105636597, alpha: 0.0040137799258304074\n",
      "epoch 1920 iteration0, G Loss: 0.6842535734176636, D Loss: 1.2134653329849243, alpha: 0.003989865148994021\n",
      "epoch 1920 iteration100, G Loss: 1.45607328414917, D Loss: 1.208738923072815, alpha: 0.003989865148994021\n",
      "epoch 1921 iteration0, G Loss: 0.8873479962348938, D Loss: 1.0822558403015137, alpha: 0.003966092293027024\n",
      "epoch 1921 iteration100, G Loss: 1.1696507930755615, D Loss: 1.1438237428665161, alpha: 0.003966092293027024\n",
      "epoch 1922 iteration0, G Loss: 0.7754522562026978, D Loss: 1.1563961505889893, alpha: 0.00394246052244962\n",
      "epoch 1922 iteration100, G Loss: 1.0364667177200317, D Loss: 1.2359423637390137, alpha: 0.00394246052244962\n",
      "epoch 1923 iteration0, G Loss: 0.801102876663208, D Loss: 1.2496377229690552, alpha: 0.003918969006620587\n",
      "epoch 1923 iteration100, G Loss: 1.1276525259017944, D Loss: 1.1095231771469116, alpha: 0.003918969006620587\n",
      "epoch 1924 iteration0, G Loss: 0.7694211006164551, D Loss: 1.211754560470581, alpha: 0.0038956169197096324\n",
      "epoch 1924 iteration100, G Loss: 0.8719874620437622, D Loss: 1.222224235534668, alpha: 0.0038956169197096324\n",
      "epoch 1925 iteration0, G Loss: 0.8136622905731201, D Loss: 1.2667078971862793, alpha: 0.0038724034406710794\n",
      "epoch 1925 iteration100, G Loss: 1.1530909538269043, D Loss: 1.0994071960449219, alpha: 0.0038724034406710794\n",
      "epoch 1926 iteration0, G Loss: 0.7972531318664551, D Loss: 1.1744189262390137, alpha: 0.003849327753216558\n",
      "epoch 1926 iteration100, G Loss: 1.0033875703811646, D Loss: 1.1757256984710693, alpha: 0.003849327753216558\n",
      "epoch 1927 iteration0, G Loss: 0.7474494576454163, D Loss: 1.2551647424697876, alpha: 0.003826389045788914\n",
      "epoch 1927 iteration100, G Loss: 1.0656638145446777, D Loss: 1.2134549617767334, alpha: 0.003826389045788914\n",
      "epoch 1928 iteration0, G Loss: 0.9243959188461304, D Loss: 1.1278059482574463, alpha: 0.0038035865115351175\n",
      "epoch 1928 iteration100, G Loss: 0.9746473431587219, D Loss: 1.1467725038528442, alpha: 0.0038035865115351175\n",
      "epoch 1929 iteration0, G Loss: 0.8503587245941162, D Loss: 1.1447504758834839, alpha: 0.003780919348280065\n",
      "epoch 1929 iteration100, G Loss: 0.9462527632713318, D Loss: 1.1483670473098755, alpha: 0.003780919348280065\n",
      "epoch 1930 iteration0, G Loss: 0.6669225096702576, D Loss: 1.1214648485183716, alpha: 0.003758386758500709\n",
      "epoch 1930 iteration100, G Loss: 0.9879251718521118, D Loss: 1.1682765483856201, alpha: 0.003758386758500709\n",
      "epoch 1931 iteration0, G Loss: 0.9633392691612244, D Loss: 1.1684010028839111, alpha: 0.003735987949299524\n",
      "epoch 1931 iteration100, G Loss: 1.294278860092163, D Loss: 1.0301446914672852, alpha: 0.003735987949299524\n",
      "epoch 1932 iteration0, G Loss: 0.8106152415275574, D Loss: 1.1022264957427979, alpha: 0.0037137221323788605\n",
      "epoch 1932 iteration100, G Loss: 1.132680058479309, D Loss: 1.185713768005371, alpha: 0.0037137221323788605\n",
      "epoch 1933 iteration0, G Loss: 0.77073734998703, D Loss: 1.1378591060638428, alpha: 0.003691588524014411\n",
      "epoch 1933 iteration100, G Loss: 1.10209321975708, D Loss: 1.1670401096343994, alpha: 0.003691588524014411\n",
      "epoch 1934 iteration0, G Loss: 0.7939192652702332, D Loss: 1.1656363010406494, alpha: 0.003669586345030784\n",
      "epoch 1934 iteration100, G Loss: 1.3574094772338867, D Loss: 1.1374129056930542, alpha: 0.003669586345030784\n",
      "epoch 1935 iteration0, G Loss: 0.8174338340759277, D Loss: 1.203674554824829, alpha: 0.003647714820774972\n",
      "epoch 1935 iteration100, G Loss: 1.6391364336013794, D Loss: 1.0379927158355713, alpha: 0.003647714820774972\n",
      "epoch 1936 iteration0, G Loss: 0.9009193181991577, D Loss: 1.1525784730911255, alpha: 0.0036259731810909246\n",
      "epoch 1936 iteration100, G Loss: 1.1070669889450073, D Loss: 1.1829956769943237, alpha: 0.0036259731810909246\n",
      "epoch 1937 iteration0, G Loss: 0.9463323950767517, D Loss: 1.1864368915557861, alpha: 0.003604360660294792\n",
      "epoch 1937 iteration100, G Loss: 1.0359094142913818, D Loss: 1.1720881462097168, alpha: 0.003604360660294792\n",
      "epoch 1938 iteration0, G Loss: 0.8163929581642151, D Loss: 1.154882550239563, alpha: 0.003582876497149612\n",
      "epoch 1938 iteration100, G Loss: 1.0329939126968384, D Loss: 1.298683524131775, alpha: 0.003582876497149612\n",
      "epoch 1939 iteration0, G Loss: 0.8539665937423706, D Loss: 1.1709675788879395, alpha: 0.003561519934839552\n",
      "epoch 1939 iteration100, G Loss: 1.1864880323410034, D Loss: 1.16615891456604, alpha: 0.003561519934839552\n",
      "epoch 1940 iteration0, G Loss: 0.9441578388214111, D Loss: 1.2019363641738892, alpha: 0.003540290220946485\n",
      "epoch 1940 iteration100, G Loss: 0.9615582227706909, D Loss: 1.2590365409851074, alpha: 0.003540290220946485\n",
      "epoch 1941 iteration0, G Loss: 0.8709055185317993, D Loss: 1.1356436014175415, alpha: 0.0035191866074238964\n",
      "epoch 1941 iteration100, G Loss: 1.2875744104385376, D Loss: 1.2360279560089111, alpha: 0.0035191866074238964\n",
      "epoch 1942 iteration0, G Loss: 0.9120361804962158, D Loss: 1.1159738302230835, alpha: 0.0034982083505723516\n",
      "epoch 1942 iteration100, G Loss: 1.1901113986968994, D Loss: 1.2580676078796387, alpha: 0.0034982083505723516\n",
      "epoch 1943 iteration0, G Loss: 0.8547956943511963, D Loss: 1.1652638912200928, alpha: 0.0034773547110162895\n",
      "epoch 1943 iteration100, G Loss: 0.8501992225646973, D Loss: 1.1737806797027588, alpha: 0.0034773547110162895\n",
      "epoch 1944 iteration0, G Loss: 0.9402342438697815, D Loss: 1.22261643409729, alpha: 0.0034566249536777116\n",
      "epoch 1944 iteration100, G Loss: 1.0868393182754517, D Loss: 1.1521577835083008, alpha: 0.0034566249536777116\n",
      "epoch 1945 iteration0, G Loss: 1.007920265197754, D Loss: 1.1337037086486816, alpha: 0.0034360183477538664\n",
      "epoch 1945 iteration100, G Loss: 0.9414140582084656, D Loss: 1.244251012802124, alpha: 0.0034360183477538664\n",
      "epoch 1946 iteration0, G Loss: 0.8647916316986084, D Loss: 1.1194764375686646, alpha: 0.0034155341666913808\n",
      "epoch 1946 iteration100, G Loss: 1.0961482524871826, D Loss: 1.115307331085205, alpha: 0.0034155341666913808\n",
      "epoch 1947 iteration0, G Loss: 0.8585278987884521, D Loss: 1.211092233657837, alpha: 0.003395171688163612\n",
      "epoch 1947 iteration100, G Loss: 0.99113529920578, D Loss: 1.1450488567352295, alpha: 0.003395171688163612\n",
      "epoch 1948 iteration0, G Loss: 1.0812398195266724, D Loss: 1.1254281997680664, alpha: 0.0033749301940461107\n",
      "epoch 1948 iteration100, G Loss: 1.1074013710021973, D Loss: 1.2032338380813599, alpha: 0.0033749301940461107\n",
      "epoch 1949 iteration0, G Loss: 0.9382652044296265, D Loss: 1.1569970846176147, alpha: 0.003354808970393086\n",
      "epoch 1949 iteration100, G Loss: 1.2224518060684204, D Loss: 1.1799038648605347, alpha: 0.003354808970393086\n",
      "epoch 1950 iteration0, G Loss: 1.0447521209716797, D Loss: 1.2478327751159668, alpha: 0.003334807307413312\n",
      "epoch 1950 iteration100, G Loss: 1.1120433807373047, D Loss: 1.1049513816833496, alpha: 0.003334807307413312\n",
      "Saving content.\n",
      "epoch 1951 iteration0, G Loss: 0.9982718825340271, D Loss: 1.0651851892471313, alpha: 0.0033149244994477023\n",
      "epoch 1951 iteration100, G Loss: 1.5695600509643555, D Loss: 1.284410834312439, alpha: 0.0033149244994477023\n",
      "epoch 1952 iteration0, G Loss: 0.9577082991600037, D Loss: 1.215260624885559, alpha: 0.003295159844945217\n",
      "epoch 1952 iteration100, G Loss: 1.3415889739990234, D Loss: 1.190476894378662, alpha: 0.003295159844945217\n",
      "epoch 1953 iteration0, G Loss: 0.949053168296814, D Loss: 1.1304324865341187, alpha: 0.003275512646438994\n",
      "epoch 1953 iteration100, G Loss: 1.3887341022491455, D Loss: 1.217550277709961, alpha: 0.003275512646438994\n",
      "epoch 1954 iteration0, G Loss: 1.1101404428482056, D Loss: 1.0404267311096191, alpha: 0.0032559822105249214\n",
      "epoch 1954 iteration100, G Loss: 1.0568995475769043, D Loss: 1.1492927074432373, alpha: 0.0032559822105249214\n",
      "epoch 1955 iteration0, G Loss: 0.7105540037155151, D Loss: 1.1384767293930054, alpha: 0.00323656784783688\n",
      "epoch 1955 iteration100, G Loss: 1.1135029792785645, D Loss: 1.1478887796401978, alpha: 0.00323656784783688\n",
      "epoch 1956 iteration0, G Loss: 1.0805683135986328, D Loss: 1.2495322227478027, alpha: 0.003217268873025092\n",
      "epoch 1956 iteration100, G Loss: 1.3073700666427612, D Loss: 1.2125838994979858, alpha: 0.003217268873025092\n",
      "epoch 1957 iteration0, G Loss: 1.0736737251281738, D Loss: 1.1469311714172363, alpha: 0.0031980846047329203\n",
      "epoch 1957 iteration100, G Loss: 1.3227814435958862, D Loss: 1.0484434366226196, alpha: 0.0031980846047329203\n",
      "epoch 1958 iteration0, G Loss: 0.830557107925415, D Loss: 1.1389944553375244, alpha: 0.0031790143655742176\n",
      "epoch 1958 iteration100, G Loss: 1.3634999990463257, D Loss: 1.1375231742858887, alpha: 0.0031790143655742176\n",
      "epoch 1959 iteration0, G Loss: 1.0176218748092651, D Loss: 1.1585114002227783, alpha: 0.0031600574821104566\n",
      "epoch 1959 iteration100, G Loss: 1.2744805812835693, D Loss: 1.2263095378875732, alpha: 0.0031600574821104566\n",
      "epoch 1960 iteration0, G Loss: 1.0540964603424072, D Loss: 1.0942492485046387, alpha: 0.003141213284829414\n",
      "epoch 1960 iteration100, G Loss: 1.2386008501052856, D Loss: 1.212161898612976, alpha: 0.003141213284829414\n",
      "epoch 1961 iteration0, G Loss: 0.953030526638031, D Loss: 1.166041374206543, alpha: 0.003122481108121855\n",
      "epoch 1961 iteration100, G Loss: 1.1077361106872559, D Loss: 1.0824370384216309, alpha: 0.003122481108121855\n",
      "epoch 1962 iteration0, G Loss: 0.9681740999221802, D Loss: 1.2929506301879883, alpha: 0.0031038602902599965\n",
      "epoch 1962 iteration100, G Loss: 0.9292471408843994, D Loss: 1.2345244884490967, alpha: 0.0031038602902599965\n",
      "epoch 1963 iteration0, G Loss: 0.9959544539451599, D Loss: 1.1144604682922363, alpha: 0.0030853501733745237\n",
      "epoch 1963 iteration100, G Loss: 1.2186166048049927, D Loss: 1.192293405532837, alpha: 0.0030853501733745237\n",
      "epoch 1964 iteration0, G Loss: 1.0656198263168335, D Loss: 1.1646275520324707, alpha: 0.003066950103434496\n",
      "epoch 1964 iteration100, G Loss: 1.2905659675598145, D Loss: 1.1853489875793457, alpha: 0.003066950103434496\n",
      "epoch 1965 iteration0, G Loss: 0.9211614727973938, D Loss: 1.192681074142456, alpha: 0.00304865943022381\n",
      "epoch 1965 iteration100, G Loss: 1.7456146478652954, D Loss: 1.042823076248169, alpha: 0.00304865943022381\n",
      "epoch 1966 iteration0, G Loss: 0.9024133086204529, D Loss: 1.0994057655334473, alpha: 0.003030477507319884\n",
      "epoch 1966 iteration100, G Loss: 1.0088151693344116, D Loss: 1.1316215991973877, alpha: 0.003030477507319884\n",
      "epoch 1967 iteration0, G Loss: 0.9508296847343445, D Loss: 1.1638938188552856, alpha: 0.003012403692072785\n",
      "epoch 1967 iteration100, G Loss: 1.249931812286377, D Loss: 1.1407350301742554, alpha: 0.003012403692072785\n",
      "epoch 1968 iteration0, G Loss: 0.7824311852455139, D Loss: 1.093355655670166, alpha: 0.002994437345583467\n",
      "epoch 1968 iteration100, G Loss: 1.2521511316299438, D Loss: 1.2607202529907227, alpha: 0.002994437345583467\n",
      "epoch 1969 iteration0, G Loss: 0.6614984273910522, D Loss: 1.3468048572540283, alpha: 0.0029765778326821257\n",
      "epoch 1969 iteration100, G Loss: 1.4160624742507935, D Loss: 1.2113800048828125, alpha: 0.0029765778326821257\n",
      "epoch 1970 iteration0, G Loss: 0.7805593013763428, D Loss: 1.0770314931869507, alpha: 0.0029588245219072107\n",
      "epoch 1970 iteration100, G Loss: 0.8913224339485168, D Loss: 1.1835328340530396, alpha: 0.0029588245219072107\n",
      "epoch 1971 iteration0, G Loss: 0.9182698130607605, D Loss: 1.1408146619796753, alpha: 0.002941176785484223\n",
      "epoch 1971 iteration100, G Loss: 1.362343192100525, D Loss: 1.3076608180999756, alpha: 0.002941176785484223\n",
      "epoch 1972 iteration0, G Loss: 0.8412123322486877, D Loss: 1.1339130401611328, alpha: 0.002923633999304842\n",
      "epoch 1972 iteration100, G Loss: 1.2261403799057007, D Loss: 1.2081886529922485, alpha: 0.002923633999304842\n",
      "epoch 1973 iteration0, G Loss: 0.8387773633003235, D Loss: 1.128751516342163, alpha: 0.0029061955429060538\n",
      "epoch 1973 iteration100, G Loss: 1.2083661556243896, D Loss: 1.1784377098083496, alpha: 0.0029061955429060538\n",
      "epoch 1974 iteration0, G Loss: 0.7553107738494873, D Loss: 1.1815857887268066, alpha: 0.0028888607994494997\n",
      "epoch 1974 iteration100, G Loss: 1.2371258735656738, D Loss: 1.1955355405807495, alpha: 0.0028888607994494997\n",
      "epoch 1975 iteration0, G Loss: 1.0251272916793823, D Loss: 1.2171294689178467, alpha: 0.0028716291557004947\n",
      "epoch 1975 iteration100, G Loss: 0.862983763217926, D Loss: 1.1529090404510498, alpha: 0.0028716291557004947\n",
      "epoch 1976 iteration0, G Loss: 0.8117042779922485, D Loss: 1.0896475315093994, alpha: 0.0028545000020072653\n",
      "epoch 1976 iteration100, G Loss: 1.5684762001037598, D Loss: 1.3053345680236816, alpha: 0.0028545000020072653\n",
      "epoch 1977 iteration0, G Loss: 0.7174071669578552, D Loss: 1.0821744203567505, alpha: 0.002837472732281743\n",
      "epoch 1977 iteration100, G Loss: 1.0271451473236084, D Loss: 1.1119239330291748, alpha: 0.002837472732281743\n",
      "epoch 1978 iteration0, G Loss: 0.7203875184059143, D Loss: 1.198160171508789, alpha: 0.002820546743977803\n",
      "epoch 1978 iteration100, G Loss: 1.2411692142486572, D Loss: 1.3263795375823975, alpha: 0.002820546743977803\n",
      "epoch 1979 iteration0, G Loss: 0.8970214128494263, D Loss: 1.2154059410095215, alpha: 0.0028037214380716158\n",
      "epoch 1979 iteration100, G Loss: 0.8969582319259644, D Loss: 1.1814098358154297, alpha: 0.0028037214380716158\n",
      "epoch 1980 iteration0, G Loss: 0.7685132026672363, D Loss: 1.0782442092895508, alpha: 0.002786996219042215\n",
      "epoch 1980 iteration100, G Loss: 0.9217098355293274, D Loss: 1.2372980117797852, alpha: 0.002786996219042215\n",
      "epoch 1981 iteration0, G Loss: 0.8552476763725281, D Loss: 1.1545886993408203, alpha: 0.002770370494850294\n",
      "epoch 1981 iteration100, G Loss: 1.171722173690796, D Loss: 1.2111178636550903, alpha: 0.002770370494850294\n",
      "epoch 1982 iteration0, G Loss: 0.850799560546875, D Loss: 1.104533314704895, alpha: 0.00275384367691911\n",
      "epoch 1982 iteration100, G Loss: 0.9007298946380615, D Loss: 1.204709529876709, alpha: 0.00275384367691911\n",
      "epoch 1983 iteration0, G Loss: 0.714974045753479, D Loss: 1.1923339366912842, alpha: 0.0027374151801143887\n",
      "epoch 1983 iteration100, G Loss: 1.0804331302642822, D Loss: 1.1341477632522583, alpha: 0.0027374151801143887\n",
      "epoch 1984 iteration0, G Loss: 0.8234281539916992, D Loss: 1.1286512613296509, alpha: 0.0027210844227250064\n",
      "epoch 1984 iteration100, G Loss: 1.1952283382415771, D Loss: 1.1322047710418701, alpha: 0.0027210844227250064\n",
      "epoch 1985 iteration0, G Loss: 0.7761868834495544, D Loss: 1.1508092880249023, alpha: 0.002704850826442895\n",
      "epoch 1985 iteration100, G Loss: 1.4615384340286255, D Loss: 1.252003788948059, alpha: 0.002704850826442895\n",
      "epoch 1986 iteration0, G Loss: 0.9281799793243408, D Loss: 1.1771819591522217, alpha: 0.002688713816344279\n",
      "epoch 1986 iteration100, G Loss: 1.0568946599960327, D Loss: 1.1696830987930298, alpha: 0.002688713816344279\n",
      "epoch 1987 iteration0, G Loss: 1.1875640153884888, D Loss: 1.2048485279083252, alpha: 0.0026726728208695816\n",
      "epoch 1987 iteration100, G Loss: 0.8905137181282043, D Loss: 1.3088154792785645, alpha: 0.0026726728208695816\n",
      "epoch 1988 iteration0, G Loss: 0.6806395053863525, D Loss: 1.1622928380966187, alpha: 0.0026567272718047708\n",
      "epoch 1988 iteration100, G Loss: 0.9743633270263672, D Loss: 1.0412864685058594, alpha: 0.0026567272718047708\n",
      "epoch 1989 iteration0, G Loss: 1.0294359922409058, D Loss: 1.115053415298462, alpha: 0.0026408766042620435\n",
      "epoch 1989 iteration100, G Loss: 1.070549726486206, D Loss: 1.209553837776184, alpha: 0.0026408766042620435\n",
      "epoch 1990 iteration0, G Loss: 0.7910128235816956, D Loss: 1.11921226978302, alpha: 0.002625120256660174\n",
      "epoch 1990 iteration100, G Loss: 1.0130271911621094, D Loss: 1.1575753688812256, alpha: 0.002625120256660174\n",
      "epoch 1991 iteration0, G Loss: 0.8264843821525574, D Loss: 1.2052143812179565, alpha: 0.0026094576707069717\n",
      "epoch 1991 iteration100, G Loss: 0.9893234372138977, D Loss: 1.1841912269592285, alpha: 0.0026094576707069717\n",
      "epoch 1992 iteration0, G Loss: 0.7908418774604797, D Loss: 1.3038076162338257, alpha: 0.002593888291378965\n",
      "epoch 1992 iteration100, G Loss: 1.1812560558319092, D Loss: 1.23923659324646, alpha: 0.002593888291378965\n",
      "epoch 1993 iteration0, G Loss: 0.8955675363540649, D Loss: 1.2283008098602295, alpha: 0.002578411566903749\n",
      "epoch 1993 iteration100, G Loss: 1.1814473867416382, D Loss: 1.1298292875289917, alpha: 0.002578411566903749\n",
      "epoch 1994 iteration0, G Loss: 0.9360008835792542, D Loss: 1.1572242975234985, alpha: 0.0025630269487407764\n",
      "epoch 1994 iteration100, G Loss: 1.2704957723617554, D Loss: 1.167145013809204, alpha: 0.0025630269487407764\n",
      "epoch 1995 iteration0, G Loss: 1.0128306150436401, D Loss: 1.16991126537323, alpha: 0.002547733891562598\n",
      "epoch 1995 iteration100, G Loss: 0.862193763256073, D Loss: 1.2810086011886597, alpha: 0.002547733891562598\n",
      "epoch 1996 iteration0, G Loss: 0.9021514654159546, D Loss: 1.1906859874725342, alpha: 0.0025325318532376517\n",
      "epoch 1996 iteration100, G Loss: 1.1396284103393555, D Loss: 1.1606576442718506, alpha: 0.0025325318532376517\n",
      "epoch 1997 iteration0, G Loss: 0.9106106162071228, D Loss: 1.24055814743042, alpha: 0.002517420294810613\n",
      "epoch 1997 iteration100, G Loss: 1.1061629056930542, D Loss: 1.1810495853424072, alpha: 0.002517420294810613\n",
      "epoch 1998 iteration0, G Loss: 0.7256040573120117, D Loss: 1.1614558696746826, alpha: 0.002502398680485074\n",
      "epoch 1998 iteration100, G Loss: 1.3244796991348267, D Loss: 1.124009370803833, alpha: 0.002502398680485074\n",
      "epoch 1999 iteration0, G Loss: 0.893068253993988, D Loss: 1.1470744609832764, alpha: 0.0024874664776043387\n",
      "epoch 1999 iteration100, G Loss: 1.1834760904312134, D Loss: 1.1807304620742798, alpha: 0.0024874664776043387\n",
      "epoch 2000 iteration0, G Loss: 0.767301082611084, D Loss: 1.0555274486541748, alpha: 0.002472623156634657\n",
      "epoch 2000 iteration100, G Loss: 1.0281152725219727, D Loss: 1.1762125492095947, alpha: 0.002472623156634657\n",
      "Saving content.\n"
     ]
    }
   ],
   "source": [
    "print('starting in debug mode')\n",
    "init_processes(0, 1, train, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a339923d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b3c4e1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### ###  ####    ######  ######  #####    ###### #####      #     #### ### ### #### ### ###  ##### \n",
    " ##  #  ##  ##    ##  ##  ##  ##  ## ##   # ## #  ## ##     ##     ##   ##  #   ##   ##  #  ##  ## \n",
    " ### #  ##  ##    ##  ##  ##  ##  ## ##     ##    ## ##    ###     ##   ### #   ##   ### #  ##     \n",
    " # # #  ##  ##    ##  ##  ##  ##  ####      ##    ####     # ##    ##   # # #   ##   # # #  ## ### \n",
    " # ###  ##  ##    ##  ##  ##  ##  ##        ##    ## #    #####    ##   # ###   ##   # ###  ##  ## \n",
    " #  ##  ##  ##    ##  ##  ##  ##  ##        ##    ## ##   #  ###   ##   #  ##   ##   #  ##  ##  ## \n",
    "###  #   ####    ######  ######  ####      ####  ### ### ### #### #### ###  #  #### ###  #   ####  \n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from datasets_prep.dataset import create_dataset\n",
    "from diffusion import sample_from_model, sample_posterior, \\\n",
    "    q_sample_pairs, get_time_schedule, \\\n",
    "    Posterior_Coefficients, Diffusion_Coefficients\n",
    "#from DWT_IDWT.DWT_IDWT_layer import DWT_2D, IDWT_2D\n",
    "#from pytorch_wavelets import DWTForward, DWTInverse\n",
    "from torch.multiprocessing import Process\n",
    "from utils import init_processes, copy_source, broadcast_params\n",
    "import yaml\n",
    "\n",
    "from ldm.util import instantiate_from_config\n",
    "from omegaconf import OmegaConf\n",
    "import wandb\n",
    "\n",
    "def load_model_from_config(config_path, ckpt):\n",
    "    print(f\"Loading model from {ckpt}\")\n",
    "    config = OmegaConf.load(config_path)\n",
    "    pl_sd = torch.load(ckpt, map_location=\"cpu\")\n",
    "    #global_step = pl_sd[\"global_step\"]\n",
    "    sd = pl_sd[\"state_dict\"]\n",
    "    model = instantiate_from_config(config.model)\n",
    "    m, u = model.load_state_dict(sd, strict=False)\n",
    "    model = model.first_stage_model\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    del m\n",
    "    del u\n",
    "    del pl_sd\n",
    "    return model\n",
    "\n",
    "def grad_penalty_call(args, D_real, x_t):\n",
    "    grad_real = torch.autograd.grad(\n",
    "        outputs=D_real.sum(), inputs=x_t, create_graph=True\n",
    "    )[0]\n",
    "    grad_penalty = (\n",
    "        grad_real.view(grad_real.size(0), -1).norm(2, dim=1) ** 2\n",
    "    ).mean()\n",
    "\n",
    "    grad_penalty = args.r1_gamma / 2 * grad_penalty\n",
    "    grad_penalty.backward()\n",
    "\n",
    "\n",
    "# %%\n",
    "def train(rank, gpu, args):\n",
    "    from EMA import EMA\n",
    "    from score_sde.models.discriminator import Discriminator_large, Discriminator_small\n",
    "    from score_sde.models.ncsnpp_generator_adagn import NCSNpp, WaveletNCSNpp\n",
    "\n",
    "    torch.manual_seed(args.seed + rank)\n",
    "    torch.cuda.manual_seed(args.seed + rank)\n",
    "    torch.cuda.manual_seed_all(args.seed + rank)\n",
    "    device = torch.device('cuda:{}'.format(gpu))\n",
    "\n",
    "    batch_size = args.batch_size\n",
    "\n",
    "    nz = args.nz  # latent dimension\n",
    "\n",
    "    dataset = create_dataset(args)\n",
    "    #train_sampler = torch.utils.data.distributed.DistributedSampler(dataset,\n",
    "    #                                                                num_replicas=args.world_size,\n",
    "    #                                                                rank=rank)\n",
    "    data_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=args.num_workers,\n",
    "                                              pin_memory=True,\n",
    "                                              #sampler=train_sampler,\n",
    "                                              drop_last=True)\n",
    "    args.ori_image_size = args.image_size\n",
    "    args.image_size = args.current_resolution\n",
    "    G_NET_ZOO = {\"normal\": NCSNpp, \"wavelet\": WaveletNCSNpp}\n",
    "    gen_net = G_NET_ZOO[args.net_type]\n",
    "    disc_net = [Discriminator_small, Discriminator_large]\n",
    "    print(\"GEN: {}, DISC: {}\".format(gen_net, disc_net))\n",
    "    netG = gen_net(args).to(device)\n",
    "\n",
    "    if args.dataset in ['cifar10', 'stl10']:\n",
    "        netD = disc_net[0](nc=2 * args.num_channels, ngf=args.ngf,\n",
    "                           t_emb_dim=args.t_emb_dim,\n",
    "                           act=nn.LeakyReLU(0.2), num_layers=args.num_disc_layers).to(device)\n",
    "    else:\n",
    "        netD = disc_net[1](nc=2 * args.num_channels, ngf=args.ngf,\n",
    "                           t_emb_dim=args.t_emb_dim,\n",
    "                           act=nn.LeakyReLU(0.2), num_layers=args.num_disc_layers).to(device)\n",
    "\n",
    "    #broadcast_params(netG.parameters())\n",
    "    #broadcast_params(netD.parameters())\n",
    "\n",
    "    optimizerD = optim.Adam(filter(lambda p: p.requires_grad, netD.parameters(\n",
    "    )), lr=args.lr_d, betas=(args.beta1, args.beta2))\n",
    "    optimizerG = optim.Adam(filter(lambda p: p.requires_grad, netG.parameters(\n",
    "    )), lr=args.lr_g, betas=(args.beta1, args.beta2))\n",
    "\n",
    "    if args.use_ema:\n",
    "        optimizerG = EMA(optimizerG, ema_decay=args.ema_decay)\n",
    "\n",
    "    schedulerG = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizerG, args.num_epoch, eta_min=1e-5)\n",
    "    schedulerD = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizerD, args.num_epoch, eta_min=1e-5)\n",
    "\n",
    "    # ddp\n",
    "    #netG = nn.parallel.DistributedDataParallel(\n",
    "    #    netG, device_ids=[gpu], find_unused_parameters=True)\n",
    "    #netD = nn.parallel.DistributedDataParallel(netD, device_ids=[gpu])\n",
    "\n",
    "    \"\"\"############### DELETE TO AVOID ERROR ###############\"\"\"\n",
    "    # Wavelet Pooling\n",
    "    #if not args.use_pytorch_wavelet:\n",
    "    #    dwt = DWT_2D(\"haar\")\n",
    "    #    iwt = IDWT_2D(\"haar\")\n",
    "    #else:\n",
    "    #    dwt = DWTForward(J=1, mode='zero', wave='haar').cuda()\n",
    "    #    iwt = DWTInverse(mode='zero', wave='haar').cuda()\n",
    "        \n",
    "    \n",
    "    #load encoder and decoder\n",
    "    config_path = args.AutoEncoder_config \n",
    "    ckpt_path = args.AutoEncoder_ckpt \n",
    "    \n",
    "    if args.dataset in ['cifar10', 'stl10'] or True:\n",
    "\n",
    "        with open(config_path, 'r') as file:\n",
    "            config = yaml.safe_load(file)\n",
    "        \n",
    "        AutoEncoder = instantiate_from_config(config['model'])\n",
    "        \n",
    "\n",
    "        checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "        AutoEncoder.load_state_dict(checkpoint['state_dict'])\n",
    "        AutoEncoder.eval()\n",
    "        AutoEncoder.to(device)\n",
    "    \n",
    "    else:\n",
    "        AutoEncoder = load_model_from_config(config_path, ckpt_path)\n",
    "    \"\"\"############### END DELETING ###############\"\"\"\n",
    "    \n",
    "    num_levels = int(np.log2(args.ori_image_size // args.current_resolution))\n",
    "\n",
    "    exp = args.exp\n",
    "    parent_dir = \"./saved_info/{}\".format(args.dataset)\n",
    "\n",
    "    exp_path = os.path.join(parent_dir, exp)\n",
    "    if rank == 0:\n",
    "        if not os.path.exists(exp_path):\n",
    "            os.makedirs(exp_path)\n",
    "            copy_source(__file__, exp_path)\n",
    "            shutil.copytree('score_sde/models',\n",
    "                            os.path.join(exp_path, 'score_sde/models'))\n",
    "\n",
    "    coeff = Diffusion_Coefficients(args, device)\n",
    "    pos_coeff = Posterior_Coefficients(args, device)\n",
    "    T = get_time_schedule(args, device)\n",
    "\n",
    "    if args.resume or os.path.exists(os.path.join(exp_path, 'content.pth')):\n",
    "        checkpoint_file = os.path.join(exp_path, 'content.pth')\n",
    "        checkpoint = torch.load(checkpoint_file, map_location=device)\n",
    "        init_epoch = checkpoint['epoch']\n",
    "        epoch = init_epoch\n",
    "        # load G\n",
    "        netG.load_state_dict(checkpoint['netG_dict'])\n",
    "        #optimizerG.load_state_dict(checkpoint['optimizerG'])\n",
    "        schedulerG.load_state_dict(checkpoint['schedulerG'])\n",
    "        # load D\n",
    "        netD.load_state_dict(checkpoint['netD_dict'])\n",
    "        #optimizerD.load_state_dict(checkpoint['optimizerD'])\n",
    "        schedulerD.load_state_dict(checkpoint['schedulerD'])\n",
    "\n",
    "        global_step = checkpoint['global_step']\n",
    "        print(\"=> loaded checkpoint (epoch {})\"\n",
    "              .format(checkpoint['epoch']))\n",
    "    else:\n",
    "        global_step, epoch, init_epoch = 0, 0, 0\n",
    "\n",
    "    '''Sigmoid learning parameter'''\n",
    "    gamma = 6\n",
    "    beta = np.linspace(-gamma, gamma, args.num_epoch+1)\n",
    "    alpha = 1 - 1 / (1+np.exp(-beta))\n",
    "\n",
    "    for epoch in range(init_epoch, args.num_epoch + 1):\n",
    "        #train_sampler.set_epoch(epoch)\n",
    "\n",
    "        for iteration, (x, y) in enumerate(data_loader):\n",
    "            for p in netD.parameters():\n",
    "                p.requires_grad = True\n",
    "            netD.zero_grad()\n",
    "\n",
    "            for p in netG.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "            # sample from p(x_0)\n",
    "            x0 = x.to(device, non_blocking=True)\n",
    "\n",
    "            \"\"\"################# Change here: Encoder #################\"\"\"\n",
    "            with torch.no_grad():\n",
    "                posterior = AutoEncoder.encode(x0)\n",
    "                real_data = posterior.detach()\n",
    "            #print(\"MIN:{}, MAX:{}\".format(real_data.min(), real_data.max()))\n",
    "            real_data = real_data / args.scale_factor #300.0  # [-1, 1]\n",
    "            \n",
    "            \n",
    "            #assert -1 <= real_data.min() < 0\n",
    "            #assert 0 < real_data.max() <= 1\n",
    "            \"\"\"################# End change: Encoder #################\"\"\"\n",
    "            # sample t\n",
    "            t = torch.randint(0, args.num_timesteps,\n",
    "                              (real_data.size(0),), device=device)\n",
    "\n",
    "            x_t, x_tp1 = q_sample_pairs(coeff, real_data, t)\n",
    "            x_t.requires_grad = True\n",
    "\n",
    "            # train with real\n",
    "            D_real = netD(x_t, t, x_tp1.detach()).view(-1)\n",
    "            errD_real = F.softplus(-D_real).mean()\n",
    "\n",
    "            errD_real.backward(retain_graph=True)\n",
    "\n",
    "            if args.lazy_reg is None:\n",
    "                grad_penalty_call(args, D_real, x_t)\n",
    "            else:\n",
    "                if global_step % args.lazy_reg == 0:\n",
    "                    grad_penalty_call(args, D_real, x_t)\n",
    "\n",
    "            # train with fake\n",
    "            latent_z = torch.randn(batch_size, nz, device=device)\n",
    "            x_0_predict = netG(x_tp1.detach(), t, latent_z)\n",
    "            x_pos_sample = sample_posterior(pos_coeff, x_0_predict, x_tp1, t)\n",
    "\n",
    "            output = netD(x_pos_sample, t, x_tp1.detach()).view(-1)\n",
    "            errD_fake = F.softplus(output).mean()\n",
    "\n",
    "            errD_fake.backward()\n",
    "\n",
    "            errD = errD_real + errD_fake\n",
    "            # Update D\n",
    "            optimizerD.step()\n",
    "\n",
    "            # update G\n",
    "            for p in netD.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "            for p in netG.parameters():\n",
    "                p.requires_grad = True\n",
    "            netG.zero_grad()\n",
    "\n",
    "            t = torch.randint(0, args.num_timesteps,\n",
    "                              (real_data.size(0),), device=device)\n",
    "            x_t, x_tp1 = q_sample_pairs(coeff, real_data, t)\n",
    "\n",
    "            latent_z = torch.randn(batch_size, nz, device=device)\n",
    "            x_0_predict = netG(x_tp1.detach(), t, latent_z)\n",
    "            x_pos_sample = sample_posterior(pos_coeff, x_0_predict, x_tp1, t)\n",
    "\n",
    "            output = netD(x_pos_sample, t, x_tp1.detach()).view(-1)\n",
    "            errG = F.softplus(-output).mean()\n",
    "\n",
    "            # reconstructior loss\n",
    "            if args.sigmoid_learning and args.rec_loss:\n",
    "                ######alpha\n",
    "                rec_loss = F.l1_loss(x_0_predict, real_data)\n",
    "                errG = errG + alpha[epoch]*rec_loss\n",
    "\n",
    "            elif args.rec_loss and not args.sigmoid_learning:\n",
    "                rec_loss = F.l1_loss(x_0_predict, real_data)\n",
    "                errG = errG + rec_loss\n",
    "            \n",
    "\n",
    "            errG.backward()\n",
    "            optimizerG.step()\n",
    "\n",
    "            global_step += 1\n",
    "            if iteration % 100 == 0:\n",
    "                if rank == 0:\n",
    "                    if args.sigmoid_learning:\n",
    "                        print('epoch {} iteration{}, G Loss: {}, D Loss: {}, alpha: {}'.format(\n",
    "                            epoch, iteration, errG.item(), errD.item(), alpha[epoch]))\n",
    "                    elif args.rec_loss:\n",
    "                        print('epoch {} iteration{}, G Loss: {}, D Loss: {}, rec_loss: {}'.format(\n",
    "                            epoch, iteration, errG.item(), errD.item(), rec_loss.item()))\n",
    "                    else:   \n",
    "                        print('epoch {} iteration{}, G Loss: {}, D Loss: {}'.format(\n",
    "                            epoch, iteration, errG.item(), errD.item()))\n",
    "\n",
    "        if not args.no_lr_decay:\n",
    "\n",
    "            schedulerG.step()\n",
    "            schedulerD.step()\n",
    "\n",
    "        if rank == 0:\n",
    "            wandb.log({\"G_loss\": errG.item(), \"D_loss\": errD.item(), \"alpha\": alpha[epoch]})\n",
    "            ########################################\n",
    "            x_t_1 = torch.randn_like(posterior)\n",
    "            fake_sample = sample_from_model(\n",
    "                pos_coeff, netG, args.num_timesteps, x_t_1, T, args)\n",
    "\n",
    "            \"\"\"############## CHANGE HERE: DECODER ##############\"\"\"\n",
    "            fake_sample *= args.scale_factor #300\n",
    "            real_data *= args.scale_factor #300\n",
    "            with torch.no_grad():\n",
    "                fake_sample = AutoEncoder.decode(fake_sample)\n",
    "                real_data = AutoEncoder.decode(real_data)\n",
    "            \n",
    "            fake_sample = (torch.clamp(fake_sample, -1, 1) + 1) / 2  # 0-1\n",
    "            real_data = (torch.clamp(real_data, -1, 1) + 1) / 2  # 0-1 \n",
    "            \n",
    "            \"\"\"############## END HERE: DECODER ##############\"\"\"\n",
    "\n",
    "            torchvision.utils.save_image(fake_sample, os.path.join(\n",
    "                exp_path, 'sample_discrete_epoch_{}.png'.format(epoch)))\n",
    "            torchvision.utils.save_image(\n",
    "                real_data, os.path.join(exp_path, 'real_data.png'))\n",
    "\n",
    "            if args.save_content:\n",
    "                if epoch % args.save_content_every == 0:\n",
    "                    print('Saving content.')\n",
    "                    content = {'epoch': epoch + 1, 'global_step': global_step, 'args': args,\n",
    "                               'netG_dict': netG.state_dict(), 'optimizerG': optimizerG.state_dict(),\n",
    "                               'schedulerG': schedulerG.state_dict(), 'netD_dict': netD.state_dict(),\n",
    "                               'optimizerD': optimizerD.state_dict(), 'schedulerD': schedulerD.state_dict()}\n",
    "                    torch.save(content, os.path.join(exp_path, 'content.pth'))\n",
    "\n",
    "            if epoch % args.save_ckpt_every == 0:\n",
    "                if args.use_ema:\n",
    "                    optimizerG.swap_parameters_with_ema(\n",
    "                        store_params_in_ema=True)\n",
    "\n",
    "                torch.save(netG.state_dict(), os.path.join(\n",
    "                    exp_path, 'netG_{}.pth'.format(epoch)))\n",
    "                if args.use_ema:\n",
    "                    optimizerG.swap_parameters_with_ema(\n",
    "                        store_params_in_ema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250846f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(0, 0, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fbeeb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iddgan",
   "language": "python",
   "name": "iddgan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
