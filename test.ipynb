{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fe2d806-5b57-427b-b5fa-57bf19a5bede",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 [1, 2, 2, 2] [16]\n",
      "GEN: <class 'score_sde.models.ncsnpp_generator_adagn.NCSNpp'>\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Working with z of shape (1, 3, 64, 64) = 12288 dimensions.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "/scratch/users/std/2021/21k0005/improved-ddgan/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/scratch/users/std/2021/21k0005/improved-ddgan/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n",
      "['./wddgan_generated_samples/celeba_256/vq-f4-256/450', 'pytorch_fid/celebahq_stat.npy']\n",
      "/scratch/users/std/2021/21k0005/improved-ddgan/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "/scratch/users/std/2021/21k0005/improved-ddgan/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "100%|█████████████████████████████████████████| 500/500 [00:56<00:00,  8.88it/s]\n",
      "FID = 6.047161905975514\n",
      "dataset: celeba_256, exp: vq-f4-256, epoch: 450, FID: 6.047161905975514\n"
     ]
    }
   ],
   "source": [
    "#@title celeba\n",
    "!python3 test_iddgan_celeba.py --dataset celeba_256 --image_size 256 --exp vq-f4-256 --epoch_id 450 --num_channels 3 \\\n",
    "            --num_channels_dae 128 --nz 100 --z_emb_dim 256  --ch_mult 1 2 2 2  --num_timesteps 2 --num_res_blocks 2 \\\n",
    "\t\t\t--current_resolution 64 --attn_resolutions 16 --n_mlp 4\\\n",
    "\t\t\t--AutoEncoder_config ./autoencoder/config/vq-f4.yaml \\\n",
    "\t\t\t--AutoEncoder_ckpt ./autoencoder/weight/vq-f4.ckpt \\\n",
    "\t\t\t--scale_factor 6.0 \\\n",
    "\t\t\t--batch_size 100 \\\n",
    "\t\t\t--compute_fid --real_img_dir pytorch_fid/celebahq_stat.npy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5b2974-1053-4077-8f56-f706651b3229",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset: celeba_256, exp: vq-f4-256\n",
    "epoch: 450, FID: 6.047161905975514, Inference time(25 batch): 284.59+/-7.73ms, Inference time(1 batch): 38.62+/-9.04ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1075cd01-3c38-4baa-922f-a90e07d71fc5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 [1, 2, 2] [32]\n",
      "GEN: <class 'score_sde.models.ncsnpp_generator_adagn.NCSNpp'>\n",
      "making attention of type 'vanilla' with 256 in_channels\n",
      "making attention of type 'vanilla' with 256 in_channels\n",
      "making attention of type 'vanilla' with 256 in_channels\n",
      "Working with z of shape (1, 4, 16, 16) = 1024 dimensions.\n",
      "making attention of type 'vanilla' with 256 in_channels\n",
      "making attention of type 'vanilla' with 256 in_channels\n",
      "making attention of type 'vanilla' with 256 in_channels\n",
      "making attention of type 'vanilla' with 256 in_channels\n",
      "/scratch/users/std/2021/21k0005/improved-ddgan/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/scratch/users/std/2021/21k0005/improved-ddgan/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "Inference time: 36.84+/-5.13ms\n"
     ]
    }
   ],
   "source": [
    "#@title measure time\n",
    "!python3 test_iddgan.py --dataset cifar10 --exp kl-f2-3 --epoch_id 1000 --num_channels 4 \\\n",
    "--num_channels_dae 128 --num_timesteps 4 --num_res_blocks 2 --nz 50 --z_emb_dim 256 \\\n",
    "--n_mlp 4 --ch_mult 1 2 2 --image_size 32 --current_resolution 16 --attn_resolutions 32 \\\n",
    "--scale_factor 105.0 --AutoEncoder_config autoencoder/config/kl-f2.yaml --AutoEncoder_ckpt autoencoder/weight/kl-f2.ckpt \\\n",
    "--batch_size 1 --measure_time --real_img_dir pytorch_fid/cifar10_train_stat.npy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0f8469-3f85-4c17-8f86-30033b2f805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset: cifar10, exp: kl-f2-4\n",
    "epoch: 1000, FID: 7.7001933186085125\n",
    "epoch: 1100, FID: 8.0272711865656\n",
    "epoch: 1200, FID: 6.965406890685074"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79122c0c-b9f5-40cd-8343-30801977ec3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/scratch/users/std/2021/21k0005/improved-ddgan/test_iddgan.py\", line 12, in <module>\n",
      "    from score_sde.models.ncsnpp_generator_adagn import NCSNpp, WaveletNCSNpp\n",
      "  File \"/scratch/users/std/2021/21k0005/improved-ddgan/score_sde/models/ncsnpp_generator_adagn.py\", line 42, in <module>\n",
      "    from . import dense_layer, layers, layerspp, utils\n",
      "  File \"/scratch/users/std/2021/21k0005/improved-ddgan/score_sde/models/layerspp.py\", line 37, in <module>\n",
      "    from . import dense_layer, layers, up_or_down_sampling\n",
      "  File \"/scratch/users/std/2021/21k0005/improved-ddgan/score_sde/models/up_or_down_sampling.py\", line 15, in <module>\n",
      "    from score_sde.op import upfirdn2d\n",
      "  File \"/scratch/users/std/2021/21k0005/improved-ddgan/score_sde/op/__init__.py\", line 1, in <module>\n",
      "    from .fused_act import FusedLeakyReLU, fused_leaky_relu\n",
      "  File \"/scratch/users/std/2021/21k0005/improved-ddgan/score_sde/op/fused_act.py\", line 19, in <module>\n",
      "    fused = load(\n",
      "  File \"/scratch/users/std/2021/21k0005/improved-ddgan/.venv/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 1306, in load\n",
      "    return _jit_compile(\n",
      "  File \"/scratch/users/std/2021/21k0005/improved-ddgan/.venv/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 1724, in _jit_compile\n",
      "    baton.wait()\n",
      "  File \"/scratch/users/std/2021/21k0005/improved-ddgan/.venv/lib/python3.10/site-packages/torch/utils/file_baton.py\", line 42, in wait\n",
      "    time.sleep(self.wait_seconds)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "#@title cumpute FID\n",
    "!python3 test_iddgan.py --dataset cifar10 --exp kl-f2-4 --epoch_id 1300 --num_channels 4 \\\n",
    "--num_channels_dae 128 --num_timesteps 4 --num_res_blocks 2 --nz 50 --z_emb_dim 256 \\\n",
    "--n_mlp 4 --ch_mult 1 2 2 --image_size 32 --current_resolution 16 --attn_resolutions 32 \\\n",
    "--scale_factor 105.0 --AutoEncoder_config autoencoder/config/kl-f2.yaml --AutoEncoder_ckpt autoencoder/weight/kl-f2.ckpt \\\n",
    "--batch_size 250 --fid_only --real_img_dir pytorch_fid/cifar10_train_stat.npy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ffd6b4-6967-4a32-8d64-de051333183c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title cumpute FID\n",
    "!python3 test_iddgan.py --dataset cifar10 --exp kl-f2-4 --epoch_id 1400 --num_channels 4 \\\n",
    "--num_channels_dae 128 --num_timesteps 4 --num_res_blocks 2 --nz 50 --z_emb_dim 256 \\\n",
    "--n_mlp 4 --ch_mult 1 2 2 --image_size 32 --current_resolution 16 --attn_resolutions 32 \\\n",
    "--scale_factor 105.0 --AutoEncoder_config autoencoder/config/kl-f2.yaml --AutoEncoder_ckpt autoencoder/weight/kl-f2.ckpt \\\n",
    "--batch_size 250 --compute_fid --real_img_dir pytorch_fid/cifar10_train_stat.npy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6043dd5-64e5-4441-bc77-88a3ddc6206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title cumpute FID\n",
    "!python3 test_iddgan.py --dataset cifar10 --exp kl-f2-4 --epoch_id 1500 --num_channels 4 \\\n",
    "--num_channels_dae 128 --num_timesteps 4 --num_res_blocks 2 --nz 50 --z_emb_dim 256 \\\n",
    "--n_mlp 4 --ch_mult 1 2 2 --image_size 32 --current_resolution 16 --attn_resolutions 32 \\\n",
    "--scale_factor 105.0 --AutoEncoder_config autoencoder/config/kl-f2.yaml --AutoEncoder_ckpt autoencoder/weight/kl-f2.ckpt \\\n",
    "--batch_size 250 --compute_fid --real_img_dir pytorch_fid/cifar10_train_stat.npy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612be7c7-9b40-49a0-99c7-eeadd5baf5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title cumpute FID\n",
    "!python3 test_iddgan.py --dataset cifar10 --exp kl-f2-4 --epoch_id 1600 --num_channels 4 \\\n",
    "--num_channels_dae 128 --num_timesteps 4 --num_res_blocks 2 --nz 50 --z_emb_dim 256 \\\n",
    "--n_mlp 4 --ch_mult 1 2 2 --image_size 32 --current_resolution 16 --attn_resolutions 32 \\\n",
    "--scale_factor 105.0 --AutoEncoder_config autoencoder/config/kl-f2.yaml --AutoEncoder_ckpt autoencoder/weight/kl-f2.ckpt \\\n",
    "--batch_size 250 --compute_fid --real_img_dir pytorch_fid/cifar10_train_stat.npy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66891ac-7d68-4717-a144-86e184b7f6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title cumpute FID\n",
    "!python3 test_iddgan.py --dataset cifar10 --exp kl-f2-4 --epoch_id 1700 --num_channels 4 \\\n",
    "--num_channels_dae 128 --num_timesteps 4 --num_res_blocks 2 --nz 50 --z_emb_dim 256 \\\n",
    "--n_mlp 4 --ch_mult 1 2 2 --image_size 32 --current_resolution 16 --attn_resolutions 32 \\\n",
    "--scale_factor 105.0 --AutoEncoder_config autoencoder/config/kl-f2.yaml --AutoEncoder_ckpt autoencoder/weight/kl-f2.ckpt \\\n",
    "--batch_size 250 --compute_fid --real_img_dir pytorch_fid/cifar10_train_stat.npy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34140d5b-3ff4-46aa-aa87-d9f1e189343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title cumpute FID\n",
    "!python3 test_iddgan.py --dataset cifar10 --exp kl-f2-4 --epoch_id 1800 --num_channels 4 \\\n",
    "--num_channels_dae 128 --num_timesteps 4 --num_res_blocks 2 --nz 50 --z_emb_dim 256 \\\n",
    "--n_mlp 4 --ch_mult 1 2 2 --image_size 32 --current_resolution 16 --attn_resolutions 32 \\\n",
    "--scale_factor 105.0 --AutoEncoder_config autoencoder/config/kl-f2.yaml --AutoEncoder_ckpt autoencoder/weight/kl-f2.ckpt \\\n",
    "--batch_size 250 --compute_fid --real_img_dir pytorch_fid/cifar10_train_stat.npy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8278ecab-757b-47ec-9ac2-d3b56b4f4453",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title cumpute FID\n",
    "!python3 test_iddgan.py --dataset cifar10 --exp kl-f2-4 --epoch_id 1900 --num_channels 4 \\\n",
    "--num_channels_dae 128 --num_timesteps 4 --num_res_blocks 2 --nz 50 --z_emb_dim 256 \\\n",
    "--n_mlp 4 --ch_mult 1 2 2 --image_size 32 --current_resolution 16 --attn_resolutions 32 \\\n",
    "--scale_factor 105.0 --AutoEncoder_config autoencoder/config/kl-f2.yaml --AutoEncoder_ckpt autoencoder/weight/kl-f2.ckpt \\\n",
    "--batch_size 250 --compute_fid --real_img_dir pytorch_fid/cifar10_train_stat.npy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817a501b-5734-4db6-9a01-ee3757e30fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title cumpute FID\n",
    "!python3 test_iddgan.py --dataset cifar10 --exp kl-f2-4 --epoch_id 2000 --num_channels 4 \\\n",
    "--num_channels_dae 128 --num_timesteps 4 --num_res_blocks 2 --nz 50 --z_emb_dim 256 \\\n",
    "--n_mlp 4 --ch_mult 1 2 2 --image_size 32 --current_resolution 16 --attn_resolutions 32 \\\n",
    "--scale_factor 105.0 --AutoEncoder_config autoencoder/config/kl-f2.yaml --AutoEncoder_ckpt autoencoder/weight/kl-f2.ckpt \\\n",
    "--batch_size 250 --compute_fid --real_img_dir pytorch_fid/cifar10_train_stat.npy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e5c468-32a2-4ec6-9de7-d334600f5b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3107f1d9-7536-412c-9f22-b3eac70ba73c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dd00f1e-1a6d-46ef-acb4-aefcc9d7f921",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 [1, 2, 2] [32]\n",
      "GEN: <class 'score_sde.models.ncsnpp_generator_adagn.NCSNpp'>\n",
      "making attention of type 'vanilla' with 256 in_channels\n",
      "making attention of type 'vanilla' with 256 in_channels\n",
      "making attention of type 'vanilla' with 256 in_channels\n",
      "Working with z of shape (1, 4, 16, 16) = 1024 dimensions.\n",
      "making attention of type 'vanilla' with 256 in_channels\n",
      "making attention of type 'vanilla' with 256 in_channels\n",
      "making attention of type 'vanilla' with 256 in_channels\n",
      "making attention of type 'vanilla' with 256 in_channels\n",
      "/scratch/users/std/2021/21k0005/improved-ddgan/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/scratch/users/std/2021/21k0005/improved-ddgan/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "['./wddgan_generated_samples/cifar10/kl-f2-3/2000', 'pytorch_fid/cifar10_train_stat.npy']\n",
      "/scratch/users/std/2021/21k0005/improved-ddgan/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "/scratch/users/std/2021/21k0005/improved-ddgan/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "100%|█████████████████████████████████████████| 500/500 [00:20<00:00, 24.44it/s]\n",
      "dataset: cifar10, exp: kl-f2-3, epoch: 2000, FID: 4.146907299500981\n",
      "Results are saved at samples_cifar10.jpg\n"
     ]
    }
   ],
   "source": [
    "#@title FID only\n",
    "!python3 test_iddgan.py --dataset cifar10 --exp kl-f2-3 --epoch_id 2000 --num_channels 4 \\\n",
    "--num_channels_dae 128 --num_timesteps 4 --num_res_blocks 2 --nz 50 --z_emb_dim 256 \\\n",
    "--n_mlp 4 --ch_mult 1 2 2 --image_size 32 --current_resolution 16 --attn_resolutions 32 \\\n",
    "--scale_factor 105.0 --AutoEncoder_config autoencoder/config/kl-f2.yaml --AutoEncoder_ckpt autoencoder/weight/kl-f2.ckpt \\\n",
    "--batch_size 250 --fid_only --real_img_dir pytorch_fid/cifar10_train_stat.npy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22e4365b-b180-43a1-b993-9f5182d4d46f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 [1, 2, 2, 2] [16]\n",
      "GEN: <class 'score_sde.models.ncsnpp_generator_adagn.NCSNpp'>\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Working with z of shape (1, 3, 64, 64) = 12288 dimensions.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "/scratch/users/std/2021/21k0005/improved-ddgan/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/scratch/users/std/2021/21k0005/improved-ddgan/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n",
      "['./wddgan_generated_samples/afhq_cat/vq-f4-256/400', 'data/afhq/train/cat']\n",
      "/scratch/users/std/2021/21k0005/improved-ddgan/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "/scratch/users/std/2021/21k0005/improved-ddgan/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "100%|█████████████████████████████████████████| 500/500 [01:45<00:00,  4.75it/s]\n",
      "100%|███████████████████████████████████████████| 52/52 [00:40<00:00,  1.30it/s]\n",
      "FID = 22.459739544399042\n"
     ]
    }
   ],
   "source": [
    "!python3 test_iddgan_celeba.py --dataset afhq_cat --exp vq-f4-256 --epoch_id 400 --num_channels 3 \\\n",
    "--num_channels_dae 128 --num_timesteps 4 --num_res_blocks 2 --nz 100 --z_emb_dim 256 \\\n",
    "--n_mlp 4 --ch_mult 1 2 2 2 --image_size 256 --current_resolution 64 --attn_resolutions 16 \\\n",
    "--scale_factor 6.0 --AutoEncoder_config autoencoder/config/vq-f4.yaml --AutoEncoder_ckpt autoencoder/weight/vq-f4.ckpt \\\n",
    "--batch_size 50 --measure_time --compute_fid --real_img_dir data/afhq/train/cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ae3603-aac0-4fee-a077-1bf72df80804",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset: CIFAR10, exp: kl-f2, epoch:475, FID: 9.471584868250147"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ee2753-8c6b-4afc-b957-44ddcff0be58",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset: cifar10, exp: kl-f2-2, epoch: 1000, FID: 5.449565416646351\n",
    "dataset: cifar10, exp: kl-f2-2, epoch: 1100, FID: 5.218899761556486\n",
    "dataset: cifar10, exp: kl-f2-2, epoch: 1200, FID: 4.695496785675118\n",
    "dataset: cifar10, exp: kl-f2-2, epoch: 1300, FID: 4.564839950266332\n",
    "dataset: cifar10, exp: kl-f2-2, epoch: 1400, FID: 4.5482688011948085\n",
    "dataset: cifar10, exp: kl-f2-2, epoch: 1500, FID: 4.59995502717527\n",
    "dataset: cifar10, exp: kl-f2-2, epoch: 1600, FID: 4.540297830066777\n",
    "dataset: cifar10, exp: kl-f2-2, epoch: 1650, FID: 4.57000753925297\n",
    "dataset: cifar10, exp: kl-f2-2, epoch: 1675, FID: 4.939058043092189\n",
    "dataset: cifar10, exp: kl-f2-2, epoch: 1700, FID: 4.3555737228003295, Inference time(batch 100): 301.88+/-70.94ms, Inference time(batch 1): 240.47+/-64.81ms, Inference time(batch 1000): 1179.33+/-54.45ms\n",
    "dataset: cifar10, exp: kl-f2-2, epoch: 1725, FID: 4.648243839433746\n",
    "dataset: cifar10, exp: kl-f2-2, epoch: 1750, FID: 5.364749508773798\n",
    "dataset: cifar10, exp: kl-f2-2, epoch: 1800, FID: 6.04712383350892\n",
    "dataset: cifar10, exp: kl-f2-2, epoch: 2000, FID: 8.840900641825328"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6f0ff7-a26b-4a25-96ba-f5c04300aae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset: cifar10, exp: kl-f2-3, \n",
    "epoch: 1000, FID: 5.105137949359914\n",
    "epoch: 1100, FID: 5.0770264059576675\n",
    "epoch: 1200, FID: 4.96211908980996\n",
    "epoch: 1300, FID: 4.437076291003905\n",
    "epoch: 1400, FID: 5.160231192035496\n",
    "epoch: 1500, FID: 4.176725399173108\n",
    "epoch: 1525, FID: 4.17484843314071\n",
    "epoch: 1550, FID: 4.144169482670179\n",
    "epoch: 1575, FID: 4.0306193305124225\n",
    "epoch: 1600, FID: 4.030334598838294\n",
    "epoch: 1625, FID: 4.257021107989885\n",
    "epoch: 1650, FID: 4.2181519657891045\n",
    "epoch: 1700, FID: 4.550198534654214\n",
    "epoch: 1750, FID: 4.325918065430983\n",
    "epoch: 1775, FID: 4.073972311063983\n",
    "epoch: 1800, FID: 4.0148707295130635\n",
    "epoch: 1825, FID: 3.91055155030233 Inference time(100 batch): 59.71+/-6.66ms, Inference time(1 batch): 36.84+/-5.13ms\n",
    "epoch: 1850, FID: 3.9791375357232255\n",
    "epoch: 1900, FID: 4.031493533134892\n",
    "epoch: 2000, FID: 4.146907299500981"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb18af61-33f3-40ec-a8ac-71c9be7b6148",
   "metadata": {},
   "outputs": [],
   "source": [
    "AFHQ-CAT vq-f4-256 epoch:400 FID = 22.459739544399042\n",
    "AFHQ-CAT vq-f4-256 epoch:500 FID = 21.64908864472619"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da23f938-86e0-4931-aace-ffd213e50d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/users/std/2021/21k0005/improved-ddgan\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983453f9-9523-48f6-a866-12516394dcde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
