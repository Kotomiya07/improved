{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3e150ff-a647-4d14-b4d5-ab6d46fe22b4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from get_args import get_args\n",
    "args = [\n",
    "\"--dataset\",\"afhq_cat\",\n",
    "\"--image_size\",\"256\",\n",
    "\"--exp\",\"vq-f8-256\",\n",
    "\"--num_channels\",\"4\",\n",
    "\"--num_channels_dae\",\"128\",\n",
    "\"--num_timesteps\",\"2\",\n",
    "\"--num_res_blocks\",\"2\",\n",
    "\"--batch_size\",\"32\",\n",
    "\"--num_epoch\",\"500\",\n",
    "\"--ngf\",\"64\",\n",
    "\"--nz\",\"100\",\n",
    "\"--z_emb_dim\",\"256\",\n",
    "\"--n_mlp\",\"4\",\n",
    "\"--embedding_type\",\"positional\",\n",
    "\"--use_ema\",\n",
    "\"--ema_decay\",\"0.999\",\n",
    "\"--r1_gamma\",\"0.02\",\n",
    "\"--lr_d\",\"1.0e-4\",\n",
    "\"--lr_g\",\"2.0e-4\",\n",
    "\"--lazy_reg\",\"10\",\n",
    "\"--ch_mult\", \"1\", \"2\", \"2\", \"2\",\n",
    "\"--save_content\",\n",
    "\"--datadir\",\"data/afhq\",\n",
    "\"--master_port\",\"6087\",\n",
    "\"--num_process_per_node\",\"1\",\n",
    "\"--save_content_every\",\"1\",\n",
    "\"--current_resolution\", \"32\",\n",
    "\"--attn_resolutions\", \"16\",\n",
    "\"--num_disc_layers\", \"4\",\n",
    "\"--scale_factor\", \"6.0\",\n",
    "\"--no_lr_decay\", \n",
    "\"--AutoEncoder_config\", \"autoencoder/config/vq-f8.yaml\", \n",
    "\"--AutoEncoder_ckpt\", \"autoencoder/weight/vq-f8.ckpt\", \n",
    "\"--rec_loss\",\n",
    "\"--sigmoid_learning\",\n",
    "]\n",
    "\n",
    "args = get_args(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daf952f1-4fc4-46fb-84e1-6236a8fd564e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_args import get_args\n",
    "args = [\n",
    "\"--dataset\",\"celeba_256\",\n",
    "\"--image_size\",\"256\",\n",
    "\"--exp\",\"vq-f4-256\",\n",
    "\"--num_channels\",\"3\",\n",
    "\"--num_channels_dae\",\"128\",\n",
    "\"--num_timesteps\",\"2\",\n",
    "\"--num_res_blocks\",\"2\",\n",
    "\"--batch_size\",\"32\",\n",
    "\"--num_epoch\",\"500\",\n",
    "\"--ngf\",\"64\",\n",
    "\"--nz\",\"100\",\n",
    "\"--z_emb_dim\",\"256\",\n",
    "\"--n_mlp\",\"4\",\n",
    "\"--embedding_type\",\"positional\",\n",
    "\"--use_ema\",\n",
    "\"--ema_decay\",\"0.999\",\n",
    "\"--r1_gamma\",\"2.\",\n",
    "\"--lr_d\",\"1.0e-4\",\n",
    "\"--lr_g\",\"2.0e-4\",\n",
    "\"--lazy_reg\",\"10\",\n",
    "\"--ch_mult\", \"1\", \"2\", \"2\", \"2\",\n",
    "\"--save_content\",\n",
    "\"--datadir\",\"data/celeba/celeba-lmdb/\",\n",
    "\"--master_port\",\"6087\",\n",
    "\"--num_process_per_node\",\"1\",\n",
    "\"--save_content_every\",\"1\",\n",
    "\"--current_resolution\", \"64\",\n",
    "\"--attn_resolutions\", \"16\",\n",
    "\"--num_disc_layers\", \"4\",\n",
    "\"--scale_factor\", \"6.0\",\n",
    "\"--no_lr_decay\", \n",
    "\"--AutoEncoder_config\", \"autoencoder/config/vq-f4.yaml\", \n",
    "\"--AutoEncoder_ckpt\", \"autoencoder/weight/vq-f4.ckpt\", \n",
    "\"--rec_loss\",\n",
    "\"--sigmoid_learning\",\n",
    "]\n",
    "\n",
    "args = get_args(args) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "414e48d4-68ae-49af-a4ba-86470b9cf192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from datasets_prep.dataset import create_dataset\n",
    "from diffusion import sample_from_model, sample_posterior, \\\n",
    "    q_sample_pairs, get_time_schedule, \\\n",
    "    Posterior_Coefficients, Diffusion_Coefficients\n",
    "#from DWT_IDWT.DWT_IDWT_layer import DWT_2D, IDWT_2D\n",
    "#from pytorch_wavelets import DWTForward, DWTInverse\n",
    "from torch.multiprocessing import Process\n",
    "from utils import init_processes, copy_source, broadcast_params\n",
    "import yaml\n",
    "\n",
    "from ldm.util import instantiate_from_config\n",
    "from omegaconf import OmegaConf\n",
    "import wandb\n",
    "\n",
    "def load_model_from_config(config_path, ckpt):\n",
    "    print(f\"Loading model from {ckpt}\")\n",
    "    config = OmegaConf.load(config_path)\n",
    "    pl_sd = torch.load(ckpt, map_location=\"cpu\")\n",
    "    #global_step = pl_sd[\"global_step\"]\n",
    "    sd = pl_sd[\"state_dict\"]\n",
    "    model = instantiate_from_config(config.model)\n",
    "    m, u = model.load_state_dict(sd, strict=False)\n",
    "    model = model.first_stage_model\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    del m\n",
    "    del u\n",
    "    del pl_sd\n",
    "    return model\n",
    "\n",
    "def grad_penalty_call(args, D_real, x_t):\n",
    "    grad_real = torch.autograd.grad(\n",
    "        outputs=D_real.sum(), inputs=x_t, create_graph=True\n",
    "    )[0]\n",
    "    grad_penalty = (\n",
    "        grad_real.view(grad_real.size(0), -1).norm(2, dim=1) ** 2\n",
    "    ).mean()\n",
    "\n",
    "    grad_penalty = args.r1_gamma / 2 * grad_penalty\n",
    "    grad_penalty.backward()\n",
    "\n",
    "\n",
    "# %%\n",
    "def train(rank, gpu, args):\n",
    "    from EMA import EMA\n",
    "    from score_sde.models.discriminator import Discriminator_large, Discriminator_small\n",
    "    from score_sde.models.ncsnpp_generator_adagn import NCSNpp, WaveletNCSNpp\n",
    "\n",
    "    torch.manual_seed(args.seed + rank)\n",
    "    torch.cuda.manual_seed(args.seed + rank)\n",
    "    torch.cuda.manual_seed_all(args.seed + rank)\n",
    "    device = torch.device('cuda:{}'.format(gpu))\n",
    "\n",
    "    batch_size = args.batch_size\n",
    "\n",
    "    nz = args.nz  # latent dimension\n",
    "\n",
    "    dataset = create_dataset(args)\n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(dataset,\n",
    "                                                                    num_replicas=args.world_size,\n",
    "                                                                    rank=rank)\n",
    "    data_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=False,\n",
    "                                              num_workers=args.num_workers,\n",
    "                                              pin_memory=True,\n",
    "                                              sampler=train_sampler,\n",
    "                                              drop_last=True)\n",
    "    args.ori_image_size = args.image_size\n",
    "    args.image_size = args.current_resolution\n",
    "    G_NET_ZOO = {\"normal\": NCSNpp, \"wavelet\": WaveletNCSNpp}\n",
    "    gen_net = G_NET_ZOO[args.net_type]\n",
    "    disc_net = [Discriminator_small, Discriminator_large]\n",
    "    print(\"GEN: {}, DISC: {}\".format(gen_net, disc_net))\n",
    "    netG = gen_net(args).to(device)\n",
    "\n",
    "    if args.dataset in ['cifar10', 'stl10']:\n",
    "        netD = disc_net[0](nc=2 * args.num_channels, ngf=args.ngf,\n",
    "                           t_emb_dim=args.t_emb_dim,\n",
    "                           act=nn.LeakyReLU(0.2), num_layers=args.num_disc_layers).to(device)\n",
    "    else:\n",
    "        netD = disc_net[1](nc=2 * args.num_channels, ngf=args.ngf,\n",
    "                           t_emb_dim=args.t_emb_dim,\n",
    "                           act=nn.LeakyReLU(0.2), num_layers=args.num_disc_layers).to(device)\n",
    "\n",
    "    broadcast_params(netG.parameters())\n",
    "    broadcast_params(netD.parameters())\n",
    "\n",
    "    optimizerD = optim.Adam(filter(lambda p: p.requires_grad, netD.parameters(\n",
    "    )), lr=args.lr_d, betas=(args.beta1, args.beta2))\n",
    "    optimizerG = optim.Adam(filter(lambda p: p.requires_grad, netG.parameters(\n",
    "    )), lr=args.lr_g, betas=(args.beta1, args.beta2))\n",
    "\n",
    "    if args.use_ema:\n",
    "        optimizerG = EMA(optimizerG, ema_decay=args.ema_decay)\n",
    "\n",
    "    schedulerG = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizerG, args.num_epoch, eta_min=1e-5)\n",
    "    schedulerD = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizerD, args.num_epoch, eta_min=1e-5)\n",
    "\n",
    "    # ddp\n",
    "    netG = nn.parallel.DistributedDataParallel(\n",
    "        netG, device_ids=[gpu], find_unused_parameters=True)\n",
    "    netD = nn.parallel.DistributedDataParallel(netD, device_ids=[gpu])\n",
    "\n",
    "    \"\"\"############### DELETE TO AVOID ERROR ###############\"\"\"\n",
    "    # Wavelet Pooling\n",
    "    #if not args.use_pytorch_wavelet:\n",
    "    #    dwt = DWT_2D(\"haar\")\n",
    "    #    iwt = IDWT_2D(\"haar\")\n",
    "    #else:\n",
    "    #    dwt = DWTForward(J=1, mode='zero', wave='haar').cuda()\n",
    "    #    iwt = DWTInverse(mode='zero', wave='haar').cuda()\n",
    "        \n",
    "    \n",
    "    #load encoder and decoder\n",
    "    config_path = args.AutoEncoder_config \n",
    "    ckpt_path = args.AutoEncoder_ckpt \n",
    "    \n",
    "    if args.dataset in ['cifar10', 'stl10'] or True:\n",
    "\n",
    "        with open(config_path, 'r') as file:\n",
    "            config = yaml.safe_load(file)\n",
    "        \n",
    "        AutoEncoder = instantiate_from_config(config['model'])\n",
    "        \n",
    "\n",
    "        checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "        AutoEncoder.load_state_dict(checkpoint['state_dict'])\n",
    "        AutoEncoder.eval()\n",
    "        AutoEncoder.to(device)\n",
    "    \n",
    "    else:\n",
    "        AutoEncoder = load_model_from_config(config_path, ckpt_path)\n",
    "    \"\"\"############### END DELETING ###############\"\"\"\n",
    "    \n",
    "    num_levels = int(np.log2(args.ori_image_size // args.current_resolution))\n",
    "\n",
    "    exp = args.exp\n",
    "    parent_dir = \"./saved_info/{}\".format(args.dataset)\n",
    "\n",
    "    exp_path = os.path.join(parent_dir, exp)\n",
    "    if rank == 0:\n",
    "        if not os.path.exists(exp_path):\n",
    "            os.makedirs(exp_path)\n",
    "            copy_source(__file__, exp_path)\n",
    "            shutil.copytree('score_sde/models',\n",
    "                            os.path.join(exp_path, 'score_sde/models'))\n",
    "\n",
    "    coeff = Diffusion_Coefficients(args, device)\n",
    "    pos_coeff = Posterior_Coefficients(args, device)\n",
    "    T = get_time_schedule(args, device)\n",
    "\n",
    "    if args.resume or os.path.exists(os.path.join(exp_path, 'content.pth')):\n",
    "        checkpoint_file = os.path.join(exp_path, 'content.pth')\n",
    "        checkpoint = torch.load(checkpoint_file, map_location=device)\n",
    "        init_epoch = checkpoint['epoch']\n",
    "        epoch = init_epoch\n",
    "        # load G\n",
    "        netG.load_state_dict(checkpoint['netG_dict'])\n",
    "        #optimizerG.load_state_dict(checkpoint['optimizerG'])\n",
    "        schedulerG.load_state_dict(checkpoint['schedulerG'])\n",
    "        # load D\n",
    "        netD.load_state_dict(checkpoint['netD_dict'])\n",
    "        #optimizerD.load_state_dict(checkpoint['optimizerD'])\n",
    "        schedulerD.load_state_dict(checkpoint['schedulerD'])\n",
    "\n",
    "        global_step = checkpoint['global_step']\n",
    "        print(\"=> loaded checkpoint (epoch {})\"\n",
    "              .format(checkpoint['epoch']))\n",
    "    else:\n",
    "        global_step, epoch, init_epoch = 0, 0, 0\n",
    "\n",
    "    '''Sigmoid learning parameter'''\n",
    "    gamma = 6\n",
    "    beta = np.linspace(-gamma, gamma, args.num_epoch+1)\n",
    "    alpha = 1 - 1 / (1+np.exp(-beta))\n",
    "\n",
    "    for epoch in range(init_epoch, args.num_epoch + 1):\n",
    "        train_sampler.set_epoch(epoch)\n",
    "\n",
    "        for iteration, (x, y) in enumerate(data_loader):\n",
    "            for p in netD.parameters():\n",
    "                p.requires_grad = True\n",
    "            netD.zero_grad()\n",
    "\n",
    "            for p in netG.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "            # sample from p(x_0)\n",
    "            x0 = x.to(device, non_blocking=True)\n",
    "\n",
    "            \"\"\"################# Change here: Encoder #################\"\"\"\n",
    "            with torch.no_grad():\n",
    "                posterior = AutoEncoder.encode(x0)\n",
    "                real_data = posterior.detach()\n",
    "            #print(\"MIN:{}, MAX:{}\".format(real_data.min(), real_data.max()))\n",
    "            real_data = real_data / args.scale_factor #300.0  # [-1, 1]\n",
    "            \n",
    "            \n",
    "            #assert -1 <= real_data.min() < 0\n",
    "            #assert 0 < real_data.max() <= 1\n",
    "            \"\"\"################# End change: Encoder #################\"\"\"\n",
    "            # sample t\n",
    "            t = torch.randint(0, args.num_timesteps,\n",
    "                              (real_data.size(0),), device=device)\n",
    "\n",
    "            x_t, x_tp1 = q_sample_pairs(coeff, real_data, t)\n",
    "            x_t.requires_grad = True\n",
    "\n",
    "            # train with real\n",
    "            D_real = netD(x_t, t, x_tp1.detach()).view(-1)\n",
    "            errD_real = F.softplus(-D_real).mean()\n",
    "\n",
    "            errD_real.backward(retain_graph=True)\n",
    "\n",
    "            if args.lazy_reg is None:\n",
    "                grad_penalty_call(args, D_real, x_t)\n",
    "            else:\n",
    "                if global_step % args.lazy_reg == 0:\n",
    "                    grad_penalty_call(args, D_real, x_t)\n",
    "\n",
    "            # train with fake\n",
    "            latent_z = torch.randn(batch_size, nz, device=device)\n",
    "            x_0_predict = netG(x_tp1.detach(), t, latent_z)\n",
    "            x_pos_sample = sample_posterior(pos_coeff, x_0_predict, x_tp1, t)\n",
    "\n",
    "            output = netD(x_pos_sample, t, x_tp1.detach()).view(-1)\n",
    "            errD_fake = F.softplus(output).mean()\n",
    "\n",
    "            errD_fake.backward()\n",
    "\n",
    "            errD = errD_real + errD_fake\n",
    "            # Update D\n",
    "            optimizerD.step()\n",
    "\n",
    "            # update G\n",
    "            for p in netD.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "            for p in netG.parameters():\n",
    "                p.requires_grad = True\n",
    "            netG.zero_grad()\n",
    "\n",
    "            t = torch.randint(0, args.num_timesteps,\n",
    "                              (real_data.size(0),), device=device)\n",
    "            x_t, x_tp1 = q_sample_pairs(coeff, real_data, t)\n",
    "\n",
    "            latent_z = torch.randn(batch_size, nz, device=device)\n",
    "            x_0_predict = netG(x_tp1.detach(), t, latent_z)\n",
    "            x_pos_sample = sample_posterior(pos_coeff, x_0_predict, x_tp1, t)\n",
    "\n",
    "            output = netD(x_pos_sample, t, x_tp1.detach()).view(-1)\n",
    "            errG = F.softplus(-output).mean()\n",
    "\n",
    "            # reconstructior loss\n",
    "            if args.sigmoid_learning and args.rec_loss:\n",
    "                ######alpha\n",
    "                rec_loss = F.l1_loss(x_0_predict, real_data)\n",
    "                errG = errG + alpha[epoch]*rec_loss\n",
    "\n",
    "            elif args.rec_loss and not args.sigmoid_learning:\n",
    "                rec_loss = F.l1_loss(x_0_predict, real_data)\n",
    "                errG = errG + rec_loss\n",
    "            \n",
    "\n",
    "            errG.backward()\n",
    "            optimizerG.step()\n",
    "\n",
    "            global_step += 1\n",
    "            if iteration % 100 == 0:\n",
    "                if rank == 0:\n",
    "                    if args.sigmoid_learning:\n",
    "                        print('epoch {} iteration{}, G Loss: {}, D Loss: {}, alpha: {}'.format(\n",
    "                            epoch, iteration, errG.item(), errD.item(), alpha[epoch]))\n",
    "                    elif args.rec_loss:\n",
    "                        print('epoch {} iteration{}, G Loss: {}, D Loss: {}, rec_loss: {}'.format(\n",
    "                            epoch, iteration, errG.item(), errD.item(), rec_loss.item()))\n",
    "                    else:   \n",
    "                        print('epoch {} iteration{}, G Loss: {}, D Loss: {}'.format(\n",
    "                            epoch, iteration, errG.item(), errD.item()))\n",
    "\n",
    "        if not args.no_lr_decay:\n",
    "\n",
    "            schedulerG.step()\n",
    "            schedulerD.step()\n",
    "\n",
    "        if rank == 0:\n",
    "            wandb.log({\"G_loss\": errG.item(), \"D_loss\": errD.item(), \"alpha\": alpha[epoch]})\n",
    "            ########################################\n",
    "            x_t_1 = torch.randn_like(posterior)\n",
    "            fake_sample = sample_from_model(\n",
    "                pos_coeff, netG, args.num_timesteps, x_t_1, T, args)\n",
    "\n",
    "            \"\"\"############## CHANGE HERE: DECODER ##############\"\"\"\n",
    "            fake_sample *= args.scale_factor #300\n",
    "            real_data *= args.scale_factor #300\n",
    "            with torch.no_grad():\n",
    "                fake_sample = AutoEncoder.decode(fake_sample)\n",
    "                real_data = AutoEncoder.decode(real_data)\n",
    "            \n",
    "            fake_sample = (torch.clamp(fake_sample, -1, 1) + 1) / 2  # 0-1\n",
    "            real_data = (torch.clamp(real_data, -1, 1) + 1) / 2  # 0-1 \n",
    "            \n",
    "            \"\"\"############## END HERE: DECODER ##############\"\"\"\n",
    "\n",
    "            torchvision.utils.save_image(fake_sample, os.path.join(\n",
    "                exp_path, 'sample_discrete_epoch_{}.png'.format(epoch)))\n",
    "            torchvision.utils.save_image(\n",
    "                real_data, os.path.join(exp_path, 'real_data.png'))\n",
    "\n",
    "            if args.save_content:\n",
    "                if epoch % args.save_content_every == 0:\n",
    "                    print('Saving content.')\n",
    "                    content = {'epoch': epoch + 1, 'global_step': global_step, 'args': args,\n",
    "                               'netG_dict': netG.state_dict(), 'optimizerG': optimizerG.state_dict(),\n",
    "                               'schedulerG': schedulerG.state_dict(), 'netD_dict': netD.state_dict(),\n",
    "                               'optimizerD': optimizerD.state_dict(), 'schedulerD': schedulerD.state_dict()}\n",
    "                    torch.save(content, os.path.join(exp_path, 'content.pth'))\n",
    "\n",
    "            if epoch % args.save_ckpt_every == 0:\n",
    "                if args.use_ema:\n",
    "                    optimizerG.swap_parameters_with_ema(\n",
    "                        store_params_in_ema=True)\n",
    "\n",
    "                torch.save(netG.state_dict(), os.path.join(\n",
    "                    exp_path, 'netG_{}.pth'.format(epoch)))\n",
    "                if args.use_ema:\n",
    "                    optimizerG.swap_parameters_with_ema(\n",
    "                        store_params_in_ema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "103c482e-774c-4f91-a209-aa2e8e6bf643",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkotomiya07\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/users/std/2021/21k0005/improved-ddgan/wandb/run-20240917_230640-2s9qmnyn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kotomiya07/TEST/runs/2s9qmnyn' target=\"_blank\">vq-f4-256</a></strong> to <a href='https://wandb.ai/kotomiya07/TEST' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kotomiya07/TEST' target=\"_blank\">https://wandb.ai/kotomiya07/TEST</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kotomiya07/TEST/runs/2s9qmnyn' target=\"_blank\">https://wandb.ai/kotomiya07/TEST/runs/2s9qmnyn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/kotomiya07/TEST/runs/2s9qmnyn?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fccd98b35b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "            project=\"TEST\",\n",
    "            name=args.exp,\n",
    "            config={\n",
    "                \"dataset\": args.dataset,\n",
    "                \"image_size\": args.image_size,\n",
    "                \"channels\": args.num_channels,\n",
    "                \"channels_dae\": args.num_channels_dae,\n",
    "                \"ch_nult\": args.ch_mult,\n",
    "                \"timesteps\": args.num_timesteps,\n",
    "                \"res_blocks\": args.num_res_blocks,\n",
    "                \"nz\": args.nz,\n",
    "                \"epochs\": args.num_epoch,\n",
    "                \"ngf\": args.ngf,\n",
    "                \"lr_g\": args.lr_g,\n",
    "                \"lr_d\": args.lr_d,\n",
    "                \"batch_size\": args.batch_size,\n",
    "                \"r1_gamma\": args.r1_gamma,\n",
    "                \"lazy_reg\": args.lazy_reg,\n",
    "                \"embedding_type\": args.embedding_type,\n",
    "                \"use_ema\": args.use_ema,\n",
    "                \"ema_decay\": args.ema_decay,\n",
    "                \"no_lr_decay\": args.no_lr_decay,\n",
    "                \"z_emb_dim\": args.z_emb_dim,\n",
    "                \"attn_resolutions\": args.attn_resolutions,\n",
    "                \"use_pytorch_wavelet\": args.use_pytorch_wavelet,\n",
    "                \"rec_loss\": args.rec_loss,\n",
    "                \"net_type\": args.net_type,\n",
    "                \"num_disc_layers\": args.num_disc_layers,\n",
    "                \"no_use_fbn\": args.no_use_fbn,\n",
    "                \"no_use_freq\": args.no_use_freq,\n",
    "                \"no_use_residual\": args.no_use_residual,\n",
    "                \"scale_factor\": args.scale_factor,\n",
    "                \"AutoEncoder_config\": args.AutoEncoder_config,\n",
    "                \"AutoEncoder_ckpt\": args.AutoEncoder_ckpt,\n",
    "                \"sigmoid_learning\": args.sigmoid_learning,\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17debf4-678d-48e4-94c3-015065223e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting in debug mode\n",
      "GEN: <class 'score_sde.models.ncsnpp_generator_adagn.NCSNpp'>, DISC: [<class 'score_sde.models.discriminator.Discriminator_small'>, <class 'score_sde.models.discriminator.Discriminator_large'>]\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Working with z of shape (1, 3, 64, 64) = 12288 dimensions.\n",
      "making attention of type 'vanilla' with 512 in_channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/users/std/2021/21k0005/improved-ddgan/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/scratch/users/std/2021/21k0005/improved-ddgan/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n",
      "=> loaded checkpoint (epoch 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank0]:[W reducer.cpp:1360] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 iteration0, G Loss: 0.3554559648036957, D Loss: 1.2480608224868774, alpha: 0.9971454999979927\n",
      "epoch 6 iteration100, G Loss: 0.9318748116493225, D Loss: 1.3364592790603638, alpha: 0.9971454999979927\n",
      "epoch 6 iteration200, G Loss: 0.8323537111282349, D Loss: 1.7107274532318115, alpha: 0.9971454999979927\n",
      "epoch 6 iteration300, G Loss: 0.9617724418640137, D Loss: 1.3582987785339355, alpha: 0.9971454999979927\n",
      "epoch 6 iteration400, G Loss: 1.2378530502319336, D Loss: 1.3253788948059082, alpha: 0.9971454999979927\n",
      "epoch 6 iteration500, G Loss: 0.6397876739501953, D Loss: 1.378718376159668, alpha: 0.9971454999979927\n",
      "epoch 6 iteration600, G Loss: 0.8313594460487366, D Loss: 1.2738375663757324, alpha: 0.9971454999979927\n",
      "epoch 6 iteration700, G Loss: 1.2065318822860718, D Loss: 1.323931336402893, alpha: 0.9971454999979927\n",
      "epoch 6 iteration800, G Loss: 0.8264327049255371, D Loss: 1.3116447925567627, alpha: 0.9971454999979927\n",
      "Saving content.\n",
      "epoch 7 iteration0, G Loss: 0.9378058314323425, D Loss: 1.2900117635726929, alpha: 0.9970763660006952\n",
      "epoch 7 iteration100, G Loss: 1.075791358947754, D Loss: 1.2596495151519775, alpha: 0.9970763660006952\n",
      "epoch 7 iteration200, G Loss: 1.3336989879608154, D Loss: 1.4424604177474976, alpha: 0.9970763660006952\n",
      "epoch 7 iteration300, G Loss: 0.9943295121192932, D Loss: 1.4534400701522827, alpha: 0.9970763660006952\n",
      "epoch 7 iteration400, G Loss: 0.9938949346542358, D Loss: 1.3428680896759033, alpha: 0.9970763660006952\n",
      "epoch 7 iteration500, G Loss: 1.0948925018310547, D Loss: 1.199700951576233, alpha: 0.9970763660006952\n",
      "epoch 7 iteration600, G Loss: 1.0901000499725342, D Loss: 1.2994029521942139, alpha: 0.9970763660006952\n",
      "epoch 7 iteration700, G Loss: 0.8992996215820312, D Loss: 1.2919538021087646, alpha: 0.9970763660006952\n",
      "epoch 7 iteration800, G Loss: 0.7173446416854858, D Loss: 1.2811193466186523, alpha: 0.9970763660006952\n",
      "Saving content.\n",
      "epoch 8 iteration0, G Loss: 1.5098419189453125, D Loss: 1.3424118757247925, alpha: 0.9970055626544164\n",
      "epoch 8 iteration100, G Loss: 0.9261100888252258, D Loss: 1.3073780536651611, alpha: 0.9970055626544164\n",
      "epoch 8 iteration200, G Loss: 1.190016508102417, D Loss: 1.3181394338607788, alpha: 0.9970055626544164\n",
      "epoch 8 iteration300, G Loss: 1.2022055387496948, D Loss: 1.495734453201294, alpha: 0.9970055626544164\n",
      "epoch 8 iteration400, G Loss: 0.8894602656364441, D Loss: 1.438887357711792, alpha: 0.9970055626544164\n",
      "epoch 8 iteration500, G Loss: 1.0661468505859375, D Loss: 1.3069055080413818, alpha: 0.9970055626544164\n",
      "epoch 8 iteration600, G Loss: 0.9440438747406006, D Loss: 1.3995482921600342, alpha: 0.9970055626544164\n",
      "epoch 8 iteration700, G Loss: 1.2533413171768188, D Loss: 1.3119494915008545, alpha: 0.9970055626544164\n",
      "epoch 8 iteration800, G Loss: 1.0319998264312744, D Loss: 1.2334892749786377, alpha: 0.9970055626544164\n",
      "Saving content.\n",
      "epoch 9 iteration0, G Loss: 1.2220017910003662, D Loss: 1.3028020858764648, alpha: 0.9969330498965654\n",
      "epoch 9 iteration100, G Loss: 0.9622882008552551, D Loss: 1.335893154144287, alpha: 0.9969330498965654\n",
      "epoch 9 iteration200, G Loss: 1.1120434999465942, D Loss: 1.414320945739746, alpha: 0.9969330498965654\n",
      "epoch 9 iteration300, G Loss: 0.9514904618263245, D Loss: 1.230311393737793, alpha: 0.9969330498965654\n",
      "epoch 9 iteration400, G Loss: 1.4078750610351562, D Loss: 1.3194093704223633, alpha: 0.9969330498965654\n",
      "epoch 9 iteration500, G Loss: 1.0338459014892578, D Loss: 1.311525821685791, alpha: 0.9969330498965654\n",
      "epoch 9 iteration600, G Loss: 1.147463321685791, D Loss: 1.2246296405792236, alpha: 0.9969330498965654\n",
      "epoch 9 iteration700, G Loss: 1.1873124837875366, D Loss: 1.3864071369171143, alpha: 0.9969330498965654\n",
      "epoch 9 iteration800, G Loss: 1.6327321529388428, D Loss: 1.536616563796997, alpha: 0.9969330498965654\n",
      "Saving content.\n",
      "epoch 10 iteration0, G Loss: 1.2168309688568115, D Loss: 1.3692810535430908, alpha: 0.9968587867151706\n",
      "epoch 10 iteration100, G Loss: 1.3176660537719727, D Loss: 1.400043249130249, alpha: 0.9968587867151706\n",
      "epoch 10 iteration200, G Loss: 1.3458092212677002, D Loss: 1.4064843654632568, alpha: 0.9968587867151706\n",
      "epoch 10 iteration300, G Loss: 0.9752777218818665, D Loss: 1.3070859909057617, alpha: 0.9968587867151706\n",
      "epoch 10 iteration400, G Loss: 1.3458948135375977, D Loss: 1.3077433109283447, alpha: 0.9968587867151706\n",
      "epoch 10 iteration500, G Loss: 1.2085593938827515, D Loss: 1.282177448272705, alpha: 0.9968587867151706\n",
      "epoch 10 iteration600, G Loss: 1.156865119934082, D Loss: 1.348490595817566, alpha: 0.9968587867151706\n",
      "epoch 10 iteration700, G Loss: 1.1960011720657349, D Loss: 1.2918412685394287, alpha: 0.9968587867151706\n",
      "epoch 10 iteration800, G Loss: 1.4169732332229614, D Loss: 1.1971688270568848, alpha: 0.9968587867151706\n",
      "Saving content.\n",
      "epoch 11 iteration0, G Loss: 0.5250426530838013, D Loss: 1.315666675567627, alpha: 0.9967827311269749\n",
      "epoch 11 iteration100, G Loss: 1.393357515335083, D Loss: 1.3737423419952393, alpha: 0.9967827311269749\n",
      "epoch 11 iteration200, G Loss: 0.9194197654724121, D Loss: 1.243760108947754, alpha: 0.9967827311269749\n",
      "epoch 11 iteration300, G Loss: 1.1021500825881958, D Loss: 1.3121188879013062, alpha: 0.9967827311269749\n",
      "epoch 11 iteration400, G Loss: 0.8900134563446045, D Loss: 1.3693299293518066, alpha: 0.9967827311269749\n",
      "epoch 11 iteration500, G Loss: 0.8495917916297913, D Loss: 1.3444793224334717, alpha: 0.9967827311269749\n",
      "epoch 11 iteration600, G Loss: 1.3660651445388794, D Loss: 1.21157705783844, alpha: 0.9967827311269749\n",
      "epoch 11 iteration700, G Loss: 1.046658992767334, D Loss: 1.2994704246520996, alpha: 0.9967827311269749\n",
      "epoch 11 iteration800, G Loss: 1.1679561138153076, D Loss: 1.361345887184143, alpha: 0.9967827311269749\n",
      "Saving content.\n",
      "epoch 12 iteration0, G Loss: 0.3273698091506958, D Loss: 1.3902935981750488, alpha: 0.9967048401550548\n",
      "epoch 12 iteration100, G Loss: 1.1198409795761108, D Loss: 1.319939136505127, alpha: 0.9967048401550548\n",
      "epoch 12 iteration200, G Loss: 1.320624828338623, D Loss: 1.2314527034759521, alpha: 0.9967048401550548\n",
      "epoch 12 iteration300, G Loss: 0.8679282665252686, D Loss: 1.3723809719085693, alpha: 0.9967048401550548\n",
      "epoch 12 iteration400, G Loss: 1.32161283493042, D Loss: 1.5981289148330688, alpha: 0.9967048401550548\n",
      "epoch 12 iteration500, G Loss: 1.2512487173080444, D Loss: 1.3142216205596924, alpha: 0.9967048401550548\n",
      "epoch 12 iteration600, G Loss: 1.8830616474151611, D Loss: 1.3692896366119385, alpha: 0.9967048401550548\n",
      "epoch 12 iteration700, G Loss: 1.054582118988037, D Loss: 1.2415294647216797, alpha: 0.9967048401550548\n",
      "epoch 12 iteration800, G Loss: 1.5398993492126465, D Loss: 1.1194097995758057, alpha: 0.9967048401550548\n",
      "Saving content.\n",
      "epoch 13 iteration0, G Loss: 1.0726776123046875, D Loss: 1.3011850118637085, alpha: 0.9966250698059539\n",
      "epoch 13 iteration100, G Loss: 0.9540203809738159, D Loss: 1.3324147462844849, alpha: 0.9966250698059539\n",
      "epoch 13 iteration200, G Loss: 1.18186616897583, D Loss: 1.2813383340835571, alpha: 0.9966250698059539\n",
      "epoch 13 iteration300, G Loss: 1.2019766569137573, D Loss: 1.5261073112487793, alpha: 0.9966250698059539\n",
      "epoch 13 iteration400, G Loss: 0.9166587591171265, D Loss: 1.5266666412353516, alpha: 0.9966250698059539\n",
      "epoch 13 iteration500, G Loss: 1.3161965608596802, D Loss: 1.129123568534851, alpha: 0.9966250698059539\n",
      "epoch 13 iteration600, G Loss: 0.8044578433036804, D Loss: 1.3408663272857666, alpha: 0.9966250698059539\n",
      "epoch 13 iteration700, G Loss: 1.1832795143127441, D Loss: 1.1271662712097168, alpha: 0.9966250698059539\n",
      "epoch 13 iteration800, G Loss: 1.2337815761566162, D Loss: 1.2677254676818848, alpha: 0.9966250698059539\n",
      "Saving content.\n",
      "epoch 14 iteration0, G Loss: 1.083375334739685, D Loss: 1.3577373027801514, alpha: 0.9965433750463222\n",
      "epoch 14 iteration100, G Loss: 0.8750090599060059, D Loss: 1.2994170188903809, alpha: 0.9965433750463222\n",
      "epoch 14 iteration200, G Loss: 1.106483817100525, D Loss: 1.2757153511047363, alpha: 0.9965433750463222\n",
      "epoch 14 iteration300, G Loss: 1.3397818803787231, D Loss: 1.2945225238800049, alpha: 0.9965433750463222\n",
      "epoch 14 iteration400, G Loss: 1.2813061475753784, D Loss: 1.488306999206543, alpha: 0.9965433750463222\n",
      "epoch 14 iteration500, G Loss: 0.9860349297523499, D Loss: 1.1568231582641602, alpha: 0.9965433750463222\n",
      "epoch 14 iteration600, G Loss: 0.8740973472595215, D Loss: 1.2793339490890503, alpha: 0.9965433750463222\n",
      "epoch 14 iteration700, G Loss: 1.0951529741287231, D Loss: 1.4123485088348389, alpha: 0.9965433750463222\n",
      "epoch 14 iteration800, G Loss: 1.17925226688385, D Loss: 1.2175651788711548, alpha: 0.9965433750463222\n",
      "Saving content.\n",
      "epoch 15 iteration0, G Loss: 1.311449408531189, D Loss: 1.2472305297851562, alpha: 0.9964597097790535\n",
      "epoch 15 iteration100, G Loss: 1.643255352973938, D Loss: 1.2436379194259644, alpha: 0.9964597097790535\n",
      "epoch 15 iteration200, G Loss: 1.07674241065979, D Loss: 1.167392611503601, alpha: 0.9964597097790535\n",
      "epoch 15 iteration300, G Loss: 1.1411327123641968, D Loss: 1.3264596462249756, alpha: 0.9964597097790535\n",
      "epoch 15 iteration400, G Loss: 0.9731426239013672, D Loss: 1.355236291885376, alpha: 0.9964597097790535\n",
      "epoch 15 iteration500, G Loss: 1.3569079637527466, D Loss: 1.6140869855880737, alpha: 0.9964597097790535\n",
      "epoch 15 iteration600, G Loss: 0.8039194941520691, D Loss: 1.589830994606018, alpha: 0.9964597097790535\n",
      "epoch 15 iteration700, G Loss: 2.0738048553466797, D Loss: 1.2817120552062988, alpha: 0.9964597097790535\n",
      "epoch 15 iteration800, G Loss: 0.7632731795310974, D Loss: 1.4004793167114258, alpha: 0.9964597097790535\n",
      "Saving content.\n",
      "epoch 16 iteration0, G Loss: 1.0334111452102661, D Loss: 1.3170511722564697, alpha: 0.9963740268189091\n",
      "epoch 16 iteration100, G Loss: 0.5894307494163513, D Loss: 1.7326830625534058, alpha: 0.9963740268189091\n"
     ]
    }
   ],
   "source": [
    "print('starting in debug mode')\n",
    "init_processes(0, 1, train, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769e13c6-9f5d-4b5d-8d40-fe862e1f0919",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
